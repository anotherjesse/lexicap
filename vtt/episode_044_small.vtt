WEBVTT

00:00.000 --> 00:03.040
 The following is a conversation with David Ferrochi.

00:03.040 --> 00:05.200
 He led the team that built Watson,

00:05.200 --> 00:07.040
 the IBM question answering system

00:07.040 --> 00:09.080
 that beat the top humans in the world

00:09.080 --> 00:11.160
 at the game of jeopardy.

00:11.160 --> 00:12.920
 For spending a couple hours with David,

00:12.920 --> 00:14.960
 I saw a genuine passion,

00:14.960 --> 00:17.720
 not only for abstract understanding of intelligence,

00:17.720 --> 00:21.240
 but for engineering it to solve real world problems

00:21.240 --> 00:24.800
 under real world deadlines and resource constraints.

00:24.800 --> 00:26.540
 Where science meets engineering

00:26.540 --> 00:29.960
 is where brilliant simple ingenuity emerges.

00:29.960 --> 00:33.160
 People who work and joining it to have a lot of wisdom

00:33.160 --> 00:36.960
 earned through failures and eventual success.

00:36.960 --> 00:39.080
 David is also the founder, CEO

00:39.080 --> 00:41.680
 and chief scientist of Elemental Cognition,

00:41.680 --> 00:44.480
 a company working to engineer AI systems

00:44.480 --> 00:47.440
 that understand the world the way people do.

00:47.440 --> 00:50.280
 This is the Artificial Intelligence podcast.

00:50.280 --> 00:52.720
 If you enjoy it, subscribe on YouTube,

00:52.720 --> 00:54.440
 give it five stars on iTunes,

00:54.440 --> 00:57.920
 support it on Patreon or simply connect with me on Twitter.

00:57.920 --> 01:01.360
 Alex Friedman spelled F R I D M A N.

01:01.360 --> 01:05.160
 And now here's my conversation with David Ferrochi.

01:06.120 --> 01:08.000
 Your undergrad was in biology

01:08.000 --> 01:11.280
 with an eye toward medical school

01:11.280 --> 01:14.320
 before you went on for the PhD in computer science.

01:14.320 --> 01:16.800
 So let me ask you an easy question.

01:16.800 --> 01:20.520
 What is the difference between biological systems

01:20.520 --> 01:22.440
 and computer systems?

01:22.440 --> 01:25.240
 In your, when you sit back,

01:25.240 --> 01:28.800
 look at the stars and think philosophically.

01:28.800 --> 01:29.640
 I often wonder,

01:29.640 --> 01:32.880
 I often wonder whether or not there is a substantive difference.

01:32.880 --> 01:35.960
 And I think the thing that got me into computer science

01:35.960 --> 01:37.200
 and into artificial intelligence

01:37.200 --> 01:39.800
 was exactly this presupposition

01:39.800 --> 01:44.360
 that if we can get machines to think

01:44.360 --> 01:47.440
 or I should say this question, this philosophical question,

01:47.440 --> 01:50.560
 if we can get machines to think,

01:50.560 --> 01:54.800
 to understand, to process information the way we do,

01:54.800 --> 01:57.960
 so if we can describe a procedure, describe a process,

01:57.960 --> 01:59.800
 even if that process,

01:59.800 --> 02:02.480
 where the intelligence process itself,

02:02.480 --> 02:05.280
 then what would be the difference?

02:05.280 --> 02:07.680
 So from a philosophical standpoint,

02:07.680 --> 02:11.640
 I'm not trying to convince that there is.

02:11.640 --> 02:14.960
 I mean, you can go in the direction of spirituality,

02:14.960 --> 02:16.680
 you can go in the direction of the soul,

02:16.680 --> 02:21.200
 but in terms of what we can experience

02:21.200 --> 02:26.000
 from an intellectual and physical perspective,

02:26.000 --> 02:27.480
 I'm not sure there is.

02:27.480 --> 02:31.120
 Clearly there are different implementations,

02:31.120 --> 02:33.240
 but if you were to say,

02:33.240 --> 02:36.200
 is a biological information processing system

02:36.200 --> 02:38.440
 fundamentally more capable

02:38.440 --> 02:41.040
 than one we might be able to build out of silicon

02:41.040 --> 02:43.920
 or some other substrate,

02:44.920 --> 02:46.560
 I don't know that there is.

02:46.560 --> 02:50.600
 How distant do you think is the biological implementation?

02:50.600 --> 02:53.840
 So fundamentally, they may have the same capabilities,

02:53.840 --> 02:58.320
 but is it really a far mystery

02:58.320 --> 03:00.720
 where a huge number of breakthroughs are needed

03:00.720 --> 03:02.720
 to be able to understand it,

03:02.720 --> 03:06.320
 or is it something that for the most part

03:06.320 --> 03:08.640
 in the important aspects,

03:08.640 --> 03:11.160
 echoes of the same kind of characteristics?

03:11.160 --> 03:12.120
 Yeah, that's interesting.

03:12.120 --> 03:15.600
 I mean, so your question presupposes

03:15.600 --> 03:17.560
 that there's this goal to recreate

03:17.560 --> 03:20.880
 what we perceive as biological intelligence.

03:20.880 --> 03:24.360
 I'm not sure that's the,

03:24.360 --> 03:26.560
 I'm not sure that's how I would state the goal.

03:26.560 --> 03:27.680
 I mean, I think that's studying.

03:27.680 --> 03:29.200
 What is the goal?

03:29.200 --> 03:32.160
 Good, so I think there are a few goals.

03:32.160 --> 03:35.720
 I think that understanding the human brain

03:35.720 --> 03:40.440
 and how it works is important for us

03:40.440 --> 03:44.720
 to be able to diagnose and treat issues

03:44.720 --> 03:48.200
 for us to understand our own strengths and weaknesses,

03:49.960 --> 03:52.400
 both intellectual, psychological, and physical.

03:52.400 --> 03:54.960
 So neuroscience and understanding the brain

03:54.960 --> 03:59.520
 from that perspective, there's a clear, clear goal there.

03:59.520 --> 04:00.880
 From the perspective of saying,

04:00.880 --> 04:04.800
 I want to mimic human intelligence.

04:04.800 --> 04:06.400
 That one's a little bit more interesting.

04:06.400 --> 04:10.440
 Human intelligence certainly has a lot of things we envy.

04:10.440 --> 04:12.840
 It's also got a lot of problems too.

04:12.840 --> 04:16.640
 So I think we're capable of sort of stepping back

04:16.640 --> 04:21.240
 and saying, what do we want out of an intelligence?

04:22.240 --> 04:24.360
 How do we want to communicate with that intelligence?

04:24.360 --> 04:25.520
 How do we want it to behave?

04:25.520 --> 04:27.400
 How do we want it to perform?

04:27.400 --> 04:30.320
 Now, of course, it's somewhat of an interesting argument

04:30.320 --> 04:33.880
 because I'm sitting here as a human with a biological brain

04:33.880 --> 04:36.400
 and I'm critiquing the strengths and weaknesses

04:36.400 --> 04:38.600
 of human intelligence and saying

04:38.600 --> 04:42.160
 that we have the capacity to step back

04:42.160 --> 04:44.120
 and say, gee, what is intelligence

04:44.120 --> 04:46.000
 and what do we really want out of it?

04:46.000 --> 04:48.080
 And that even in and of itself suggests

04:48.080 --> 04:52.080
 that human intelligence is something quite enviable,

04:52.080 --> 04:57.080
 that it can introspect that way.

04:58.360 --> 05:00.240
 And the flaws, you mentioned the flaws,

05:00.240 --> 05:01.080
 the humans have flaws.

05:01.080 --> 05:04.720
 Yeah, I think that flaws that human intelligence has

05:04.720 --> 05:08.400
 is extremely prejudicial and bias

05:08.400 --> 05:10.440
 in the way it draws many inferences.

05:10.440 --> 05:12.040
 Do you think those are sorry to interrupt?

05:12.040 --> 05:14.360
 Do you think those are features or are those bugs?

05:14.360 --> 05:19.360
 Do you think the prejudice, the forgetfulness,

05:19.480 --> 05:22.880
 the fear, what are the flaws?

05:22.880 --> 05:25.600
 List them all, what love, maybe that's a flaw.

05:25.600 --> 05:28.920
 You think those are all things that can be gotten,

05:28.920 --> 05:30.800
 get in the weight of intelligence

05:30.800 --> 05:33.440
 or the essential components of intelligence?

05:33.440 --> 05:36.200
 Well, again, if you go back and you define intelligence

05:36.200 --> 05:41.200
 as being able to sort of accurately, precisely,

05:41.200 --> 05:43.800
 rigorously reason, develop answers

05:43.800 --> 05:46.600
 and justify those answers in an objective way,

05:46.600 --> 05:49.680
 yeah, then human intelligence has these flaws

05:49.680 --> 05:52.840
 and that it tends to be more influenced

05:52.840 --> 05:55.160
 by some of the things you said.

05:56.480 --> 05:59.720
 And it's largely an inductive process,

05:59.720 --> 06:03.520
 meaning it takes past data, uses that to predict the future,

06:03.520 --> 06:05.960
 very advantageous in some cases,

06:05.960 --> 06:09.240
 but fundamentally biased and prejudicial in other cases

06:09.240 --> 06:11.480
 because it's gonna be strongly influenced by its priors,

06:11.480 --> 06:13.840
 whether they're right or wrong

06:13.840 --> 06:17.360
 from some objective reasoning perspective,

06:17.360 --> 06:20.480
 you're gonna favor them because those are the decisions

06:20.480 --> 06:23.880
 or those are the paths that succeeded in the past.

06:23.880 --> 06:27.320
 And I think that mode of intelligence

06:27.320 --> 06:31.560
 makes a lot of sense for when your primary goal

06:31.560 --> 06:36.560
 is to act quickly and survive and make fast decisions.

06:36.560 --> 06:38.880
 And I think those create problems

06:39.880 --> 06:41.520
 when you wanna think more deeply

06:41.520 --> 06:44.560
 and make more objective and reasoned decisions.

06:44.560 --> 06:47.880
 Of course, humans capable of doing both.

06:47.880 --> 06:50.560
 They do sort of one more naturally than they do the other,

06:50.560 --> 06:52.800
 but they're capable of doing both.

06:52.800 --> 06:55.040
 You're saying they do the one that responds quickly

06:55.040 --> 06:55.960
 and more naturally?

06:55.960 --> 06:56.800
 Right.

06:56.800 --> 06:58.960
 Because that's the thing we kinda need to not be eaten

06:58.960 --> 07:02.240
 by the predators in the world.

07:02.240 --> 07:06.080
 For example, but then we've learned

07:06.080 --> 07:11.080
 to reason through logic, we've developed science,

07:11.240 --> 07:13.040
 we train people to do that.

07:14.000 --> 07:17.000
 I think that's harder for the individual to do.

07:17.000 --> 07:21.000
 I think it requires training and teaching.

07:21.000 --> 07:24.240
 I think we are, human mind certainly is capable of it,

07:24.240 --> 07:25.320
 but we find it more difficult.

07:25.320 --> 07:27.680
 And then there are other weaknesses, if you will,

07:27.680 --> 07:30.680
 as you mentioned earlier, just memory capacity

07:30.680 --> 07:35.280
 and how many chains of inference can you actually

07:35.280 --> 07:37.320
 go through without like losing your way?

07:37.320 --> 07:40.160
 So just focus and...

07:40.160 --> 07:43.280
 So the way you think about intelligence,

07:43.280 --> 07:45.080
 and we're really sort of floating

07:45.080 --> 07:47.240
 in this philosophical space,

07:47.240 --> 07:50.120
 but I think you're like the perfect person

07:50.120 --> 07:55.120
 to talk about this because we'll get to Jeopardy and Beyond.

07:55.680 --> 07:58.080
 That's like an incredible, one of the most incredible

07:58.080 --> 08:00.960
 accomplishments in AI, in the history of AI,

08:00.960 --> 08:03.440
 but hence the philosophical discussion.

08:03.440 --> 08:06.320
 So let me ask, you've kind of alluded to it,

08:06.320 --> 08:09.440
 but let me ask again, what is intelligence?

08:09.440 --> 08:12.480
 Underlying the discussions we'll have

08:12.480 --> 08:15.560
 with Jeopardy and Beyond,

08:15.560 --> 08:17.120
 how do you think about intelligence?

08:17.120 --> 08:19.840
 Is it a sufficiently complicated problem,

08:19.840 --> 08:22.480
 being able to reason your way through solving that problem?

08:22.480 --> 08:23.840
 Is that kind of how you think about

08:23.840 --> 08:25.480
 what it means to be intelligent?

08:25.480 --> 08:29.720
 So I think of intelligence two, primarily two ways.

08:29.720 --> 08:33.320
 One is the ability to predict.

08:33.320 --> 08:35.840
 So in other words, if I have a problem,

08:35.840 --> 08:37.600
 can I predict what's gonna happen next,

08:37.600 --> 08:40.880
 whether it's to predict the answer of a question

08:40.880 --> 08:43.880
 or to say, look, I'm looking at all the market dynamics

08:43.880 --> 08:46.160
 and I'm gonna tell you what's gonna happen next,

08:46.160 --> 08:49.400
 or you're in a room and somebody walks in

08:49.400 --> 08:51.320
 and you're gonna predict what they're gonna do next

08:51.320 --> 08:53.640
 or what they're gonna say next.

08:53.640 --> 08:56.560
 So in a highly dynamic environment full of uncertainty,

08:56.560 --> 08:58.600
 be able to predict.

08:58.600 --> 09:01.480
 The more variables, the more complex,

09:01.480 --> 09:04.080
 the more possibilities, the more complex.

09:04.080 --> 09:07.720
 But can I take a small amount of prior data

09:07.720 --> 09:09.880
 and learn the pattern and then predict

09:09.880 --> 09:13.000
 what's gonna happen next accurately and consistently?

09:13.880 --> 09:16.960
 That's certainly a form of intelligence.

09:16.960 --> 09:18.320
 What do you need for that, by the way?

09:18.320 --> 09:21.160
 You need to have an understanding

09:21.160 --> 09:22.880
 of the way the world works

09:22.880 --> 09:25.560
 in order to be able to unroll it into the future, right?

09:25.560 --> 09:28.040
 What do you think is needed to predict?

09:28.040 --> 09:29.480
 Depends what you mean by understanding.

09:29.480 --> 09:32.240
 I need to be able to find that function.

09:32.240 --> 09:35.120
 This is very much what deep learning does,

09:35.120 --> 09:39.000
 machine learning does, is if you give me enough prior data

09:39.000 --> 09:41.960
 and you tell me what the output variable is that matters,

09:41.960 --> 09:44.480
 I'm gonna sit there and be able to predict it.

09:44.480 --> 09:47.320
 And if I can predict it accurately

09:47.320 --> 09:50.320
 so that I can get it right more often than not,

09:50.320 --> 09:51.160
 I'm smart.

09:51.160 --> 09:54.800
 If I can do that with less data and less training time,

09:54.800 --> 09:56.000
 I'm even smarter.

09:56.000 --> 10:00.640
 If I can figure out what's even worth predicting,

10:01.640 --> 10:03.920
 I'm smarter, meaning I'm figuring out

10:03.920 --> 10:06.400
 what path is gonna get me toward a goal.

10:06.400 --> 10:07.560
 What about picking a goal?

10:07.560 --> 10:08.400
 Sorry to interrupt again.

10:08.400 --> 10:10.120
 Well, that's interesting about picking a goal,

10:10.120 --> 10:11.040
 sort of an interesting thing.

10:11.040 --> 10:13.240
 And I think that's where you bring in,

10:13.240 --> 10:15.040
 what do you pre program to do?

10:15.040 --> 10:17.040
 We talk about humans and well,

10:17.040 --> 10:19.400
 humans are pre programmed to survive.

10:19.400 --> 10:23.320
 So it's sort of their primary driving goal.

10:23.320 --> 10:24.720
 What do they have to do to do that?

10:24.720 --> 10:27.360
 And that can be very complex, right?

10:27.360 --> 10:31.680
 So it's not just figuring out that you need to run away

10:31.680 --> 10:33.640
 from the ferocious tiger,

10:33.640 --> 10:38.640
 but we survive in a social context as an example.

10:38.720 --> 10:42.320
 So understanding the subtleties of social dynamics

10:42.320 --> 10:45.440
 becomes something that's important for surviving,

10:45.440 --> 10:47.200
 finding a mate, reproducing, right?

10:47.200 --> 10:49.360
 So we're continually challenged

10:49.360 --> 10:53.760
 with complex, excessive variables, complex constraints,

10:53.760 --> 10:56.880
 rules, if you will, or patterns.

10:56.880 --> 10:59.320
 And we learn how to find the functions

10:59.320 --> 11:00.680
 and predict the things.

11:00.680 --> 11:03.560
 In other words, represent those patterns efficiently

11:03.560 --> 11:04.920
 and be able to predict what's gonna happen.

11:04.920 --> 11:06.080
 And that's a form of intelligence.

11:06.080 --> 11:11.080
 That doesn't really require anything specific

11:11.400 --> 11:13.400
 other than the ability to find that function

11:13.400 --> 11:15.840
 and predict that right answer.

11:15.840 --> 11:18.440
 That's certainly a form of intelligence.

11:18.440 --> 11:23.280
 But then when we say, well, do we understand each other?

11:23.280 --> 11:28.280
 In other words, would you perceive me as intelligent

11:28.640 --> 11:31.000
 beyond that ability to predict?

11:31.000 --> 11:35.200
 So now I can predict, but I can't really articulate

11:35.200 --> 11:37.840
 how I'm going through that process,

11:37.840 --> 11:41.240
 what my underlying theory is for predicting.

11:41.240 --> 11:43.680
 And I can't get you to understand what I'm doing

11:43.680 --> 11:48.080
 so that you can figure out how to do this yourself

11:48.080 --> 11:50.800
 if you did not have, for example,

11:50.800 --> 11:53.880
 the right pattern matching machinery that I did.

11:53.880 --> 11:55.760
 And now we potentially have this breakdown.

11:55.760 --> 11:59.120
 We're in effect, I'm intelligent,

11:59.120 --> 12:02.680
 but I'm sort of an alien intelligence relative to you.

12:02.680 --> 12:05.480
 You're intelligent, but nobody knows about it.

12:05.480 --> 12:08.240
 Well, I can see the output.

12:08.240 --> 12:11.720
 So you're saying, let's sort of separate the two things.

12:11.720 --> 12:16.640
 One is you explaining why you were able to predict

12:16.640 --> 12:21.640
 the future, and the second is me being able to,

12:23.080 --> 12:25.560
 like impressing me that you're intelligent,

12:25.560 --> 12:27.720
 me being able to know that you successfully predicted

12:27.720 --> 12:29.640
 the future, do you think that's...

12:29.640 --> 12:31.400
 Well, it's not impressing you that I'm intelligent.

12:31.400 --> 12:33.680
 In other words, you may be convinced

12:33.680 --> 12:36.000
 that I'm intelligent in some form.

12:36.000 --> 12:37.200
 So how, what would convince me?

12:37.200 --> 12:38.920
 Because of my ability to predict.

12:38.920 --> 12:41.440
 So I would look at the metrics and I'd say, wow,

12:41.440 --> 12:45.040
 you're right, you're right more times than I am.

12:45.040 --> 12:46.320
 You're doing something interesting,

12:46.320 --> 12:49.120
 that's a form of intelligence.

12:49.120 --> 12:53.400
 But then what happens is, if I say, how are you doing that?

12:53.400 --> 12:55.280
 And you can't communicate with me

12:55.280 --> 12:57.720
 and you can't describe that to me.

12:57.720 --> 13:00.680
 Now I may label you a savant.

13:00.680 --> 13:03.240
 I may say, well, you're doing something weird

13:03.240 --> 13:06.360
 and it's just not very interesting to me

13:06.360 --> 13:08.680
 because you and I can't really communicate.

13:09.360 --> 13:12.360
 And so this is interesting, right?

13:12.360 --> 13:15.120
 Because now you're in this weird place

13:15.120 --> 13:19.320
 where for you to be recognized as intelligent

13:19.320 --> 13:21.280
 the way I'm intelligent,

13:21.280 --> 13:24.280
 then you and I sort of have to be able to communicate.

13:24.280 --> 13:28.520
 And then we start to understand each other

13:28.520 --> 13:33.520
 and then my respect and my appreciation,

13:33.520 --> 13:36.760
 my ability to relate to you starts to change.

13:36.760 --> 13:39.080
 So now you're not an alien intelligence anymore.

13:39.080 --> 13:41.080
 You're a human intelligence now

13:41.080 --> 13:43.880
 because you and I can communicate.

13:43.880 --> 13:47.400
 And so I think when we look at animals,

13:47.400 --> 13:49.280
 for example, animals can do things,

13:49.280 --> 13:50.720
 we can't quite comprehend,

13:50.720 --> 13:51.800
 we don't quite know how they do them,

13:51.800 --> 13:54.400
 but they can't really communicate with us.

13:54.400 --> 13:58.360
 They can't put what they're going through in our terms.

13:58.360 --> 13:59.880
 And so we think of them as sort of low.

13:59.880 --> 14:01.520
 They're these alien intelligences

14:01.520 --> 14:03.600
 and they're not really worth necessarily what we're worth.

14:03.600 --> 14:06.360
 We don't treat them the same way as a result of that.

14:06.360 --> 14:11.360
 But it's hard because who knows what's going on.

14:11.360 --> 14:15.680
 So just a quick elaboration on that,

14:15.680 --> 14:18.800
 the explaining that you're intelligent,

14:18.800 --> 14:22.320
 the explaining the reasoning that went into the prediction

14:23.520 --> 14:27.120
 is not some kind of mathematical proof.

14:27.120 --> 14:30.240
 If we look at humans, look at political debates

14:30.240 --> 14:32.440
 and discourse on Twitter,

14:32.440 --> 14:35.400
 it's mostly just telling stories.

14:35.400 --> 14:42.400
 So your task is not to tell an accurate depiction

14:43.680 --> 14:48.440
 of how you reason, but to tell a story real or not

14:48.440 --> 14:51.120
 that convinces me that there was a mechanism

14:51.120 --> 14:51.960
 by which you...

14:51.960 --> 14:53.640
 Well, ultimately, that's what a proof is.

14:53.640 --> 14:56.280
 I mean, even a mathematical proof is that

14:56.280 --> 14:58.240
 because ultimately the other mathematicians

14:58.240 --> 15:02.120
 have to be convinced by your proof, otherwise.

15:02.120 --> 15:03.040
 In fact, there have been...

15:03.040 --> 15:04.480
 That's the metric of success, yeah.

15:04.480 --> 15:05.920
 There have been several proofs out there

15:05.920 --> 15:07.840
 where mathematicians would study for a long time

15:07.840 --> 15:10.760
 before they were convinced that it actually proved anything.

15:10.760 --> 15:12.040
 You never know if it proved anything

15:12.040 --> 15:14.680
 until the community of mathematicians decided that it did.

15:14.680 --> 15:18.480
 So I mean, but it's a real thing.

15:18.480 --> 15:20.760
 And that's sort of the point, right?

15:20.760 --> 15:24.400
 Is that ultimately, this notion of understanding us,

15:24.400 --> 15:28.000
 understanding something is ultimately a social concept.

15:28.000 --> 15:30.520
 In other words, I have to convince enough people

15:30.520 --> 15:33.520
 that I did this in a reasonable way.

15:33.520 --> 15:35.240
 I could do this in a way that other people

15:35.240 --> 15:39.640
 can understand and replicate and that it makes sense to them.

15:39.640 --> 15:44.640
 So our human intelligence is bound together in that way.

15:44.640 --> 15:47.240
 We're bound up in that sense.

15:47.240 --> 15:49.320
 We sort of never really get away with it

15:49.320 --> 15:52.360
 until we can sort of convince others

15:52.360 --> 15:55.640
 that our thinking process makes sense.

15:55.640 --> 15:58.920
 So do you think the general question of intelligence

15:58.920 --> 16:00.800
 is then also a social construct?

16:00.800 --> 16:05.120
 So if we ask questions

16:05.120 --> 16:06.480
 of an artificial intelligence system,

16:06.480 --> 16:08.440
 is this system intelligent?

16:08.440 --> 16:12.440
 The answer will ultimately be a socially constructed...

16:12.440 --> 16:15.840
 I think so I think I'm making two statements.

16:15.840 --> 16:17.840
 I'm saying we can try to define intelligence

16:17.840 --> 16:22.920
 in a super objective way that says, here's this data.

16:22.920 --> 16:26.560
 I want to predict this type of thing, learn this function,

16:26.560 --> 16:30.160
 and then if you get it right, often enough,

16:30.160 --> 16:31.920
 we consider you intelligent.

16:31.920 --> 16:34.240
 But that's more like a subordinate.

16:34.240 --> 16:36.960
 I think it is, it doesn't mean it's not useful.

16:36.960 --> 16:38.480
 It could be incredibly useful.

16:38.480 --> 16:41.280
 It could be solving a problem we can't otherwise solve

16:41.280 --> 16:44.400
 and can solve it more reliably than we can.

16:44.400 --> 16:50.240
 But then there's this notion of can humans take responsibility

16:50.240 --> 16:53.520
 for the decision that you're making?

16:53.520 --> 16:55.960
 Can we make those decisions ourselves?

16:55.960 --> 16:58.680
 Can we relate to the process that you're going through?

16:58.680 --> 17:02.040
 And now you as an agent, whether you're a machine

17:02.040 --> 17:06.440
 or another human, frankly, are now obliged

17:06.440 --> 17:09.960
 to make me understand how it is that you're arriving

17:09.960 --> 17:13.720
 at that answer and allow me, me or obviously a community

17:13.720 --> 17:16.200
 or a judge of people, to decide whether or not

17:16.200 --> 17:17.160
 that makes sense.

17:17.160 --> 17:20.040
 And by the way, that happens with humans as well.

17:20.040 --> 17:21.960
 You're sitting down with your staff, for example,

17:21.960 --> 17:26.280
 and you ask for suggestions about what to do next.

17:26.280 --> 17:28.760
 And someone says, well, I think you should buy, and I

17:28.760 --> 17:31.680
 should think you should buy this much, or have or sell

17:31.680 --> 17:34.760
 or whatever it is, or I think you should launch the product

17:34.760 --> 17:37.040
 today or tomorrow or launch this product versus that product,

17:37.040 --> 17:38.520
 whatever the decision may be.

17:38.520 --> 17:39.760
 And you ask why.

17:39.760 --> 17:42.720
 And the person said, I just have a good feeling about it.

17:42.720 --> 17:44.360
 And you're not very satisfied.

17:44.360 --> 17:48.640
 Now, that person could be, you might say, well, you've

17:48.640 --> 17:54.080
 been right before, but I'm going to put the company on the line.

17:54.080 --> 17:57.920
 Can you explain to me why I should believe this?

17:57.920 --> 18:00.920
 And that explanation may have nothing to do with the truth.

18:00.920 --> 18:03.360
 You just have to convince the other person.

18:03.360 --> 18:04.440
 You'll still be wrong.

18:04.440 --> 18:05.240
 You'll still be wrong.

18:05.240 --> 18:06.240
 You just got to be convincing.

18:06.240 --> 18:07.840
 But it's ultimately got to be convincing.

18:07.840 --> 18:12.120
 And that's why I'm saying we're bound together.

18:12.120 --> 18:14.160
 Our intelligences are bound together in that sense.

18:14.160 --> 18:16.120
 We have to understand each other.

18:16.120 --> 18:18.840
 And if, for example, you're giving me an explanation,

18:18.840 --> 18:21.000
 and this is a very important point,

18:21.000 --> 18:23.760
 you're giving me an explanation.

18:23.760 --> 18:35.160
 And I'm not good at reasoning well and being objective

18:35.160 --> 18:39.120
 and following logical paths and consistent paths.

18:39.120 --> 18:43.720
 And I'm not good at measuring and computing probabilities

18:43.720 --> 18:45.440
 across those paths.

18:45.440 --> 18:50.040
 What happens is, collectively, we're not going to do well.

18:50.040 --> 18:53.120
 How hard is that problem, the second one?

18:53.120 --> 18:57.920
 So I think we'll talk quite a bit about the first

18:57.920 --> 19:03.760
 on a specific objective metric benchmark performing well.

19:03.760 --> 19:08.960
 But being able to explain the steps, the reasoning,

19:08.960 --> 19:10.520
 how hard is that problem?

19:10.520 --> 19:11.760
 I think that's very hard.

19:11.760 --> 19:18.120
 I mean, I think that's, well, it's hard for humans.

19:18.120 --> 19:20.920
 The thing that's hard for humans, as you know,

19:20.920 --> 19:24.360
 may not necessarily be hard for computers and vice versa.

19:24.360 --> 19:25.480
 So sorry.

19:25.480 --> 19:31.080
 So how hard is that problem for computers?

19:31.080 --> 19:32.560
 I think it's hard for computers.

19:32.560 --> 19:35.640
 And the reason why I related to saying that it's also

19:35.640 --> 19:38.280
 hard for humans is because I think when we step back

19:38.280 --> 19:43.480
 and we say we want to design computers to do that,

19:43.480 --> 19:46.360
 one of the things we have to recognize

19:46.360 --> 19:50.440
 is we're not sure how to do it well.

19:50.440 --> 19:52.880
 I'm not sure we have a recipe for that.

19:52.880 --> 19:55.280
 And even if you wanted to learn it,

19:55.280 --> 19:59.400
 it's not clear exactly what data we use

19:59.400 --> 20:03.600
 and what judgments we use to learn that well.

20:03.600 --> 20:05.720
 And so what I mean by that is, if you

20:05.720 --> 20:09.440
 look at the entire enterprise of science,

20:09.440 --> 20:13.680
 science is supposed to be at about objective reason.

20:13.680 --> 20:17.640
 So we think about, who's the most intelligent person

20:17.640 --> 20:20.520
 or group of people in the world?

20:20.520 --> 20:24.040
 Do we think about the savants who can close their eyes

20:24.040 --> 20:25.560
 and give you a number?

20:25.560 --> 20:28.520
 We think about the think tanks or the scientists

20:28.520 --> 20:32.680
 or the philosophers who kind of work through the details

20:32.680 --> 20:36.400
 and write the papers and come up with the thoughtful, logical

20:36.400 --> 20:38.600
 proves and use the scientific method.

20:38.600 --> 20:42.760
 And I think it's the latter.

20:42.760 --> 20:45.760
 And my point is that, how do you train someone to do that?

20:45.760 --> 20:47.560
 And that's what I mean by it's hard.

20:47.560 --> 20:50.760
 What's the process of training people to do that well?

20:50.760 --> 20:52.360
 That's a hard process.

20:52.360 --> 20:55.960
 We work as a society, we work pretty hard

20:55.960 --> 20:59.200
 to get other people to understand our thinking

20:59.200 --> 21:02.200
 and to convince them of things.

21:02.200 --> 21:04.000
 Now, we could wade them.

21:04.000 --> 21:06.840
 Obviously, we talked about this, like human flaws

21:06.840 --> 21:12.800
 or weaknesses, we can persuade them through emotional means.

21:12.800 --> 21:16.640
 But to get them to understand and connect to and follow

21:16.640 --> 21:20.600
 a logical argument is difficult.

21:20.600 --> 21:24.160
 We do it as scientists, we try to do it as journalists,

21:24.160 --> 21:27.240
 we try to do it as even artists in many forms,

21:27.240 --> 21:29.760
 as writers, as teachers.

21:29.760 --> 21:33.800
 We go through a fairly significant training process

21:33.800 --> 21:34.520
 to do that.

21:34.520 --> 21:38.960
 And then we could ask, well, why is that so hard?

21:38.960 --> 21:39.880
 But it's hard.

21:39.880 --> 21:44.000
 And for humans, it takes a lot of work.

21:44.000 --> 21:46.160
 And when we step back and say, well, how

21:46.160 --> 21:49.160
 do we get a machine to do that?

21:49.160 --> 21:51.920
 It's a vexing question.

21:51.920 --> 21:55.400
 How would you begin to try to solve that?

21:55.400 --> 21:58.240
 And maybe just a quick pause, because there's

21:58.240 --> 22:01.040
 an optimistic notion in the things you're describing,

22:01.040 --> 22:06.000
 which is being able to explain something through reason.

22:06.000 --> 22:08.640
 But if you look at algorithms that recommend things

22:08.640 --> 22:11.800
 that we look at next, whether it's Facebook, Google,

22:11.800 --> 22:17.280
 advertisement based companies, their goal

22:17.280 --> 22:23.520
 is to convince you to buy things based on anything.

22:23.520 --> 22:27.200
 So that could be reason, because the best of advertisement

22:27.200 --> 22:29.640
 is showing you things that you really do need

22:29.640 --> 22:32.000
 and explain why you need it.

22:32.000 --> 22:37.080
 But it could also be through emotional manipulation.

22:37.080 --> 22:40.960
 The algorithm that describes why a certain reason,

22:40.960 --> 22:43.800
 a certain decision was made.

22:43.800 --> 22:48.200
 How hard is it to do it through emotional manipulation?

22:48.200 --> 22:52.760
 And why is that a good or a bad thing?

22:52.760 --> 22:57.360
 So you've kind of focused on reason, logic, really

22:57.360 --> 23:02.680
 showing in a clear way why something is good.

23:02.680 --> 23:05.960
 One, is that even a thing that us humans do?

23:05.960 --> 23:11.600
 And two, how do you think of the difference in the reasoning

23:11.600 --> 23:15.120
 aspect and the emotional manipulation?

23:15.120 --> 23:17.320
 So you call it emotional manipulation,

23:17.320 --> 23:19.280
 but more objectively, it's essentially

23:19.280 --> 23:22.600
 saying there are certain features of things

23:22.600 --> 23:24.400
 that seem to attract your attention.

23:24.400 --> 23:26.800
 I mean, it kind of give you more of that stuff.

23:26.800 --> 23:28.240
 Manipulation is a bad word.

23:28.240 --> 23:31.120
 Yeah, I'm not saying it's good, right, or wrong.

23:31.120 --> 23:33.080
 It works to get your attention, and it

23:33.080 --> 23:34.400
 works to get you to buy stuff.

23:34.400 --> 23:35.920
 And when you think about algorithms

23:35.920 --> 23:39.960
 that look at the patterns of features

23:39.960 --> 23:41.880
 that you seem to be spending your money on,

23:41.880 --> 23:43.240
 and say, I'm going to give you something

23:43.240 --> 23:46.040
 with a similar pattern, I'm going to learn that function

23:46.040 --> 23:48.120
 because the objective is to get you to click on it,

23:48.120 --> 23:51.000
 or get you to buy it, or whatever it is.

23:51.000 --> 23:51.520
 I don't know.

23:51.520 --> 23:53.360
 I mean, it is what it is.

23:53.360 --> 23:55.760
 I mean, that's what the algorithm does.

23:55.760 --> 23:57.400
 You can argue whether it's good or bad.

23:57.400 --> 24:00.400
 It depends what your goal is.

24:00.400 --> 24:04.120
 I guess this seems to be very useful for convincing.

24:04.120 --> 24:05.200
 For telling us the story.

24:05.200 --> 24:09.040
 For convincing humans, it's good because, again, this

24:09.040 --> 24:12.040
 goes back to, what is the human behavior like?

24:12.040 --> 24:16.960
 What does the human brain respond to things?

24:16.960 --> 24:19.440
 I think there's a more optimistic view of that, too,

24:19.440 --> 24:21.960
 which is that if you're searching

24:21.960 --> 24:23.640
 for certain kinds of things, you've already

24:23.640 --> 24:26.080
 reasoned that you need them.

24:26.080 --> 24:30.000
 And these algorithms are saying, look, that's up to you.

24:30.000 --> 24:33.600
 The reason whether you need something or not, that's your job.

24:33.600 --> 24:36.880
 You may have an unhealthy addiction to this stuff,

24:36.880 --> 24:42.840
 or you may have a reasoned and thoughtful explanation

24:42.840 --> 24:44.440
 for why it's important to you.

24:44.440 --> 24:47.000
 And the algorithms are saying, hey, that's like whatever.

24:47.000 --> 24:48.040
 Like, that's your problem.

24:48.040 --> 24:50.360
 All I know is you're buying stuff like that.

24:50.360 --> 24:51.880
 You're interested in stuff like that.

24:51.880 --> 24:52.760
 It could be a bad reason.

24:52.760 --> 24:53.920
 It could be a good reason.

24:53.920 --> 24:55.040
 That's up to you.

24:55.040 --> 24:58.680
 I'm going to show you more of that stuff.

24:58.680 --> 25:02.200
 And I think that it's not good or bad.

25:02.200 --> 25:03.520
 It's not reasoned or not reasoned.

25:03.520 --> 25:04.920
 And the algorithm is doing what it does,

25:04.920 --> 25:06.920
 which is saying, you seem to be interested in this.

25:06.920 --> 25:09.040
 I'm going to show you more of that stuff.

25:09.040 --> 25:11.200
 And I think we're seeing this not just in buying stuff,

25:11.200 --> 25:12.200
 but even in social media.

25:12.200 --> 25:13.960
 You're reading this kind of stuff.

25:13.960 --> 25:15.760
 I'm not judging on whether it's good or bad.

25:15.760 --> 25:16.960
 I'm not reasoning at all.

25:16.960 --> 25:19.160
 I'm just saying, I'm going to show you other stuff

25:19.160 --> 25:21.360
 with similar features.

25:21.360 --> 25:22.360
 And that's it.

25:22.360 --> 25:23.560
 And I wash my hands from it.

25:23.560 --> 25:25.800
 And I say, that's all that's going on.

25:29.320 --> 25:32.000
 People are so harsh on AI systems.

25:32.000 --> 25:34.960
 So one, the bar of performance is extremely high.

25:34.960 --> 25:39.560
 And yet, we also ask them, in the case of social media,

25:39.560 --> 25:42.960
 to help find the better angels of our nature

25:42.960 --> 25:45.920
 and help make a better society.

25:45.920 --> 25:47.840
 So what do you think about the role of AI?

25:47.840 --> 25:50.000
 So that's, I agree with you.

25:50.000 --> 25:51.560
 That's the interesting dichotomy, right?

25:51.560 --> 25:54.160
 Because on one hand, we're sitting there

25:54.160 --> 25:56.080
 and we're sort of doing the easy part, which

25:56.080 --> 25:58.000
 is finding the patterns.

25:58.000 --> 26:01.920
 We're not building a, the system's not building a theory

26:01.920 --> 26:03.560
 that is consumable and understandable

26:03.560 --> 26:06.400
 to other humans that can be explained and justified.

26:06.400 --> 26:11.520
 And so on one hand, to say, oh, AI is doing this.

26:11.520 --> 26:13.720
 Why isn't doing this other thing?

26:13.720 --> 26:16.320
 Well, this other thing is a lot harder.

26:16.320 --> 26:20.200
 And it's interesting to think about why it's harder.

26:20.200 --> 26:24.000
 And because you're interpreting the data

26:24.000 --> 26:27.280
 in the context of prior models, in other words,

26:27.280 --> 26:29.360
 understandings of what's important in the world,

26:29.360 --> 26:30.240
 what's not important.

26:30.240 --> 26:32.040
 What are all the other abstract features

26:32.040 --> 26:35.360
 that drive our decision making?

26:35.360 --> 26:37.440
 What's sensible, what's not sensible, what's good,

26:37.440 --> 26:40.000
 what's bad, what's moral, what's valuable, what isn't?

26:40.000 --> 26:41.160
 Where is that stuff?

26:41.160 --> 26:43.240
 No one's applying the interpretation.

26:43.240 --> 26:46.600
 So when I see you clicking on a bunch of stuff

26:46.600 --> 26:49.760
 and I look at these simple features, the raw features,

26:49.760 --> 26:51.640
 the features that are there in the data,

26:51.640 --> 26:57.680
 like what words are being used, or how long the material is,

26:57.680 --> 27:00.600
 or other very superficial features,

27:00.600 --> 27:02.520
 what colors are being used in the material.

27:02.520 --> 27:04.240
 Like I don't know why you're clicking on this stuff

27:04.240 --> 27:07.600
 you're clicking, or if it's products, what the price is,

27:07.600 --> 27:09.560
 or what the categories and stuff like that.

27:09.560 --> 27:11.560
 And I just feed you more of the same stuff.

27:11.560 --> 27:13.720
 That's very different than kind of getting in there

27:13.720 --> 27:17.560
 and saying, what does this mean?

27:17.560 --> 27:21.400
 The stuff you're reading, like why are you reading it?

27:21.400 --> 27:23.960
 What assumptions are you bringing to the table?

27:23.960 --> 27:26.400
 Are those assumptions sensible?

27:26.400 --> 27:29.040
 Does the material make any sense?

27:29.040 --> 27:34.120
 Does it lead you to thoughtful, good conclusions?

27:34.120 --> 27:37.440
 Again, there's interpretation and judgment involved

27:37.440 --> 27:43.720
 in that process that isn't really happening in the AI today.

27:43.720 --> 27:47.240
 That's harder because you have to start getting

27:47.240 --> 27:52.040
 at the meaning of the stuff of the content.

27:52.040 --> 27:55.760
 You have to get at how humans interpret the content

27:55.760 --> 28:00.600
 relative to their value system and deeper thought processes.

28:00.600 --> 28:06.760
 So that's what meaning means, is not just some kind of deep,

28:06.760 --> 28:10.920
 timeless, semantic thing that the statement represents,

28:10.920 --> 28:13.360
 but also how a large number of people

28:13.360 --> 28:15.200
 are likely to interpret.

28:15.200 --> 28:19.200
 So it's, again, even meaning is a social construct.

28:19.200 --> 28:22.920
 So you have to try to predict how most people would

28:22.920 --> 28:24.480
 understand this kind of statement.

28:24.480 --> 28:27.280
 Yeah, meaning is often relative,

28:27.280 --> 28:30.400
 but meaning implies that the connections go beneath

28:30.400 --> 28:31.840
 the surface of the artifacts.

28:31.840 --> 28:35.480
 If I show you a painting, it's a bunch of colors on a canvas,

28:35.480 --> 28:37.160
 what does it mean to you?

28:37.160 --> 28:39.400
 And it may mean different things to different people

28:39.400 --> 28:42.240
 because of their different experiences.

28:42.240 --> 28:45.240
 It may mean something even different to the artist

28:45.240 --> 28:47.440
 who painted it.

28:47.440 --> 28:50.720
 As we try to get more rigorous with our communication,

28:50.720 --> 28:53.280
 we try to really nail down that meaning.

28:53.280 --> 28:58.840
 So we go from abstract art to precise mathematics,

28:58.840 --> 29:01.520
 precise engineering drawings, and things like that.

29:01.520 --> 29:03.760
 We're really trying to say, I want

29:03.760 --> 29:08.280
 to narrow that space of possible interpretations

29:08.280 --> 29:10.720
 because the precision of the communication

29:10.720 --> 29:13.400
 ends up becoming more and more important.

29:13.400 --> 29:17.920
 And so that means that I have to specify,

29:17.920 --> 29:21.360
 and I think that's why this becomes really hard.

29:21.360 --> 29:24.160
 Because if I'm just showing you an artifact

29:24.160 --> 29:25.960
 and you're looking at it superficially,

29:25.960 --> 29:28.200
 whether it's a bunch of words on a page,

29:28.200 --> 29:31.880
 or whether it's brushstrokes on a canvas

29:31.880 --> 29:34.240
 or pixels on a photograph, you can sit there

29:34.240 --> 29:36.120
 and you can interpret lots of different ways

29:36.120 --> 29:37.440
 at many, many different levels.

29:39.880 --> 29:45.680
 But when I want to align our understanding of that,

29:45.680 --> 29:51.080
 I have to specify a lot more stuff that's actually not

29:51.080 --> 29:52.280
 directly in the artifact.

29:52.280 --> 29:54.760
 Now, I have to say, well, how are you

29:54.760 --> 29:57.200
 interpreting this image and that image?

29:57.200 --> 29:58.160
 And what about the colors?

29:58.160 --> 29:59.400
 And what do they mean to you?

29:59.400 --> 30:02.560
 What perspective are you bringing to the table?

30:02.560 --> 30:05.640
 What are your prior experiences with those artifacts?

30:05.640 --> 30:08.800
 What are your fundamental assumptions and values?

30:08.800 --> 30:10.840
 What is your ability to kind of reason

30:10.840 --> 30:13.320
 to chain together logical implication

30:13.320 --> 30:15.080
 as you're sitting there and saying, well, if this is

30:15.080 --> 30:16.480
 the case, then I would conclude this.

30:16.480 --> 30:19.120
 And if that's the case, then I would conclude that.

30:19.120 --> 30:22.520
 So your reasoning processes and how they work,

30:22.520 --> 30:25.360
 your prior models and what they are,

30:25.360 --> 30:27.240
 your values and your assumptions,

30:27.240 --> 30:31.600
 all those things now come together into the interpretation.

30:31.600 --> 30:34.840
 Getting and thinking of that is hard.

30:34.840 --> 30:37.640
 And yet humans are able to intuit some of that

30:37.640 --> 30:39.600
 without any pre.

30:39.600 --> 30:41.560
 Because they have the shared experience.

30:41.560 --> 30:42.920
 And we're not talking about shared,

30:42.920 --> 30:45.520
 two people having shared experience, as a society.

30:45.520 --> 30:46.560
 That's correct.

30:46.560 --> 30:48.920
 We have the shared experience.

30:48.920 --> 30:51.200
 And we have similar brains.

30:51.200 --> 30:54.080
 So we tend to, in other words,

30:54.080 --> 30:56.480
 part of our shared experiences are shared local experience.

30:56.480 --> 30:57.840
 Like we may live in the same culture,

30:57.840 --> 30:59.080
 we may live in the same society.

30:59.080 --> 31:02.040
 And therefore we have similar educations.

31:02.040 --> 31:04.120
 We have similar, what we like to call prior models

31:04.120 --> 31:05.880
 about the word prior experiences.

31:05.880 --> 31:09.560
 And we use that as a, think of it as a wide collection

31:09.560 --> 31:10.960
 of interrelated variables.

31:10.960 --> 31:12.800
 And they're all bound to similar things.

31:12.800 --> 31:15.080
 And so we take that as our background

31:15.080 --> 31:17.560
 and we start interpreting things similarly.

31:17.560 --> 31:21.840
 But as humans we have a lot of shared experience.

31:21.840 --> 31:24.960
 We do have similar brains, similar goals,

31:24.960 --> 31:28.080
 similar emotions under similar circumstances.

31:28.080 --> 31:29.040
 Because we're both humans.

31:29.040 --> 31:31.440
 So now one of the early questions you asked,

31:31.440 --> 31:36.440
 how is biological and computer information systems

31:37.040 --> 31:38.000
 fundamentally different?

31:38.000 --> 31:43.000
 Well, one is humans come with a lot of pre programmed stuff.

31:43.840 --> 31:45.960
 A ton of programmed stuff.

31:45.960 --> 31:47.240
 And they're able to communicate

31:47.240 --> 31:48.360
 because they have a lot of,

31:48.360 --> 31:50.360
 because they share that stuff.

31:50.360 --> 31:52.720
 Do you think that shared knowledge,

31:54.080 --> 31:57.560
 if we can maybe escape the hardware question,

31:57.560 --> 31:59.440
 how much is encoded in the hardware?

31:59.440 --> 32:01.200
 Just the shared knowledge in the software,

32:01.200 --> 32:04.480
 the history of the many centuries of wars

32:04.480 --> 32:07.960
 and so on that came to today, that shared knowledge.

32:09.600 --> 32:13.360
 How hard is it to encode?

32:14.320 --> 32:15.840
 Do you have a hope?

32:15.840 --> 32:19.360
 Can you speak to how hard is it to encode that knowledge

32:19.360 --> 32:22.800
 systematically in a way that could be used by a computer?

32:22.800 --> 32:26.320
 So I think it is possible to learn for a machine,

32:26.320 --> 32:29.600
 to program a machine, to acquire that knowledge

32:29.600 --> 32:31.440
 with a similar foundation.

32:31.440 --> 32:36.120
 In other words, a similar interpretive foundation

32:36.120 --> 32:38.040
 for processing that knowledge.

32:38.040 --> 32:39.080
 What do you mean by that?

32:39.080 --> 32:44.080
 So in other words, we view the world in a particular way.

32:44.080 --> 32:49.080
 And so in other words, we have, if you will, as humans,

32:49.360 --> 32:52.240
 we have a framework for interpreting the world around us.

32:52.240 --> 32:54.760
 So we have multiple frameworks

32:54.760 --> 32:55.960
 for interpreting the world around us.

32:55.960 --> 32:59.760
 But if you're interpreting, for example,

32:59.760 --> 33:01.360
 social political interactions,

33:01.360 --> 33:03.120
 you're thinking about whether there's people,

33:03.120 --> 33:05.560
 there's collections in groups of people,

33:05.560 --> 33:06.560
 they have goals,

33:06.560 --> 33:10.880
 goals are largely built around survival and quality of life.

33:10.880 --> 33:15.880
 There are fundamental economics around scarcity of resources.

33:16.640 --> 33:20.320
 And when humans come and start interpreting a situation

33:20.320 --> 33:23.600
 like that, because you brought up historical events,

33:23.600 --> 33:25.480
 they start interpreting situations like that.

33:25.480 --> 33:27.600
 They apply a lot of this,

33:27.600 --> 33:30.760
 a lot of this fundamental framework for interpreting that.

33:30.760 --> 33:32.240
 Well, who are the people?

33:32.240 --> 33:33.320
 What were their goals?

33:33.320 --> 33:35.000
 What reasons did they have?

33:35.000 --> 33:37.040
 How much power influence did they have over the other?

33:37.040 --> 33:40.560
 Like this fundamental substrate, if you will,

33:40.560 --> 33:42.800
 for interpreting and reasoning about that.

33:43.840 --> 33:46.920
 So I think it is possible to imbue a computer

33:46.920 --> 33:50.680
 with that stuff that humans take for granted

33:50.680 --> 33:54.040
 when they go and sit down and try to interpret things.

33:54.040 --> 33:58.840
 And then with that foundation, they acquire,

33:58.840 --> 34:00.320
 they start acquiring the details,

34:00.320 --> 34:02.840
 the specifics and a given situation,

34:02.840 --> 34:05.760
 are then able to interpret it with regards to that framework.

34:05.760 --> 34:07.440
 And then given that interpretation,

34:07.440 --> 34:10.320
 they can do what they can predict.

34:10.320 --> 34:12.200
 But not only can they predict,

34:12.200 --> 34:14.800
 they can predict now with an explanation

34:15.960 --> 34:17.920
 that can be given in those terms,

34:17.920 --> 34:20.200
 in the terms of that underlying framework

34:20.200 --> 34:22.320
 that most humans share.

34:22.320 --> 34:23.840
 Now you could find humans that come

34:23.840 --> 34:26.320
 and interpret events very differently than other humans

34:26.320 --> 34:30.640
 because they're like using a different framework.

34:30.640 --> 34:32.520
 The movie Matrix comes to mind

34:32.520 --> 34:36.240
 where they decided humans were really just batteries.

34:36.240 --> 34:39.920
 And that's how they interpreted the value of humans

34:39.920 --> 34:41.640
 as a source of electrical energy.

34:41.640 --> 34:45.440
 So, but I think that, for the most part,

34:45.440 --> 34:50.440
 we have a way of interpreting the events

34:50.800 --> 34:52.280
 or the social events around us

34:52.280 --> 34:54.160
 because we have this shared framework.

34:54.160 --> 34:58.720
 It comes from, again, the fact that we're similar beings

34:58.720 --> 35:01.080
 that have similar goals, similar emotions,

35:01.080 --> 35:02.920
 and we can make sense out of these.

35:02.920 --> 35:05.000
 These frameworks make sense to us.

35:05.000 --> 35:08.080
 So how much knowledge is there, do you think?

35:08.080 --> 35:09.600
 So you said it's possible.

35:09.600 --> 35:12.760
 It's tremendous amount of detailed knowledge in the world.

35:12.760 --> 35:17.600
 You can imagine effectively infinite number

35:17.600 --> 35:20.880
 of unique situations and unique configurations

35:20.880 --> 35:22.160
 of these things.

35:22.160 --> 35:25.160
 But the knowledge that you need,

35:25.160 --> 35:27.640
 what I referred to as like the frameworks,

35:27.640 --> 35:29.600
 for you need for interpreting them, I don't think.

35:29.600 --> 35:31.520
 I think that those are finite.

35:31.520 --> 35:35.040
 You think the frameworks are more important

35:35.040 --> 35:36.800
 than the bulk of the knowledge.

35:36.800 --> 35:37.800
 So like framing.

35:37.800 --> 35:39.240
 Yeah, because what the frameworks do

35:39.240 --> 35:41.600
 is they give you now the ability to interpret and reason.

35:41.600 --> 35:43.120
 And to interpret and reason it,

35:43.120 --> 35:46.800
 to interpret and reason over the specifics

35:46.800 --> 35:49.240
 in ways that other humans would understand.

35:49.240 --> 35:51.360
 What about the specifics?

35:51.360 --> 35:54.000
 Were you required the specifics by reading

35:54.000 --> 35:55.600
 and by talking to other people?

35:55.600 --> 35:57.760
 So I'm mostly actually just even,

35:57.760 --> 36:00.280
 if you can focus on even the beginning,

36:00.280 --> 36:01.520
 the common sense stuff,

36:01.520 --> 36:03.440
 the stuff that doesn't even require reading

36:03.440 --> 36:06.920
 or it almost requires playing around with the world

36:06.920 --> 36:10.840
 or something, just being able to sort of manipulate objects,

36:10.840 --> 36:13.920
 drink water and so on, all of that.

36:13.920 --> 36:16.160
 Every time we try to do that kind of thing

36:16.160 --> 36:21.080
 in robotics or AI, it seems to be like an onion.

36:21.080 --> 36:24.160
 You seem to realize how much knowledge is really required

36:24.160 --> 36:27.080
 to perform even some of these basic tasks.

36:27.080 --> 36:30.400
 Do you have that sense as well?

36:30.400 --> 36:33.840
 And so how do we get all those details?

36:33.840 --> 36:35.760
 Are they written down somewhere?

36:35.760 --> 36:39.280
 Do they have to be learned through experience?

36:39.280 --> 36:43.280
 So I think when you're talking about sort of the physics,

36:43.280 --> 36:44.760
 the basic physics around us,

36:44.760 --> 36:46.080
 for example, acquiring information

36:46.080 --> 36:48.200
 about acquiring how that works.

36:49.760 --> 36:52.280
 Yeah, I think there's a combination of things going on.

36:52.280 --> 36:54.680
 I think there's a combination of things going on.

36:54.680 --> 36:57.840
 I think there is like fundamental pattern matching

36:57.840 --> 36:59.720
 like what we were talking about before,

36:59.720 --> 37:01.120
 where you see enough examples,

37:01.120 --> 37:03.880
 enough data about something you start assuming that

37:03.880 --> 37:05.520
 and with similar input,

37:05.520 --> 37:07.760
 I'm gonna predict similar outputs.

37:07.760 --> 37:10.160
 You don't can't necessarily explain it at all.

37:10.160 --> 37:13.640
 You may learn very quickly that when you let something go,

37:14.680 --> 37:16.520
 it falls to the ground.

37:16.520 --> 37:17.840
 That's such a...

37:17.840 --> 37:19.800
 But you can't necessarily explain that.

37:19.800 --> 37:22.360
 But that's such a deep idea

37:22.360 --> 37:25.240
 that if you let something go, like the idea of gravity.

37:26.160 --> 37:28.440
 I mean, people are letting things go and counting

37:28.440 --> 37:30.800
 on them falling well before they understood gravity.

37:30.800 --> 37:33.880
 But that seems to be, that's exactly what I mean,

37:33.880 --> 37:36.120
 is before you take a physics class

37:36.120 --> 37:39.600
 or study anything about Newton,

37:39.600 --> 37:42.560
 just the idea that stuff falls to the ground

37:42.560 --> 37:45.360
 and then you'd be able to generalize

37:45.360 --> 37:48.560
 that all kinds of stuff falls to the ground.

37:49.640 --> 37:53.480
 It just seems like a non, if without encoding it,

37:53.480 --> 37:55.240
 like hard coding it in,

37:55.240 --> 37:57.440
 it seems like a difficult thing to pick up.

37:57.440 --> 38:01.400
 It seems like you have to have a lot of different knowledge

38:01.400 --> 38:05.360
 to be able to integrate that into the framework,

38:05.360 --> 38:07.760
 sort of into everything else.

38:07.760 --> 38:10.360
 So both know that stuff falls to the ground

38:10.360 --> 38:15.360
 and start to reason about social political discourse.

38:16.360 --> 38:18.600
 So both like the very basic

38:18.600 --> 38:22.560
 and the high level reasoning decision making.

38:22.560 --> 38:25.040
 I guess my question is, how hard is this problem?

38:27.040 --> 38:29.040
 Sorry to linger on it because again,

38:29.040 --> 38:32.960
 and we'll get to it for sure as Watson with Jeopardy did

38:32.960 --> 38:35.480
 is take on a problem that's much more constrained

38:35.480 --> 38:38.240
 but has the same hugeness of scale,

38:38.240 --> 38:40.640
 at least from the outsider's perspective.

38:40.640 --> 38:42.880
 So I'm asking the general life question

38:42.880 --> 38:45.600
 of to be able to be an intelligent being

38:45.600 --> 38:48.920
 and reasoning in the world about both gravity

38:48.920 --> 38:52.120
 and politics, how hard is that problem?

38:52.120 --> 38:57.480
 So I think it's solvable.

38:57.480 --> 39:00.720
 Okay, now beautiful.

39:00.720 --> 39:04.120
 So what about time travel?

39:04.120 --> 39:10.760
 Okay, I'm not as convinced yet.

39:10.760 --> 39:14.240
 No, I think it is solvable.

39:14.240 --> 39:16.880
 I mean, I think that it's, first of all,

39:16.880 --> 39:18.400
 it's about getting machines to learn.

39:18.400 --> 39:20.520
 Learning is fundamental.

39:20.520 --> 39:22.520
 And I think we're already in a place

39:22.520 --> 39:24.200
 that we understand, for example,

39:24.200 --> 39:27.800
 how machines can learn in various ways.

39:27.800 --> 39:31.600
 Right now, our learning stuff is sort of primitive

39:31.600 --> 39:37.200
 in that we haven't sort of taught machines

39:37.200 --> 39:38.600
 to learn the frameworks.

39:38.600 --> 39:40.520
 We don't communicate our frameworks

39:40.520 --> 39:42.200
 because of how shared there are some cases we do,

39:42.200 --> 39:45.560
 but we don't annotate, if you will,

39:45.560 --> 39:48.200
 all the data in the world with the frameworks

39:48.200 --> 39:52.200
 that are inherent or underlying our understanding.

39:52.200 --> 39:55.200
 Instead, we just operate with the data.

39:55.200 --> 39:58.200
 So if we want to be able to reason over the data

39:58.200 --> 40:01.200
 in similar terms in the common frameworks,

40:01.200 --> 40:03.200
 we need to be able to teach the computer,

40:03.200 --> 40:06.200
 or at least we need to program the computer

40:06.200 --> 40:08.200
 to acquire, to have access to

40:08.200 --> 40:12.200
 and acquire, learn the frameworks as well

40:12.200 --> 40:15.200
 and connect the frameworks to the data.

40:15.200 --> 40:17.200
 I think this can be done

40:17.200 --> 40:22.200
 I think we can start, I think machine learning,

40:22.200 --> 40:25.200
 for example, with enough examples,

40:25.200 --> 40:28.200
 can start to learn these basic dynamics.

40:28.200 --> 40:32.200
 Will they relate them necessarily to gravity,

40:32.200 --> 40:37.200
 not unless they can also acquire those theories as well

40:37.200 --> 40:40.200
 and put the experiential knowledge

40:40.200 --> 40:43.200
 and connect it back to the theoretical knowledge.

40:43.200 --> 40:46.200
 I think if we think in terms of these class of architectures,

40:46.200 --> 40:50.200
 that are designed to both learn the specifics,

40:50.200 --> 40:53.200
 find the patterns, but also acquire the frameworks

40:53.200 --> 40:55.200
 and connect the data to the frameworks,

40:55.200 --> 40:59.200
 if we think in terms of robust architectures like this,

40:59.200 --> 41:02.200
 I think there is a path toward getting there.

41:02.200 --> 41:05.200
 In terms of encoding architectures like that,

41:05.200 --> 41:09.200
 do you think systems that are able to do this

41:09.200 --> 41:11.200
 will look like neural networks

41:11.200 --> 41:16.200
 or representing, if you look back to the 80s and 90s

41:16.200 --> 41:18.200
 of the expert systems,

41:18.200 --> 41:23.200
 so more like graphs, systems that are based in logic,

41:23.200 --> 41:26.200
 able to contain a large amount of knowledge

41:26.200 --> 41:28.200
 where the challenge was the automated acquisition

41:28.200 --> 41:29.200
 of that knowledge.

41:29.200 --> 41:31.200
 I guess the question is,

41:31.200 --> 41:33.200
 when you collect both the frameworks

41:33.200 --> 41:35.200
 and the knowledge from the data,

41:35.200 --> 41:37.200
 what do you think that thing will look like?

41:37.200 --> 41:39.200
 I think asking the question,

41:39.200 --> 41:41.200
 they look like neural networks is a bit of a red herring.

41:41.200 --> 41:45.200
 I think that they will certainly do inductive

41:45.200 --> 41:47.200
 or pattern match based reasoning.

41:47.200 --> 41:49.200
 I've already experimented with architectures

41:49.200 --> 41:52.200
 that combine both that use machine learning

41:52.200 --> 41:55.200
 and neural networks to learn certain classes of knowledge

41:55.200 --> 41:57.200
 in order to find repeated patterns

41:57.200 --> 42:01.200
 in order for it to make good inductive guesses,

42:01.200 --> 42:05.200
 but then ultimately to try to take those learnings

42:05.200 --> 42:09.200
 and marry them, in other words, connect them to frameworks

42:09.200 --> 42:11.200
 so that it can then reason over that

42:11.200 --> 42:13.200
 in terms other humans understand.

42:13.200 --> 42:16.200
 For example, at Elemental Cognition, we do both.

42:16.200 --> 42:18.200
 We have architectures that do both,

42:18.200 --> 42:20.200
 but both those things,

42:20.200 --> 42:22.200
 but also have a learning method

42:22.200 --> 42:24.200
 for acquiring the frameworks themselves

42:24.200 --> 42:27.200
 and saying, look, ultimately, I need to take this data.

42:27.200 --> 42:30.200
 I need to interpret it in the form of these frameworks

42:30.200 --> 42:31.200
 so they can reason over it.

42:31.200 --> 42:33.200
 There is a fundamental knowledge representation,

42:33.200 --> 42:36.200
 like you saying, like these graphs of logic, if you will.

42:36.200 --> 42:39.200
 There are also neural networks

42:39.200 --> 42:42.200
 that acquire certain class of information.

42:42.200 --> 42:45.200
 Then they align them with these frameworks,

42:45.200 --> 42:49.200
 but there's also a mechanism to acquire the frameworks themselves.

42:49.200 --> 42:52.200
 It seems like the idea of frameworks

42:52.200 --> 42:55.200
 requires some kind of collaboration with humans.

42:55.200 --> 42:56.200
 Absolutely.

42:56.200 --> 42:59.200
 Do you think of that collaboration as different?

42:59.200 --> 43:01.200
 Let's be clear.

43:01.200 --> 43:04.200
 Only for the express purpose

43:04.200 --> 43:07.200
 that you're designing machine,

43:07.200 --> 43:09.200
 you're designing an intelligence

43:09.200 --> 43:12.200
 that can ultimately communicate with humans

43:12.200 --> 43:14.200
 in the terms of frameworks

43:14.200 --> 43:17.200
 that help them understand things.

43:17.200 --> 43:19.200
 To be really clear,

43:19.200 --> 43:22.200
 you can independently create

43:22.200 --> 43:24.200
 a machine learning system

43:24.200 --> 43:26.200
 and intelligence

43:26.200 --> 43:28.200
 that I might call an alien intelligence

43:28.200 --> 43:30.200
 that does a better job than you would some things,

43:30.200 --> 43:33.200
 but can't explain the framework to you.

43:33.200 --> 43:36.200
 That doesn't mean it might be better than you at the thing.

43:36.200 --> 43:39.200
 It might be that you cannot comprehend the framework

43:39.200 --> 43:41.200
 that it may have created for itself

43:41.200 --> 43:43.200
 that is inexplicable to you.

43:43.200 --> 43:45.200
 That's a reality.

43:45.200 --> 43:48.200
 But you're more interested in a case where you can.

43:48.200 --> 43:50.200
 I am.

43:50.200 --> 43:53.200
 My sort of approach to AI

43:53.200 --> 43:56.200
 is because I've set the goal for myself.

43:56.200 --> 43:59.200
 I want machines to be able to ultimately communicate

43:59.200 --> 44:01.200
 understanding with humans.

44:01.200 --> 44:03.200
 I want them to be able to acquire and communicate.

44:03.200 --> 44:05.200
 Acquire knowledge from humans

44:05.200 --> 44:07.200
 and communicate knowledge to humans.

44:07.200 --> 44:09.200
 They should be using

44:09.200 --> 44:11.200
 what inductive

44:11.200 --> 44:13.200
 machine learning techniques are good at,

44:13.200 --> 44:15.200
 which is to observe

44:15.200 --> 44:17.200
 patterns of data,

44:17.200 --> 44:19.200
 whether it be in language or whether it be in images

44:19.200 --> 44:21.200
 or videos or whatever,

44:23.200 --> 44:25.200
 to acquire these patterns

44:25.200 --> 44:27.200
 to induce

44:27.200 --> 44:29.200
 the generalizations from those patterns,

44:29.200 --> 44:31.200
 but then ultimately to work with humans

44:31.200 --> 44:33.200
 to connect them to frameworks,

44:33.200 --> 44:35.200
 interpretations, if you will,

44:35.200 --> 44:37.200
 that ultimately make sense to humans.

44:37.200 --> 44:39.200
 Of course, the machine is going to have the strength

44:39.200 --> 44:41.200
 that it has, the richer and longer memory,

44:41.200 --> 44:43.200
 but it has

44:43.200 --> 44:45.200
 the more rigorous reasoning abilities,

44:45.200 --> 44:47.200
 the deeper reasoning abilities,

44:47.200 --> 44:49.200
 so it'll be an interesting

44:49.200 --> 44:51.200
 complementary relationship

44:51.200 --> 44:53.200
 between the human and the machine.

44:53.200 --> 44:55.200
 Do you think that ultimately needs explainability,

44:55.200 --> 44:57.200
 like a machine?

44:57.200 --> 44:59.200
 If you study, for example, Tesla autopilot a lot,

44:59.200 --> 45:01.200
 where humans,

45:01.200 --> 45:03.200
 I don't know if you've driven the vehicle

45:03.200 --> 45:05.200
 or are aware of...

45:05.200 --> 45:07.200
 You're basically

45:07.200 --> 45:09.200
 the human

45:09.200 --> 45:11.200
 and machine are working together there,

45:11.200 --> 45:13.200
 and the human is responsible for their own life

45:13.200 --> 45:15.200
 to monitor the system,

45:15.200 --> 45:17.200
 and the system fails

45:17.200 --> 45:19.200
 every few miles.

45:19.200 --> 45:21.200
 There's hundreds,

45:21.200 --> 45:23.200
 there's millions of those failures

45:23.200 --> 45:25.200
 and so that's like a moment

45:25.200 --> 45:27.200
 of interaction. Do you see...

45:27.200 --> 45:29.200
 That's exactly right. That's a moment of interaction

45:29.200 --> 45:31.200
 where

45:31.200 --> 45:33.200
 the machine has learned some stuff,

45:35.200 --> 45:37.200
 it has a failure,

45:37.200 --> 45:39.200
 somehow the failure is communicated,

45:39.200 --> 45:41.200
 the human is now filling in

45:41.200 --> 45:43.200
 the mistake, if you will, or maybe correcting

45:43.200 --> 45:45.200
 or doing something that is more successful in that case,

45:45.200 --> 45:47.200
 the computer takes that learning.

45:47.200 --> 45:49.200
 So I believe

45:49.200 --> 45:51.200
 that the collaboration between human

45:51.200 --> 45:53.200
 and machine,

45:53.200 --> 45:55.200
 that's sort of a primitive example

45:55.200 --> 45:57.200
 and sort of a more...

45:57.200 --> 45:59.200
 Another example is where the machine

45:59.200 --> 46:01.200
 is literally talking to you and saying,

46:01.200 --> 46:03.200
 look, I'm reading this thing.

46:03.200 --> 46:05.200
 I know that

46:05.200 --> 46:07.200
 the next word might be this or that,

46:07.200 --> 46:09.200
 but I don't really understand why.

46:09.200 --> 46:11.200
 I have my guess.

46:11.200 --> 46:13.200
 Can you help me understand the framework

46:13.200 --> 46:15.200
 that supports this

46:15.200 --> 46:17.200
 and then can kind of acquire that,

46:17.200 --> 46:19.200
 take that and reason about it and reuse it?

46:19.200 --> 46:21.200
 Try to understand something.

46:21.200 --> 46:23.200
 Not unlike

46:23.200 --> 46:25.200
 a human student might do.

46:25.200 --> 46:27.200
 I remember when my daughter was in first grade

46:27.200 --> 46:29.200
 and she had a

46:29.200 --> 46:31.200
 reading assignment about electricity

46:31.200 --> 46:33.200
 and

46:33.200 --> 46:35.200
 somewhere in the text it says

46:35.200 --> 46:37.200
 an electricity is produced by water

46:37.200 --> 46:39.200
 flowing over turbines or something like that.

46:39.200 --> 46:41.200
 And then there's a question that says,

46:41.200 --> 46:43.200
 well, how is the electricity created?

46:43.200 --> 46:45.200
 And so my daughter comes to me and says,

46:45.200 --> 46:47.200
 I mean, I could create it and produce

46:47.200 --> 46:49.200
 or kind of send it in this case.

46:49.200 --> 46:51.200
 So I can go back to the text and I can copy

46:51.200 --> 46:53.200
 by water flowing over turbines.

46:53.200 --> 46:55.200
 But I have no idea what that means.

46:55.200 --> 46:57.200
 Like, I don't know how to

46:57.200 --> 46:59.200
 interpret water flowing over turbines

46:59.200 --> 47:01.200
 and what electricity even is. I mean, I can get the

47:01.200 --> 47:03.200
 answer right by matching the text.

47:03.200 --> 47:05.200
 But I don't have any framework

47:05.200 --> 47:07.200
 for understanding what this means at all.

47:07.200 --> 47:09.200
 And framework, really,

47:09.200 --> 47:11.200
 I mean, it's a set of not to be mathematical,

47:11.200 --> 47:13.200
 but axioms of

47:13.200 --> 47:15.200
 ideas that you bring to the table

47:15.200 --> 47:17.200
 and interpreting stuff and then you build those up

47:17.200 --> 47:19.200
 somehow.

47:19.200 --> 47:21.200
 You build them up with the expectation that

47:21.200 --> 47:23.200
 there's a shared understanding of what

47:23.200 --> 47:25.200
 they are.

47:25.200 --> 47:27.200
 Yeah, it's the social that us humans

47:27.200 --> 47:29.200
 do you

47:29.200 --> 47:31.200
 have a sense that humans on earth

47:31.200 --> 47:33.200
 in general share a set of

47:33.200 --> 47:35.200
 like how many frameworks are there?

47:35.200 --> 47:37.200
 I mean, it depends on how

47:37.200 --> 47:39.200
 you bound them, right? So in other words, how

47:39.200 --> 47:41.200
 big or small like their individual scope.

47:41.200 --> 47:43.200
 But there's lots

47:43.200 --> 47:45.200
 and there are new ones. I think

47:45.200 --> 47:47.200
 the way I think about is kind of in a

47:47.200 --> 47:49.200
 layer. I think that the architect is being layered

47:49.200 --> 47:51.200
 in that there's a small

47:51.200 --> 47:53.200
 set of primitives

47:53.200 --> 47:55.200
 that allow you the foundation to build

47:55.200 --> 47:57.200
 frameworks. And then there may be

47:57.200 --> 47:59.200
 many frameworks, but you have the ability

47:59.200 --> 48:01.200
 to acquire them. And then you have the ability

48:01.200 --> 48:03.200
 to reuse them.

48:03.200 --> 48:05.200
 I mean, one of the most compelling ways of thinking

48:05.200 --> 48:07.200
 about this is reasoning by analogy

48:07.200 --> 48:09.200
 where I can say, oh, wow, I've learned something very

48:09.200 --> 48:11.200
 similar.

48:11.200 --> 48:13.200
 I never heard of this. I never heard of this

48:13.200 --> 48:15.200
 game soccer.

48:15.200 --> 48:17.200
 But if it's like basketball

48:17.200 --> 48:19.200
 in the sense that the goals like the hoop

48:19.200 --> 48:21.200
 and I have to get the ball in the hoop and I

48:21.200 --> 48:23.200
 have guards and I have this and I have that

48:23.200 --> 48:25.200
 like where does the

48:25.200 --> 48:27.200
 where the similarities and where the differences

48:27.200 --> 48:29.200
 and I have a foundation now for

48:29.200 --> 48:31.200
 interpreting this new information.

48:31.200 --> 48:33.200
 And then the different groups

48:33.200 --> 48:35.200
 like the millennials will have a framework

48:35.200 --> 48:37.200
 and then then

48:37.200 --> 48:39.200
 well, that you know, yeah, well

48:39.200 --> 48:41.200
 Democrats and Republicans

48:41.200 --> 48:43.200
 millennials, nobody wants that framework.

48:43.200 --> 48:45.200
 Well, I mean, I think

48:45.200 --> 48:47.200
 right. I mean, we're talking about political

48:47.200 --> 48:49.200
 and social ways of interpreting the world around

48:49.200 --> 48:51.200
 them. And I think these frameworks are

48:51.200 --> 48:53.200
 still largely, largely similar. I think they

48:53.200 --> 48:55.200
 differ in maybe what some fundamental

48:55.200 --> 48:57.200
 assumptions and values are.

48:57.200 --> 48:59.200
 Now, from a reasoning

48:59.200 --> 49:01.200
 perspective, like the ability to process the

49:01.200 --> 49:03.200
 framework, it might not be that

49:03.200 --> 49:05.200
 different. The implications of different

49:05.200 --> 49:07.200
 fundamental values or fundamental assumptions

49:07.200 --> 49:09.200
 in those framework

49:09.200 --> 49:11.200
 frameworks may reach very different conclusions.

49:11.200 --> 49:13.200
 So from

49:13.200 --> 49:15.200
 a social perspective, the conclusions

49:15.200 --> 49:17.200
 may be very different. From an intelligence

49:17.200 --> 49:19.200
 perspective, I

49:19.200 --> 49:21.200
 just followed where my assumptions took me.

49:21.200 --> 49:23.200
 Yeah, the process itself looks similar,

49:23.200 --> 49:25.200
 but that's a fascinating idea

49:25.200 --> 49:27.200
 that

49:27.200 --> 49:29.200
 frameworks really

49:29.200 --> 49:31.200
 help carve

49:31.200 --> 49:33.200
 how a statement will be interpreted.

49:33.200 --> 49:35.200
 I mean, having

49:35.200 --> 49:37.200
 a Democrat

49:37.200 --> 49:39.200
 and a Republican

49:39.200 --> 49:41.200
 framework

49:41.200 --> 49:43.200
 and read the exact same statement and the conclusions

49:43.200 --> 49:45.200
 that you derive will be totally different

49:45.200 --> 49:47.200
 from an AI perspective is fascinating.

49:47.200 --> 49:49.200
 What we would want out of the AI

49:49.200 --> 49:51.200
 is to be able to tell you

49:51.200 --> 49:53.200
 that this perspective, one

49:53.200 --> 49:55.200
 perspective, one set of assumptions is going to lead

49:55.200 --> 49:57.200
 you here, another set of assumptions is going to lead

49:57.200 --> 49:59.200
 you there.

49:59.200 --> 50:01.200
 And in fact, you know, to help people

50:01.200 --> 50:03.200
 reason and say, oh, I see where

50:03.200 --> 50:05.200
 our differences lie.

50:05.200 --> 50:07.200
 I have this fundamental belief about that.

50:07.200 --> 50:09.200
 I have this fundamental belief about that.

50:09.200 --> 50:11.200
 Yeah, that's quite brilliant. From my perspective

50:11.200 --> 50:13.200
 NLP, there's this idea

50:13.200 --> 50:15.200
 that there's one way to really understand a statement.

50:15.200 --> 50:17.200
 But

50:17.200 --> 50:19.200
 there probably isn't. There's probably

50:19.200 --> 50:21.200
 an infinite number of ways to understand a statement.

50:21.200 --> 50:23.200
 Well, there's lots of different interpretations

50:25.200 --> 50:27.200
 and the broader

50:27.200 --> 50:29.200
 the content

50:29.200 --> 50:31.200
 that Richard is

50:31.200 --> 50:33.200
 and so, you know, you

50:33.200 --> 50:35.200
 and I can have very different experiences

50:35.200 --> 50:37.200
 with the same text obviously

50:37.200 --> 50:39.200
 and

50:39.200 --> 50:41.200
 if we're committed to understanding each other

50:41.200 --> 50:43.200
 we start

50:43.200 --> 50:45.200
 and that's the other important point like

50:45.200 --> 50:47.200
 if we're committed to understanding each other

50:47.200 --> 50:49.200
 we start decomposing

50:49.200 --> 50:51.200
 and breaking down our interpretation

50:51.200 --> 50:53.200
 towards more and more primitive components

50:53.200 --> 50:55.200
 until we get to that

50:55.200 --> 50:57.200
 point where we say, oh, I see why we disagree

50:57.200 --> 50:59.200
 and we try to

50:59.200 --> 51:01.200
 understand how fundamental that disagreement really is.

51:01.200 --> 51:03.200
 But that requires

51:03.200 --> 51:05.200
 a commitment to breaking down

51:05.200 --> 51:07.200
 that interpretation in terms of that

51:07.200 --> 51:09.200
 framework in a logical way.

51:09.200 --> 51:11.200
 Otherwise, you know, and this is why

51:11.200 --> 51:13.200
 I think of AIs as really

51:13.200 --> 51:15.200
 complimenting and helping human intelligence

51:15.200 --> 51:17.200
 to overcome some of its biases

51:17.200 --> 51:19.200
 and its predisposition

51:19.200 --> 51:21.200
 to be persuaded

51:21.200 --> 51:23.200
 by, you know,

51:23.200 --> 51:25.200
 by more shallow reasoning

51:25.200 --> 51:27.200
 in the sense that like we get over this idea

51:27.200 --> 51:29.200
 you know, I'm right

51:29.200 --> 51:31.200
 because I'm Republican or I'm right because I'm Democratic

51:31.200 --> 51:33.200
 and someone labeled this as Democratic point of view

51:33.200 --> 51:35.200
 or it has the following keywords in it

51:35.200 --> 51:37.200
 and if the machine can help us

51:37.200 --> 51:39.200
 break that argument down and say, wait a second,

51:39.200 --> 51:41.200
 you know, what do you really

51:41.200 --> 51:43.200
 think about this, right? So, essentially

51:43.200 --> 51:45.200
 holding us accountable

51:45.200 --> 51:47.200
 to doing more critical thinking.

51:47.200 --> 51:49.200
 We're not just sitting and thinking about that as fast

51:49.200 --> 51:51.200
 and that's, I love that.

51:51.200 --> 51:53.200
 I think that's really empowering use of AI

51:53.200 --> 51:55.200
 for the public discourse that's completely

51:55.200 --> 51:57.200
 disintegrating

51:57.200 --> 51:59.200
 currently as we

51:59.200 --> 52:01.200
 learn how to do it on social media.

52:01.200 --> 52:03.200
 So,

52:03.200 --> 52:05.200
 one of the greatest accomplishments

52:05.200 --> 52:07.200
 in the history of AI

52:07.200 --> 52:09.200
 is

52:09.200 --> 52:11.200
 Watson

52:11.200 --> 52:13.200
 competing in a game of Jeopardy against humans

52:13.200 --> 52:15.200
 and you were

52:15.200 --> 52:17.200
 a lead in that

52:17.200 --> 52:19.200
 a critical part of that.

52:19.200 --> 52:21.200
 Let's start at the very basics. What is the game of Jeopardy?

52:21.200 --> 52:23.200
 The game

52:23.200 --> 52:25.200
 for us humans, human versus human.

52:25.200 --> 52:27.200
 Right. So,

52:27.200 --> 52:29.200
 it's to take a

52:29.200 --> 52:31.200
 question

52:31.200 --> 52:33.200
 and answer it.

52:33.200 --> 52:35.200
 The game of Jeopardy. Well,

52:35.200 --> 52:37.200
 actually, it's the opposite.

52:37.200 --> 52:39.200
 Well, no, but it's not, right?

52:39.200 --> 52:41.200
 It's really not. It's really to get a question

52:41.200 --> 52:43.200
 and answer but it's what we call a factoid

52:43.200 --> 52:45.200
 question. So, this notion of like

52:45.200 --> 52:47.200
 it really relates to some fact that

52:47.200 --> 52:49.200
 a few people would argue

52:49.200 --> 52:51.200
 whether the facts are true or not. In fact,

52:51.200 --> 52:53.200
 what in Jeopardy kind of counts on the idea that

52:53.200 --> 52:55.200
 these statements

52:55.200 --> 52:57.200
 have factual answers

52:57.200 --> 52:59.200
 and

52:59.200 --> 53:01.200
 the idea is

53:01.200 --> 53:03.200
 to first of all determine whether or not you know

53:03.200 --> 53:05.200
 the answer which is sort of an interesting twist.

53:05.200 --> 53:07.200
 So, first of all, understand the question.

53:07.200 --> 53:09.200
 You have to understand the question. What is it

53:09.200 --> 53:11.200
 asking and that's a good point because

53:11.200 --> 53:13.200
 the questions are not

53:13.200 --> 53:15.200
 asked directly, right? They're all like

53:15.200 --> 53:17.200
 the way the questions are asked is

53:17.200 --> 53:19.200
 nonlinear. It's like

53:19.200 --> 53:21.200
 it's a little bit witty. It's a little bit

53:21.200 --> 53:23.200
 playful sometimes.

53:23.200 --> 53:25.200
 It's a little bit tricky.

53:25.200 --> 53:27.200
 Yeah, they're asking

53:27.200 --> 53:29.200
 exactly in numerous witty, tricky ways

53:29.200 --> 53:31.200
 exactly what

53:31.200 --> 53:33.200
 they're asking is not obvious. It takes

53:33.200 --> 53:35.200
 inexperienced humans a while to go,

53:35.200 --> 53:37.200
 what is it even asking? Right.

53:37.200 --> 53:39.200
 And it's sort of an interesting realization that

53:39.200 --> 53:41.200
 you have when somebody says, oh, what's the

53:41.200 --> 53:43.200
 Jeopardy! is a question answering show and they say, oh,

53:43.200 --> 53:45.200
 like I know a lot and then you read it and

53:45.200 --> 53:47.200
 you're still trying to process the question

53:47.200 --> 53:49.200
 and the champions have answered and moved on.

53:49.200 --> 53:51.200
 There are three questions ahead

53:51.200 --> 53:53.200
 by the time you figured out what the question

53:53.200 --> 53:55.200
 even meant. So, there's definitely

53:55.200 --> 53:57.200
 an ability there to just

53:57.200 --> 53:59.200
 parse out what the question even is.

53:59.200 --> 54:01.200
 So, that was certainly challenging. It's

54:01.200 --> 54:03.200
 interesting historically though if you look back

54:03.200 --> 54:05.200
 at the Jeopardy! games much earlier

54:05.200 --> 54:07.200
 you know, like 60s, 70s, that kind of thing.

54:07.200 --> 54:09.200
 The questions were much more direct.

54:09.200 --> 54:11.200
 They weren't quite like that.

54:11.200 --> 54:13.200
 They got sort of more and more interesting

54:13.200 --> 54:15.200
 the way they asked them that sort of got

54:15.200 --> 54:17.200
 more and more interesting and subtle

54:17.200 --> 54:19.200
 and nuanced and humorous and

54:19.200 --> 54:21.200
 witty over time which really

54:21.200 --> 54:23.200
 required the human to kind of make

54:23.200 --> 54:25.200
 the right connections in figuring out what the question

54:25.200 --> 54:27.200
 was even asking. So, yeah,

54:27.200 --> 54:29.200
 you have to figure out the questions even asking.

54:29.200 --> 54:31.200
 Then you have to

54:31.200 --> 54:33.200
 determine whether or not you think you know the answer

54:33.200 --> 54:35.200
 and

54:35.200 --> 54:37.200
 because you have to buzz in really quickly

54:37.200 --> 54:39.200
 you sort of have to make that determination

54:39.200 --> 54:41.200
 as quickly as you possibly can

54:41.200 --> 54:43.200
 otherwise you lose the opportunity to buzz in.

54:43.200 --> 54:45.200
 Even before you really know

54:45.200 --> 54:47.200
 if you know the answer. I think a lot of humans

54:47.200 --> 54:49.200
 will assume they'll

54:49.200 --> 54:51.200
 look at it.

54:51.200 --> 54:53.200
 They'll process it very superficially. In other words,

54:53.200 --> 54:55.200
 what's the topic? What are some

54:55.200 --> 54:57.200
 keywords and just say do I know

54:57.200 --> 54:59.200
 this area or not before they actually

54:59.200 --> 55:01.200
 know the answer? Then they'll buzz

55:01.200 --> 55:03.200
 in and think about it.

55:03.200 --> 55:05.200
 It's interesting what humans do. Now some

55:05.200 --> 55:07.200
 people who know all things like

55:07.200 --> 55:09.200
 Ken Jennings or something or the more recent

55:09.200 --> 55:11.200
 Big Jeopardy! player

55:11.200 --> 55:13.200
 they'll just assume they know all the Jeopardy!

55:13.200 --> 55:15.200
 and they'll just suppose that.

55:15.200 --> 55:17.200
 Watson interestingly

55:17.200 --> 55:19.200
 didn't even come close to knowing all of

55:19.200 --> 55:21.200
 Jeopardy!

55:21.200 --> 55:23.200
 Even at the peak.

55:23.200 --> 55:25.200
 So, for example, we had this thing called Recall

55:25.200 --> 55:27.200
 which is how many

55:27.200 --> 55:29.200
 of all the Jeopardy! questions

55:29.200 --> 55:31.200
 how many could we even

55:31.200 --> 55:33.200
 find the right answer

55:33.200 --> 55:35.200
 for anywhere?

55:35.200 --> 55:37.200
 Can we come up with if we had

55:37.200 --> 55:39.200
 a big body of knowledge in the order of several

55:39.200 --> 55:41.200
 ways? I mean, from a web

55:41.200 --> 55:43.200
 scale was actually very small.

55:43.200 --> 55:45.200
 But from a book scale, I was talking about

55:45.200 --> 55:47.200
 millions of books.

55:47.200 --> 55:49.200
 Equally millions of books.

55:49.200 --> 55:51.200
 Cyclopedias, dictionaries, books.

55:51.200 --> 55:53.200
 It's still a ton of information.

55:53.200 --> 55:55.200
 I think it was only

55:55.200 --> 55:57.200
 85% was the answer anywhere to be found.

55:57.200 --> 55:59.200
 So you're

55:59.200 --> 56:01.200
 ready down at that level just

56:01.200 --> 56:03.200
 to get started.

56:03.200 --> 56:05.200
 And so it was important

56:05.200 --> 56:07.200
 to get a very

56:07.200 --> 56:09.200
 quick sense of do you think you know the right

56:09.200 --> 56:11.200
 answer to this question? So we had to compute that

56:11.200 --> 56:13.200
 confidence as quickly as we

56:13.200 --> 56:15.200
 possibly could. So in effect

56:15.200 --> 56:17.200
 we had to answer it.

56:17.200 --> 56:19.200
 And at least

56:19.200 --> 56:21.200
 spend some time essentially answering

56:21.200 --> 56:23.200
 it. And then judging

56:23.200 --> 56:25.200
 the confidence that we, you know, that

56:25.200 --> 56:27.200
 our answer was right. And then deciding

56:27.200 --> 56:29.200
 whether or not we were confident enough to buzz

56:29.200 --> 56:31.200
 in. And that would depend on what else

56:31.200 --> 56:33.200
 was going on in the game because it was a risk.

56:33.200 --> 56:35.200
 So like if you're really in a situation

56:35.200 --> 56:37.200
 where I have to take a guess, I have very little

56:37.200 --> 56:39.200
 to lose, then you'll buzz in with less

56:39.200 --> 56:41.200
 confidence. So that was a counter for

56:41.200 --> 56:43.200
 the financial standings of the different

56:43.200 --> 56:45.200
 competitors. Correct.

56:45.200 --> 56:47.200
 How much of the game was left, how much time

56:47.200 --> 56:49.200
 was left, where you were in the standing

56:49.200 --> 56:51.200
 and things like that. What, how many

56:51.200 --> 56:53.200
 hundreds of milliseconds that we're talking

56:53.200 --> 56:55.200
 about here? Do you have a sense of

56:55.200 --> 56:57.200
 what is... We targeted

56:57.200 --> 56:59.200
 what's the target? So

56:59.200 --> 57:01.200
 I mean we targeted answering

57:01.200 --> 57:03.200
 in under three seconds

57:03.200 --> 57:05.200
 and...

57:05.200 --> 57:07.200
 So the decision to

57:07.200 --> 57:09.200
 buzz in and then the actual

57:09.200 --> 57:11.200
 answering, are those two different

57:11.200 --> 57:13.200
 stages? Yeah, they were two different things. In fact, we

57:13.200 --> 57:15.200
 had multiple stages, whereas like we

57:15.200 --> 57:17.200
 would say let's estimate our confidence

57:17.200 --> 57:19.200
 which was sort of a shallow

57:19.200 --> 57:21.200
 answering process.

57:21.200 --> 57:23.200
 And then ultimately

57:23.200 --> 57:25.200
 decide to buzz in and then we may take another

57:25.200 --> 57:27.200
 second or something

57:27.200 --> 57:29.200
 to kind of go in there and

57:29.200 --> 57:31.200
 do that. But by

57:31.200 --> 57:33.200
 and large we're saying like we can't play the game.

57:33.200 --> 57:35.200
 We can't even

57:35.200 --> 57:37.200
 compete if we can't

57:37.200 --> 57:39.200
 on average answer these questions in around

57:39.200 --> 57:41.200
 three seconds or less. So you

57:41.200 --> 57:43.200
 stepped in, so there's this, there's these

57:43.200 --> 57:45.200
 three humans playing a game

57:45.200 --> 57:47.200
 and you stepped in with the idea that

57:47.200 --> 57:49.200
 IBM Watson would be one of, replace

57:49.200 --> 57:51.200
 one of the humans and compete against

57:51.200 --> 57:53.200
 two. Can you tell the story

57:53.200 --> 57:55.200
 of Watson taking

57:55.200 --> 57:57.200
 on this game? Sure.

57:57.200 --> 57:59.200
 Seems exceptionally difficult. Yeah.

57:59.200 --> 58:01.200
 So the story

58:01.200 --> 58:03.200
 was that

58:03.200 --> 58:05.200
 it was coming up I think to the 10 year anniversary

58:05.200 --> 58:07.200
 of Big Blue.

58:07.200 --> 58:09.200
 Deep Blue. IBM

58:09.200 --> 58:11.200
 wanted to do sort of another kind of

58:11.200 --> 58:13.200
 really fun challenge, public

58:13.200 --> 58:15.200
 challenge that can bring attention

58:15.200 --> 58:17.200
 to IBM research and the kind of the cool stuff

58:17.200 --> 58:19.200
 that we were doing.

58:19.200 --> 58:21.200
 I had been working in

58:21.200 --> 58:23.200
 AI at IBM for some time.

58:23.200 --> 58:25.200
 I had a team doing

58:25.200 --> 58:27.200
 what's called open domain

58:27.200 --> 58:29.200
 factoid question answering, which is

58:29.200 --> 58:31.200
 we're not going to tell you what the questions are.

58:31.200 --> 58:33.200
 We're not even going to tell you what they're about.

58:33.200 --> 58:35.200
 Can you go off and get accurate answers

58:35.200 --> 58:37.200
 to these questions?

58:37.200 --> 58:39.200
 And it was an area of

58:39.200 --> 58:41.200
 AI research that I was involved in.

58:41.200 --> 58:43.200
 And so it was a big, it was a very

58:43.200 --> 58:45.200
 specific passion of mine. Language understanding

58:45.200 --> 58:47.200
 had always been a passion of mine.

58:47.200 --> 58:49.200
 One sort of narrow slice on

58:49.200 --> 58:51.200
 whether or not you could do anything with language was

58:51.200 --> 58:53.200
 this notion of open domain and meaning I could

58:53.200 --> 58:55.200
 ask anything about anything. Factoid

58:55.200 --> 58:57.200
 meaning it essentially had an answer

58:57.200 --> 58:59.200
 and

58:59.200 --> 59:01.200
 being able to do that accurately and quickly.

59:01.200 --> 59:03.200
 So that was a research area that my team had already been

59:03.200 --> 59:05.200
 in. And so completely independently

59:05.200 --> 59:07.200
 several IBM

59:07.200 --> 59:09.200
 executives were like, what are we going to do?

59:09.200 --> 59:11.200
 What's the next cool thing to do?

59:11.200 --> 59:13.200
 And Ken Jennings was on his winning

59:13.200 --> 59:15.200
 streak. This was like whatever

59:15.200 --> 59:17.200
 was 2004, I think, was on his

59:17.200 --> 59:19.200
 winning streak. And someone

59:19.200 --> 59:21.200
 thought, hey, that would be really cool

59:21.200 --> 59:23.200
 if the computer can play Jeopardy.

59:23.200 --> 59:25.200
 And so this was like

59:25.200 --> 59:27.200
 in 2004, they were shopping this thing around

59:27.200 --> 59:29.200
 and everyone

59:29.200 --> 59:31.200
 was telling the research

59:31.200 --> 59:33.200
 execs, no way.

59:33.200 --> 59:35.200
 Like, this is crazy.

59:35.200 --> 59:37.200
 And we had some pretty senior people in the field

59:37.200 --> 59:39.200
 saying, no, this is crazy. And it would come across my

59:39.200 --> 59:41.200
 desk and I was like, but that's kind of what

59:41.200 --> 59:43.200
 I'm really interested in doing.

59:43.200 --> 59:45.200
 But there was

59:45.200 --> 59:47.200
 such this prevailing sense of this is

59:47.200 --> 59:49.200
 nuts, we're not going to risk IBM's reputation on

59:49.200 --> 59:51.200
 this, we're just not doing it. And this happened in

59:51.200 --> 59:53.200
 2004, it happened in 2005.

59:53.200 --> 59:55.200
 At the end of

59:55.200 --> 59:57.200
 2006,

59:57.200 --> 59:59.200
 it was coming around again

59:59.200 --> 1:00:01.200
 and I was coming off of a,

1:00:01.200 --> 1:00:03.200
 I was doing the open domain question answering

1:00:03.200 --> 1:00:05.200
 stuff, but I was coming off a couple other

1:00:05.200 --> 1:00:07.200
 projects. I had a lot more time

1:00:07.200 --> 1:00:09.200
 to put into this and I argued

1:00:09.200 --> 1:00:11.200
 that it could be done and I argued

1:00:11.200 --> 1:00:13.200
 it would be crazy not to do this.

1:00:13.200 --> 1:00:15.200
 Can I, you can be honest at this point.

1:00:15.200 --> 1:00:17.200
 So even though you argued for it,

1:00:17.200 --> 1:00:19.200
 what's the confidence that you had

1:00:19.200 --> 1:00:21.200
 yourself privately

1:00:21.200 --> 1:00:23.200
 that this could be done?

1:00:23.200 --> 1:00:25.200
 We just told the

1:00:25.200 --> 1:00:27.200
 story how you tell stories to convince others.

1:00:27.200 --> 1:00:29.200
 How confident were you? What was

1:00:29.200 --> 1:00:31.200
 your estimation of the problem

1:00:31.200 --> 1:00:33.200
 at that time? So I thought it was

1:00:33.200 --> 1:00:35.200
 possible and a lot of people

1:00:35.200 --> 1:00:37.200
 thought it was impossible. I thought it was possible.

1:00:37.200 --> 1:00:39.200
 The reason why I thought it was possible is

1:00:39.200 --> 1:00:41.200
 because I did some brief experimentation.

1:00:41.200 --> 1:00:43.200
 I knew a lot about how we were approaching

1:00:43.200 --> 1:00:45.200
 open domain factoid

1:00:45.200 --> 1:00:47.200
 question answering. We've been doing it for some years.

1:00:47.200 --> 1:00:49.200
 I looked at the Jafferty stuff.

1:00:49.200 --> 1:00:51.200
 I said this is going to be hard

1:00:51.200 --> 1:00:53.200
 for a lot of the points that

1:00:53.200 --> 1:00:55.200
 we mentioned earlier. Hard to interpret the question.

1:00:57.200 --> 1:00:59.200
 Hard to do it quickly enough. Hard

1:00:59.200 --> 1:01:01.200
 to compute an accurate confidence. None of this stuff

1:01:01.200 --> 1:01:03.200
 had been done well enough before.

1:01:03.200 --> 1:01:05.200
 But a lot of the technologies we're building with the kinds

1:01:05.200 --> 1:01:07.200
 of technologies that should work.

1:01:07.200 --> 1:01:09.200
 But more to the point

1:01:09.200 --> 1:01:11.200
 what was driving me was

1:01:11.200 --> 1:01:13.200
 I was an IBM research.

1:01:13.200 --> 1:01:15.200
 I was a senior leader in IBM research

1:01:15.200 --> 1:01:17.200
 and this is the kind of stuff we were supposed

1:01:17.200 --> 1:01:19.200
 to do.

1:01:19.200 --> 1:01:21.200
 We were supposed to take things

1:01:21.200 --> 1:01:23.200
 and say this is an active research

1:01:23.200 --> 1:01:25.200
 area.

1:01:25.200 --> 1:01:27.200
 It's our obligation

1:01:27.200 --> 1:01:29.200
 if we have the opportunity

1:01:29.200 --> 1:01:31.200
 to push it to the limits. And if it doesn't

1:01:31.200 --> 1:01:33.200
 work to understand more deeply

1:01:33.200 --> 1:01:35.200
 why we can't do it.

1:01:35.200 --> 1:01:37.200
 I was very committed to that notion

1:01:37.200 --> 1:01:39.200
 saying folks this is what we do.

1:01:39.200 --> 1:01:41.200
 It's crazy

1:01:41.200 --> 1:01:43.200
 not to do it. This is an active

1:01:43.200 --> 1:01:45.200
 research area. We've been in this for years.

1:01:45.200 --> 1:01:47.200
 Why wouldn't we take this grand challenge

1:01:47.200 --> 1:01:49.200
 and

1:01:49.200 --> 1:01:51.200
 push it as hard as we can.

1:01:51.200 --> 1:01:53.200
 At the very least we'd be able to come out and say

1:01:53.200 --> 1:01:55.200
 here's why this problem

1:01:55.200 --> 1:01:57.200
 is way hard.

1:01:57.200 --> 1:01:59.200
 Here's what we tried and here's how we failed.

1:01:59.200 --> 1:02:01.200
 I was very driven

1:02:01.200 --> 1:02:03.200
 as a scientist from that perspective

1:02:03.200 --> 1:02:05.200
 and then I also argued

1:02:05.200 --> 1:02:07.200
 based on

1:02:07.200 --> 1:02:09.200
 what we did a feasibility study.

1:02:09.200 --> 1:02:11.200
 Why I thought it was hard but possible

1:02:11.200 --> 1:02:13.200
 for us to take some sort of examples

1:02:13.200 --> 1:02:15.200
 of where it succeeded

1:02:15.200 --> 1:02:17.200
 where it failed, why it failed

1:02:17.200 --> 1:02:19.200
 and sort of a high level architectural approach

1:02:19.200 --> 1:02:21.200
 for why we should do it.

1:02:21.200 --> 1:02:23.200
 But for the most part at that point

1:02:23.200 --> 1:02:25.200
 the execs really were just looking for someone

1:02:25.200 --> 1:02:27.200
 crazy enough to say yes

1:02:27.200 --> 1:02:29.200
 because for several years at that point

1:02:29.200 --> 1:02:31.200
 everyone had said no.

1:02:31.200 --> 1:02:33.200
 I'm not willing to risk my reputation

1:02:33.200 --> 1:02:35.200
 and my career

1:02:35.200 --> 1:02:37.200
 on this thing.

1:02:37.200 --> 1:02:39.200
 Clearly you did not have such fears.

1:02:39.200 --> 1:02:41.200
 And yet

1:02:41.200 --> 1:02:43.200
 for what I understand

1:02:43.200 --> 1:02:45.200
 it was performing very poorly

1:02:45.200 --> 1:02:47.200
 in the beginning. So what were the

1:02:47.200 --> 1:02:49.200
 initial approaches and why did they fail?

1:02:51.200 --> 1:02:53.200
 Well, there were lots

1:02:53.200 --> 1:02:55.200
 of hard aspects to it.

1:02:55.200 --> 1:02:57.200
 One of the reasons why prior

1:02:57.200 --> 1:02:59.200
 approaches that we had worked

1:02:59.200 --> 1:03:01.200
 on in the past

1:03:01.200 --> 1:03:03.200
 failed was because

1:03:05.200 --> 1:03:07.200
 the questions were difficult

1:03:07.200 --> 1:03:09.200
 to interpret. What are you even asking for?

1:03:09.200 --> 1:03:11.200
 Very often

1:03:11.200 --> 1:03:13.200
 if the question was very direct

1:03:13.200 --> 1:03:15.200
 what city

1:03:15.200 --> 1:03:17.200
 even then it could be tricky

1:03:17.200 --> 1:03:19.200
 but what city

1:03:19.200 --> 1:03:21.200
 or what person

1:03:21.200 --> 1:03:23.200
 often when it would name it

1:03:23.200 --> 1:03:25.200
 very clearly you would know that.

1:03:25.200 --> 1:03:27.200
 And if there was just a small

1:03:27.200 --> 1:03:29.200
 set of them, in other words we're going to ask

1:03:29.200 --> 1:03:31.200
 about these five types.

1:03:31.200 --> 1:03:33.200
 It's going to be an answer

1:03:33.200 --> 1:03:35.200
 and the answer will be

1:03:35.200 --> 1:03:37.200
 a city in this state

1:03:37.200 --> 1:03:39.200
 or a city in this country. The answer will be

1:03:39.200 --> 1:03:41.200
 a person of this type

1:03:41.200 --> 1:03:43.200
 like an actor or whatever it is.

1:03:43.200 --> 1:03:45.200
 But turns out that in Jeopardy

1:03:45.200 --> 1:03:47.200
 there were like tens of thousands of these things

1:03:47.200 --> 1:03:49.200
 and it was a very, very long

1:03:49.200 --> 1:03:51.200
 tail.

1:03:51.200 --> 1:03:53.200
 Meaning it just went on and on

1:03:53.200 --> 1:03:55.200
 and so even if you focused on trying

1:03:55.200 --> 1:03:57.200
 to encode the types

1:03:57.200 --> 1:03:59.200
 at the very top like there's

1:03:59.200 --> 1:04:01.200
 five that were the most let's say five of the most frequent

1:04:01.200 --> 1:04:03.200
 you still cover a very small

1:04:03.200 --> 1:04:05.200
 range of the data. So you couldn't take

1:04:05.200 --> 1:04:07.200
 that approach of saying

1:04:07.200 --> 1:04:09.200
 I'm just going to try to collect facts

1:04:09.200 --> 1:04:11.200
 about these five

1:04:11.200 --> 1:04:13.200
 or ten types or twenty types or fifty types

1:04:13.200 --> 1:04:15.200
 or whatever. So

1:04:15.200 --> 1:04:17.200
 that was like one of the first things like

1:04:17.200 --> 1:04:19.200
 what do you do about that and so we came up

1:04:19.200 --> 1:04:21.200
 with an approach toward that

1:04:21.200 --> 1:04:23.200
 and the approach looked promising

1:04:23.200 --> 1:04:25.200
 and we continued to improve

1:04:25.200 --> 1:04:27.200
 our ability to handle

1:04:27.200 --> 1:04:29.200
 that problem throughout the project.

1:04:29.200 --> 1:04:31.200
 The other issue was that

1:04:31.200 --> 1:04:33.200
 right from the outside I said we're not

1:04:33.200 --> 1:04:35.200
 going to, I committed

1:04:35.200 --> 1:04:37.200
 to doing this in three to five years

1:04:37.200 --> 1:04:39.200
 so we did it in four

1:04:39.200 --> 1:04:41.200
 so I got lucky.

1:04:41.200 --> 1:04:43.200
 But one of the things that that putting that

1:04:43.200 --> 1:04:45.200
 stake in the ground

1:04:45.200 --> 1:04:47.200
 was I knew how hard the language

1:04:47.200 --> 1:04:49.200
 understanding problem was. I said we're not going to

1:04:49.200 --> 1:04:51.200
 actually understand

1:04:51.200 --> 1:04:53.200
 language to solve this problem.

1:04:53.200 --> 1:04:55.200
 We are not going to

1:04:55.200 --> 1:04:57.200
 interpret the question

1:04:57.200 --> 1:04:59.200
 and the domain of knowledge

1:04:59.200 --> 1:05:01.200
 that the question refers to and reason over

1:05:01.200 --> 1:05:03.200
 to that to answer these questions. Obviously

1:05:03.200 --> 1:05:05.200
 we're not going to be doing that. At the same time

1:05:05.200 --> 1:05:07.200
 simple search

1:05:07.200 --> 1:05:09.200
 wasn't good enough to

1:05:09.200 --> 1:05:11.200
 confidently answer with this

1:05:11.200 --> 1:05:13.200
 a single correct answer.

1:05:13.200 --> 1:05:15.200
 First of all it's like brilliant. It's such a great

1:05:15.200 --> 1:05:17.200
 mix of innovation in practical engineering

1:05:17.200 --> 1:05:19.200
 three, three, four, eight.

1:05:19.200 --> 1:05:21.200
 So you're not trying to solve the general

1:05:21.200 --> 1:05:23.200
 NLU problem. You're saying let's

1:05:23.200 --> 1:05:25.200
 solve this in any way possible.

1:05:25.200 --> 1:05:27.200
 Yeah, no I was committed to

1:05:27.200 --> 1:05:29.200
 saying look we're just solving the open

1:05:29.200 --> 1:05:31.200
 domain question answering problem.

1:05:31.200 --> 1:05:33.200
 We're using Jeopardy as a driver

1:05:33.200 --> 1:05:35.200
 for that. Hard enough. Big benchmark

1:05:35.200 --> 1:05:37.200
 exactly. And now

1:05:37.200 --> 1:05:39.200
 how do we do it?

1:05:39.200 --> 1:05:41.200
 We could just like whatever like just figure out what works

1:05:41.200 --> 1:05:43.200
 because I want to be able to go back to the academic

1:05:43.200 --> 1:05:45.200
 and scientific community and say here's what

1:05:45.200 --> 1:05:47.200
 we tried. Here's what worked. Here's what

1:05:47.200 --> 1:05:49.200
 didn't work. I don't want to go

1:05:49.200 --> 1:05:51.200
 in and say oh I only have

1:05:51.200 --> 1:05:53.200
 one technology. I have a hammer and I'm only going to use

1:05:53.200 --> 1:05:55.200
 this. I'm going to do whatever it takes. I'm like

1:05:55.200 --> 1:05:57.200
 let's think out of the box and do whatever it takes.

1:05:57.200 --> 1:05:59.200
 One and I also

1:05:59.200 --> 1:06:01.200
 there's another thing I believe. I believe

1:06:01.200 --> 1:06:03.200
 that the fundamental

1:06:03.200 --> 1:06:05.200
 NLP technologies and machine learning

1:06:05.200 --> 1:06:07.200
 technologies would be

1:06:07.200 --> 1:06:09.200
 would be adequate. And this was

1:06:09.200 --> 1:06:11.200
 an issue of how do we enhance

1:06:11.200 --> 1:06:13.200
 them? How do we integrate them?

1:06:13.200 --> 1:06:15.200
 How do we advance them?

1:06:15.200 --> 1:06:17.200
 So I had one researcher and came to me

1:06:17.200 --> 1:06:19.200
 who had been working on question answering with me for a very

1:06:19.200 --> 1:06:21.200
 long time

1:06:21.200 --> 1:06:23.200
 who had said we're going to need

1:06:23.200 --> 1:06:25.200
 Maxwell's equations for question answering.

1:06:25.200 --> 1:06:27.200
 And I said if we need

1:06:27.200 --> 1:06:29.200
 some fundamental formula that

1:06:29.200 --> 1:06:31.200
 breaks new ground and how we understand

1:06:31.200 --> 1:06:33.200
 language, we're screwed. We're

1:06:33.200 --> 1:06:35.200
 not going to get there from here.

1:06:35.200 --> 1:06:37.200
 I am not counting

1:06:37.200 --> 1:06:39.200
 my assumption is I'm not

1:06:39.200 --> 1:06:41.200
 counting on some brand new

1:06:41.200 --> 1:06:43.200
 invention. What I'm counting

1:06:43.200 --> 1:06:45.200
 on is the ability

1:06:45.200 --> 1:06:47.200
 to take everything that has done before

1:06:47.200 --> 1:06:49.200
 to figure out

1:06:49.200 --> 1:06:51.200
 an architecture on how to integrate

1:06:51.200 --> 1:06:53.200
 it well and then see where it

1:06:53.200 --> 1:06:55.200
 breaks and make the necessary

1:06:55.200 --> 1:06:57.200
 advances we need to make

1:06:57.200 --> 1:06:59.200
 until this thing works. Yeah. Push it

1:06:59.200 --> 1:07:01.200
 hard to see where it breaks and then patch

1:07:01.200 --> 1:07:03.200
 it up. I mean, that's how people change the world.

1:07:03.200 --> 1:07:05.200
 I mean, that's the Elon Musk approach with

1:07:05.200 --> 1:07:07.200
 rockets, SpaceX, that's the

1:07:07.200 --> 1:07:09.200
 Henry Ford and so on.

1:07:09.200 --> 1:07:11.200
 And I happen to be and in this case

1:07:11.200 --> 1:07:13.200
 I happen to be right, but like we didn't

1:07:13.200 --> 1:07:15.200
 know. Right. But you kind of have to

1:07:15.200 --> 1:07:17.200
 put a stake in terms of how you're going to run the project.

1:07:17.200 --> 1:07:19.200
 So yeah, and backtracking to

1:07:19.200 --> 1:07:21.200
 search. So if you

1:07:21.200 --> 1:07:23.200
 were to do, what's the brute force

1:07:23.200 --> 1:07:25.200
 solution? What would

1:07:25.200 --> 1:07:27.200
 you search over? So you have a question.

1:07:27.200 --> 1:07:29.200
 How would you search

1:07:29.200 --> 1:07:31.200
 the possible space of answers?

1:07:31.200 --> 1:07:33.200
 Look, web searches come a long way even since

1:07:33.200 --> 1:07:35.200
 then. But at the

1:07:35.200 --> 1:07:37.200
 time, like, you know, you first of

1:07:37.200 --> 1:07:39.200
 all, I mean, there are a couple other constraints

1:07:39.200 --> 1:07:41.200
 around the problems. Interesting. So

1:07:41.200 --> 1:07:43.200
 you couldn't go out to the web. You

1:07:43.200 --> 1:07:45.200
 couldn't search the Internet. In other

1:07:45.200 --> 1:07:47.200
 words, the AI experiment was

1:07:47.200 --> 1:07:49.200
 we want a self contained

1:07:49.200 --> 1:07:51.200
 device.

1:07:51.200 --> 1:07:53.200
 If the device is as big as a room, fine, it's as

1:07:53.200 --> 1:07:55.200
 big as a room, but we want a self

1:07:55.200 --> 1:07:57.200
 contained device, contained

1:07:57.200 --> 1:07:59.200
 device. You're not going out to the Internet.

1:07:59.200 --> 1:08:01.200
 You don't have a lifeline to anything.

1:08:01.200 --> 1:08:03.200
 So it had to kind of fit in a shoebox

1:08:03.200 --> 1:08:05.200
 if you will, or at least

1:08:05.200 --> 1:08:07.200
 size of a few refrigerators, whatever it might be.

1:08:07.200 --> 1:08:09.200
 See, but also

1:08:09.200 --> 1:08:11.200
 you couldn't just get out there. You couldn't go off

1:08:11.200 --> 1:08:13.200
 network, right, to kind of go. So

1:08:13.200 --> 1:08:15.200
 there was that limitation. But then

1:08:15.200 --> 1:08:17.200
 we did, but the basic thing was go

1:08:17.200 --> 1:08:19.200
 do a web search.

1:08:19.200 --> 1:08:21.200
 The problem was even when we went and did a

1:08:21.200 --> 1:08:23.200
 web search, I

1:08:23.200 --> 1:08:25.200
 don't remember exactly the numbers, but someone

1:08:25.200 --> 1:08:27.200
 in the order of 65% of the time,

1:08:27.200 --> 1:08:29.200
 the answer would be somewhere

1:08:29.200 --> 1:08:31.200
 in the top 10 or 20

1:08:31.200 --> 1:08:33.200
 documents. So first of

1:08:33.200 --> 1:08:35.200
 all, that's not even good enough to play Jeopardy.

1:08:35.200 --> 1:08:37.200
 In other words, even

1:08:37.200 --> 1:08:39.200
 if you could pull the, even if you could perfectly

1:08:39.200 --> 1:08:41.200
 pull the answer out of the top

1:08:41.200 --> 1:08:43.200
 20 documents, top 10 documents, whatever

1:08:43.200 --> 1:08:45.200
 it was, which we didn't know how to do.

1:08:45.200 --> 1:08:47.200
 But even if you could do that,

1:08:47.200 --> 1:08:49.200
 you'd be, and you knew it was right.

1:08:49.200 --> 1:08:51.200
 We had enough confidence in it, right?

1:08:51.200 --> 1:08:53.200
 You'd have to pull out the right answer. You'd have to

1:08:53.200 --> 1:08:55.200
 have confidence it was the right answer.

1:08:55.200 --> 1:08:57.200
 And then you'd have to do that fast enough to now go buzz

1:08:57.200 --> 1:08:59.200
 in. And you'd still only

1:08:59.200 --> 1:09:01.200
 get 65% of them right, which doesn't even

1:09:01.200 --> 1:09:03.200
 put you in the winner circle. Winner circle

1:09:03.200 --> 1:09:05.200
 you have to be up over 70.

1:09:05.200 --> 1:09:07.200
 And you have to do it really, and you have to do it really

1:09:07.200 --> 1:09:09.200
 quickly. But now the problem is,

1:09:09.200 --> 1:09:11.200
 well, even if I had

1:09:11.200 --> 1:09:13.200
 somewhere in the top 10 documents, how do I figure out

1:09:13.200 --> 1:09:15.200
 where in the top 10 documents that

1:09:15.200 --> 1:09:17.200
 answer is? And how do I compute

1:09:17.200 --> 1:09:19.200
 a confidence of all the possible candidates?

1:09:19.200 --> 1:09:21.200
 So it's not like I go in knowing

1:09:21.200 --> 1:09:23.200
 the right answer and have to pick it. I don't know

1:09:23.200 --> 1:09:25.200
 the right answer. I have a bunch of documents

1:09:25.200 --> 1:09:27.200
 somewhere in there's the right answer.

1:09:27.200 --> 1:09:29.200
 How do I, as a machine, go out and figure out

1:09:29.200 --> 1:09:31.200
 which one's right? And then how do I score

1:09:31.200 --> 1:09:33.200
 it? So,

1:09:33.200 --> 1:09:35.200
 and now how do I deal with the fact

1:09:35.200 --> 1:09:37.200
 that I can't actually go out to the web?

1:09:37.200 --> 1:09:39.200
 First of all, if you pause on that, just think

1:09:39.200 --> 1:09:41.200
 about it. If you could go to the web,

1:09:41.200 --> 1:09:43.200
 do you think that problem is

1:09:43.200 --> 1:09:45.200
 solvable? If you just pause on it?

1:09:45.200 --> 1:09:47.200
 Just thinking even beyond

1:09:47.200 --> 1:09:49.200
 jeopardy.

1:09:49.200 --> 1:09:51.200
 Do you think the problem of reading text

1:09:51.200 --> 1:09:53.200
 to find where the answer is?

1:09:53.200 --> 1:09:55.200
 Well, we solved that in some

1:09:55.200 --> 1:09:57.200
 definition of solved, given the jeopardy challenge.

1:09:57.200 --> 1:09:59.200
 How did you do it for jeopardy? So how

1:09:59.200 --> 1:10:01.200
 did you take a body

1:10:01.200 --> 1:10:03.200
 of work in a particular topic

1:10:03.200 --> 1:10:05.200
 and extract the key pieces of information?

1:10:05.200 --> 1:10:07.200
 So what, so, now, forgetting

1:10:07.200 --> 1:10:09.200
 about the huge volumes that are

1:10:09.200 --> 1:10:11.200
 on the web, right? So now we have to figure out

1:10:11.200 --> 1:10:13.200
 we did a lot of source research. In other words,

1:10:13.200 --> 1:10:15.200
 what body of knowledge

1:10:15.200 --> 1:10:17.200
 is going to be small enough but

1:10:17.200 --> 1:10:19.200
 broad enough to answer

1:10:19.200 --> 1:10:21.200
 jeopardy? And we ultimately did find

1:10:21.200 --> 1:10:23.200
 the body of knowledge that did that. I mean, it included

1:10:23.200 --> 1:10:25.200
 Wikipedia and a bunch of other stuff.

1:10:25.200 --> 1:10:27.200
 So, like, encyclopedia type of stuff? I don't know if you can

1:10:27.200 --> 1:10:29.200
 speak to it. Encyclopedia is different times of

1:10:29.200 --> 1:10:31.200
 semantic resources,

1:10:31.200 --> 1:10:33.200
 like WordNet and other types of semantic resources

1:10:33.200 --> 1:10:35.200
 like that, as well as, like, some web

1:10:35.200 --> 1:10:37.200
 crawls. In other words, where we went out

1:10:37.200 --> 1:10:39.200
 and took that content

1:10:39.200 --> 1:10:41.200
 and then expanded it based on producing

1:10:41.200 --> 1:10:43.200
 statistical, you know, statistically

1:10:43.200 --> 1:10:45.200
 producing seeds, using those

1:10:45.200 --> 1:10:47.200
 seeds for other searches

1:10:47.200 --> 1:10:49.200
 and then expanding that. So

1:10:49.200 --> 1:10:51.200
 using these, like, expansion techniques

1:10:51.200 --> 1:10:53.200
 we went out and had found enough content

1:10:53.200 --> 1:10:55.200
 and were like, okay, this is good. And even

1:10:55.200 --> 1:10:57.200
 up until the end, you know, we had

1:10:57.200 --> 1:10:59.200
 a threat of research that was always trying to figure

1:10:59.200 --> 1:11:01.200
 out what content could we

1:11:01.200 --> 1:11:03.200
 efficiently include. I mean, there's a lot of popular

1:11:03.200 --> 1:11:05.200
 content, like, what is the church lady?

1:11:05.200 --> 1:11:07.200
 Well, I think it was one of the, like,

1:11:07.200 --> 1:11:09.200
 what

1:11:09.200 --> 1:11:11.200
 where do you, I guess, that's probably

1:11:11.200 --> 1:11:13.200
 in encyclopedias. So, I guess,

1:11:13.200 --> 1:11:15.200
 but then we would

1:11:15.200 --> 1:11:17.200
 take that stuff and we would go out and we would

1:11:17.200 --> 1:11:19.200
 expand. In other words, we go find

1:11:19.200 --> 1:11:21.200
 other content that wasn't in the core

1:11:21.200 --> 1:11:23.200
 resources and expand it. You know,

1:11:23.200 --> 1:11:25.200
 the amount of content that grew it by an order of

1:11:25.200 --> 1:11:27.200
 magnitude, but still, again

1:11:27.200 --> 1:11:29.200
 from a web scale perspective, this is a very

1:11:29.200 --> 1:11:31.200
 small amount of content. It's very select.

1:11:31.200 --> 1:11:33.200
 We then took all that content,

1:11:33.200 --> 1:11:35.200
 we preanalyzed the crap out of it,

1:11:35.200 --> 1:11:37.200
 meaning we

1:11:37.200 --> 1:11:39.200
 parsed it, you know, broke it down

1:11:39.200 --> 1:11:41.200
 into all those individual words, and then we did

1:11:41.200 --> 1:11:43.200
 semantic, static and semantic

1:11:43.200 --> 1:11:45.200
 parses on it, you know, had computer

1:11:45.200 --> 1:11:47.200
 algorithms that annotated it, and

1:11:47.200 --> 1:11:49.200
 we indexed that in

1:11:49.200 --> 1:11:51.200
 a very rich and very fast

1:11:51.200 --> 1:11:53.200
 index.

1:11:53.200 --> 1:11:55.200
 So, we have a relatively huge amount of, you

1:11:55.200 --> 1:11:57.200
 know, let's say the equivalent of, for the sake of

1:11:57.200 --> 1:11:59.200
 argument, two to five million bucks, we've

1:11:59.200 --> 1:12:01.200
 now analyzed all that, blowing up its size

1:12:01.200 --> 1:12:03.200
 even more, because now we have all this metadata,

1:12:03.200 --> 1:12:05.200
 and then we richly indexed all of

1:12:05.200 --> 1:12:07.200
 that, and by the way,

1:12:07.200 --> 1:12:09.200
 in a giant in memory cache.

1:12:09.200 --> 1:12:11.200
 So, Watson did not go to disk.

1:12:11.200 --> 1:12:13.200
 So, the infrastructure component

1:12:13.200 --> 1:12:15.200
 there, if you could just speak to it, how tough

1:12:15.200 --> 1:12:17.200
 it, I mean, I know

1:12:17.200 --> 1:12:19.200
 2000, maybe this is

1:12:19.200 --> 1:12:21.200
 2008, 2009,

1:12:21.200 --> 1:12:23.200
 you know, that's

1:12:23.200 --> 1:12:25.200
 kind of a long time ago.

1:12:25.200 --> 1:12:27.200
 How hard is it to use multiple

1:12:27.200 --> 1:12:29.200
 machines? How hard is

1:12:29.200 --> 1:12:31.200
 the infrastructure component, the hardware component?

1:12:31.200 --> 1:12:33.200
 So, we used IBM hardware.

1:12:33.200 --> 1:12:35.200
 We had something like, I

1:12:35.200 --> 1:12:37.200
 forget exactly, but 2,000, close

1:12:37.200 --> 1:12:39.200
 to 3,000 cores

1:12:39.200 --> 1:12:41.200
 completely connected. So, we had a switch

1:12:41.200 --> 1:12:43.200
 where, you know, every CPU was connected

1:12:43.200 --> 1:12:45.200
 to every other CPU. And they were sharing memory in some kind of way.

1:12:45.200 --> 1:12:47.200
 Large, shared memory,

1:12:47.200 --> 1:12:49.200
 right? And all this data

1:12:49.200 --> 1:12:51.200
 was preanalyzed and

1:12:51.200 --> 1:12:53.200
 put into a very fast

1:12:53.200 --> 1:12:55.200
 indexing structure that

1:12:55.200 --> 1:12:57.200
 was all

1:12:57.200 --> 1:12:59.200
 in memory. And then

1:12:59.200 --> 1:13:01.200
 we took that question

1:13:01.200 --> 1:13:03.200
 we would analyze

1:13:03.200 --> 1:13:05.200
 the question. So, all the content

1:13:05.200 --> 1:13:07.200
 was now preanalyzed.

1:13:07.200 --> 1:13:09.200
 So, if I went

1:13:09.200 --> 1:13:11.200
 and tried to find a piece of content, it would

1:13:11.200 --> 1:13:13.200
 come back with all the metadata that we had

1:13:13.200 --> 1:13:15.200
 precomputed. How do you

1:13:15.200 --> 1:13:17.200
 shove that question?

1:13:17.200 --> 1:13:19.200
 How do you connect the big

1:13:19.200 --> 1:13:21.200
 stuff, the big knowledge base

1:13:21.200 --> 1:13:23.200
 of the metadata and that's indexed to

1:13:23.200 --> 1:13:25.200
 the simple little witty

1:13:25.200 --> 1:13:27.200
 confusing question?

1:13:27.200 --> 1:13:29.200
 Right. So, there

1:13:29.200 --> 1:13:31.200
 lies, you know, the Watson architecture.

1:13:31.200 --> 1:13:33.200
 So, we would take the question, we would

1:13:33.200 --> 1:13:35.200
 analyze the question. So, which

1:13:35.200 --> 1:13:37.200
 means that we would parse it

1:13:37.200 --> 1:13:39.200
 and interpret it a bunch of different ways. We'd try to

1:13:39.200 --> 1:13:41.200
 figure out what is it asking about. So, we

1:13:41.200 --> 1:13:43.200
 would come, we had

1:13:43.200 --> 1:13:45.200
 multiple strategies to kind of determine

1:13:45.200 --> 1:13:47.200
 what was it asking for.

1:13:47.200 --> 1:13:49.200
 That might be represented as a simple

1:13:49.200 --> 1:13:51.200
 string, a character string

1:13:51.200 --> 1:13:53.200
 or something we would connect back to

1:13:53.200 --> 1:13:55.200
 different semantic types that were from

1:13:55.200 --> 1:13:57.200
 existing resources. So, anyway,

1:13:57.200 --> 1:13:59.200
 the bottom line is we would do a bunch of analysis in the question.

1:13:59.200 --> 1:14:01.200
 And question analysis

1:14:01.200 --> 1:14:03.200
 had to finish and had to finish fast.

1:14:03.200 --> 1:14:05.200
 So, we do the question analysis

1:14:05.200 --> 1:14:07.200
 because then from the question analysis

1:14:07.200 --> 1:14:09.200
 we would now produce searches.

1:14:09.200 --> 1:14:11.200
 So, we would, and we

1:14:11.200 --> 1:14:13.200
 had built, using

1:14:13.200 --> 1:14:15.200
 open source search engines, we modified

1:14:15.200 --> 1:14:17.200
 them. We had a number of different

1:14:17.200 --> 1:14:19.200
 search engines we would use that had

1:14:19.200 --> 1:14:21.200
 different characteristics. We went in there

1:14:21.200 --> 1:14:23.200
 and engineered and modified those

1:14:23.200 --> 1:14:25.200
 search engines ultimately

1:14:25.200 --> 1:14:27.200
 to now take

1:14:27.200 --> 1:14:29.200
 our question analysis, produce multiple

1:14:29.200 --> 1:14:31.200
 queries based on different interpretations

1:14:31.200 --> 1:14:33.200
 of the question

1:14:33.200 --> 1:14:35.200
 and fire out a whole bunch of searches

1:14:35.200 --> 1:14:37.200
 in parallel.

1:14:37.200 --> 1:14:39.200
 And they would produce, they would come back

1:14:39.200 --> 1:14:41.200
 with passages.

1:14:41.200 --> 1:14:43.200
 So, these are passive search algorithms, they would

1:14:43.200 --> 1:14:45.200
 come back with passages. And so, now

1:14:45.200 --> 1:14:47.200
 let's say you had a thousand

1:14:47.200 --> 1:14:49.200
 passages. Now, for each passage

1:14:49.200 --> 1:14:51.200
 you parallelize again.

1:14:51.200 --> 1:14:53.200
 So, you went out and you

1:14:53.200 --> 1:14:55.200
 parallelize the search.

1:14:55.200 --> 1:14:57.200
 Each search would now come back

1:14:57.200 --> 1:14:59.200
 with a whole bunch of passages.

1:14:59.200 --> 1:15:01.200
 Maybe you had a total of a thousand

1:15:01.200 --> 1:15:03.200
 or five thousand whatever passages.

1:15:03.200 --> 1:15:05.200
 For each passage now, you'd go and

1:15:05.200 --> 1:15:07.200
 figure out whether or not there was a candidate,

1:15:07.200 --> 1:15:09.200
 we would call it candidate answer in there.

1:15:09.200 --> 1:15:11.200
 So, you had a whole bunch of other algorithms

1:15:11.200 --> 1:15:13.200
 that would find candidate answers.

1:15:13.200 --> 1:15:15.200
 Possible answers to the question.

1:15:15.200 --> 1:15:17.200
 And so, you had

1:15:17.200 --> 1:15:19.200
 candidate answers, called candidate answers

1:15:19.200 --> 1:15:21.200
 generators, the whole bunch of those.

1:15:21.200 --> 1:15:23.200
 So, for every one of these components

1:15:23.200 --> 1:15:25.200
 the team was constantly doing research

1:15:25.200 --> 1:15:27.200
 coming up better ways to generate

1:15:27.200 --> 1:15:29.200
 search queries from the questions, better ways

1:15:29.200 --> 1:15:31.200
 to analyze the question, better ways to

1:15:31.200 --> 1:15:33.200
 generate candidates. And speed, so better

1:15:33.200 --> 1:15:35.200
 is accuracy and

1:15:35.200 --> 1:15:37.200
 speed. Correct. So,

1:15:37.200 --> 1:15:39.200
 right, speed and accuracy for the most

1:15:39.200 --> 1:15:41.200
 part were separated.

1:15:41.200 --> 1:15:43.200
 We handle that sort of in separate ways, like I

1:15:43.200 --> 1:15:45.200
 was, purely on accuracy and

1:15:45.200 --> 1:15:47.200
 to an accuracy, are we ultimately getting more

1:15:47.200 --> 1:15:49.200
 questions and producing more accurate

1:15:49.200 --> 1:15:51.200
 confidences. And then a whole other team

1:15:51.200 --> 1:15:53.200
 that was constantly analyzing the workflow

1:15:53.200 --> 1:15:55.200
 to find the bottlenecks. And then figuring

1:15:55.200 --> 1:15:57.200
 out how to both parallelize and drive

1:15:57.200 --> 1:15:59.200
 the algorithm speed. But anyway, so

1:15:59.200 --> 1:16:01.200
 now think of it like you have this big fan

1:16:01.200 --> 1:16:03.200
 out now, right? Because you have

1:16:03.200 --> 1:16:05.200
 multiple queries, now you have

1:16:05.200 --> 1:16:07.200
 thousands of candidate answers.

1:16:07.200 --> 1:16:09.200
 For each candidate answer, you're going to score

1:16:09.200 --> 1:16:11.200
 it. So, you're going to use

1:16:11.200 --> 1:16:13.200
 all the data that built up, you're going to use

1:16:13.200 --> 1:16:15.200
 the question analysis,

1:16:15.200 --> 1:16:17.200
 you're going to use how the query was generated,

1:16:17.200 --> 1:16:19.200
 you're going to use the passage itself

1:16:19.200 --> 1:16:21.200
 and you're going to use the

1:16:21.200 --> 1:16:23.200
 candidate answer that was generated

1:16:23.200 --> 1:16:25.200
 and you're going to score that.

1:16:25.200 --> 1:16:27.200
 So, now we have

1:16:27.200 --> 1:16:29.200
 a group of researchers coming up with scores.

1:16:29.200 --> 1:16:31.200
 There are hundreds of different

1:16:31.200 --> 1:16:33.200
 scores. So, now you're getting a fan

1:16:33.200 --> 1:16:35.200
 out of it again from however many

1:16:35.200 --> 1:16:37.200
 candidate answers you have

1:16:37.200 --> 1:16:39.200
 to all the different scores.

1:16:39.200 --> 1:16:41.200
 So, if you have a 200 different scores

1:16:41.200 --> 1:16:43.200
 and you have 1,000 candidates, now you have

1:16:43.200 --> 1:16:45.200
 200,000 scores.

1:16:45.200 --> 1:16:47.200
 And so, now you've got to figure out

1:16:47.200 --> 1:16:49.200
 how do I now

1:16:49.200 --> 1:16:51.200
 rank these

1:16:51.200 --> 1:16:53.200
 answers based on the scores that

1:16:53.200 --> 1:16:55.200
 came back? And I want to rank

1:16:55.200 --> 1:16:57.200
 them based on the likelihood that they're a correct answer

1:16:57.200 --> 1:16:59.200
 to the question. So, every

1:16:59.200 --> 1:17:01.200
 score was its own research project.

1:17:01.200 --> 1:17:03.200
 What do you mean by score? So, is that the

1:17:03.200 --> 1:17:05.200
 annotation process of basically

1:17:05.200 --> 1:17:07.200
 a human being saying that this

1:17:07.200 --> 1:17:09.200
 answer has quality?

1:17:09.200 --> 1:17:11.200
 Think of it, if you want to think of it, what you're doing

1:17:11.200 --> 1:17:13.200
 you know, if you want to think about

1:17:13.200 --> 1:17:15.200
 what a human would be doing, a human would be looking at

1:17:15.200 --> 1:17:17.200
 a possible answer.

1:17:17.200 --> 1:17:19.200
 They'd be reading the

1:17:19.200 --> 1:17:21.200
 you know, Emily Dickinson. They'd be

1:17:21.200 --> 1:17:23.200
 reading the passage in which that occurred.

1:17:23.200 --> 1:17:25.200
 They'd be looking at the question

1:17:25.200 --> 1:17:27.200
 and they'd be making a decision of how

1:17:27.200 --> 1:17:29.200
 likely it is that Emily Dickinson

1:17:29.200 --> 1:17:31.200
 given this evidence in this passage

1:17:31.200 --> 1:17:33.200
 is the right answer to that question.

1:17:33.200 --> 1:17:35.200
 Got it. So, that's the annotation

1:17:35.200 --> 1:17:37.200
 task. That's the annotation

1:17:37.200 --> 1:17:39.200
 task. That's the scoring task.

1:17:39.200 --> 1:17:41.200
 So, but scoring implies 0 to 1

1:17:41.200 --> 1:17:43.200
 kind of continuous. That's right. You give it a 0 to 1 score.

1:17:43.200 --> 1:17:45.200
 Since it's not a binary. No.

1:17:45.200 --> 1:17:47.200
 You give it a score.

1:17:47.200 --> 1:17:49.200
 You give it a 0, yeah, exactly.

1:17:49.200 --> 1:17:51.200
 So, humans do give different scores so

1:17:51.200 --> 1:17:53.200
 you have to somehow normalize and all that kind of stuff

1:17:53.200 --> 1:17:55.200
 that deal with all that complexity. Depends on

1:17:55.200 --> 1:17:57.200
 what your strategy is. We both, we

1:17:57.200 --> 1:17:59.200
 could be relative to. It could be

1:17:59.200 --> 1:18:01.200
 we actually looked at the raw scores

1:18:01.200 --> 1:18:03.200
 as well, standardized scores because humans

1:18:03.200 --> 1:18:05.200
 are not involved in this.

1:18:05.200 --> 1:18:07.200
 Humans are not involved. Sorry. So, I'm

1:18:07.200 --> 1:18:09.200
 misunderstanding the process here. There's

1:18:09.200 --> 1:18:11.200
 passages. Where is

1:18:11.200 --> 1:18:13.200
 the ground truth coming from?

1:18:13.200 --> 1:18:15.200
 Grand truth is only the answers to the questions.

1:18:15.200 --> 1:18:17.200
 So, it's

1:18:17.200 --> 1:18:19.200
 end to end. It's end to end.

1:18:19.200 --> 1:18:21.200
 So, I was always

1:18:21.200 --> 1:18:23.200
 driving end to end performance. It was a very

1:18:23.200 --> 1:18:25.200
 interesting. Wow. A very interesting

1:18:25.200 --> 1:18:27.200
 engineering

1:18:27.200 --> 1:18:29.200
 approach and ultimately

1:18:29.200 --> 1:18:31.200
 scientific research approach. Always driving

1:18:31.200 --> 1:18:33.200
 now. That's not to say

1:18:33.200 --> 1:18:35.200
 we

1:18:35.200 --> 1:18:37.200
 wouldn't make

1:18:37.200 --> 1:18:39.200
 hypotheses that

1:18:39.200 --> 1:18:41.200
 individual component performance

1:18:41.200 --> 1:18:43.200
 was related in some way

1:18:43.200 --> 1:18:45.200
 to end to end performance. Of course we would

1:18:45.200 --> 1:18:47.200
 because people would have to

1:18:47.200 --> 1:18:49.200
 build individual components. But

1:18:49.200 --> 1:18:51.200
 ultimately to get your component integrated

1:18:51.200 --> 1:18:53.200
 into the system, you have to show impact

1:18:53.200 --> 1:18:55.200
 on end to end performance. Question

1:18:55.200 --> 1:18:57.200
 answering performance. So, there's many very

1:18:57.200 --> 1:18:59.200
 smart people working on this and they're basically

1:18:59.200 --> 1:19:01.200
 trying to sell

1:19:01.200 --> 1:19:03.200
 their ideas as a component that should be part

1:19:03.200 --> 1:19:05.200
 of the system. That's right. And

1:19:05.200 --> 1:19:07.200
 they would do research on their component

1:19:07.200 --> 1:19:09.200
 and they would say things like

1:19:09.200 --> 1:19:11.200
 I'm going to improve

1:19:11.200 --> 1:19:13.200
 this as a candidate generator.

1:19:13.200 --> 1:19:15.200
 I'm going to improve this as a

1:19:15.200 --> 1:19:17.200
 question score or as a passive

1:19:17.200 --> 1:19:19.200
 score. I'm going to improve this

1:19:19.200 --> 1:19:21.200
 or as a parser. And I

1:19:21.200 --> 1:19:23.200
 can improve it by 2%

1:19:23.200 --> 1:19:25.200
 on its component metric.

1:19:25.200 --> 1:19:27.200
 Like a better parse or better

1:19:27.200 --> 1:19:29.200
 candidate or a better type estimation

1:19:29.200 --> 1:19:31.200
 whatever it is. And then I would say

1:19:31.200 --> 1:19:33.200
 I need to understand how

1:19:33.200 --> 1:19:35.200
 the improvement on that component metric

1:19:35.200 --> 1:19:37.200
 is going to affect the end to end performance.

1:19:37.200 --> 1:19:39.200
 If you can't estimate that

1:19:39.200 --> 1:19:41.200
 and can't do experiments to demonstrate that

1:19:41.200 --> 1:19:43.200
 it doesn't get in.

1:19:43.200 --> 1:19:45.200
 That's like the best

1:19:45.200 --> 1:19:47.200
 run AI project I've ever

1:19:47.200 --> 1:19:49.200
 heard. That's awesome. Okay.

1:19:49.200 --> 1:19:51.200
 What breakthrough would

1:19:51.200 --> 1:19:53.200
 you say? Like I'm sure there's a lot

1:19:53.200 --> 1:19:55.200
 of day to day breakthroughs but was there like a breakthrough

1:19:55.200 --> 1:19:57.200
 that really helped improve performance?

1:19:57.200 --> 1:19:59.200
 Like wait, were people

1:19:59.200 --> 1:20:01.200
 began to believe?

1:20:01.200 --> 1:20:03.200
 Or is it just a gradual process? Well, I think

1:20:03.200 --> 1:20:05.200
 it was a gradual process but

1:20:05.200 --> 1:20:07.200
 one of the things that I think

1:20:07.200 --> 1:20:09.200
 gave people confidence

1:20:09.200 --> 1:20:11.200
 that we can get there was that

1:20:11.200 --> 1:20:13.200
 as we follow this

1:20:13.200 --> 1:20:15.200
 as we follow this procedure of

1:20:17.200 --> 1:20:19.200
 different ideas, build different components

1:20:19.200 --> 1:20:21.200
 plug them into the architecture, run the system

1:20:21.200 --> 1:20:23.200
 see how we do

1:20:23.200 --> 1:20:25.200
 the error analysis, start off

1:20:25.200 --> 1:20:27.200
 new research projects to improve things

1:20:27.200 --> 1:20:29.200
 and

1:20:29.200 --> 1:20:31.200
 the very important idea

1:20:31.200 --> 1:20:33.200
 that the individual

1:20:33.200 --> 1:20:35.200
 component

1:20:35.200 --> 1:20:37.200
 work

1:20:37.200 --> 1:20:39.200
 did not have to deeply understand

1:20:39.200 --> 1:20:41.200
 everything that was going on with every other component.

1:20:41.200 --> 1:20:43.200
 And this is where

1:20:43.200 --> 1:20:45.200
 we leveraged machine learning in a very

1:20:45.200 --> 1:20:47.200
 important way.

1:20:47.200 --> 1:20:49.200
 So while individual components could be

1:20:49.200 --> 1:20:51.200
 statistically driven machine learning components

1:20:51.200 --> 1:20:53.200
 some of them were heuristic, some of them were

1:20:53.200 --> 1:20:55.200
 machine learning components, the system has

1:20:55.200 --> 1:20:57.200
 a whole combined all the scores

1:20:57.200 --> 1:20:59.200
 using machine learning.

1:20:59.200 --> 1:21:01.200
 This was critical

1:21:01.200 --> 1:21:03.200
 because that way you can divide

1:21:03.200 --> 1:21:05.200
 and conquer. So you can say

1:21:05.200 --> 1:21:07.200
 okay, you work on your candidate generator

1:21:07.200 --> 1:21:09.200
 or you work on this approach to answer scoring

1:21:09.200 --> 1:21:11.200
 you work on this approach to type scoring

1:21:11.200 --> 1:21:13.200
 you work on this approach to

1:21:13.200 --> 1:21:15.200
 passage search or to passage selection

1:21:15.200 --> 1:21:17.200
 and so forth.

1:21:17.200 --> 1:21:19.200
 But when we just plug it in

1:21:19.200 --> 1:21:21.200
 and we had enough training

1:21:21.200 --> 1:21:23.200
 data to say now we can

1:21:23.200 --> 1:21:25.200
 train and figure out how do we

1:21:25.200 --> 1:21:27.200
 weigh all the scores

1:21:27.200 --> 1:21:29.200
 relative to each other

1:21:29.200 --> 1:21:31.200
 based on predicting

1:21:31.200 --> 1:21:33.200
 the outcome which is right or wrong on

1:21:33.200 --> 1:21:35.200
 jeopardy. And we had enough training data

1:21:35.200 --> 1:21:37.200
 to do that. So this

1:21:37.200 --> 1:21:39.200
 enabled people to work

1:21:39.200 --> 1:21:41.200
 independently and to let the machine

1:21:41.200 --> 1:21:43.200
 learning do the integration.

1:21:43.200 --> 1:21:45.200
 Beautiful. So the machine learning

1:21:45.200 --> 1:21:47.200
 is doing the fusion and then it's a human

1:21:47.200 --> 1:21:49.200
 orchestrated ensemble

1:21:49.200 --> 1:21:51.200
 with different approaches.

1:21:51.200 --> 1:21:53.200
 That's great.

1:21:53.200 --> 1:21:55.200
 Still impressive that you were able to get it

1:21:55.200 --> 1:21:57.200
 done in a few years.

1:21:57.200 --> 1:21:59.200
 That's not obvious to me

1:21:59.200 --> 1:22:01.200
 that it's doable if I just put myself

1:22:01.200 --> 1:22:03.200
 in that mindset.

1:22:03.200 --> 1:22:05.200
 But when you look back at the jeopardy challenge

1:22:07.200 --> 1:22:09.200
 again when you're looking up at the stars

1:22:09.200 --> 1:22:11.200
 what are you most proud of?

1:22:11.200 --> 1:22:15.200
 It's looking back at those days.

1:22:17.200 --> 1:22:19.200
 I'm most proud of

1:22:27.200 --> 1:22:29.200
 my commitment

1:22:29.200 --> 1:22:31.200
 and my team's commitment

1:22:31.200 --> 1:22:33.200
 to be true to the science.

1:22:35.200 --> 1:22:37.200
 To not be afraid

1:22:37.200 --> 1:22:39.200
 to fail.

1:22:39.200 --> 1:22:41.200
 It's beautiful because there's so much pressure

1:22:41.200 --> 1:22:43.200
 because it is a public event.

1:22:43.200 --> 1:22:45.200
 It is a public show

1:22:45.200 --> 1:22:47.200
 that you were dedicated to the idea.

1:22:47.200 --> 1:22:49.200
 That's right.

1:22:51.200 --> 1:22:53.200
 Do you think it was a success?

1:22:53.200 --> 1:22:55.200
 In the eyes of the world it was a success.

1:22:57.200 --> 1:22:59.200
 By your I'm sure exceptionally high standards

1:23:01.200 --> 1:23:03.200
 is there something you regret you would do

1:23:03.200 --> 1:23:05.200
 differently?

1:23:05.200 --> 1:23:07.200
 It was a success.

1:23:07.200 --> 1:23:09.200
 It was a success for our goal.

1:23:09.200 --> 1:23:11.200
 Our goal was to

1:23:11.200 --> 1:23:13.200
 build the most advanced

1:23:13.200 --> 1:23:15.200
 open domain question answering system.

1:23:15.200 --> 1:23:17.200
 We went back

1:23:17.200 --> 1:23:19.200
 to the old problems that we used to try

1:23:19.200 --> 1:23:21.200
 to solve and we did

1:23:21.200 --> 1:23:23.200
 dramatically better on all of them

1:23:23.200 --> 1:23:25.200
 as well as we beat jeopardy.

1:23:25.200 --> 1:23:27.200
 So we won the jeopardy.

1:23:27.200 --> 1:23:29.200
 So it was a success.

1:23:31.200 --> 1:23:33.200
 I worry that the

1:23:33.200 --> 1:23:35.200
 world would not understand it as a success

1:23:35.200 --> 1:23:37.200
 because

1:23:37.200 --> 1:23:39.200
 it came down to only one game and I knew

1:23:39.200 --> 1:23:41.200
 statistically speaking this can be a huge

1:23:41.200 --> 1:23:43.200
 technical success and we could still lose that

1:23:43.200 --> 1:23:45.200
 one game and that's a whole other theme

1:23:45.200 --> 1:23:47.200
 of the journey.

1:23:47.200 --> 1:23:49.200
 But it was a success.

1:23:49.200 --> 1:23:51.200
 It was not a success

1:23:51.200 --> 1:23:53.200
 in natural language understanding

1:23:53.200 --> 1:23:55.200
 but that was not the goal.

1:23:57.200 --> 1:23:59.200
 I would argue

1:23:59.200 --> 1:24:01.200
 I understand what you're saying

1:24:01.200 --> 1:24:03.200
 in terms of the science

1:24:03.200 --> 1:24:05.200
 but I would argue that

1:24:05.200 --> 1:24:07.200
 the inspiration of it

1:24:09.200 --> 1:24:11.200
 not a success in terms of solving

1:24:11.200 --> 1:24:13.200
 natural language understanding.

1:24:13.200 --> 1:24:15.200
 It was a success of being an inspiration

1:24:15.200 --> 1:24:17.200
 to future challenges.

1:24:17.200 --> 1:24:19.200
 Absolutely.

1:24:19.200 --> 1:24:21.200
 To drive future efforts.

1:24:21.200 --> 1:24:23.200
 What's the difference between how human being

1:24:23.200 --> 1:24:25.200
 compete in jeopardy

1:24:25.200 --> 1:24:27.200
 and how Watson does it.

1:24:27.200 --> 1:24:29.200
 That's important in terms of intelligence.

1:24:29.200 --> 1:24:31.200
 That actually came up very early

1:24:31.200 --> 1:24:33.200
 on in the project also.

1:24:33.200 --> 1:24:35.200
 In fact I had people who wanted to be on the project

1:24:35.200 --> 1:24:37.200
 who were

1:24:37.200 --> 1:24:39.200
 early on who approached me

1:24:39.200 --> 1:24:41.200
 once I committed to do it

1:24:41.200 --> 1:24:43.200
 I wanted to think about

1:24:43.200 --> 1:24:45.200
 how humans do it and they were

1:24:45.200 --> 1:24:47.200
 from a cognition perspective

1:24:47.200 --> 1:24:49.200
 like human cognition and how that should play.

1:24:49.200 --> 1:24:51.200
 And I would not

1:24:51.200 --> 1:24:53.200
 take them on the project because

1:24:53.200 --> 1:24:55.200
 another assumption

1:24:55.200 --> 1:24:57.200
 or another state I put in the ground

1:24:57.200 --> 1:24:59.200
 was I don't really care how humans do this.

1:24:59.200 --> 1:25:01.200
 At least in the context of this project.

1:25:01.200 --> 1:25:03.200
 I need to build in the context of this project

1:25:03.200 --> 1:25:05.200
 in NLU

1:25:05.200 --> 1:25:07.200
 and in building an AI that understands

1:25:07.200 --> 1:25:09.200
 how it needs to ultimately communicate

1:25:09.200 --> 1:25:11.200
 with humans, I very much care.

1:25:11.200 --> 1:25:13.200
 So it wasn't that

1:25:13.200 --> 1:25:15.200
 I didn't care

1:25:15.200 --> 1:25:17.200
 in general.

1:25:17.200 --> 1:25:19.200
 In fact as an AI scientist

1:25:19.200 --> 1:25:21.200
 I care a lot about that.

1:25:21.200 --> 1:25:23.200
 But I'm also a practical engineer

1:25:23.200 --> 1:25:25.200
 and I committed to getting this thing done

1:25:25.200 --> 1:25:27.200
 and I wasn't going to get distracted

1:25:27.200 --> 1:25:29.200
 I had to kind of

1:25:29.200 --> 1:25:31.200
 say like if I'm going to get this done

1:25:31.200 --> 1:25:33.200
 I'm going to chart this path and this path says

1:25:33.200 --> 1:25:35.200
 we're going to engineer a machine

1:25:35.200 --> 1:25:37.200
 that's going to get this thing done

1:25:37.200 --> 1:25:39.200
 and we know what

1:25:39.200 --> 1:25:41.200
 search and NLP can do

1:25:41.200 --> 1:25:43.200
 we have to build on that foundation

1:25:43.200 --> 1:25:45.200
 if I come in and take

1:25:45.200 --> 1:25:47.200
 a different approach and start wondering about

1:25:47.200 --> 1:25:49.200
 how the human mind might or might not do this

1:25:49.200 --> 1:25:51.200
 I'm not going to get there from here

1:25:51.200 --> 1:25:53.200
 in the time frame.

1:25:53.200 --> 1:25:55.200
 I think that's a great way to lead the team.

1:25:55.200 --> 1:25:57.200
 But now

1:25:57.200 --> 1:25:59.200
 there's done and there's one

1:25:59.200 --> 1:26:01.200
 when you look back, analyze

1:26:01.200 --> 1:26:03.200
 what's the difference actually.

1:26:03.200 --> 1:26:05.200
 So I was a little bit surprised actually

1:26:05.200 --> 1:26:07.200
 to discover

1:26:07.200 --> 1:26:09.200
 over time as this would come up

1:26:09.200 --> 1:26:11.200
 from time to time and we'd reflect on it

1:26:11.200 --> 1:26:13.200
 that

1:26:13.200 --> 1:26:15.200
 and talking to Ken Jennings a little bit

1:26:15.200 --> 1:26:17.200
 and hearing Ken Jennings talk about

1:26:17.200 --> 1:26:19.200
 how he answered questions

1:26:19.200 --> 1:26:21.200
 that it might have been closer to the way humans

1:26:21.200 --> 1:26:23.200
 answer questions than I might have imagined

1:26:23.200 --> 1:26:25.200
 previously.

1:26:25.200 --> 1:26:27.200
 Because humans are probably in the game of Jeopardy

1:26:27.200 --> 1:26:29.200
 at the level of Ken Jennings

1:26:29.200 --> 1:26:31.200
 are probably also

1:26:31.200 --> 1:26:33.200
 cheating their way

1:26:33.200 --> 1:26:35.200
 to winning, right?

1:26:35.200 --> 1:26:37.200
 Well, they're doing shallow analysis.

1:26:37.200 --> 1:26:39.200
 They're doing the fastest possible.

1:26:39.200 --> 1:26:41.200
 They're doing shallow analysis.

1:26:41.200 --> 1:26:43.200
 So they are

1:26:43.200 --> 1:26:45.200
 very quickly analyzing the question

1:26:45.200 --> 1:26:47.200
 and coming up with some

1:26:47.200 --> 1:26:49.200
 key vectors or cues if you will

1:26:49.200 --> 1:26:51.200
 and they're taking those cues

1:26:51.200 --> 1:26:53.200
 and very quickly going through

1:26:53.200 --> 1:26:55.200
 their library of stuff

1:26:55.200 --> 1:26:57.200
 not deeply reasoning about what's going on

1:26:57.200 --> 1:26:59.200
 and then

1:26:59.200 --> 1:27:01.200
 lots of different

1:27:01.200 --> 1:27:03.200
 what we call these scores

1:27:03.200 --> 1:27:05.200
 what's kind of score

1:27:05.200 --> 1:27:07.200
 in a very shallow way

1:27:07.200 --> 1:27:09.200
 and then say, oh, boom, that's what it is.

1:27:09.200 --> 1:27:11.200
 And so it's interesting

1:27:11.200 --> 1:27:13.200
 as we reflected on that

1:27:13.200 --> 1:27:15.200
 we may be doing something that's not too far off

1:27:15.200 --> 1:27:17.200
 from the way humans do it

1:27:17.200 --> 1:27:19.200
 but we certainly

1:27:19.200 --> 1:27:21.200
 didn't approach it by saying,

1:27:21.200 --> 1:27:23.200
 you know, how would a human do this?

1:27:23.200 --> 1:27:25.200
 Now, in elemental cognition

1:27:25.200 --> 1:27:27.200
 like the project I'm leading now

1:27:27.200 --> 1:27:29.200
 we ask those questions all the time

1:27:29.200 --> 1:27:31.200
 because ultimately

1:27:31.200 --> 1:27:33.200
 we're trying to do something that

1:27:33.200 --> 1:27:35.200
 is to make the intelligence of the machine

1:27:35.200 --> 1:27:37.200
 and the intelligence of the human very compatible.

1:27:37.200 --> 1:27:39.200
 Well, compatible in the sense

1:27:39.200 --> 1:27:41.200
 they can communicate with one another

1:27:41.200 --> 1:27:43.200
 and they can reason

1:27:43.200 --> 1:27:45.200
 with this shared understanding.

1:27:45.200 --> 1:27:47.200
 So how they think about things

1:27:47.200 --> 1:27:49.200
 answers, how they build explanations

1:27:49.200 --> 1:27:51.200
 becomes a very important question to consider.

1:27:51.200 --> 1:27:53.200
 So what's the difference

1:27:53.200 --> 1:27:55.200
 between this

1:27:55.200 --> 1:27:57.200
 open domain

1:27:57.200 --> 1:27:59.200
 but cold

1:27:59.200 --> 1:28:01.200
 constructed question answering

1:28:01.200 --> 1:28:03.200
 of Jeopardy

1:28:03.200 --> 1:28:05.200
 and more

1:28:05.200 --> 1:28:07.200
 something that requires understanding

1:28:07.200 --> 1:28:09.200
 for shared communication with humans and machines?

1:28:09.200 --> 1:28:11.200
 Yeah, well, this goes back

1:28:11.200 --> 1:28:13.200
 to the interpretation

1:28:13.200 --> 1:28:15.200
 of what we were talking about before.

1:28:15.200 --> 1:28:17.200
 Jeopardy, the system is not

1:28:17.200 --> 1:28:19.200
 trying to interpret the question

1:28:19.200 --> 1:28:21.200
 and it's not interpreting the content

1:28:21.200 --> 1:28:23.200
 that's reusing with regard to any particular

1:28:23.200 --> 1:28:25.200
 framework. I mean it is

1:28:25.200 --> 1:28:27.200
 parsing it and parsing the content

1:28:27.200 --> 1:28:29.200
 and using grammatical cues and stuff like that.

1:28:29.200 --> 1:28:31.200
 So if you think of grammar as a human

1:28:31.200 --> 1:28:33.200
 framework in some sense it has that

1:28:33.200 --> 1:28:35.200
 but when you get into the richer

1:28:35.200 --> 1:28:37.200
 semantic frameworks,

1:28:37.200 --> 1:28:39.200
 what do people, how do they think, what motivates them,

1:28:39.200 --> 1:28:41.200
 what are the events that are

1:28:41.200 --> 1:28:43.200
 occurring and why they're occurring and what causes

1:28:43.200 --> 1:28:45.200
 what else to happen and

1:28:45.200 --> 1:28:47.200
 where are things in time and space

1:28:47.200 --> 1:28:49.200
 and when you start to think about

1:28:49.200 --> 1:28:51.200
 how humans formulate

1:28:51.200 --> 1:28:53.200
 and structure the knowledge that they acquire in their head

1:28:53.200 --> 1:28:55.200
 and wasn't doing any of that.

1:28:57.200 --> 1:28:59.200
 What do you think are the

1:28:59.200 --> 1:29:01.200
 essential challenges

1:29:01.200 --> 1:29:03.200
 of free flowing

1:29:03.200 --> 1:29:05.200
 communication, free flowing dialogue

1:29:05.200 --> 1:29:07.200
 versus question answering

1:29:07.200 --> 1:29:09.200
 even with a framework, with the

1:29:09.200 --> 1:29:11.200
 interpretation dialogue?

1:29:11.200 --> 1:29:13.200
 Yep. Do you see

1:29:13.200 --> 1:29:15.200
 free flowing dialogue

1:29:15.200 --> 1:29:17.200
 as

1:29:17.200 --> 1:29:19.200
 fundamentally more difficult

1:29:19.200 --> 1:29:21.200
 than question answering even with

1:29:21.200 --> 1:29:23.200
 shared

1:29:23.200 --> 1:29:25.200
 interpretation? So dialogue

1:29:25.200 --> 1:29:27.200
 is important in a number of different ways.

1:29:27.200 --> 1:29:29.200
 I mean it's a challenge. So first of all

1:29:29.200 --> 1:29:31.200
 when I think about the machine

1:29:31.200 --> 1:29:33.200
 that understands language

1:29:33.200 --> 1:29:35.200
 and ultimately can reason

1:29:35.200 --> 1:29:37.200
 in an objective way

1:29:37.200 --> 1:29:39.200
 that can take the

1:29:39.200 --> 1:29:41.200
 information that it perceives through language

1:29:41.200 --> 1:29:43.200
 or other means and connect it back

1:29:43.200 --> 1:29:45.200
 to these frameworks, reason

1:29:45.200 --> 1:29:47.200
 and explain itself

1:29:47.200 --> 1:29:49.200
 that system ultimately needs

1:29:49.200 --> 1:29:51.200
 to be able to talk to humans, right?

1:29:51.200 --> 1:29:53.200
 It needs to be able to interact with humans

1:29:53.200 --> 1:29:55.200
 so in some sense it needs to dialogue.

1:29:55.200 --> 1:29:57.200
 That doesn't mean that

1:29:57.200 --> 1:29:59.200
 sometimes

1:29:59.200 --> 1:30:01.200
 people talk about dialogue and they think

1:30:01.200 --> 1:30:03.200
 how do humans

1:30:03.200 --> 1:30:05.200
 talk to each other

1:30:05.200 --> 1:30:07.200
 in a casual conversation

1:30:07.200 --> 1:30:09.200
 and you could mimic casual conversations.

1:30:11.200 --> 1:30:13.200
 We're not trying to mimic casual

1:30:13.200 --> 1:30:15.200
 conversations. We're really trying

1:30:15.200 --> 1:30:17.200
 to produce a machine

1:30:17.200 --> 1:30:19.200
 whose goal is to help you

1:30:19.200 --> 1:30:21.200
 think and help you reason

1:30:21.200 --> 1:30:23.200
 about your answers and explain why.

1:30:23.200 --> 1:30:25.200
 So instead of like talking to your

1:30:25.200 --> 1:30:27.200
 friend down the street about having

1:30:27.200 --> 1:30:29.200
 a small talk conversation with your friend

1:30:29.200 --> 1:30:31.200
 down the street, this is more about

1:30:31.200 --> 1:30:33.200
 like you would be communicating to the computer

1:30:33.200 --> 1:30:35.200
 on Star Trek where

1:30:35.200 --> 1:30:37.200
 what do you want to think about?

1:30:37.200 --> 1:30:39.200
 What do you want to reason about? I'm going to tell you the information I have

1:30:39.200 --> 1:30:41.200
 and I'm going to have to summarize it. I'm going to ask you questions

1:30:41.200 --> 1:30:43.200
 and you're going to answer those questions.

1:30:43.200 --> 1:30:45.200
 I'm going to go back and forth with you.

1:30:45.200 --> 1:30:47.200
 I'm going to figure out what your mental model is.

1:30:47.200 --> 1:30:49.200
 I'm going to now relate that

1:30:49.200 --> 1:30:51.200
 to the information I have and present it to you

1:30:51.200 --> 1:30:53.200
 in a way that you can understand

1:30:53.200 --> 1:30:55.200
 and then we can ask follow up questions.

1:30:55.200 --> 1:30:57.200
 So it's that type of dialogue

1:30:57.200 --> 1:30:59.200
 that you want to construct.

1:30:59.200 --> 1:31:01.200
 It's more structured.

1:31:01.200 --> 1:31:03.200
 It's more goal oriented

1:31:03.200 --> 1:31:05.200
 and fluid.

1:31:05.200 --> 1:31:07.200
 In other words, it can't

1:31:07.200 --> 1:31:09.200
 it has to be engaging and fluid.

1:31:09.200 --> 1:31:11.200
 It has to be productive

1:31:11.200 --> 1:31:13.200
 and not distracting.

1:31:13.200 --> 1:31:15.200
 So there has to be a model

1:31:15.200 --> 1:31:17.200
 of, in other words, the machine has to have

1:31:17.200 --> 1:31:19.200
 a model of how humans

1:31:19.200 --> 1:31:21.200
 think through things

1:31:21.200 --> 1:31:23.200
 and discuss them.

1:31:23.200 --> 1:31:25.200
 So basically a productive, rich

1:31:25.200 --> 1:31:27.200
 conversation

1:31:29.200 --> 1:31:31.200
 unlike this podcast

1:31:31.200 --> 1:31:33.200
 what I'd like to think

1:31:33.200 --> 1:31:35.200
 it's more similar to this podcast.

1:31:35.200 --> 1:31:37.200
 I was just joking.

1:31:37.200 --> 1:31:39.200
 I'll ask you about humor as well, actually.

1:31:39.200 --> 1:31:41.200
 But

1:31:41.200 --> 1:31:43.200
 what's the hardest part of that

1:31:43.200 --> 1:31:45.200
 because it seems we're quite far away

1:31:45.200 --> 1:31:47.200
 as a community

1:31:47.200 --> 1:31:49.200
 from that still to be

1:31:49.200 --> 1:31:51.200
 able to. So one is having a shared

1:31:51.200 --> 1:31:53.200
 understanding.

1:31:53.200 --> 1:31:55.200
 I think a lot of the stuff you said with frameworks

1:31:55.200 --> 1:31:57.200
 is quite brilliant.

1:31:57.200 --> 1:31:59.200
 But just

1:31:59.200 --> 1:32:01.200
 creating a smooth discourse

1:32:01.200 --> 1:32:03.200
 feels

1:32:03.200 --> 1:32:05.200
 clunky right now.

1:32:05.200 --> 1:32:07.200
 Which aspects of this whole

1:32:07.200 --> 1:32:09.200
 problem that you just specified

1:32:09.200 --> 1:32:11.200
 of having a productive

1:32:11.200 --> 1:32:13.200
 conversation is the hardest

1:32:13.200 --> 1:32:15.200
 or maybe

1:32:15.200 --> 1:32:17.200
 maybe any

1:32:17.200 --> 1:32:19.200
 aspect of it you can comment on because it's so shrouded

1:32:19.200 --> 1:32:21.200
 in mystery.

1:32:21.200 --> 1:32:23.200
 So I think to do this you kind of have to

1:32:23.200 --> 1:32:25.200
 be creative in the following

1:32:25.200 --> 1:32:27.200
 sense.

1:32:27.200 --> 1:32:29.200
 So how to do this is purely a machine

1:32:29.200 --> 1:32:31.200
 learning approach. And someone said

1:32:31.200 --> 1:32:33.200
 learn how to have a

1:32:33.200 --> 1:32:35.200
 good, fluent, structured

1:32:35.200 --> 1:32:37.200
 knowledge acquisition conversation.

1:32:37.200 --> 1:32:39.200
 I'd go out

1:32:39.200 --> 1:32:41.200
 and say okay I have to collect a bunch of data

1:32:41.200 --> 1:32:43.200
 of people doing that. People reasoning

1:32:43.200 --> 1:32:45.200
 well

1:32:45.200 --> 1:32:47.200
 having a good structured

1:32:47.200 --> 1:32:49.200
 conversation that both acquires

1:32:49.200 --> 1:32:51.200
 knowledge efficiently as well as

1:32:51.200 --> 1:32:53.200
 produces answers and explanations as part of

1:32:53.200 --> 1:32:55.200
 the process.

1:32:55.200 --> 1:32:57.200
 And you struggle

1:32:57.200 --> 1:32:59.200
 to collect the data

1:32:59.200 --> 1:33:01.200
 because I don't know how much data

1:33:01.200 --> 1:33:03.200
 is like that.

1:33:03.200 --> 1:33:05.200
 There's one

1:33:05.200 --> 1:33:07.200
 there's a humorous comment around the lack of

1:33:07.200 --> 1:33:09.200
 rational discourse but also

1:33:09.200 --> 1:33:11.200
 even if it's out there

1:33:11.200 --> 1:33:13.200
 say it was out there how do you

1:33:13.200 --> 1:33:15.200
 actually

1:33:15.200 --> 1:33:17.200
 successful example.

1:33:17.200 --> 1:33:19.200
 So I think any problem like this

1:33:19.200 --> 1:33:21.200
 where you don't have

1:33:21.200 --> 1:33:23.200
 enough data to represent

1:33:23.200 --> 1:33:25.200
 the phenomenon you want to learn.

1:33:25.200 --> 1:33:27.200
 In other words, if you have enough data

1:33:27.200 --> 1:33:29.200
 you could potentially learn the pattern.

1:33:29.200 --> 1:33:31.200
 In an example like this it's hard to do.

1:33:31.200 --> 1:33:33.200
 This is sort of a human

1:33:33.200 --> 1:33:35.200
 sort of thing to do. What recently came

1:33:35.200 --> 1:33:37.200
 out at IBM was the debate or project

1:33:37.200 --> 1:33:39.200
 interest thing. Because now you do

1:33:39.200 --> 1:33:41.200
 have these structured dialogues, these debate

1:33:41.200 --> 1:33:43.200
 things where they did

1:33:43.200 --> 1:33:45.200
 use machine learning techniques to

1:33:45.200 --> 1:33:47.200
 generate these debates.

1:33:49.200 --> 1:33:51.200
 Dialogues are a little bit

1:33:51.200 --> 1:33:53.200
 tougher in my opinion than

1:33:53.200 --> 1:33:55.200
 generating a structured argument

1:33:55.200 --> 1:33:57.200
 where you have lots of other structured

1:33:57.200 --> 1:33:59.200
 arguments like this. You could potentially annotate

1:33:59.200 --> 1:34:01.200
 that data and you could say this is a good response

1:34:01.200 --> 1:34:03.200
 a bad response in a particular domain.

1:34:03.200 --> 1:34:05.200
 Here

1:34:05.200 --> 1:34:07.200
 I have to be responsive and I have to be

1:34:07.200 --> 1:34:09.200
 opportunistic

1:34:09.200 --> 1:34:11.200
 with regard to what is the human saying

1:34:11.200 --> 1:34:13.200
 so I'm goal oriented

1:34:13.200 --> 1:34:15.200
 and saying I want to solve the problem

1:34:15.200 --> 1:34:17.200
 I want to acquire the knowledge necessary. But I also

1:34:17.200 --> 1:34:19.200
 have to be opportunistic and responsive

1:34:19.200 --> 1:34:21.200
 to what the human is saying.

1:34:21.200 --> 1:34:23.200
 So I think that it's not clear

1:34:23.200 --> 1:34:25.200
 that we could just train on the body of data

1:34:25.200 --> 1:34:27.200
 to do this. But we

1:34:27.200 --> 1:34:29.200
 could bootstrap it. In other words we can be creative

1:34:29.200 --> 1:34:31.200
 and we could say what do we think

1:34:31.200 --> 1:34:33.200
 what do we think the structure of a good

1:34:33.200 --> 1:34:35.200
 dialogue is that does this well

1:34:35.200 --> 1:34:37.200
 and we can start to create that

1:34:37.200 --> 1:34:39.200
 if we can create

1:34:39.200 --> 1:34:41.200
 that more programmatically

1:34:41.200 --> 1:34:43.200
 at least to get this process started

1:34:43.200 --> 1:34:45.200
 and I can

1:34:45.200 --> 1:34:47.200
 create a tool that now engages humans effectively

1:34:47.200 --> 1:34:49.200
 I could start both

1:34:49.200 --> 1:34:51.200
 I could start generating data

1:34:51.200 --> 1:34:53.200
 I could start the human learning process

1:34:53.200 --> 1:34:55.200
 and I can update my machine

1:34:55.200 --> 1:34:57.200
 but I could also start the automatic learning process

1:34:57.200 --> 1:34:59.200
 as well.

1:34:59.200 --> 1:35:01.200
 But I have to understand what features to even learn over

1:35:01.200 --> 1:35:03.200
 so I have to bootstrap the process

1:35:03.200 --> 1:35:05.200
 a little bit first.

1:35:05.200 --> 1:35:07.200
 And that's a creative design task

1:35:07.200 --> 1:35:09.200
 that I could then use

1:35:09.200 --> 1:35:11.200
 as input

1:35:11.200 --> 1:35:13.200
 into a more automatic learning task.

1:35:13.200 --> 1:35:15.200
 Some creativity in

1:35:15.200 --> 1:35:17.200
 bootstrapping. What elements

1:35:17.200 --> 1:35:19.200
 of a conversation do you think

1:35:19.200 --> 1:35:21.200
 you would like to see?

1:35:21.200 --> 1:35:23.200
 So one of the benchmarks

1:35:23.200 --> 1:35:25.200
 for me is humor.

1:35:25.200 --> 1:35:27.200
 That seems to be one of the hardest

1:35:27.200 --> 1:35:29.200
 and to me the biggest contrast

1:35:29.200 --> 1:35:31.200
 is Watson.

1:35:31.200 --> 1:35:33.200
 So one of the greatest

1:35:33.200 --> 1:35:35.200
 comedy sketches of all time

1:35:35.200 --> 1:35:37.200
 is the SNL celebrity

1:35:37.200 --> 1:35:39.200
 Jeopardy

1:35:39.200 --> 1:35:41.200
 with Alex Rebecca and

1:35:41.200 --> 1:35:43.200
 John Connery and Bert Reynolds

1:35:43.200 --> 1:35:45.200
 and so on

1:35:45.200 --> 1:35:47.200
 with John Connery commentating

1:35:47.200 --> 1:35:49.200
 on Alex Rebecca's mother a lot.

1:35:49.200 --> 1:35:51.200
 And I think all of them

1:35:51.200 --> 1:35:53.200
 are in the negative point that's why.

1:35:53.200 --> 1:35:55.200
 So they're clearly all losing

1:35:55.200 --> 1:35:57.200
 in terms of the game of Jeopardy

1:35:57.200 --> 1:35:59.200
 but they're winning in terms of comedy.

1:35:59.200 --> 1:36:01.200
 So what do you think

1:36:01.200 --> 1:36:03.200
 about humor in this whole interaction

1:36:03.200 --> 1:36:05.200
 in the dialogue

1:36:05.200 --> 1:36:07.200
 that's productive?

1:36:07.200 --> 1:36:09.200
 Or even just whatever

1:36:09.200 --> 1:36:11.200
 what humor represents to me is

1:36:11.200 --> 1:36:13.200
 the same

1:36:13.200 --> 1:36:15.200
 idea that you're saying about framework

1:36:15.200 --> 1:36:17.200
 because humor only exists within a particular

1:36:17.200 --> 1:36:19.200
 human framework. So what do you think

1:36:19.200 --> 1:36:21.200
 about humor? What do you think about things

1:36:21.200 --> 1:36:23.200
 like humor that connect to the kind of creativity

1:36:23.200 --> 1:36:25.200
 you mentioned that's needed?

1:36:25.200 --> 1:36:27.200
 I think there's a couple of things going on there.

1:36:27.200 --> 1:36:29.200
 So I sort of feel like

1:36:29.200 --> 1:36:31.200
 and I might be too optimistic

1:36:31.200 --> 1:36:33.200
 this way but I think that

1:36:33.200 --> 1:36:35.200
 there are, we did

1:36:35.200 --> 1:36:37.200
 a little bit about with this

1:36:37.200 --> 1:36:39.200
 with puns in Jeopardy.

1:36:39.200 --> 1:36:41.200
 We literally sat down and said

1:36:41.200 --> 1:36:43.200
 how do puns work?

1:36:43.200 --> 1:36:45.200
 And it's like word play

1:36:45.200 --> 1:36:47.200
 and you could formalize these things.

1:36:47.200 --> 1:36:49.200
 So I think there's a lot aspects of humor

1:36:49.200 --> 1:36:51.200
 that you could formalize.

1:36:51.200 --> 1:36:53.200
 You could also learn humor. You could just say

1:36:53.200 --> 1:36:55.200
 what do people laugh at.

1:36:55.200 --> 1:36:57.200
 And if you have enough data to represent

1:36:57.200 --> 1:36:59.200
 the phenomenon, you might be able to

1:36:59.200 --> 1:37:01.200
 weigh the features and figure out

1:37:01.200 --> 1:37:03.200
 what humans find funny and what they don't find funny.

1:37:03.200 --> 1:37:05.200
 The machine might not be able to explain

1:37:05.200 --> 1:37:07.200
 why you might want to get funny

1:37:07.200 --> 1:37:09.200
 unless we sit back and think about that

1:37:09.200 --> 1:37:11.200
 more formally. I think, again,

1:37:11.200 --> 1:37:13.200
 I think you do a combination of both.

1:37:13.200 --> 1:37:15.200
 And I'm always a big proponent of that.

1:37:15.200 --> 1:37:17.200
 I think robust architectures and approaches

1:37:17.200 --> 1:37:19.200
 are always a little bit of a combination of

1:37:19.200 --> 1:37:21.200
 us reflecting and being creative about

1:37:21.200 --> 1:37:23.200
 how things are structured, how to formalize them

1:37:23.200 --> 1:37:25.200
 and then taking advantage of large data

1:37:25.200 --> 1:37:27.200
 and doing learning and figuring out how to combine

1:37:27.200 --> 1:37:29.200
 these two approaches.

1:37:29.200 --> 1:37:31.200
 I think there's another aspect to humor though

1:37:31.200 --> 1:37:33.200
 which goes to the idea that

1:37:33.200 --> 1:37:35.200
 I feel like I can relate to the person

1:37:35.200 --> 1:37:37.200
 telling the story.

1:37:37.200 --> 1:37:39.200
 And I think that's

1:37:39.200 --> 1:37:41.200
 an interesting theme

1:37:41.200 --> 1:37:43.200
 in the whole AI theme

1:37:43.200 --> 1:37:45.200
 which is, do I

1:37:45.200 --> 1:37:47.200
 feel differently when I know it's a robot?

1:37:47.200 --> 1:37:49.200
 And

1:37:49.200 --> 1:37:51.200
 when I imagine

1:37:51.200 --> 1:37:53.200
 that the robot is not conscious the way I'm

1:37:53.200 --> 1:37:55.200
 conscious, when I imagine

1:37:55.200 --> 1:37:57.200
 the robot does not actually have the experiences

1:37:57.200 --> 1:37:59.200
 that I experience, do I find

1:37:59.200 --> 1:38:01.200
 it funny?

1:38:01.200 --> 1:38:03.200
 Or do, because it's not as related,

1:38:03.200 --> 1:38:05.200
 I don't imagine

1:38:05.200 --> 1:38:07.200
 that the person is relating it to it the way I relate to it.

1:38:07.200 --> 1:38:09.200
 I think this also

1:38:09.200 --> 1:38:11.200
 you see this in

1:38:11.200 --> 1:38:13.200
 the arts and in entertainment where

1:38:13.200 --> 1:38:15.200
 like, you know, sometimes you have

1:38:15.200 --> 1:38:17.200
 savants who are remarkable at a thing

1:38:17.200 --> 1:38:19.200
 whether it's sculpture, it's music or whatever.

1:38:19.200 --> 1:38:21.200
 But the people who get the most attention

1:38:21.200 --> 1:38:23.200
 are the people who can

1:38:23.200 --> 1:38:25.200
 evoke

1:38:25.200 --> 1:38:27.200
 a similar emotional response

1:38:27.200 --> 1:38:29.200
 who can get you to

1:38:29.200 --> 1:38:31.200
 emote, right?

1:38:31.200 --> 1:38:33.200
 So the way they are, in other words, who can

1:38:33.200 --> 1:38:35.200
 basically make the connection

1:38:35.200 --> 1:38:37.200
 from the artifact, from the music

1:38:37.200 --> 1:38:39.200
 or the painting of the sculpture

1:38:39.200 --> 1:38:41.200
 to the emotion and get you

1:38:41.200 --> 1:38:43.200
 to share that emotion with them.

1:38:43.200 --> 1:38:45.200
 And that's when it becomes compelling.

1:38:45.200 --> 1:38:47.200
 So they're communicating at a whole different level.

1:38:47.200 --> 1:38:49.200
 They're just not communicating the artifact.

1:38:49.200 --> 1:38:51.200
 They're communicating their emotional response

1:38:51.200 --> 1:38:53.200
 to the artifact. And then you feel like,

1:38:53.200 --> 1:38:55.200
 oh wow, I can relate to that person.

1:38:55.200 --> 1:38:57.200
 I can connect to that person.

1:38:57.200 --> 1:38:59.200
 So I think humor has that

1:38:59.200 --> 1:39:01.200
 part as well.

1:39:01.200 --> 1:39:03.200
 So the idea that

1:39:03.200 --> 1:39:05.200
 you can connect to that person,

1:39:05.200 --> 1:39:07.200
 person being the critical thing.

1:39:07.200 --> 1:39:09.200
 But we're also

1:39:09.200 --> 1:39:11.200
 able to anthropomorphize objects

1:39:11.200 --> 1:39:13.200
 pretty, robots

1:39:13.200 --> 1:39:15.200
 and AI systems pretty well.

1:39:15.200 --> 1:39:17.200
 So we're almost looking

1:39:17.200 --> 1:39:19.200
 to make them human.

1:39:19.200 --> 1:39:21.200
 Maybe from your experience with Watson,

1:39:21.200 --> 1:39:23.200
 maybe you can comment on

1:39:23.200 --> 1:39:25.200
 did you consider that as part,

1:39:25.200 --> 1:39:27.200
 well, obviously the problem of Jeopardy

1:39:27.200 --> 1:39:29.200
 can require anthropomorphization.

1:39:29.200 --> 1:39:31.200
 But nevertheless...

1:39:31.200 --> 1:39:33.200
 Well, there was some interest in doing that

1:39:33.200 --> 1:39:35.200
 and that's another thing I didn't want to do.

1:39:35.200 --> 1:39:37.200
 Because I didn't want to distract from

1:39:37.200 --> 1:39:39.200
 the actual scientific task.

1:39:39.200 --> 1:39:41.200
 But you're absolutely right.

1:39:41.200 --> 1:39:43.200
 Humans do anthropomorphize

1:39:43.200 --> 1:39:45.200
 and without necessarily

1:39:45.200 --> 1:39:47.200
 a lot of work. I mean, you just put some eyes

1:39:47.200 --> 1:39:49.200
 in a couple of eyebrow movements

1:39:49.200 --> 1:39:51.200
 and you're getting humans to react emotionally.

1:39:51.200 --> 1:39:53.200
 And I think you can do that.

1:39:53.200 --> 1:39:55.200
 So I didn't mean to suggest

1:39:55.200 --> 1:39:57.200
 that

1:39:57.200 --> 1:39:59.200
 that connection

1:39:59.200 --> 1:40:01.200
 cannot be mimicked.

1:40:01.200 --> 1:40:03.200
 I think that connection can be mimicked

1:40:03.200 --> 1:40:05.200
 and can produce

1:40:05.200 --> 1:40:07.200
 that emotional response.

1:40:07.200 --> 1:40:09.200
 I just wonder though

1:40:09.200 --> 1:40:11.200
 if you're told

1:40:11.200 --> 1:40:13.200
 what's really going on,

1:40:13.200 --> 1:40:15.200
 if you know that

1:40:15.200 --> 1:40:17.200
 the machine is not conscious,

1:40:17.200 --> 1:40:19.200
 not having the same richness

1:40:19.200 --> 1:40:21.200
 of emotional reactions and understanding

1:40:21.200 --> 1:40:23.200
 that doesn't really share the understanding

1:40:23.200 --> 1:40:25.200
 but essentially just moving its eyebrow

1:40:25.200 --> 1:40:27.200
 or drooping its eyes or making them big

1:40:27.200 --> 1:40:29.200
 or whatever it's doing. Just getting the emotional

1:40:29.200 --> 1:40:31.200
 response. Will you still feel it?

1:40:31.200 --> 1:40:33.200
 Interesting. I think you probably would for a while.

1:40:33.200 --> 1:40:35.200
 And then when it becomes

1:40:35.200 --> 1:40:37.200
 more important that there's a deeper

1:40:37.200 --> 1:40:39.200
 shared understanding, it may run flat.

1:40:39.200 --> 1:40:41.200
 But I don't know. I'm...

1:40:41.200 --> 1:40:43.200
 I'm pretty confident that

1:40:43.200 --> 1:40:45.200
 the majority of the world

1:40:45.200 --> 1:40:47.200
 even if you tell them how it works...

1:40:47.200 --> 1:40:49.200
 It will not matter.

1:40:49.200 --> 1:40:51.200
 Especially if the machine

1:40:51.200 --> 1:40:53.200
 herself says

1:40:53.200 --> 1:40:55.200
 that she is conscious.

1:40:55.200 --> 1:40:57.200
 That's very possible.

1:40:57.200 --> 1:40:59.200
 So you, the scientist that made the machine

1:40:59.200 --> 1:41:01.200
 is saying

1:41:01.200 --> 1:41:03.200
 that this is how the algorithm works.

1:41:03.200 --> 1:41:05.200
 Everybody will just assume you're lying

1:41:05.200 --> 1:41:07.200
 and that there's a conscious being there.

1:41:07.200 --> 1:41:09.200
 You're deep into the science fiction genre now.

1:41:09.200 --> 1:41:11.200
 I don't think it's actually psychology.

1:41:11.200 --> 1:41:13.200
 I think it's not science fiction.

1:41:13.200 --> 1:41:15.200
 I think it's reality.

1:41:15.200 --> 1:41:17.200
 I think it's a really powerful one

1:41:17.200 --> 1:41:19.200
 that we'll have to be exploring

1:41:19.200 --> 1:41:21.200
 for the next few decades.

1:41:21.200 --> 1:41:23.200
 It's a very interesting

1:41:23.200 --> 1:41:25.200
 element of intelligence.

1:41:25.200 --> 1:41:27.200
 So what do you think...

1:41:27.200 --> 1:41:29.200
 We talked about social constructs of intelligence

1:41:29.200 --> 1:41:31.200
 and frameworks

1:41:31.200 --> 1:41:33.200
 in the way humans kind of

1:41:33.200 --> 1:41:35.200
 interpret information.

1:41:35.200 --> 1:41:37.200
 What do you think is a good test of intelligence

1:41:37.200 --> 1:41:39.200
 in your view?

1:41:39.200 --> 1:41:41.200
 So there's the Alan Turing

1:41:41.200 --> 1:41:43.200
 with the Turing test.

1:41:43.200 --> 1:41:45.200
 Watson accomplished something very impressive with Jeopardy.

1:41:45.200 --> 1:41:47.200
 What do you think is a test

1:41:47.200 --> 1:41:49.200
 that would impress the heck out of you

1:41:49.200 --> 1:41:51.200
 that you saw that a computer could do?

1:41:51.200 --> 1:41:53.200
 They would say this is

1:41:53.200 --> 1:41:55.200
 crossing a kind of

1:41:55.200 --> 1:41:57.200
 threshold

1:41:57.200 --> 1:41:59.200
 that gives me pause

1:41:59.200 --> 1:42:01.200
 in a good way.

1:42:01.200 --> 1:42:03.200
 My expectations

1:42:03.200 --> 1:42:05.200
 for AR are generally high.

1:42:05.200 --> 1:42:07.200
 What does high look like, by the way?

1:42:07.200 --> 1:42:09.200
 So not the threshold.

1:42:09.200 --> 1:42:11.200
 Test is a threshold.

1:42:11.200 --> 1:42:13.200
 What do you think is the destination?

1:42:13.200 --> 1:42:15.200
 What do you think is the ceiling?

1:42:15.200 --> 1:42:17.200
 I think

1:42:17.200 --> 1:42:19.200
 machines will, in many measures,

1:42:19.200 --> 1:42:21.200
 will be better than us,

1:42:21.200 --> 1:42:23.200
 will become more effective.

1:42:23.200 --> 1:42:25.200
 In other words, better predictors

1:42:25.200 --> 1:42:27.200
 about a lot of things

1:42:27.200 --> 1:42:29.200
 than ultimately we can do.

1:42:29.200 --> 1:42:31.200
 I think where they're going to struggle

1:42:31.200 --> 1:42:33.200
 is what we've talked about before,

1:42:33.200 --> 1:42:35.200
 which is

1:42:35.200 --> 1:42:37.200
 relating to communicating

1:42:37.200 --> 1:42:39.200
 with and understanding humans

1:42:39.200 --> 1:42:41.200
 in deeper ways.

1:42:41.200 --> 1:42:43.200
 So I think that's a key point.

1:42:43.200 --> 1:42:45.200
 You can create the super parrot.

1:42:45.200 --> 1:42:47.200
 What I mean by the super parrot is

1:42:47.200 --> 1:42:49.200
 given enough data, a machine can mimic

1:42:49.200 --> 1:42:51.200
 your emotional response, can even

1:42:51.200 --> 1:42:53.200
 generate language that will sound smart

1:42:53.200 --> 1:42:55.200
 and what someone else might say

1:42:55.200 --> 1:42:57.200
 under similar circumstances.

1:42:57.200 --> 1:42:59.200
 I would just pause on that.

1:42:59.200 --> 1:43:01.200
 That's the super parrot, right?

1:43:01.200 --> 1:43:03.200
 So given similar circumstances,

1:43:03.200 --> 1:43:05.200
 moves its faces

1:43:05.200 --> 1:43:07.200
 in similar ways,

1:43:07.200 --> 1:43:09.200
 changes its tone of voice in similar ways,

1:43:09.200 --> 1:43:11.200
 produces strings of language

1:43:11.200 --> 1:43:13.200
 that would similar that a human might say,

1:43:13.200 --> 1:43:15.200
 not necessarily

1:43:15.200 --> 1:43:17.200
 being able to produce a

1:43:17.200 --> 1:43:19.200
 logical interpretation or understanding

1:43:19.200 --> 1:43:21.200
 that would

1:43:21.200 --> 1:43:23.200
 ultimately satisfy

1:43:23.200 --> 1:43:25.200
 a critical interrogation

1:43:25.200 --> 1:43:27.200
 or a critical understanding.

1:43:27.200 --> 1:43:29.200
 I think you just described me

1:43:29.200 --> 1:43:31.200
 in a nutshell.

1:43:31.200 --> 1:43:33.200
 So I think philosophically

1:43:33.200 --> 1:43:35.200
 speaking, you could argue

1:43:35.200 --> 1:43:37.200
 that that's all we're doing as human beings

1:43:37.200 --> 1:43:39.200
 to a worse extent.

1:43:39.200 --> 1:43:41.200
 It's very possible humans

1:43:41.200 --> 1:43:43.200
 do behave that way too.

1:43:43.200 --> 1:43:45.200
 So upon deeper probing

1:43:45.200 --> 1:43:47.200
 and deeper interrogation, you may find out

1:43:47.200 --> 1:43:49.200
 that there isn't a shared understanding

1:43:49.200 --> 1:43:51.200
 because I think humans do both.

1:43:51.200 --> 1:43:53.200
 Humans are statistical language model machines

1:43:55.200 --> 1:43:57.200
 and they are capable reasoners.

1:43:57.200 --> 1:43:59.200
 They're both

1:43:59.200 --> 1:44:01.200
 and you don't know which is going on.

1:44:05.200 --> 1:44:07.200
 I think it's an interesting

1:44:07.200 --> 1:44:09.200
 problem

1:44:09.200 --> 1:44:11.200
 we talked earlier about like where we are

1:44:11.200 --> 1:44:13.200
 in our social and political landscape.

1:44:13.200 --> 1:44:15.200
 Can you distinguish

1:44:15.200 --> 1:44:17.200
 someone

1:44:17.200 --> 1:44:19.200
 who can string words together

1:44:19.200 --> 1:44:21.200
 and sound like they know what they're talking about

1:44:21.200 --> 1:44:23.200
 from someone who actually does?

1:44:23.200 --> 1:44:25.200
 Can you do that without dialogue?

1:44:25.200 --> 1:44:27.200
 With that interrogative or probing dialogue?

1:44:29.200 --> 1:44:31.200
 So it's interesting because humans are

1:44:31.200 --> 1:44:33.200
 really good at in their own mind

1:44:33.200 --> 1:44:35.200
 justifying or explaining what they hear

1:44:35.200 --> 1:44:37.200
 because they project

1:44:37.200 --> 1:44:39.200
 their understanding onto yours.

1:44:39.200 --> 1:44:41.200
 So you could say you could put together

1:44:41.200 --> 1:44:43.200
 a string of words

1:44:43.200 --> 1:44:45.200
 and someone will sit there and interpret it

1:44:45.200 --> 1:44:47.200
 in a way that's extremely bias

1:44:47.200 --> 1:44:49.200
 to the way they want to interpret it.

1:44:49.200 --> 1:44:51.200
 They want to assume you're an idiot and they'll interpret it one way.

1:44:51.200 --> 1:44:53.200
 They will assume you're a genius

1:44:53.200 --> 1:44:55.200
 and they'll interpret it another way that suits their needs.

1:44:55.200 --> 1:44:57.200
 So this is tricky business.

1:44:57.200 --> 1:44:59.200
 So I think to answer your question

1:44:59.200 --> 1:45:01.200
 as

1:45:01.200 --> 1:45:03.200
 AI gets better and better mimic

1:45:03.200 --> 1:45:05.200
 and we create the super parrots

1:45:05.200 --> 1:45:07.200
 we're challenged

1:45:07.200 --> 1:45:09.200
 just as we are challenged with humans.

1:45:09.200 --> 1:45:11.200
 Do you really know what you're talking about?

1:45:11.200 --> 1:45:13.200
 Do you have

1:45:13.200 --> 1:45:15.200
 a meaningful interpretation

1:45:15.200 --> 1:45:17.200
 a powerful

1:45:17.200 --> 1:45:19.200
 framework that you could reason over

1:45:19.200 --> 1:45:21.200
 and justify

1:45:21.200 --> 1:45:23.200
 your answers, justify

1:45:23.200 --> 1:45:25.200
 your predictions and your beliefs

1:45:25.200 --> 1:45:27.200
 why you think they make sense?

1:45:27.200 --> 1:45:29.200
 Can you convince me what the implications are?

1:45:29.200 --> 1:45:31.200
 So

1:45:31.200 --> 1:45:33.200
 can you reason intelligently

1:45:33.200 --> 1:45:35.200
 and make me believe

1:45:35.200 --> 1:45:37.200
 that those

1:45:37.200 --> 1:45:39.200
 the implications

1:45:39.200 --> 1:45:41.200
 of your prediction and so forth.

1:45:41.200 --> 1:45:43.200
 So what happens is it becomes reflective.

1:45:45.200 --> 1:45:47.200
 My standard for judging your intelligence

1:45:47.200 --> 1:45:49.200
 depends a lot on mine.

1:45:51.200 --> 1:45:53.200
 But you're saying

1:45:53.200 --> 1:45:55.200
 there should be a large group of people

1:45:55.200 --> 1:45:57.200
 with a certain standard of intelligence

1:45:57.200 --> 1:45:59.200
 to be convinced

1:45:59.200 --> 1:46:01.200
 by this particular

1:46:01.200 --> 1:46:03.200
 AI system

1:46:03.200 --> 1:46:05.200
 then there will pass.

1:46:05.200 --> 1:46:07.200
 There should be.

1:46:07.200 --> 1:46:09.200
 I think depending on the content

1:46:09.200 --> 1:46:11.200
 one of the problems we have there

1:46:11.200 --> 1:46:13.200
 is that if that large community of people

1:46:13.200 --> 1:46:15.200
 are not judging it

1:46:15.200 --> 1:46:17.200
 with regard to a rigorous standard

1:46:17.200 --> 1:46:19.200
 of objective logic and reason

1:46:19.200 --> 1:46:21.200
 you still have a problem

1:46:21.200 --> 1:46:23.200
 like masses of people can be

1:46:23.200 --> 1:46:25.200
 persuaded

1:46:25.200 --> 1:46:27.200
 to turn their brains off.

1:46:31.200 --> 1:46:33.200
 By the way, I have nothing against the one of you.

1:46:33.200 --> 1:46:35.200
 No, I don't know.

1:46:35.200 --> 1:46:37.200
 So you're

1:46:37.200 --> 1:46:39.200
 a part of one of the great

1:46:39.200 --> 1:46:41.200
 benchmarks, challenges

1:46:41.200 --> 1:46:43.200
 of AI history.

1:46:43.200 --> 1:46:45.200
 What do you think about

1:46:45.200 --> 1:46:47.200
 AlphaZero, OpenAI5,

1:46:47.200 --> 1:46:49.200
 AlphaStar accomplishments on video games

1:46:49.200 --> 1:46:51.200
 recently, which are also

1:46:51.200 --> 1:46:53.200
 I think

1:46:53.200 --> 1:46:55.200
 at least in the case of Go

1:46:55.200 --> 1:46:57.200
 with AlphaGo and AlphaZero playing Go

1:46:57.200 --> 1:46:59.200
 was a monumental accomplishment as well.

1:46:59.200 --> 1:47:01.200
 What are your thoughts about that challenge?

1:47:01.200 --> 1:47:03.200
 I think it was a giant landmark for AI.

1:47:03.200 --> 1:47:05.200
 I think it was phenomenal.

1:47:05.200 --> 1:47:07.200
 As one of those other things nobody thought

1:47:07.200 --> 1:47:09.200
 solving Go was going to be easy

1:47:09.200 --> 1:47:11.200
 because it's hard

1:47:11.200 --> 1:47:13.200
 for humans,

1:47:13.200 --> 1:47:15.200
 hard for humans to learn, hard for humans to excel at

1:47:15.200 --> 1:47:17.200
 and so it was

1:47:17.200 --> 1:47:19.200
 another measure of intelligence.

1:47:19.200 --> 1:47:21.200
 It's very cool.

1:47:21.200 --> 1:47:23.200
 I mean, it's very interesting

1:47:23.200 --> 1:47:25.200
 what they did.

1:47:25.200 --> 1:47:27.200
 I loved how they solved the data problem

1:47:27.200 --> 1:47:29.200
 which again, they bootstrapped it

1:47:29.200 --> 1:47:31.200
 and got the machine to play itself

1:47:31.200 --> 1:47:33.200
 to generate enough data to learn from.

1:47:33.200 --> 1:47:35.200
 I think that was brilliant. I think that was great.

1:47:35.200 --> 1:47:37.200
 And of course

1:47:37.200 --> 1:47:39.200
 the result speaks for itself.

1:47:39.200 --> 1:47:41.200
 I think it makes us think about

1:47:41.200 --> 1:47:43.200
 again, what's intelligence?

1:47:43.200 --> 1:47:45.200
 What aspects of intelligence are important?

1:47:45.200 --> 1:47:47.200
 Can the Go machine help

1:47:47.200 --> 1:47:49.200
 make me a better Go player?

1:47:49.200 --> 1:47:51.200
 Is it an alien intelligence?

1:47:51.200 --> 1:47:53.200
 Am I even capable of

1:47:53.200 --> 1:47:55.200
 like again, if we put in

1:47:55.200 --> 1:47:57.200
 very simple terms, it found the function.

1:47:57.200 --> 1:47:59.200
 It found the Go function.

1:47:59.200 --> 1:48:01.200
 Can I even comprehend the Go function?

1:48:01.200 --> 1:48:03.200
 Can I talk about the Go function?

1:48:03.200 --> 1:48:05.200
 Can I conceptualize the Go function like whatever it might be?

1:48:05.200 --> 1:48:07.200
 One of the interesting ideas

1:48:07.200 --> 1:48:09.200
 of that system is that it plays against itself.

1:48:09.200 --> 1:48:11.200
 But there's no human in the loop there.

1:48:13.200 --> 1:48:15.200
 Like you're saying, it could have

1:48:15.200 --> 1:48:17.200
 itself created

1:48:17.200 --> 1:48:19.200
 an alien intelligence.

1:48:19.200 --> 1:48:21.200
 Toward a goal.

1:48:21.200 --> 1:48:23.200
 Imagine you're sentencing, you're judging

1:48:23.200 --> 1:48:25.200
 you're sentencing people.

1:48:25.200 --> 1:48:27.200
 Or you're setting policy.

1:48:27.200 --> 1:48:29.200
 Or you're

1:48:29.200 --> 1:48:31.200
 making medical decisions.

1:48:31.200 --> 1:48:33.200
 And you can't explain.

1:48:33.200 --> 1:48:35.200
 You can't get anybody to understand

1:48:35.200 --> 1:48:37.200
 what you're doing or why.

1:48:37.200 --> 1:48:39.200
 So it's

1:48:39.200 --> 1:48:41.200
 an interesting dilemma

1:48:41.200 --> 1:48:43.200
 for the applications of

1:48:43.200 --> 1:48:45.200
 AI. Do we hold AI to

1:48:45.200 --> 1:48:47.200
 this

1:48:47.200 --> 1:48:49.200
 accountability that says,

1:48:49.200 --> 1:48:51.200
 humans have to be

1:48:51.200 --> 1:48:53.200
 when you take responsibility

1:48:53.200 --> 1:48:55.200
 for the

1:48:55.200 --> 1:48:57.200
 decision. In other words, can you

1:48:57.200 --> 1:48:59.200
 explain why you would do the thing?

1:48:59.200 --> 1:49:01.200
 Will you get up and speak

1:49:01.200 --> 1:49:03.200
 to other humans and convince them that this was

1:49:03.200 --> 1:49:05.200
 a smart decision? Is the AI

1:49:05.200 --> 1:49:07.200
 enabling you to do that?

1:49:07.200 --> 1:49:09.200
 Can you get behind the logic that was

1:49:09.200 --> 1:49:11.200
 made there?

1:49:11.200 --> 1:49:13.200
 Sorry to linger on this point

1:49:13.200 --> 1:49:15.200
 because it's a fascinating one.

1:49:15.200 --> 1:49:17.200
 It's a great goal for AI.

1:49:17.200 --> 1:49:19.200
 Do you think it's achievable

1:49:19.200 --> 1:49:21.200
 in many cases?

1:49:21.200 --> 1:49:23.200
 Okay, there's two possible worlds

1:49:23.200 --> 1:49:25.200
 that we have in the future.

1:49:25.200 --> 1:49:27.200
 One is where AI systems

1:49:27.200 --> 1:49:29.200
 do medical diagnosis or

1:49:29.200 --> 1:49:31.200
 things like that, or drive a car

1:49:31.200 --> 1:49:33.200
 without ever

1:49:33.200 --> 1:49:35.200
 explaining to you why

1:49:35.200 --> 1:49:37.200
 it fails when it does.

1:49:37.200 --> 1:49:39.200
 That's one possible world

1:49:39.200 --> 1:49:41.200
 we're okay with it. Or the other

1:49:41.200 --> 1:49:43.200
 where we are not okay with it and

1:49:43.200 --> 1:49:45.200
 we really hold back the technology

1:49:45.200 --> 1:49:47.200
 from getting too good before it gets

1:49:47.200 --> 1:49:49.200
 able to explain which of those worlds

1:49:49.200 --> 1:49:51.200
 are more likely, do you think, and

1:49:51.200 --> 1:49:53.200
 which are concerning to you or not?

1:49:53.200 --> 1:49:55.200
 I think the reality is it's going to be a mix.

1:49:55.200 --> 1:49:57.200
 I'm not sure I have a problem with

1:49:57.200 --> 1:49:59.200
 that. I think there are tasks that are perfectly

1:49:59.200 --> 1:50:01.200
 fine with

1:50:01.200 --> 1:50:03.200
 machines show a certain level

1:50:03.200 --> 1:50:05.200
 of performance and that level of performance

1:50:05.200 --> 1:50:07.200
 is already better than humans.

1:50:07.200 --> 1:50:09.200
 So, for example, I don't know that

1:50:09.200 --> 1:50:11.200
 I take driverless cars.

1:50:11.200 --> 1:50:13.200
 If driverless cars learn how to be more

1:50:13.200 --> 1:50:15.200
 effective drivers than humans but can't

1:50:15.200 --> 1:50:17.200
 explain what they're doing, but

1:50:17.200 --> 1:50:19.200
 bottom line, statistically speaking,

1:50:19.200 --> 1:50:21.200
 they're 10 times safer

1:50:21.200 --> 1:50:23.200
 than humans. I don't know that

1:50:23.200 --> 1:50:25.200
 I care.

1:50:25.200 --> 1:50:27.200
 I think when we have these edge cases

1:50:27.200 --> 1:50:29.200
 when something bad happens and we want

1:50:29.200 --> 1:50:31.200
 to decide who's liable for that thing

1:50:31.200 --> 1:50:33.200
 and who made that mistake and what do we do

1:50:33.200 --> 1:50:35.200
 about that? And I think in those edge cases

1:50:35.200 --> 1:50:37.200
 are interesting cases.

1:50:37.200 --> 1:50:39.200
 And now do we go to designers of the AI

1:50:39.200 --> 1:50:41.200
 and the AI says, I don't know, that's what it learned

1:50:41.200 --> 1:50:43.200
 to do and it says, well, you didn't train it

1:50:43.200 --> 1:50:45.200
 properly. You know, you were

1:50:45.200 --> 1:50:47.200
 negligent in the training data that you gave

1:50:47.200 --> 1:50:49.200
 that machine. Like, how do we drive down

1:50:49.200 --> 1:50:51.200
 the real level? So, I think those are

1:50:51.200 --> 1:50:53.200
 interesting questions.

1:50:53.200 --> 1:50:55.200
 So, the optimization problem there, sorry,

1:50:55.200 --> 1:50:57.200
 is to create an ass system that's able to

1:50:57.200 --> 1:50:59.200
 explain the lawyers away.

1:50:59.200 --> 1:51:01.200
 There you go.

1:51:01.200 --> 1:51:03.200
 I think that

1:51:03.200 --> 1:51:05.200
 is going to be interesting. I mean, I think this is where

1:51:05.200 --> 1:51:07.200
 technology and social discourse are going to get

1:51:07.200 --> 1:51:09.200
 like deeply intertwined

1:51:09.200 --> 1:51:11.200
 in how we start thinking about

1:51:11.200 --> 1:51:13.200
 problems, decisions and problems like that.

1:51:13.200 --> 1:51:15.200
 I think in other cases, it becomes more obvious

1:51:15.200 --> 1:51:17.200
 where

1:51:17.200 --> 1:51:19.200
 it's like

1:51:19.200 --> 1:51:21.200
 why did you decide to give that person

1:51:21.200 --> 1:51:23.200
 a longer sentence

1:51:23.200 --> 1:51:25.200
 or deny them

1:51:25.200 --> 1:51:27.200
 parole?

1:51:27.200 --> 1:51:29.200
 Again, policy decisions or

1:51:29.200 --> 1:51:31.200
 why did you pick that treatment? Like that treatment

1:51:31.200 --> 1:51:33.200
 ended up killing that guy. Like, why was that

1:51:33.200 --> 1:51:35.200
 a reasonable choice to make?

1:51:35.200 --> 1:51:37.200
 So,

1:51:37.200 --> 1:51:39.200
 and people are going to demand

1:51:39.200 --> 1:51:41.200
 explanations. Now, there's a reality

1:51:41.200 --> 1:51:43.200
 though here.

1:51:43.200 --> 1:51:45.200
 And the reality is that it's not,

1:51:45.200 --> 1:51:47.200
 I'm not sure humans are making

1:51:47.200 --> 1:51:49.200
 reasonable choices when they do these

1:51:49.200 --> 1:51:51.200
 things. They are using

1:51:51.200 --> 1:51:53.200
 statistical hunches,

1:51:53.200 --> 1:51:55.200
 biases, or even

1:51:55.200 --> 1:51:57.200
 systematically using

1:51:57.200 --> 1:51:59.200
 statistical averages to make cause.

1:51:59.200 --> 1:52:01.200
 And this is what happened. My dad, if you saw

1:52:01.200 --> 1:52:03.200
 the talk I gave about that, but

1:52:03.200 --> 1:52:05.200
 you know, I mean, they decided

1:52:05.200 --> 1:52:07.200
 that my father was brain dead.

1:52:07.200 --> 1:52:09.200
 He had went into cardiac arrest

1:52:09.200 --> 1:52:11.200
 and it took a long time

1:52:11.200 --> 1:52:13.200
 for the ambulance to get there and he wasn't not

1:52:13.200 --> 1:52:15.200
 resuscitated right away and so forth. And they came

1:52:15.200 --> 1:52:17.200
 and they told me he was brain dead and why

1:52:17.200 --> 1:52:19.200
 was he brain dead? Because essentially they gave me

1:52:19.200 --> 1:52:21.200
 a purely statistical argument

1:52:21.200 --> 1:52:23.200
 under these conditions with these four features

1:52:23.200 --> 1:52:25.200
 98% chance he's brain dead.

1:52:25.200 --> 1:52:27.200
 I said, but can you just tell me

1:52:27.200 --> 1:52:29.200
 not inductively, but deductively

1:52:29.200 --> 1:52:31.200
 go there and tell me his brain's not functioning

1:52:31.200 --> 1:52:33.200
 is the way for you to do that. And

1:52:33.200 --> 1:52:35.200
 the protocol

1:52:35.200 --> 1:52:37.200
 in response was, no, this is how we make this decision.

1:52:37.200 --> 1:52:39.200
 I said, this is inadequate for me.

1:52:39.200 --> 1:52:41.200
 I understand the statistics and

1:52:41.200 --> 1:52:43.200
 I don't know how, you know,

1:52:43.200 --> 1:52:45.200
 there's a 2% chance he's still alive. I just don't

1:52:45.200 --> 1:52:47.200
 know the specifics. I need the specifics

1:52:47.200 --> 1:52:49.200
 of this case

1:52:49.200 --> 1:52:51.200
 and I want the deductive logical argument

1:52:51.200 --> 1:52:53.200
 about why you actually know he's brain dead.

1:52:53.200 --> 1:52:55.200
 So I wouldn't sign that do not resuscitate.

1:52:55.200 --> 1:52:57.200
 And I don't know, it was like

1:52:57.200 --> 1:52:59.200
 they went through lots of procedures, a big long

1:52:59.200 --> 1:53:01.200
 story, but the bottom was a fascinating

1:53:01.200 --> 1:53:03.200
 story, by the way, but how I reasoned

1:53:03.200 --> 1:53:05.200
 and how the doctors reasoned through this whole process.

1:53:05.200 --> 1:53:07.200
 But I don't know, somewhere around

1:53:07.200 --> 1:53:09.200
 24 hours later or something, he was sitting up

1:53:09.200 --> 1:53:11.200
 in bed with zero brain damage.

1:53:13.200 --> 1:53:15.200
 What lessons do you draw from

1:53:15.200 --> 1:53:17.200
 that

1:53:17.200 --> 1:53:19.200
 story, that experience?

1:53:19.200 --> 1:53:21.200
 That the data that

1:53:21.200 --> 1:53:23.200
 the data that's being used to make statistical

1:53:23.200 --> 1:53:25.200
 inferences doesn't adequately

1:53:25.200 --> 1:53:27.200
 reflect the phenomenon. So in other words,

1:53:27.200 --> 1:53:29.200
 you're getting shit wrong, sorry,

1:53:29.200 --> 1:53:31.200
 you're getting stuff wrong

1:53:31.200 --> 1:53:33.200
 because your model

1:53:33.200 --> 1:53:35.200
 is not robust enough

1:53:35.200 --> 1:53:37.200
 and you might be

1:53:37.200 --> 1:53:39.200
 better off

1:53:39.200 --> 1:53:41.200
 not using statistical

1:53:41.200 --> 1:53:43.200
 inferences and statistical averages in certain cases

1:53:43.200 --> 1:53:45.200
 when you know the model is insufficient

1:53:45.200 --> 1:53:47.200
 and that you should be reasoning about the

1:53:47.200 --> 1:53:49.200
 specific case more logically

1:53:49.200 --> 1:53:51.200
 and more deductively

1:53:51.200 --> 1:53:53.200
 and hold yourself responsible and accountable

1:53:53.200 --> 1:53:55.200
 to doing that.

1:53:55.200 --> 1:53:57.200
 And perhaps

1:53:57.200 --> 1:53:59.200
 AI has a role to say the exact

1:53:59.200 --> 1:54:01.200
 thing that you just said, which is

1:54:01.200 --> 1:54:03.200
 perhaps this is a case

1:54:03.200 --> 1:54:05.200
 you should think for yourself.

1:54:05.200 --> 1:54:07.200
 You should reason deductively.

1:54:09.200 --> 1:54:11.200
 So it's hard because

1:54:11.200 --> 1:54:13.200
 it's hard to know

1:54:13.200 --> 1:54:15.200
 that.

1:54:15.200 --> 1:54:17.200
 You'd have to go back and you'd have to have enough

1:54:17.200 --> 1:54:19.200
 data to essentially say, and this goes back

1:54:19.200 --> 1:54:21.200
 to the case of how do we decide

1:54:21.200 --> 1:54:23.200
 whether AI is good enough to do a particular

1:54:23.200 --> 1:54:25.200
 task.

1:54:25.200 --> 1:54:27.200
 And regardless of whether or not

1:54:27.200 --> 1:54:29.200
 it produces an explanation.

1:54:29.200 --> 1:54:31.200
 So and

1:54:31.200 --> 1:54:33.200
 what standard do we hold

1:54:33.200 --> 1:54:35.200
 for that?

1:54:39.200 --> 1:54:41.200
 If you look more

1:54:41.200 --> 1:54:43.200
 broadly, for example,

1:54:43.200 --> 1:54:45.200
 as my father, as a medical

1:54:45.200 --> 1:54:47.200
 case,

1:54:47.200 --> 1:54:49.200
 the medical system ultimately

1:54:49.200 --> 1:54:51.200
 helped him a lot throughout his life.

1:54:51.200 --> 1:54:53.200
 Without it, he probably

1:54:53.200 --> 1:54:55.200
 would have died much sooner.

1:54:55.200 --> 1:54:57.200
 So overall sort of

1:54:57.200 --> 1:54:59.200
 work for him

1:54:59.200 --> 1:55:01.200
 in sort of a net kind of way.

1:55:01.200 --> 1:55:03.200
 Actually, I don't know

1:55:03.200 --> 1:55:05.200
 that's fair.

1:55:05.200 --> 1:55:07.200
 But it may be not in that particular case, but overall

1:55:07.200 --> 1:55:09.200
 the medical system overall

1:55:09.200 --> 1:55:11.200
 does more good than bad.

1:55:11.200 --> 1:55:13.200
 The medical system overall was doing

1:55:13.200 --> 1:55:15.200
 more good than bad. Now there's another argument

1:55:15.200 --> 1:55:17.200
 that suggests that there wasn't a case,

1:55:17.200 --> 1:55:19.200
 but for the sake of argument, let's say like

1:55:19.200 --> 1:55:21.200
 that's let's say a net positive.

1:55:21.200 --> 1:55:23.200
 And I think you have to sit there and take that

1:55:23.200 --> 1:55:25.200
 into consideration. Now you

1:55:25.200 --> 1:55:27.200
 look at a particular use case, like for example

1:55:27.200 --> 1:55:29.200
 making this decision.

1:55:29.200 --> 1:55:31.200
 Have you done enough studies

1:55:31.200 --> 1:55:33.200
 to know

1:55:33.200 --> 1:55:35.200
 how good that prediction really is?

1:55:35.200 --> 1:55:37.200
 Right.

1:55:37.200 --> 1:55:39.200
 And have you done enough studies to compare

1:55:39.200 --> 1:55:41.200
 it to say, well, what if we

1:55:41.200 --> 1:55:43.200
 what if we dug in

1:55:43.200 --> 1:55:45.200
 in a more direct

1:55:45.200 --> 1:55:47.200
 let's get the evidence, let's do

1:55:47.200 --> 1:55:49.200
 the deductive thing and not use statistics here.

1:55:49.200 --> 1:55:51.200
 How often would that have done better?

1:55:51.200 --> 1:55:53.200
 So you have to do

1:55:53.200 --> 1:55:55.200
 the studies to know how good the AI actually

1:55:55.200 --> 1:55:57.200
 is. And it's complicated

1:55:57.200 --> 1:55:59.200
 because it depends how fast you have to make the decision.

1:55:59.200 --> 1:56:01.200
 So if you have to make the decision super fast,

1:56:01.200 --> 1:56:03.200
 do you have no choice?

1:56:03.200 --> 1:56:05.200
 Right. If you have

1:56:05.200 --> 1:56:07.200
 more time, right, but if you're ready

1:56:07.200 --> 1:56:09.200
 to pull the plug,

1:56:09.200 --> 1:56:11.200
 and this is a lot of the argument that I had was a doctor,

1:56:11.200 --> 1:56:13.200
 I said, what's he going to do if you do it?

1:56:13.200 --> 1:56:15.200
 What's going to happen to him in that room

1:56:15.200 --> 1:56:17.200
 if you do it my way?

1:56:17.200 --> 1:56:19.200
 Well, he's going to die anyway.

1:56:19.200 --> 1:56:21.200
 So let's do it my way then.

1:56:21.200 --> 1:56:23.200
 I mean, it raises questions for our society

1:56:23.200 --> 1:56:25.200
 to struggle with as

1:56:25.200 --> 1:56:27.200
 the case with your father,

1:56:27.200 --> 1:56:29.200
 but also when things like race and gender

1:56:29.200 --> 1:56:31.200
 start coming into play, when

1:56:31.200 --> 1:56:33.200
 when judgments are

1:56:33.200 --> 1:56:35.200
 made based on things

1:56:35.200 --> 1:56:37.200
 that are

1:56:37.200 --> 1:56:39.200
 complicated in our society, at least

1:56:39.200 --> 1:56:41.200
 in discourse. And it starts

1:56:41.200 --> 1:56:43.200
 I think

1:56:43.200 --> 1:56:45.200
 I'm safe to say that most

1:56:45.200 --> 1:56:47.200
 of the violent crime is committed by males.

1:56:49.200 --> 1:56:51.200
 So if you discriminate based

1:56:51.200 --> 1:56:53.200
 with the male versus female

1:56:53.200 --> 1:56:55.200
 saying that if it's a male, more likely

1:56:55.200 --> 1:56:57.200
 to commit the crime. This is one of my

1:56:57.200 --> 1:56:59.200
 very positive

1:56:59.200 --> 1:57:01.200
 and optimistic views

1:57:01.200 --> 1:57:03.200
 of why

1:57:03.200 --> 1:57:05.200
 the study of artificial intelligence,

1:57:05.200 --> 1:57:07.200
 the process of thinking and reasoning,

1:57:07.200 --> 1:57:09.200
 logically and statistically

1:57:09.200 --> 1:57:11.200
 and how to combine them is so important

1:57:11.200 --> 1:57:13.200
 for the discourse today because it's causing

1:57:13.200 --> 1:57:15.200
 regardless of what

1:57:15.200 --> 1:57:17.200
 what state AI devices

1:57:17.200 --> 1:57:19.200
 are or not

1:57:19.200 --> 1:57:21.200
 it's causing this

1:57:21.200 --> 1:57:23.200
 dialogue to happen. This is one of the most

1:57:23.200 --> 1:57:25.200
 important dialogues that

1:57:25.200 --> 1:57:27.200
 in my view, the human species can have

1:57:27.200 --> 1:57:29.200
 right now, which is

1:57:29.200 --> 1:57:31.200
 how to think well.

1:57:31.200 --> 1:57:33.200
 How to reason

1:57:33.200 --> 1:57:35.200
 well, how to understand our

1:57:35.200 --> 1:57:37.200
 own

1:57:37.200 --> 1:57:39.200
 cognitive biases

1:57:39.200 --> 1:57:41.200
 and what to do about them.

1:57:41.200 --> 1:57:43.200
 That has got to be one of the most important

1:57:43.200 --> 1:57:45.200
 things we as

1:57:45.200 --> 1:57:47.200
 a species can be doing honestly.

1:57:47.200 --> 1:57:49.200
 We have created

1:57:49.200 --> 1:57:51.200
 an incredibly complex society.

1:57:51.200 --> 1:57:53.200
 We've created amazing

1:57:53.200 --> 1:57:55.200
 abilities to amplify

1:57:55.200 --> 1:57:57.200
 noise faster than we can

1:57:57.200 --> 1:57:59.200
 amplify signal.

1:57:59.200 --> 1:58:01.200
 We are challenged.

1:58:01.200 --> 1:58:03.200
 We are deeply, deeply challenged.

1:58:03.200 --> 1:58:05.200
 We have

1:58:05.200 --> 1:58:07.200
 big segments of the population getting hit with

1:58:07.200 --> 1:58:09.200
 enormous amounts of information.

1:58:09.200 --> 1:58:11.200
 Do they know how to do critical thinking?

1:58:11.200 --> 1:58:13.200
 Do they know how to objectively

1:58:13.200 --> 1:58:15.200
 reason? Do they understand

1:58:15.200 --> 1:58:17.200
 what they are doing, never mind

1:58:17.200 --> 1:58:19.200
 what their AI is doing?

1:58:19.200 --> 1:58:21.200
 This is such an important dialogue

1:58:21.200 --> 1:58:23.200
 to be having.

1:58:23.200 --> 1:58:25.200
 And

1:58:25.200 --> 1:58:27.200
 we are fundamentally

1:58:27.200 --> 1:58:29.200
 thinking can be and easily becomes

1:58:29.200 --> 1:58:31.200
 fundamentally bias.

1:58:31.200 --> 1:58:33.200
 And there are statistics

1:58:33.200 --> 1:58:35.200
 and we shouldn't blind us. We shouldn't

1:58:35.200 --> 1:58:37.200
 discard statistical inference.

1:58:37.200 --> 1:58:39.200
 But we should understand the nature

1:58:39.200 --> 1:58:41.200
 of statistical inference.

1:58:41.200 --> 1:58:43.200
 As a society,

1:58:43.200 --> 1:58:45.200
 we decide

1:58:45.200 --> 1:58:47.200
 to reject statistical

1:58:47.200 --> 1:58:49.200
 inference

1:58:49.200 --> 1:58:51.200
 to favor

1:58:51.200 --> 1:58:53.200
 understanding and

1:58:53.200 --> 1:58:55.200
 deciding on the individual.

1:58:55.200 --> 1:58:57.200
 Yes.

1:58:57.200 --> 1:58:59.200
 We consciously

1:58:59.200 --> 1:59:01.200
 reject that choice.

1:59:01.200 --> 1:59:03.200
 So even if the statistics said

1:59:03.200 --> 1:59:05.200
 even

1:59:05.200 --> 1:59:07.200
 if the statistics said

1:59:07.200 --> 1:59:09.200
 males are more likely to have

1:59:09.200 --> 1:59:11.200
 to be violent criminals, we still take

1:59:11.200 --> 1:59:13.200
 each person as an individual

1:59:13.200 --> 1:59:15.200
 and we treat them

1:59:15.200 --> 1:59:17.200
 based on the logic

1:59:17.200 --> 1:59:19.200
 and the knowledge of that

1:59:19.200 --> 1:59:21.200
 situation.

1:59:21.200 --> 1:59:23.200
 We purposefully and intentionally

1:59:23.200 --> 1:59:25.200
 reject

1:59:25.200 --> 1:59:27.200
 the statistical inference.

1:59:27.200 --> 1:59:29.200
 We do that

1:59:29.200 --> 1:59:31.200
 at a respect for the individual.

1:59:31.200 --> 1:59:33.200
 For the individual. And that requires reasoning

1:59:33.200 --> 1:59:35.200
 and thinking.

1:59:35.200 --> 1:59:37.200
 Looking forward, what grand challenges

1:59:37.200 --> 1:59:39.200
 would you like to see in the future?

1:59:39.200 --> 1:59:41.200
 Because

1:59:41.200 --> 1:59:43.200
 the Jeopardy Challenge

1:59:43.200 --> 1:59:45.200
 captivated the world.

1:59:45.200 --> 1:59:47.200
 AlphaGo, AlphaZero

1:59:47.200 --> 1:59:49.200
 captivated the world. DBLU, certainly beating

1:59:49.200 --> 1:59:51.200
 Kasparov,

1:59:51.200 --> 1:59:53.200
 Gary's bitterness aside

1:59:53.200 --> 1:59:55.200
 captivated the world.

1:59:55.200 --> 1:59:57.200
 What do you think

1:59:57.200 --> 1:59:59.200
 do you have ideas for next grand challenges for

1:59:59.200 --> 2:00:01.200
 future challenges of that?

2:00:01.200 --> 2:00:03.200
 Look, I mean, I think there are lots of

2:00:03.200 --> 2:00:05.200
 really great ideas for grand challenges.

2:00:05.200 --> 2:00:07.200
 I'm particularly

2:00:07.200 --> 2:00:09.200
 focused on one right now which is

2:00:09.200 --> 2:00:11.200
 can you

2:00:11.200 --> 2:00:13.200
 demonstrate that they understand, that they could

2:00:13.200 --> 2:00:15.200
 read and understand

2:00:15.200 --> 2:00:17.200
 that they can acquire these frameworks

2:00:17.200 --> 2:00:19.200
 and

2:00:19.200 --> 2:00:21.200
 reason and communicate with humans.

2:00:21.200 --> 2:00:23.200
 So it is kind of like the Turing task

2:00:23.200 --> 2:00:25.200
 but it's a little bit more demanding

2:00:25.200 --> 2:00:27.200
 than the Turing task. It's not enough

2:00:27.200 --> 2:00:29.200
 to convince me

2:00:29.200 --> 2:00:31.200
 that you might be human

2:00:31.200 --> 2:00:33.200
 because you can

2:00:33.200 --> 2:00:35.200
 pair it a conversation.

2:00:35.200 --> 2:00:37.200
 I think the standard

2:00:37.200 --> 2:00:39.200
 is a little bit higher.

2:00:39.200 --> 2:00:41.200
 For example,

2:00:41.200 --> 2:00:43.200
 the standard is higher

2:00:43.200 --> 2:00:45.200
 and I think one of the challenges

2:00:45.200 --> 2:00:47.200
 of devising this grand challenge

2:00:47.200 --> 2:00:49.200
 is that

2:00:49.200 --> 2:00:51.200
 we're not sure

2:00:51.200 --> 2:00:53.200
 what intelligence is.

2:00:53.200 --> 2:00:55.200
 We're not sure how to determine

2:00:55.200 --> 2:00:57.200
 whether or not two people

2:00:57.200 --> 2:00:59.200
 actually understand each other

2:00:59.200 --> 2:01:01.200
 and in what depth they understand it.

2:01:01.200 --> 2:01:03.200
 You know, to what depth they understand

2:01:03.200 --> 2:01:05.200
 each other. So

2:01:05.200 --> 2:01:07.200
 the challenge becomes something along the lines

2:01:07.200 --> 2:01:09.200
 of can you

2:01:09.200 --> 2:01:11.200
 satisfy me

2:01:11.200 --> 2:01:13.200
 that we have

2:01:13.200 --> 2:01:15.200
 a shared understanding.

2:01:15.200 --> 2:01:17.200
 So if I were to probe

2:01:17.200 --> 2:01:19.200
 and probe and you probe me,

2:01:19.200 --> 2:01:21.200
 can machines really

2:01:21.200 --> 2:01:23.200
 act like thought partners

2:01:23.200 --> 2:01:25.200
 where they can satisfy me

2:01:25.200 --> 2:01:27.200
 that we have

2:01:27.200 --> 2:01:29.200
 our understanding is shared enough

2:01:29.200 --> 2:01:31.200
 that we can collaborate

2:01:31.200 --> 2:01:33.200
 and produce answers together

2:01:33.200 --> 2:01:35.200
 and that they can help me explain

2:01:35.200 --> 2:01:37.200
 and justify those answers.

2:01:37.200 --> 2:01:39.200
 So maybe here's an idea.

2:01:39.200 --> 2:01:41.200
 We'll have AI system

2:01:41.200 --> 2:01:43.200
 run for president

2:01:43.200 --> 2:01:45.200
 and convince...

2:01:45.200 --> 2:01:47.200
 That's too easy.

2:01:47.200 --> 2:01:49.200
 We can convince the voters

2:01:49.200 --> 2:01:51.200
 that they should vote.

2:01:51.200 --> 2:01:53.200
 So like, I guess, what does

2:01:53.200 --> 2:01:55.200
 winning look like?

2:01:55.200 --> 2:01:57.200
 Again, that's why I think this is such a challenge

2:01:57.200 --> 2:01:59.200
 because we go back to

2:01:59.200 --> 2:02:01.200
 the emotional persuasion.

2:02:01.200 --> 2:02:03.200
 We go back to, you know,

2:02:03.200 --> 2:02:05.200
 now we're checking off

2:02:05.200 --> 2:02:07.200
 an aspect

2:02:07.200 --> 2:02:09.200
 of human cognition

2:02:09.200 --> 2:02:11.200
 that is in many ways

2:02:11.200 --> 2:02:13.200
 weak or flawed, right?

2:02:13.200 --> 2:02:15.200
 We're so easily manipulated.

2:02:15.200 --> 2:02:17.200
 We're on

2:02:17.200 --> 2:02:19.200
 for often the wrong reasons,

2:02:19.200 --> 2:02:21.200
 right? Not the reasons

2:02:21.200 --> 2:02:23.200
 that ultimately mattered us,

2:02:23.200 --> 2:02:25.200
 but the reasons that can easily persuade us.

2:02:25.200 --> 2:02:27.200
 I think we can be persuaded

2:02:27.200 --> 2:02:29.200
 to believe one thing or another

2:02:29.200 --> 2:02:31.200
 for reasons that ultimately

2:02:31.200 --> 2:02:33.200
 don't serve us well in the long term.

2:02:33.200 --> 2:02:35.200
 And a good benchmark

2:02:35.200 --> 2:02:37.200
 should not play with those

2:02:37.200 --> 2:02:39.200
 elements

2:02:39.200 --> 2:02:41.200
 of emotional manipulation.

2:02:41.200 --> 2:02:43.200
 I don't think so. And I think that's where

2:02:43.200 --> 2:02:45.200
 we set the higher standard

2:02:45.200 --> 2:02:47.200
 for ourselves.

2:02:47.200 --> 2:02:49.200
 This goes back to rationality

2:02:49.200 --> 2:02:51.200
 and it goes back to objective thinking.

2:02:51.200 --> 2:02:53.200
 Can you acquire information

2:02:53.200 --> 2:02:55.200
 and produce reasoned arguments

2:02:55.200 --> 2:02:57.200
 and to those reasons, arguments pass

2:02:57.200 --> 2:02:59.200
 a certain amount of muster?

2:02:59.200 --> 2:03:01.200
 And can you

2:03:01.200 --> 2:03:03.200
 acquire new knowledge?

2:03:03.200 --> 2:03:05.200
 For example,

2:03:05.200 --> 2:03:07.200
 I have acquired new knowledge.

2:03:07.200 --> 2:03:09.200
 Can you identify where it's

2:03:09.200 --> 2:03:11.200
 consistent or contradictory

2:03:11.200 --> 2:03:13.200
 with other things you've learned?

2:03:13.200 --> 2:03:15.200
 And can you explain that to me and get me to understand that?

2:03:15.200 --> 2:03:17.200
 So I think another way

2:03:17.200 --> 2:03:19.200
 to think about it perhaps

2:03:21.200 --> 2:03:23.200
 is can a machine teach you?

2:03:27.200 --> 2:03:29.200
 Can it help you?

2:03:29.200 --> 2:03:31.200
 Can it help you understand

2:03:31.200 --> 2:03:33.200
 something that you didn't really understand before?

2:03:33.200 --> 2:03:35.200
 Where

2:03:35.200 --> 2:03:37.200
 it's taking you through?

2:03:37.200 --> 2:03:39.200
 So you're not,

2:03:39.200 --> 2:03:41.200
 again, it's almost like, can it teach

2:03:41.200 --> 2:03:43.200
 you? Can it help you learn?

2:03:43.200 --> 2:03:45.200
 And

2:03:45.200 --> 2:03:47.200
 in an arbitrary space

2:03:47.200 --> 2:03:49.200
 so it can open those domain space.

2:03:49.200 --> 2:03:51.200
 So can you tell the machine, again, this

2:03:51.200 --> 2:03:53.200
 borrows from some science fictions, but

2:03:53.200 --> 2:03:55.200
 can you go off and learn about this

2:03:55.200 --> 2:03:57.200
 topic that I'd like to understand

2:03:57.200 --> 2:03:59.200
 better and then work with

2:03:59.200 --> 2:04:01.200
 me to help me understand it?

2:04:01.200 --> 2:04:03.200
 That's quite brilliant.

2:04:03.200 --> 2:04:05.200
 Well, the machine

2:04:05.200 --> 2:04:07.200
 that passes that kind of test,

2:04:07.200 --> 2:04:09.200
 do you think it would need to

2:04:09.200 --> 2:04:11.200
 have

2:04:11.200 --> 2:04:13.200
 self awareness or even consciousness?

2:04:13.200 --> 2:04:15.200
 What do you think about

2:04:15.200 --> 2:04:17.200
 consciousness and the importance of it?

2:04:17.200 --> 2:04:19.200
 Maybe in relation to

2:04:19.200 --> 2:04:21.200
 having a body,

2:04:21.200 --> 2:04:23.200
 having a presence,

2:04:23.200 --> 2:04:25.200
 an entity.

2:04:25.200 --> 2:04:27.200
 Do you think that's important?

2:04:27.200 --> 2:04:29.200
 People used to ask me if Watson was conscious

2:04:29.200 --> 2:04:31.200
 and I used to say,

2:04:31.200 --> 2:04:33.200
 are you conscious of what exactly?

2:04:33.200 --> 2:04:35.200
 I think maybe it depends

2:04:35.200 --> 2:04:37.200
 on what you're conscious of.

2:04:37.200 --> 2:04:39.200
 So

2:04:39.200 --> 2:04:41.200
 it's certainly

2:04:41.200 --> 2:04:43.200
 easy for it to answer questions about

2:04:43.200 --> 2:04:45.200
 it would be trivial to program it.

2:04:45.200 --> 2:04:47.200
 So to answer questions about whether or not

2:04:47.200 --> 2:04:49.200
 it was playing jeopardy. I mean, it could

2:04:49.200 --> 2:04:51.200
 certainly answer questions that would imply

2:04:51.200 --> 2:04:53.200
 that it was aware of things. Exactly.

2:04:53.200 --> 2:04:55.200
 What does it mean to be aware and what does it

2:04:55.200 --> 2:04:57.200
 mean to consciousness? It's sort of interesting.

2:04:57.200 --> 2:04:59.200
 I mean, I think that we differ from one

2:04:59.200 --> 2:05:01.200
 another based on what we're conscious

2:05:01.200 --> 2:05:03.200
 of.

2:05:03.200 --> 2:05:05.200
 We're conscious of consciousness in there.

2:05:05.200 --> 2:05:07.200
 Well, there's just areas.

2:05:07.200 --> 2:05:09.200
 It's not just degrees.

2:05:09.200 --> 2:05:11.200
 What are you aware of?

2:05:11.200 --> 2:05:13.200
 But nevertheless, there's a very subjective element

2:05:13.200 --> 2:05:15.200
 to our experience.

2:05:15.200 --> 2:05:17.200
 Let me even not talk about

2:05:17.200 --> 2:05:19.200
 consciousness. Let me talk about

2:05:19.200 --> 2:05:21.200
 another,

2:05:21.200 --> 2:05:23.200
 to me, really interesting topic of mortality.

2:05:23.200 --> 2:05:25.200
 Fear or mortality.

2:05:25.200 --> 2:05:27.200
 Watson, as far as

2:05:27.200 --> 2:05:29.200
 I could tell,

2:05:29.200 --> 2:05:31.200
 did not have a fear of death.

2:05:31.200 --> 2:05:33.200
 Certainly not.

2:05:33.200 --> 2:05:35.200
 Most humans

2:05:35.200 --> 2:05:37.200
 do.

2:05:37.200 --> 2:05:39.200
 Wasn't conscious of death.

2:05:39.200 --> 2:05:41.200
 It wasn't that.

2:05:41.200 --> 2:05:43.200
 So there's an element of finiteness

2:05:43.200 --> 2:05:45.200
 to our existence that I think

2:05:45.200 --> 2:05:47.200
 like we mentioned, survival

2:05:47.200 --> 2:05:49.200
 that adds to the whole thing.

2:05:49.200 --> 2:05:51.200
 I mean, consciousness is tied up with that.

2:05:51.200 --> 2:05:53.200
 That we are a thing.

2:05:53.200 --> 2:05:55.200
 It's a subjective thing

2:05:55.200 --> 2:05:57.200
 that ends.

2:05:57.200 --> 2:05:59.200
 And that seems to add a color

2:05:59.200 --> 2:06:01.200
 or motivations in a way that

2:06:01.200 --> 2:06:03.200
 seems to be fundamentally important

2:06:03.200 --> 2:06:05.200
 for intelligence.

2:06:05.200 --> 2:06:07.200
 Or at least the kind of human intelligence.

2:06:07.200 --> 2:06:09.200
 Well, I think for generating goals.

2:06:09.200 --> 2:06:11.200
 Again, I think you could have

2:06:11.200 --> 2:06:13.200
 an intelligence capability

2:06:13.200 --> 2:06:15.200
 and a capability to learn,

2:06:15.200 --> 2:06:17.200
 a capability to

2:06:17.200 --> 2:06:19.200
 predict.

2:06:19.200 --> 2:06:21.200
 But I think without

2:06:21.200 --> 2:06:23.200
 I mean, again, you get a

2:06:23.200 --> 2:06:25.200
 fear, but essentially without the goal

2:06:25.200 --> 2:06:27.200
 to survive.

2:06:27.200 --> 2:06:29.200
 You think you can just encode that

2:06:29.200 --> 2:06:31.200
 without having to really.

2:06:31.200 --> 2:06:33.200
 I think you can create a robot now

2:06:33.200 --> 2:06:35.200
 and you could say, you know,

2:06:35.200 --> 2:06:37.200
 plug it in and say,

2:06:37.200 --> 2:06:39.200
 protect your power source, you know,

2:06:39.200 --> 2:06:41.200
 and give it some capabilities and we'll sit there

2:06:41.200 --> 2:06:43.200
 and operate to try to protect this power source

2:06:43.200 --> 2:06:45.200
 and survive.

2:06:45.200 --> 2:06:47.200
 So I don't know that that's

2:06:47.200 --> 2:06:49.200
 philosophically a hard thing to demonstrate.

2:06:49.200 --> 2:06:51.200
 It sounds like a fairly easy thing to demonstrate

2:06:51.200 --> 2:06:53.200
 that you can give it that goal.

2:06:53.200 --> 2:06:55.200
 Will it come up with that goal by itself?

2:06:55.200 --> 2:06:57.200
 It's something

2:06:57.200 --> 2:06:59.200
 because I think as we touched on

2:06:59.200 --> 2:07:01.200
 intelligence is kind of like a social construct.

2:07:01.200 --> 2:07:03.200
 The

2:07:03.200 --> 2:07:05.200
 fact that a robot will be protecting

2:07:05.200 --> 2:07:07.200
 its power source

2:07:07.200 --> 2:07:09.200
 would add

2:07:09.200 --> 2:07:11.200
 depth

2:07:11.200 --> 2:07:13.200
 and grounding to its intelligence

2:07:13.200 --> 2:07:15.200
 in terms of

2:07:15.200 --> 2:07:17.200
 us being able to respect that.

2:07:17.200 --> 2:07:19.200
 I mean, ultimately, it boils down to us

2:07:19.200 --> 2:07:21.200
 acknowledging that it's intelligent

2:07:21.200 --> 2:07:23.200
 and the fact that it can die

2:07:23.200 --> 2:07:25.200
 I think is an important part of that.

2:07:25.200 --> 2:07:27.200
 The interesting thing to reflect on

2:07:27.200 --> 2:07:29.200
 is how trivial that would be

2:07:29.200 --> 2:07:31.200
 and I don't think if you knew how

2:07:31.200 --> 2:07:33.200
 trivial that was, you would associate

2:07:33.200 --> 2:07:35.200
 that with being intelligence.

2:07:35.200 --> 2:07:37.200
 I mean, I literally put in a statement of code

2:07:37.200 --> 2:07:39.200
 that says, you know, you have the following actions

2:07:39.200 --> 2:07:41.200
 you can take, you give it a bunch of actions

2:07:41.200 --> 2:07:43.200
 like, maybe you mount the laser

2:07:43.200 --> 2:07:45.200
 going on or you may

2:07:45.200 --> 2:07:47.200
 or you give the ability to scream

2:07:47.200 --> 2:07:49.200
 or screech or whatever.

2:07:49.200 --> 2:07:51.200
 And you know, and you say, you know,

2:07:51.200 --> 2:07:53.200
 you're power source threatened

2:07:53.200 --> 2:07:55.200
 and you could program that in

2:07:55.200 --> 2:07:57.200
 and, you know, you're going to

2:07:57.200 --> 2:07:59.200
 you're going to take these actions to protect it.

2:07:59.200 --> 2:08:01.200
 You know, you could teach it

2:08:01.200 --> 2:08:03.200
 train it on a bunch of things.

2:08:03.200 --> 2:08:05.200
 And now you can look at that and you can say,

2:08:05.200 --> 2:08:07.200
 well, you know, that's intelligence

2:08:07.200 --> 2:08:09.200
 because it's protecting its power source, maybe,

2:08:09.200 --> 2:08:11.200
 but that's again, this human bias

2:08:11.200 --> 2:08:13.200
 that says, the thing I identify

2:08:13.200 --> 2:08:15.200
 my intelligence and my conscious

2:08:15.200 --> 2:08:17.200
 so fundamentally with the desire

2:08:17.200 --> 2:08:19.200
 or at least the behavior is associated

2:08:19.200 --> 2:08:21.200
 with the desire to survive

2:08:21.200 --> 2:08:23.200
 that if I see another thing doing

2:08:23.200 --> 2:08:25.200
 that, I'm going to assume

2:08:25.200 --> 2:08:27.200
 it's intelligent.

2:08:27.200 --> 2:08:29.200
 What timeline

2:08:29.200 --> 2:08:31.200
 year will society have

2:08:31.200 --> 2:08:33.200
 something that would

2:08:33.200 --> 2:08:35.200
 that you would be comfortable

2:08:35.200 --> 2:08:37.200
 calling an artificial general intelligence system?

2:08:39.200 --> 2:08:41.200
 Well, what's your intuition?

2:08:41.200 --> 2:08:43.200
 Nobody can predict the future.

2:08:43.200 --> 2:08:45.200
 Certainly not the next few months

2:08:45.200 --> 2:08:47.200
 or 20 years away, but

2:08:47.200 --> 2:08:49.200
 what's your intuition? How far away are we?

2:08:49.200 --> 2:08:51.200
 I know.

2:08:51.200 --> 2:08:53.200
 It's hard to make these predictions.

2:08:53.200 --> 2:08:55.200
 I would be, you know, I would be guessing

2:08:55.200 --> 2:08:57.200
 and there's so many different variables

2:08:57.200 --> 2:08:59.200
 including just how much we want to invest

2:08:59.200 --> 2:09:01.200
 in it and how important it, you know,

2:09:01.200 --> 2:09:03.200
 and how important we think it is

2:09:03.200 --> 2:09:05.200
 what kind of investment we're willing to make

2:09:05.200 --> 2:09:07.200
 in it, what kind of talent

2:09:07.200 --> 2:09:09.200
 we end up bringing to the table, all, you know,

2:09:09.200 --> 2:09:11.200
 the incentive structure, all these things.

2:09:11.200 --> 2:09:13.200
 So I think it is possible

2:09:13.200 --> 2:09:15.200
 to do this sort of thing.

2:09:15.200 --> 2:09:17.200
 I think it's

2:09:17.200 --> 2:09:19.200
 I think trying to sort of

2:09:19.200 --> 2:09:21.200
 ignore many

2:09:21.200 --> 2:09:23.200
 of the variables and things like that.

2:09:23.200 --> 2:09:25.200
 Is it a 10 year thing? Is it 23?

2:09:25.200 --> 2:09:27.200
 It's probably closer to a 20 year thing, I guess.

2:09:27.200 --> 2:09:29.200
 But not several hundred years.

2:09:29.200 --> 2:09:31.200
 No, I don't think it's several hundred years.

2:09:31.200 --> 2:09:33.200
 I don't think it's several hundred years,

2:09:33.200 --> 2:09:35.200
 but again, so much depends

2:09:35.200 --> 2:09:37.200
 on how

2:09:37.200 --> 2:09:39.200
 committed we are

2:09:39.200 --> 2:09:41.200
 to investing and incentivizing this type of

2:09:41.200 --> 2:09:43.200
 work, this type of work.

2:09:43.200 --> 2:09:45.200
 And it's sort of interesting.

2:09:45.200 --> 2:09:47.200
 Like, I don't think it's obvious

2:09:47.200 --> 2:09:49.200
 how incentivized we are.

2:09:49.200 --> 2:09:51.200
 I think from a task

2:09:51.200 --> 2:09:53.200
 perspective,

2:09:53.200 --> 2:09:55.200
 you know, if we see business

2:09:55.200 --> 2:09:57.200
 opportunities to take

2:09:57.200 --> 2:09:59.200
 this technique or that technique to solve that problem,

2:09:59.200 --> 2:10:01.200
 I think that's the main driver for many

2:10:01.200 --> 2:10:03.200
 of these things.

2:10:03.200 --> 2:10:05.200
 From a general intelligence

2:10:05.200 --> 2:10:07.200
 thing, it's kind of an interesting question.

2:10:07.200 --> 2:10:09.200
 Are we really motivated to do that?

2:10:09.200 --> 2:10:11.200
 And like, we just

2:10:11.200 --> 2:10:13.200
 struggled ourselves right now to even define

2:10:13.200 --> 2:10:15.200
 what it is.

2:10:15.200 --> 2:10:17.200
 So it's hard to incentivize when we don't even know

2:10:17.200 --> 2:10:19.200
 what it is we're incentivized to create.

2:10:19.200 --> 2:10:21.200
 And if you said mimic a human intelligence,

2:10:23.200 --> 2:10:25.200
 I just think there are so many challenges

2:10:25.200 --> 2:10:27.200
 with the significance and meaning

2:10:27.200 --> 2:10:29.200
 of that, that there's not a clear

2:10:29.200 --> 2:10:31.200
 directive. There's no clear directive to do

2:10:31.200 --> 2:10:33.200
 precisely that thing.

2:10:33.200 --> 2:10:35.200
 So assistance in a larger and larger

2:10:35.200 --> 2:10:37.200
 number of tasks.

2:10:37.200 --> 2:10:39.200
 So being able to assist

2:10:39.200 --> 2:10:41.200
 and be able to operate my microwave

2:10:41.200 --> 2:10:43.200
 and making a grilled cheese sandwich.

2:10:43.200 --> 2:10:45.200
 I don't even know how to make one of those.

2:10:45.200 --> 2:10:47.200
 And then the same system would be doing the vacuum

2:10:47.200 --> 2:10:49.200
 cleaning. And then the same system

2:10:49.200 --> 2:10:51.200
 would be teaching

2:10:53.200 --> 2:10:55.200
 my kids that I don't have

2:10:55.200 --> 2:10:57.200
 math.

2:10:57.200 --> 2:10:59.200
 I think that when you get into

2:10:59.200 --> 2:11:01.200
 a general intelligence for

2:11:01.200 --> 2:11:03.200
 learning physical

2:11:03.200 --> 2:11:05.200
 tasks, and again, I want to go back

2:11:05.200 --> 2:11:07.200
 to your body question because I think your body question was interesting, but

2:11:07.200 --> 2:11:09.200
 you want

2:11:09.200 --> 2:11:11.200
 to go back to, you know, learning the abilities to

2:11:11.200 --> 2:11:13.200
 physical tasks, you might have

2:11:13.200 --> 2:11:15.200
 we might get, I imagine

2:11:15.200 --> 2:11:17.200
 in that time frame, we will get better and better

2:11:17.200 --> 2:11:19.200
 at learning these kinds of tasks, whether

2:11:19.200 --> 2:11:21.200
 it's mowing your lawn or driving a car

2:11:21.200 --> 2:11:23.200
 or whatever it is. I think we will get better

2:11:23.200 --> 2:11:25.200
 and better at that where it's learning how to make

2:11:25.200 --> 2:11:27.200
 predictions over large bodies of data. I think we're

2:11:27.200 --> 2:11:29.200
 going to continue to get better and better at that.

2:11:29.200 --> 2:11:31.200
 And

2:11:31.200 --> 2:11:33.200
 machines will out, you know, outpace humans

2:11:33.200 --> 2:11:35.200
 and a variety of those things.

2:11:35.200 --> 2:11:37.200
 The underlying mechanisms

2:11:37.200 --> 2:11:39.200
 for doing that

2:11:39.200 --> 2:11:41.200
 may be the same, meaning

2:11:41.200 --> 2:11:43.200
 that, you know, maybe these are deep nets,

2:11:43.200 --> 2:11:45.200
 there's infrastructure to train

2:11:45.200 --> 2:11:47.200
 them, reusable components

2:11:47.200 --> 2:11:49.200
 to get them to different

2:11:49.200 --> 2:11:51.200
 classes of tasks, and we get better

2:11:51.200 --> 2:11:53.200
 and better at building these kinds of machines.

2:11:53.200 --> 2:11:55.200
 You could see, argue that

2:11:55.200 --> 2:11:57.200
 the general learning infrastructure in there is

2:11:57.200 --> 2:11:59.200
 a form of a general type of

2:11:59.200 --> 2:12:01.200
 intelligence. I think

2:12:01.200 --> 2:12:03.200
 what starts getting harder

2:12:03.200 --> 2:12:05.200
 is this notion of

2:12:05.200 --> 2:12:07.200
 you know, can we

2:12:07.200 --> 2:12:09.200
 effectively communicate and understand and build

2:12:09.200 --> 2:12:11.200
 that shared understanding because of the

2:12:11.200 --> 2:12:13.200
 layers of interpretation that are required to do

2:12:13.200 --> 2:12:15.200
 that and the need for the machine

2:12:15.200 --> 2:12:17.200
 to be engaged with humans at that level

2:12:17.200 --> 2:12:19.200
 in a continuous

2:12:19.200 --> 2:12:21.200
 basis. So how do you get in there?

2:12:21.200 --> 2:12:23.200
 How do you get the machine in the game?

2:12:23.200 --> 2:12:25.200
 How do you get the machine in the intellectual

2:12:25.200 --> 2:12:27.200
 game?

2:12:27.200 --> 2:12:29.200
 To solve AGI, you probably

2:12:29.200 --> 2:12:31.200
 have to solve that problem. You have to get

2:12:31.200 --> 2:12:33.200
 the machine. So it's a little bit of a bootstrapping

2:12:33.200 --> 2:12:35.200
 thing. Can we get the machine engaged

2:12:35.200 --> 2:12:37.200
 in, you know, in the intellectual

2:12:37.200 --> 2:12:39.200
 game, but in

2:12:39.200 --> 2:12:41.200
 the intellectual dialogue

2:12:41.200 --> 2:12:43.200
 with the humans? Are the humans

2:12:43.200 --> 2:12:45.200
 sufficiently in intellectual dialogue with each other

2:12:45.200 --> 2:12:47.200
 to generate enough

2:12:47.200 --> 2:12:49.200
 data in this context?

2:12:49.200 --> 2:12:51.200
 And how do you bootstrap that? Because

2:12:51.200 --> 2:12:53.200
 every one of those conversations,

2:12:53.200 --> 2:12:55.200
 every one of those conversations,

2:12:55.200 --> 2:12:57.200
 those intelligent interactions

2:12:57.200 --> 2:12:59.200
 require so much prior knowledge

2:12:59.200 --> 2:13:01.200
 that it's a challenge to bootstrap it.

2:13:01.200 --> 2:13:03.200
 So the question

2:13:03.200 --> 2:13:05.200
 is, and how committed

2:13:05.200 --> 2:13:07.200
 so I think that's possible, but

2:13:07.200 --> 2:13:09.200
 when I go back to, are we incentivized

2:13:09.200 --> 2:13:11.200
 to do that?

2:13:11.200 --> 2:13:13.200
 I know we're incentivized to do the former.

2:13:13.200 --> 2:13:15.200
 Are we incentivized to do the latter significantly

2:13:15.200 --> 2:13:17.200
 enough? Do people understand what the latter really

2:13:17.200 --> 2:13:19.200
 is well enough? Part of the

2:13:19.200 --> 2:13:21.200
 elemental cognition mission is to try

2:13:21.200 --> 2:13:23.200
 to articulate that better and better

2:13:23.200 --> 2:13:25.200
 through demonstrations and through trying to craft

2:13:25.200 --> 2:13:27.200
 these grand challenges and get

2:13:27.200 --> 2:13:29.200
 people to say, look, this is a class of intelligence.

2:13:29.200 --> 2:13:31.200
 This is a class of AI.

2:13:31.200 --> 2:13:33.200
 Do we want this?

2:13:33.200 --> 2:13:35.200
 What is the potential of this?

2:13:35.200 --> 2:13:37.200
 What are the business, what's the business potential?

2:13:37.200 --> 2:13:39.200
 What's the societal potential

2:13:39.200 --> 2:13:41.200
 to that? And to, you know, and to

2:13:41.200 --> 2:13:43.200
 build up that incentive system

2:13:43.200 --> 2:13:45.200
 around that?

2:13:45.200 --> 2:13:47.200
 Yeah, I think if people don't understand yet, I think they will.

2:13:47.200 --> 2:13:49.200
 I think there's a huge business potential

2:13:49.200 --> 2:13:51.200
 here. So it's exciting that you're working on it.

2:13:53.200 --> 2:13:55.200
 I kind of skipped over, but

2:13:55.200 --> 2:13:57.200
 I'm a huge fan of

2:13:57.200 --> 2:13:59.200
 physical presence of things.

2:13:59.200 --> 2:14:01.200
 Do you think

2:14:01.200 --> 2:14:03.200
 Watson had a body?

2:14:03.200 --> 2:14:05.200
 Do you think

2:14:05.200 --> 2:14:07.200
 having a body adds to

2:14:07.200 --> 2:14:09.200
 the interactive element

2:14:09.200 --> 2:14:11.200
 between the AI system and a human

2:14:11.200 --> 2:14:13.200
 or just in general to intelligence?

2:14:13.200 --> 2:14:15.200
 So I think

2:14:15.200 --> 2:14:17.200
 going back to that

2:14:17.200 --> 2:14:19.200
 shared understanding bit

2:14:19.200 --> 2:14:21.200
 humans are very connected to their bodies.

2:14:21.200 --> 2:14:23.200
 I mean, one of the reasons,

2:14:23.200 --> 2:14:25.200
 one of the challenges in getting

2:14:25.200 --> 2:14:27.200
 an AI to kind of be a compatible

2:14:27.200 --> 2:14:29.200
 human intelligence

2:14:29.200 --> 2:14:31.200
 is that our physical bodies

2:14:31.200 --> 2:14:33.200
 are generating a lot of features

2:14:33.200 --> 2:14:35.200
 that make up

2:14:35.200 --> 2:14:37.200
 the input.

2:14:37.200 --> 2:14:39.200
 So in other words, where our bodies are

2:14:39.200 --> 2:14:41.200
 are the tool we use to

2:14:41.200 --> 2:14:43.200
 affect output, but

2:14:43.200 --> 2:14:45.200
 they also generate a lot of input

2:14:45.200 --> 2:14:47.200
 for our brains. So we generate

2:14:47.200 --> 2:14:49.200
 emotion, we generate all these

2:14:49.200 --> 2:14:51.200
 feelings, we generate all these signals

2:14:51.200 --> 2:14:53.200
 that machines don't have. So it means

2:14:53.200 --> 2:14:55.200
 those that have this as the input data

2:14:55.200 --> 2:14:57.200
 and they don't

2:14:57.200 --> 2:14:59.200
 have the feedback that says, okay, I've

2:14:59.200 --> 2:15:01.200
 gotten this, I've gotten this emotion

2:15:01.200 --> 2:15:03.200
 or I've gotten this idea, I now

2:15:03.200 --> 2:15:05.200
 want to process it and then I can

2:15:05.200 --> 2:15:07.200
 it then affects me

2:15:07.200 --> 2:15:09.200
 as a physical being and then

2:15:09.200 --> 2:15:11.200
 I can play that

2:15:11.200 --> 2:15:13.200
 out. In other words, I could realize

2:15:13.200 --> 2:15:15.200
 the implications of that, because the implications again on

2:15:15.200 --> 2:15:17.200
 my body complex

2:15:17.200 --> 2:15:19.200
 I then process that and

2:15:19.200 --> 2:15:21.200
 the implications again, our internal features

2:15:21.200 --> 2:15:23.200
 are generated. I learned from

2:15:23.200 --> 2:15:25.200
 them, they have an effect on my

2:15:25.200 --> 2:15:27.200
 mind body complex. So

2:15:27.200 --> 2:15:29.200
 it's interesting when we think, do we want

2:15:29.200 --> 2:15:31.200
 a human intelligence? Well

2:15:31.200 --> 2:15:33.200
 if we want a human compatible intelligence

2:15:33.200 --> 2:15:35.200
 probably the best thing to do is to embed

2:15:35.200 --> 2:15:37.200
 it in a human body.

2:15:37.200 --> 2:15:39.200
 Just to clarify, and both concepts are

2:15:39.200 --> 2:15:41.200
 beautiful, is a humanoid

2:15:41.200 --> 2:15:43.200
 robot. So a robot

2:15:43.200 --> 2:15:45.200
 that look like humans is one

2:15:45.200 --> 2:15:47.200
 or did you mean

2:15:47.200 --> 2:15:49.200
 actually

2:15:49.200 --> 2:15:51.200
 sort of what Elon Musk was working with

2:15:51.200 --> 2:15:53.200
 Neuralink, really

2:15:53.200 --> 2:15:55.200
 embedding intelligence

2:15:55.200 --> 2:15:57.200
 systems to ride along

2:15:57.200 --> 2:15:59.200
 human bodies?

2:15:59.200 --> 2:16:01.200
 No, I mean riding along is different.

2:16:01.200 --> 2:16:03.200
 I meant like if you want

2:16:03.200 --> 2:16:05.200
 to create an intelligence

2:16:05.200 --> 2:16:07.200
 that is human compatible

2:16:07.200 --> 2:16:09.200
 meaning that

2:16:09.200 --> 2:16:11.200
 it can learn and develop a shared

2:16:11.200 --> 2:16:13.200
 understanding of the world around it, you have to

2:16:13.200 --> 2:16:15.200
 give it a lot of the same substrate.

2:16:15.200 --> 2:16:17.200
 Part of that substrate

2:16:17.200 --> 2:16:19.200
 is the idea that it

2:16:19.200 --> 2:16:21.200
 generates these kinds of internal features

2:16:21.200 --> 2:16:23.200
 like sort of emotional stuff, it has similar

2:16:23.200 --> 2:16:25.200
 senses, it has to do a lot of the same

2:16:25.200 --> 2:16:27.200
 things with those same senses.

2:16:27.200 --> 2:16:29.200
 So I think

2:16:29.200 --> 2:16:31.200
 if you want that, again, I don't know that you want

2:16:31.200 --> 2:16:33.200
 that. That's not

2:16:33.200 --> 2:16:35.200
 my specific goal. I think that's a fascinating

2:16:35.200 --> 2:16:37.200
 scientific goal. I think it has all kinds of other implications.

2:16:37.200 --> 2:16:39.200
 That's sort of not the goal.

2:16:39.200 --> 2:16:41.200
 I want to create

2:16:41.200 --> 2:16:43.200
 I think of it as I create intellectual thought

2:16:43.200 --> 2:16:45.200
 partners for humans, that kind

2:16:45.200 --> 2:16:47.200
 of intelligence.

2:16:47.200 --> 2:16:49.200
 I know there are other companies that are creating

2:16:49.200 --> 2:16:51.200
 physical thought partners, physical partners

2:16:51.200 --> 2:16:53.200
 for humans, but that's

2:16:53.200 --> 2:16:55.200
 kind of not where I'm

2:16:55.200 --> 2:16:57.200
 at. But

2:16:57.200 --> 2:16:59.200
 the important point is that

2:16:59.200 --> 2:17:01.200
 a big part of

2:17:01.200 --> 2:17:03.200
 what we process

2:17:03.200 --> 2:17:05.200
 is that

2:17:05.200 --> 2:17:07.200
 physical experience of the world around us.

2:17:07.200 --> 2:17:09.200
 On the point of thought

2:17:09.200 --> 2:17:11.200
 partners, what role

2:17:11.200 --> 2:17:13.200
 does an emotional connection

2:17:13.200 --> 2:17:15.200
 or forgive me, love

2:17:15.200 --> 2:17:17.200
 have to play

2:17:17.200 --> 2:17:19.200
 in that thought partnership?

2:17:19.200 --> 2:17:21.200
 Is that something you're interested in

2:17:21.200 --> 2:17:23.200
 put another way sort of having

2:17:23.200 --> 2:17:25.200
 a deep connection

2:17:25.200 --> 2:17:27.200
 beyond

2:17:27.200 --> 2:17:29.200
 intellectual?

2:17:29.200 --> 2:17:31.200
 With the AI? Yeah, with the AI between human

2:17:31.200 --> 2:17:33.200
 and AI. Is that something that gets

2:17:33.200 --> 2:17:35.200
 in the way of the

2:17:35.200 --> 2:17:37.200
 the rational discourse?

2:17:37.200 --> 2:17:39.200
 Is that something that's useful?

2:17:39.200 --> 2:17:41.200
 I worry about biases, obviously.

2:17:41.200 --> 2:17:43.200
 So in other words, if you develop

2:17:43.200 --> 2:17:45.200
 an emotional relationship with the machine

2:17:45.200 --> 2:17:47.200
 all of a sudden you start are more likely

2:17:47.200 --> 2:17:49.200
 to believe what it's saying even if it doesn't

2:17:49.200 --> 2:17:51.200
 make any sense. So I

2:17:51.200 --> 2:17:53.200
 worry about that.

2:17:53.200 --> 2:17:55.200
 But at the same time, I think the opportunity

2:17:55.200 --> 2:17:57.200
 to use machines to provide human companionship

2:17:57.200 --> 2:17:59.200
 is actually not crazy.

2:18:01.200 --> 2:18:03.200
 Intellectual and

2:18:03.200 --> 2:18:05.200
 social companionship is not a crazy idea.

2:18:05.200 --> 2:18:07.200
 Do you have concerns

2:18:07.200 --> 2:18:09.200
 as a few people do

2:18:09.200 --> 2:18:11.200
 Elon Musk, Sam Harris

2:18:11.200 --> 2:18:13.200
 about long term existential threats

2:18:13.200 --> 2:18:15.200
 of AI

2:18:15.200 --> 2:18:17.200
 and perhaps short term threats

2:18:17.200 --> 2:18:19.200
 of AI? We talked about bias

2:18:19.200 --> 2:18:21.200
 we talked about different misuses but

2:18:21.200 --> 2:18:23.200
 do you have concerns about

2:18:23.200 --> 2:18:25.200
 thought partners

2:18:25.200 --> 2:18:27.200
 systems that are able to

2:18:27.200 --> 2:18:29.200
 help us make decisions together with humans

2:18:29.200 --> 2:18:31.200
 somehow having a significant negative impact

2:18:31.200 --> 2:18:33.200
 on society in the long term?

2:18:33.200 --> 2:18:35.200
 I think there are things to worry about.

2:18:35.200 --> 2:18:37.200
 I think the giving machines

2:18:37.200 --> 2:18:39.200
 too much leverage

2:18:39.200 --> 2:18:41.200
 is a problem

2:18:41.200 --> 2:18:43.200
 and what I mean by leverage

2:18:43.200 --> 2:18:45.200
 is too much

2:18:45.200 --> 2:18:47.200
 control over things that can hurt us

2:18:47.200 --> 2:18:49.200
 whether it's socially,

2:18:49.200 --> 2:18:51.200
 psychologically, intellectually, or physically

2:18:51.200 --> 2:18:53.200
 and if you give the machines too much control

2:18:53.200 --> 2:18:55.200
 I think that's a concern.

2:18:55.200 --> 2:18:57.200
 You forget about the AI, just when you give them

2:18:57.200 --> 2:18:59.200
 too much control human bad actors

2:18:59.200 --> 2:19:01.200
 can hack them

2:19:01.200 --> 2:19:05.200
 and produce havoc.

2:19:05.200 --> 2:19:07.200
 That's a problem

2:19:07.200 --> 2:19:09.200
 and you imagine

2:19:09.200 --> 2:19:11.200
 hackers taking over the driverless car network

2:19:11.200 --> 2:19:13.200
 and creating all kinds of

2:19:13.200 --> 2:19:15.200
 havoc

2:19:15.200 --> 2:19:17.200
 but you could also imagine

2:19:17.200 --> 2:19:19.200
 given

2:19:19.200 --> 2:19:21.200
 the ease at which humans could be persuaded

2:19:21.200 --> 2:19:23.200
 one way or the other

2:19:23.200 --> 2:19:25.200
 and now we have algorithms that can easily

2:19:25.200 --> 2:19:27.200
 take control over that

2:19:27.200 --> 2:19:29.200
 and amplify

2:19:29.200 --> 2:19:31.200
 all ways and move people one direction

2:19:31.200 --> 2:19:33.200
 or another.

2:19:33.200 --> 2:19:35.200
 Humans do that to other humans all the time

2:19:35.200 --> 2:19:37.200
 and we have marketing campaigns, we have political campaigns

2:19:37.200 --> 2:19:39.200
 that take advantage of

2:19:39.200 --> 2:19:41.200
 our emotions

2:19:41.200 --> 2:19:43.200
 or our fears

2:19:43.200 --> 2:19:45.200
 and this is done all the time

2:19:45.200 --> 2:19:47.200
 but with machines

2:19:47.200 --> 2:19:49.200
 machines are like giant megaphones

2:19:49.200 --> 2:19:51.200
 we can amplify this in orders of magnitude

2:19:51.200 --> 2:19:53.200
 and fine tune its control

2:19:53.200 --> 2:19:55.200
 so we can tailor the message

2:19:55.200 --> 2:19:57.200
 we can now very rapidly

2:19:57.200 --> 2:19:59.200
 additionally tailor the message to the audience

2:19:59.200 --> 2:20:01.200
 taking

2:20:01.200 --> 2:20:03.200
 advantage of their

2:20:03.200 --> 2:20:05.200
 biases and amplifying them

2:20:05.200 --> 2:20:07.200
 and using them to pursue them in one direction

2:20:07.200 --> 2:20:09.200
 or another in ways that are

2:20:09.200 --> 2:20:11.200
 not fair, not logical

2:20:11.200 --> 2:20:13.200
 not objective, not meaningful

2:20:13.200 --> 2:20:15.200
 and humans

2:20:15.200 --> 2:20:17.200
 machines empower that

2:20:17.200 --> 2:20:19.200
 so that's what I mean by leverage

2:20:19.200 --> 2:20:21.200
 it's not new

2:20:21.200 --> 2:20:23.200
 but wow it's powerful because

2:20:23.200 --> 2:20:25.200
 machines can do it more effectively

2:20:25.200 --> 2:20:27.200
 you know more quickly and we see that already

2:20:27.200 --> 2:20:29.200
 going on in social media

2:20:29.200 --> 2:20:31.200
 and other places

2:20:31.200 --> 2:20:33.200
 that's scary

2:20:33.200 --> 2:20:35.200
 and that's why

2:20:35.200 --> 2:20:37.200
 I'm

2:20:37.200 --> 2:20:39.200
 that's why

2:20:39.200 --> 2:20:41.200
 I go back to saying

2:20:41.200 --> 2:20:43.200
 one of the most important public

2:20:43.200 --> 2:20:45.200
 dialogues we could be having

2:20:45.200 --> 2:20:47.200
 is about the nature of intelligence

2:20:47.200 --> 2:20:49.200
 and the nature of

2:20:49.200 --> 2:20:51.200
 inference

2:20:51.200 --> 2:20:53.200
 and logic and reason and rationality

2:20:53.200 --> 2:20:55.200
 and

2:20:55.200 --> 2:20:57.200
 us understanding our own biases

2:20:57.200 --> 2:20:59.200
 us understanding our own cognitive biases

2:20:59.200 --> 2:21:01.200
 and how they work

2:21:01.200 --> 2:21:03.200
 and then how machines work

2:21:03.200 --> 2:21:05.200
 and how do we use them to complement

2:21:05.200 --> 2:21:07.200
 basically so that in the end we have

2:21:07.200 --> 2:21:09.200
 a stronger overall system

2:21:09.200 --> 2:21:11.200
 that's just incredibly important

2:21:11.200 --> 2:21:13.200
 I don't think

2:21:13.200 --> 2:21:15.200
 most people understand that

2:21:15.200 --> 2:21:17.200
 so like telling

2:21:17.200 --> 2:21:19.200
 telling your kids or telling your students

2:21:19.200 --> 2:21:21.200
 this goes back to the cognition

2:21:21.200 --> 2:21:23.200
 here's how your brain works

2:21:23.200 --> 2:21:25.200
 here's how easy it is

2:21:25.200 --> 2:21:27.200
 to trick your brain

2:21:27.200 --> 2:21:29.200
 there are fundamental cognizant

2:21:29.200 --> 2:21:31.200
 but you should appreciate

2:21:31.200 --> 2:21:33.200
 the different types of thinking

2:21:33.200 --> 2:21:35.200
 and how they work

2:21:35.200 --> 2:21:37.200
 and what you're prone to

2:21:37.200 --> 2:21:39.200
 and what do you prefer

2:21:39.200 --> 2:21:41.200
 and under what conditions

2:21:41.200 --> 2:21:43.200
 does this make sense versus that makes sense

2:21:43.200 --> 2:21:45.200
 and then say here's what AI can do

2:21:45.200 --> 2:21:47.200
 here's how it can make this worse

2:21:47.200 --> 2:21:49.200
 and here's how it can make this better

2:21:49.200 --> 2:21:51.200
 and that's where the AI has a role

2:21:51.200 --> 2:21:53.200
 is to reveal that

2:21:53.200 --> 2:21:55.200
 that tradeoff

2:21:55.200 --> 2:21:57.200
 so if you imagine

2:21:57.200 --> 2:21:59.200
 a system that is able

2:21:59.200 --> 2:22:01.200
 to

2:22:01.200 --> 2:22:03.200
 beyond any definition

2:22:03.200 --> 2:22:05.200
 of the Turing test

2:22:05.200 --> 2:22:07.200
 the benchmark really an AGI system

2:22:07.200 --> 2:22:09.200
 as a thought partner

2:22:09.200 --> 2:22:11.200
 that you one day

2:22:11.200 --> 2:22:13.200
 will create

2:22:13.200 --> 2:22:15.200
 what

2:22:15.200 --> 2:22:17.200
 question

2:22:17.200 --> 2:22:19.200
 topic of discussion

2:22:19.200 --> 2:22:21.200
 if you get to pick one

2:22:21.200 --> 2:22:23.200
 would you have with that system

2:22:23.200 --> 2:22:25.200
 what would you ask

2:22:25.200 --> 2:22:27.200
 and you get to find out

2:22:27.200 --> 2:22:29.200
 the truth

2:22:29.200 --> 2:22:31.200
 together

2:22:33.200 --> 2:22:35.200
 so you threw me a little bit

2:22:35.200 --> 2:22:37.200
 with finding the truth at the end but

2:22:37.200 --> 2:22:39.200
 because the truth is

2:22:39.200 --> 2:22:41.200
 a whole other topic

2:22:41.200 --> 2:22:43.200
 but the I think the beauty of it

2:22:43.200 --> 2:22:45.200
 I think what excites me is the beauty of it is

2:22:45.200 --> 2:22:47.200
 if I really have that system

2:22:47.200 --> 2:22:49.200
 I don't have to pick

2:22:49.200 --> 2:22:51.200
 so in other words I can go to

2:22:51.200 --> 2:22:53.200
 and say this is what I care about today

2:22:53.200 --> 2:22:55.200
 and that's what we mean by

2:22:55.200 --> 2:22:57.200
 like this general capability

2:22:57.200 --> 2:22:59.200
 go out, read this stuff in the next 3 milliseconds

2:22:59.200 --> 2:23:01.200
 and I want to talk to you about it

2:23:01.200 --> 2:23:03.200
 I want to draw analogies

2:23:03.200 --> 2:23:05.200
 I want to understand how this affects

2:23:05.200 --> 2:23:07.200
 this decision or that decision

2:23:07.200 --> 2:23:09.200
 what if this were true

2:23:09.200 --> 2:23:11.200
 what if that were true

2:23:11.200 --> 2:23:13.200
 what knowledge should I be aware of

2:23:13.200 --> 2:23:15.200
 that could impact my decision

2:23:15.200 --> 2:23:17.200
 here's what I'm thinking

2:23:17.200 --> 2:23:19.200
 is the main implication

2:23:19.200 --> 2:23:21.200
 can you prove that out

2:23:21.200 --> 2:23:23.200
 can you give me the evidence that supports that

2:23:23.200 --> 2:23:25.200
 can you give me evidence that supports this other thing

2:23:25.200 --> 2:23:27.200
 boy would that be incredible

2:23:27.200 --> 2:23:29.200
 would that be just incredible

2:23:29.200 --> 2:23:31.200
 just to be part of

2:23:31.200 --> 2:23:33.200
 whether it's a medical diagnosis

2:23:33.200 --> 2:23:35.200
 or whether it's the various treatment options

2:23:35.200 --> 2:23:37.200
 or whether it's a

2:23:37.200 --> 2:23:39.200
 legal case or whether it's

2:23:39.200 --> 2:23:41.200
 a social problem that people are discussing

2:23:41.200 --> 2:23:43.200
 be part of the dialogue

2:23:43.200 --> 2:23:45.200
 one that holds

2:23:45.200 --> 2:23:47.200
 itself

2:23:47.200 --> 2:23:49.200
 and us accountable

2:23:49.200 --> 2:23:51.200
 to reasons and objective dialogue

2:23:51.200 --> 2:23:53.200
 you know I just

2:23:53.200 --> 2:23:55.200
 goosebumps talking about it right

2:23:55.200 --> 2:23:57.200
 this is what I want

2:23:57.200 --> 2:23:59.200
 so when you created

2:23:59.200 --> 2:24:01.200
 please come back on the podcast

2:24:01.200 --> 2:24:03.200
 and we can have a discussion together

2:24:03.200 --> 2:24:05.200
 and make it even longer

2:24:05.200 --> 2:24:07.200
 this is a record for the longest conversation

2:24:07.200 --> 2:24:09.200
 and it was an honor, it was a pleasure

2:24:09.200 --> 2:24:11.200
 thank you so much for that

