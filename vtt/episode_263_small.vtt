WEBVTT

00:00.000 --> 00:02.920
 The jury found Pfizer guilty of fraud

00:02.920 --> 00:04.560
 and racketeering violations.

00:04.560 --> 00:06.520
 How does Big Pharma affect your mind?

00:06.520 --> 00:08.800
 Everyone's allowed their own opinion.

00:08.800 --> 00:11.920
 I don't think everyone's allowed their own scientific facts.

00:11.920 --> 00:13.800
 This Pfizer played by the rules.

00:13.800 --> 00:16.440
 Pfizer isn't battling the FDA.

00:16.440 --> 00:18.760
 Pfizer has joined the FDA.

00:21.440 --> 00:24.320
 The following is a conversation with John Abramson,

00:24.320 --> 00:26.520
 faculty at Harvard Medical School,

00:26.520 --> 00:29.160
 a family physician for over two decades,

00:29.160 --> 00:32.160
 and author of the new book, Sickening,

00:32.160 --> 00:35.000
 about how Big Pharma broke American healthcare

00:35.000 --> 00:37.360
 and how we can fix it.

00:37.360 --> 00:40.200
 This conversation with John Abramson

00:40.200 --> 00:43.680
 is a critical exploration of the pharmaceutical industry.

00:43.680 --> 00:45.400
 I wanted to talk to John

00:45.400 --> 00:48.160
 in order to provide a countervailing perspective

00:48.160 --> 00:50.720
 to the one expressed in my podcast episode

00:50.720 --> 00:55.080
 with the CEO of Pfizer, Albert Burla.

00:55.080 --> 00:58.960
 And here, please allow me to say a few additional words

00:58.960 --> 01:01.920
 about this episode with the Pfizer CEO

01:01.920 --> 01:04.960
 and in general about why I do these conversations

01:04.960 --> 01:06.840
 and how I approach them.

01:06.840 --> 01:10.560
 If this is not interesting to you, please skip ahead.

01:10.560 --> 01:13.120
 What do I hope to do with this podcast?

01:13.120 --> 01:15.640
 I want to understand human nature,

01:15.640 --> 01:18.080
 the best and the worst of it.

01:18.080 --> 01:19.880
 I want to understand how power, money,

01:19.880 --> 01:21.880
 and fame changes people.

01:21.880 --> 01:24.640
 I want to understand why atrocities are committed

01:24.640 --> 01:27.280
 by crowds that believe they're doing good.

01:27.280 --> 01:29.320
 All this, ultimately,

01:29.320 --> 01:30.760
 because I want to understand

01:30.760 --> 01:33.280
 how we can build a better world together

01:33.280 --> 01:35.440
 to find hope for the future

01:35.440 --> 01:38.560
 and to rediscover each time

01:38.560 --> 01:40.920
 through the exploration of ideas,

01:40.920 --> 01:43.400
 just how beautiful this life is.

01:43.400 --> 01:45.400
 This, our human civilization,

01:45.400 --> 01:47.680
 in all of its full complexity,

01:47.680 --> 01:49.320
 the forces of good and evil,

01:49.320 --> 01:52.320
 of war and peace, of hate and love.

01:53.440 --> 01:55.600
 I don't think I can do this with a heart and mind

01:55.600 --> 01:57.360
 that is not open, fragile,

01:57.360 --> 02:00.960
 and willing to empathize with all human beings,

02:00.960 --> 02:03.480
 even those in the darkest corners of our world.

02:04.440 --> 02:06.800
 To attack is easy.

02:06.800 --> 02:09.560
 To understand is hard.

02:09.560 --> 02:11.840
 And I choose the hard path.

02:11.840 --> 02:13.880
 I have learned over the past few months

02:13.880 --> 02:17.400
 that this path involves me getting more and more attacked

02:17.400 --> 02:19.040
 from all sides.

02:19.040 --> 02:22.080
 I will get attacked when I host people like Jay

02:22.080 --> 02:24.520
 but Acharya or Francis Collins,

02:24.520 --> 02:28.160
 Jamie Merzel or Vincent Reckon Yellow,

02:28.160 --> 02:31.840
 when I stand for my friend, Joe Rogan,

02:31.840 --> 02:34.720
 when I host tech leaders like Mark Zuckerberg,

02:34.720 --> 02:36.440
 Elon Musk and others,

02:36.440 --> 02:39.600
 when I eventually talk to Vladimir Putin,

02:39.600 --> 02:42.000
 Barack Obama and other figures

02:42.000 --> 02:43.880
 that have turned the tides of history.

02:44.960 --> 02:49.960
 I have and I will get called stupid, naive, weak,

02:49.960 --> 02:54.960
 and I will take these words with respect, humility and love

02:55.400 --> 02:57.240
 and I will get better.

02:57.240 --> 03:00.720
 I will listen, think, learn and improve.

03:00.720 --> 03:04.560
 One thing I can promise is there's no amount of money

03:04.560 --> 03:06.960
 or fame that can buy my opinion

03:06.960 --> 03:09.320
 or make me go against my principles.

03:09.320 --> 03:13.520
 There's no amount of pressure that can break my integrity.

03:13.520 --> 03:16.160
 There's nothing in this world I need

03:16.160 --> 03:18.560
 that I don't already have.

03:18.560 --> 03:21.440
 Life itself is the fundamental gift.

03:21.440 --> 03:23.480
 Everything else is just a bonus.

03:24.520 --> 03:26.640
 That is freedom.

03:26.640 --> 03:28.680
 That is happiness.

03:28.680 --> 03:31.720
 If I die today, I will die a happy man.

03:33.040 --> 03:37.320
 Now, a few comments about my approach and lessons learned

03:37.320 --> 03:39.560
 from the Albert Berle conversation.

03:39.560 --> 03:41.880
 The goal was to reveal as much as I could

03:41.880 --> 03:43.920
 about the human being before me

03:43.920 --> 03:48.120
 and to give him the opportunity to contemplate in long form

03:48.120 --> 03:52.000
 the complexities of his role, including the tension

03:52.000 --> 03:54.640
 between making money and helping people,

03:54.640 --> 03:58.200
 the corruption that so often permeates human institutions,

03:58.200 --> 04:00.840
 the crafting of narratives through advertisements,

04:00.840 --> 04:02.400
 and so on.

04:02.400 --> 04:04.040
 I only had one hour.

04:04.040 --> 04:07.440
 And so this wasn't the time to address these issues deeply

04:07.440 --> 04:10.200
 but to show if Albert struggled with them

04:10.200 --> 04:12.280
 in the privacy of his own mind.

04:12.280 --> 04:16.280
 And if he would, let down the veil of political speak

04:16.280 --> 04:19.440
 for a time to let me connect with the man

04:19.440 --> 04:22.560
 who decades ago chose to become a veterinarian

04:22.560 --> 04:24.360
 who wanted to help lessen the amount

04:24.360 --> 04:26.320
 of suffering in the world.

04:26.320 --> 04:28.400
 I had no pressure placed on me.

04:28.400 --> 04:29.800
 There were no rules.

04:29.800 --> 04:32.160
 The questions I was asking were all mine

04:32.160 --> 04:34.160
 and not seen by Pfizer folks.

04:34.160 --> 04:38.720
 I had no care whether I ever talked to another CEO again.

04:38.720 --> 04:41.840
 None of this was part of the calculation

04:41.840 --> 04:44.160
 in my limited brain computer.

04:44.160 --> 04:45.960
 I didn't want to grill him.

04:45.960 --> 04:48.960
 The way politicians grill CEOs in Congress,

04:48.960 --> 04:52.680
 I thought that this approach is easy, self serving,

04:52.680 --> 04:56.280
 dehumanizing, and it reveals nothing.

04:56.280 --> 04:59.040
 I wanted to reveal the genuine intellectual struggle,

04:59.040 --> 05:01.440
 vision and motivation of a human being.

05:01.440 --> 05:04.320
 And if that fails, I trusted the listener

05:04.320 --> 05:08.120
 to draw their own conclusion and insights from the result,

05:08.120 --> 05:10.120
 whether it's the words spoken

05:10.120 --> 05:14.520
 or the words left unspoken or simply the silence.

05:14.520 --> 05:15.840
 And that's just it.

05:15.840 --> 05:20.320
 I fundamentally trust the intelligence of the listener,

05:20.320 --> 05:21.160
 you.

05:21.920 --> 05:24.880
 In fact, if I criticize the person too hard

05:24.880 --> 05:26.840
 or celebrate the person too much,

05:26.840 --> 05:29.760
 I feel I fail to give the listener a picture

05:29.760 --> 05:32.840
 of the human being that is uncontaminated

05:32.840 --> 05:35.480
 by my opinion or the opinion of the crowd.

05:36.520 --> 05:38.600
 I trust that you have the fortitude

05:38.600 --> 05:41.080
 and the courage to use your own mind

05:41.080 --> 05:43.280
 to empathize and to think.

05:43.280 --> 05:45.200
 Two practical lessons I took away.

05:45.200 --> 05:48.640
 First, I will more strongly push for longer conversations

05:48.640 --> 05:52.280
 of three, four or more hours versus just one hour.

05:52.280 --> 05:54.840
 60 minutes is too short for the guests to relax

05:54.840 --> 05:57.120
 and to think slowly and deeply.

05:57.120 --> 05:59.800
 And for me to ask many follow up questions

05:59.800 --> 06:01.800
 or follow interesting tangents.

06:01.800 --> 06:04.720
 Ultimately, I think it's in the interest of everyone,

06:04.720 --> 06:08.520
 including the guests, that we talk in true long form

06:08.520 --> 06:10.240
 for many hours.

06:10.240 --> 06:13.280
 Second, these conversations with leaders can be aided

06:13.280 --> 06:16.480
 by further conversations with people who wrote books

06:16.480 --> 06:19.200
 about those leaders or their industries.

06:19.200 --> 06:21.200
 Those that can steal man each perspective

06:21.200 --> 06:23.880
 and attempt to give an objective analysis.

06:23.880 --> 06:25.600
 I think of Teddy Roosevelt's speech

06:25.600 --> 06:27.320
 about the man in the arena.

06:27.320 --> 06:30.880
 I want to talk to both the men and women in the arena

06:30.880 --> 06:34.680
 and the critics and the supporters in the stands.

06:34.680 --> 06:37.440
 For the former, I lean toward wanting to understand

06:37.440 --> 06:41.600
 one human being's struggle with the ideas.

06:41.600 --> 06:44.240
 For the latter, I lean towards understanding

06:44.240 --> 06:46.400
 the ideas themselves.

06:46.400 --> 06:48.560
 That's why I wanted to have this conversation

06:48.560 --> 06:51.960
 with John Abramson, who is an outspoken critic

06:51.960 --> 06:54.000
 of the pharmaceutical industry.

06:54.000 --> 06:57.160
 I hope it helps add context and depth

06:57.160 --> 07:00.640
 to the conversation I had with the Pfizer CEO.

07:00.640 --> 07:05.000
 In the end, I may do worse than I could have or should have.

07:05.000 --> 07:08.600
 Always, I will listen to the criticisms without ego

07:08.600 --> 07:12.640
 and I promise I will work hard to improve.

07:12.640 --> 07:17.680
 But let me say finally that cynicism is easy.

07:17.680 --> 07:22.360
 Optimism, true optimism is hard.

07:22.360 --> 07:27.000
 It is the belief that we can and we will build

07:27.000 --> 07:31.000
 a better world and that we can only do it together.

07:31.000 --> 07:33.080
 This is the fight worth fighting.

07:33.080 --> 07:35.080
 So here we go.

07:35.080 --> 07:40.080
 Once more into the breach, dear friends, I love you all.

07:40.080 --> 07:42.400
 This is the Lex Friedman podcast.

07:42.400 --> 07:44.600
 To support it, please check out our sponsors

07:44.600 --> 07:45.800
 in the description.

07:45.800 --> 07:50.480
 And now, here's my conversation with John Abramson.

07:50.480 --> 07:53.600
 Your faculty at Harvard Medical School,

07:53.600 --> 07:56.280
 your family physician for over two decades,

07:56.280 --> 07:59.600
 rated one of the best family physicians in Massachusetts.

07:59.600 --> 08:01.840
 You wrote the book Overdose America,

08:01.840 --> 08:05.840
 and the new book coming out now called Sickening,

08:05.840 --> 08:08.840
 about how big pharma broke American healthcare,

08:08.840 --> 08:13.360
 including science and research, and how we can fix it.

08:13.360 --> 08:17.360
 First question, what is the biggest problem with big pharma

08:17.360 --> 08:20.360
 that if fixed would be the most impactful?

08:20.360 --> 08:23.360
 So if you can snap your fingers and fix one thing,

08:23.360 --> 08:25.360
 what would be the most impactful, you think?

08:25.360 --> 08:29.560
 The biggest problem is the way they...

08:29.560 --> 08:35.560
 They determine the content, the accuracy,

08:35.560 --> 08:39.560
 and the completeness of what doctors believe

08:39.560 --> 08:42.560
 to be the full range of knowledge

08:42.560 --> 08:45.560
 that they need to best take care of their patients.

08:45.560 --> 08:51.560
 So that with the knowledge having been taken over

08:51.560 --> 08:54.560
 by the commercial interests, primarily the pharmaceutical

08:54.560 --> 08:57.560
 industry, the purpose of that knowledge

08:57.560 --> 09:00.560
 is to maximize the profits that get returned

09:00.560 --> 09:03.560
 to investors and shareholders,

09:03.560 --> 09:07.560
 and not to optimize the health of the American people.

09:07.560 --> 09:11.560
 So rebalancing that equation would be the most important thing

09:11.560 --> 09:16.560
 to do to get our healthcare back aimed in the right direction.

09:16.560 --> 09:20.560
 Okay, so there's a tension between helping people

09:20.560 --> 09:22.560
 and making money.

09:22.560 --> 09:26.560
 So if we look at particularly the task of helping people

09:26.560 --> 09:30.560
 with medicine and healthcare, is it possible

09:30.560 --> 09:36.560
 if money is the primary mechanism by which you achieve

09:36.560 --> 09:39.560
 that as a motivator, is it possible to get that right?

09:39.560 --> 09:42.560
 I think it is, Lex, but I think it is not possible

09:42.560 --> 09:46.560
 without guardrails that maintain the integrity

09:46.560 --> 09:48.560
 and the balance of the knowledge.

09:48.560 --> 09:51.560
 Without those guardrails, it's like trying to play

09:51.560 --> 09:54.560
 a professional basketball game without referees

09:54.560 --> 09:57.560
 and having players call their own fouls.

09:57.560 --> 09:59.560
 But the players are paid to win,

09:59.560 --> 10:02.560
 and you can't count on them to call their own fouls.

10:02.560 --> 10:04.560
 So we have referees who are in charge.

10:04.560 --> 10:07.560
 We don't have those referees in American healthcare.

10:07.560 --> 10:13.560
 That's the biggest way that American healthcare

10:13.560 --> 10:16.560
 is distinguished from healthcare in other wealthy nations.

10:16.560 --> 10:19.560
 It's okay. You mentioned Milton Friedman.

10:19.560 --> 10:23.560
 And you mentioned his book called Capitalism and Freedom.

10:23.560 --> 10:26.560
 He writes that there are only three legitimate functions

10:26.560 --> 10:29.560
 of government to preserve law and order,

10:29.560 --> 10:31.560
 to enforce private contracts,

10:31.560 --> 10:35.560
 and to ensure that private markets work.

10:35.560 --> 10:39.560
 You said that that was a radical idea at the time,

10:39.560 --> 10:41.560
 but we're failing on all three.

10:41.560 --> 10:43.560
 How are we failing?

10:43.560 --> 10:46.560
 And also maybe the bigger picture is,

10:46.560 --> 10:49.560
 what are the strengths and weaknesses of capitalism

10:49.560 --> 10:51.560
 when it comes to medicine and healthcare?

10:51.560 --> 10:54.560
 Can we separate those out because those are two huge questions?

10:54.560 --> 10:57.560
 So how we're failing on all three,

10:57.560 --> 11:00.560
 and these are the minimal functions

11:00.560 --> 11:05.560
 that our guru of free market capitalism said

11:05.560 --> 11:07.560
 the government should perform.

11:07.560 --> 11:10.560
 So this is the absolute baseline.

11:10.560 --> 11:13.560
 On preserving law and order,

11:13.560 --> 11:17.560
 the drug companies routinely violate the law

11:17.560 --> 11:19.560
 in terms of their marketing

11:19.560 --> 11:26.560
 and in terms of their presentation

11:26.560 --> 11:28.560
 of the results of their trials.

11:28.560 --> 11:32.560
 I know this because I was an expert in litigation

11:32.560 --> 11:34.560
 for about 10 years.

11:34.560 --> 11:39.560
 I presented some of what I learned in civil litigation

11:39.560 --> 11:42.560
 to the FBI and the Department of Justice,

11:42.560 --> 11:45.560
 and that case led to the biggest criminal fine

11:45.560 --> 11:49.560
 in U.S. history as of 2009.

11:49.560 --> 11:55.560
 And I testified in a federal trial in 2010,

11:55.560 --> 11:59.560
 and the jury found Pfizer guilty of fraud

11:59.560 --> 12:01.560
 and racketeering violations.

12:01.560 --> 12:06.560
 In terms of violating the law, it's a routine occurrence.

12:06.560 --> 12:10.560
 The drug companies have paid $38 billion worth of fines

12:10.560 --> 12:15.560
 from, I think, 1991 to 2017.

12:15.560 --> 12:18.560
 It's never been enough to stop

12:18.560 --> 12:22.560
 the misrepresentation of their data,

12:22.560 --> 12:25.560
 and rarely are the fines greater

12:25.560 --> 12:28.560
 than the profits that were made.

12:28.560 --> 12:31.560
 See, executives have not gone to jail

12:31.560 --> 12:33.560
 for misrepresenting data

12:33.560 --> 12:38.560
 that have involved even tens of thousands of deaths,

12:38.560 --> 12:42.560
 in the case of Vioxx, OxyContin as well.

12:42.560 --> 12:45.560
 And when companies plead guilty to felonies,

12:45.560 --> 12:48.560
 which is not an unusual occurrence,

12:48.560 --> 12:51.560
 the government usually allows the companies,

12:51.560 --> 12:54.560
 the parent companies, to allow subsidiaries

12:54.560 --> 12:58.560
 to take the plea so that they are not one step closer

12:58.560 --> 13:01.560
 to getting disbarred from Medicare,

13:01.560 --> 13:04.560
 not being able to participate in Medicare.

13:04.560 --> 13:10.560
 So in that sense, there is a mechanism

13:10.560 --> 13:14.560
 that is appearing to impose law and order

13:14.560 --> 13:16.560
 on drug company behavior,

13:16.560 --> 13:19.560
 but it's clearly not enough. It's not working.

13:19.560 --> 13:24.560
 Can you actually speak to human nature here?

13:24.560 --> 13:28.560
 Are people corrupt? Are people malevolent?

13:28.560 --> 13:32.560
 Are people ignorant that work at the low level

13:32.560 --> 13:36.560
 and at the high level at Pfizer, for example,

13:36.560 --> 13:40.560
 at big pharma companies? How is this possible?

13:40.560 --> 13:43.560
 So I believe, just on a small tangent,

13:43.560 --> 13:45.560
 that most people are good.

13:45.560 --> 13:48.560
 And I actually believe if you join big pharma,

13:48.560 --> 13:51.560
 so a company like Pfizer,

13:51.560 --> 13:54.560
 your life trajectory often involves dreaming

13:54.560 --> 13:58.560
 and wanting and enjoying helping people.

13:58.560 --> 14:00.560
 Yes.

14:00.560 --> 14:04.560
 And then we look at the outcomes that you're describing,

14:04.560 --> 14:08.560
 and it looks, and that's why the narrative takes hold

14:08.560 --> 14:12.560
 that like Pfizer CEO Alba Brola, who I talked to,

14:12.560 --> 14:15.560
 is malevolent.

14:15.560 --> 14:19.560
 The sense is like these companies are evil.

14:19.560 --> 14:24.560
 So if the different parts, the people are good

14:24.560 --> 14:27.560
 and they want to do good, how are we getting these outcomes?

14:27.560 --> 14:32.560
 I think it has to do with the cultural milieu

14:32.560 --> 14:35.560
 that this is unfolding in.

14:35.560 --> 14:41.560
 And we need to look at sociology to understand this,

14:41.560 --> 14:48.560
 that when the cultural milieu is set up

14:48.560 --> 14:52.560
 to maximize the returns on investment

14:52.560 --> 14:55.560
 for shareholders and other venture capitalists

14:55.560 --> 14:57.560
 and hedge funds and so forth,

14:57.560 --> 15:00.560
 when that defines the culture

15:00.560 --> 15:03.560
 and the higher up you are in the corporation,

15:03.560 --> 15:09.560
 the more you're in on the game of getting rewarded

15:09.560 --> 15:12.560
 for maximizing the profits of the investors.

15:12.560 --> 15:15.560
 That's the culture they live in.

15:15.560 --> 15:19.560
 And it becomes normative behavior

15:19.560 --> 15:23.560
 to do things with science

15:23.560 --> 15:27.560
 that look normal in that environment

15:27.560 --> 15:30.560
 and are shared values within that environment

15:30.560 --> 15:35.560
 by good people whose self evaluation becomes modified

15:35.560 --> 15:39.560
 by the goals that are shared by the people around them.

15:39.560 --> 15:44.560
 And within that milieu, you have one set of standards

15:44.560 --> 15:48.560
 and then the rest of good American people

15:48.560 --> 15:51.560
 have the expectation that the drug companies

15:51.560 --> 15:55.560
 don't have money, but that they're playing by rules

15:55.560 --> 15:59.560
 that aren't part of the insider milieu.

15:59.560 --> 16:00.560
 That's fascinating.

16:00.560 --> 16:06.560
 The game they're playing modifies the culture

16:06.560 --> 16:08.560
 inside the meetings, inside the rooms,

16:08.560 --> 16:12.560
 day to day that there's a bubble that forms.

16:12.560 --> 16:15.560
 We're all in bubbles of different sizes.

16:15.560 --> 16:18.560
 And that bubble allows you to drift

16:18.560 --> 16:23.560
 in terms of what you see as ethical and unethical

16:23.560 --> 16:28.560
 because you see the game as just part of the game.

16:28.560 --> 16:31.560
 So marketing is just part of the game.

16:31.560 --> 16:36.560
 And paying the fines is just part of the game of science.

16:36.560 --> 16:42.560
 And without guardrails, it becomes even more part of the game.

16:42.560 --> 16:44.560
 You keep moving in that direction

16:44.560 --> 16:47.560
 if you're not bumping up against guardrails.

16:47.560 --> 16:49.560
 And I think that's how we've gotten

16:49.560 --> 16:52.560
 to the extreme situation we're in now.

16:52.560 --> 16:57.560
 So like I mentioned, I spoke with Pfizer CEO Albert Brola.

16:57.560 --> 17:03.560
 And I'd like to raise with you some of the concerns I raised with him.

17:03.560 --> 17:05.560
 So one, you already mentioned,

17:05.560 --> 17:07.560
 I raised the concern that Pfizer has engaged

17:07.560 --> 17:11.560
 in aggressive advertising campaigns.

17:11.560 --> 17:14.560
 As you can imagine, he said, no.

17:14.560 --> 17:16.560
 What do you think?

17:16.560 --> 17:20.560
 I think you're both right.

17:20.560 --> 17:26.560
 I agree with you that the aggressive advertising campaigns

17:26.560 --> 17:29.560
 do not add value to society.

17:29.560 --> 17:34.560
 And I agree with him that they're, for the most part, legal.

17:34.560 --> 17:36.560
 And it's the way the game is played.

17:36.560 --> 17:38.560
 Right. So sorry to interrupt,

17:38.560 --> 17:43.560
 but oftentimes his responses are,

17:43.560 --> 17:48.560
 especially now, he's been CEO for only like two years, three years.

17:48.560 --> 17:50.560
 He says Pfizer was a different company.

17:50.560 --> 17:53.560
 We've made mistakes, right, in the past.

17:53.560 --> 17:55.560
 We don't make mistakes anymore.

17:55.560 --> 17:59.560
 That there's rules and we play by the rules.

17:59.560 --> 18:02.560
 So like with every concern raised,

18:02.560 --> 18:05.560
 there's very, very strict rules, as he says.

18:05.560 --> 18:09.560
 In fact, he says sometimes way too strict and we play by them.

18:09.560 --> 18:13.560
 And so in that sense, advertisement, it doesn't seem like it's too aggressive

18:13.560 --> 18:16.560
 because it's playing by the rules.

18:16.560 --> 18:21.560
 And relative to the other, again, it's the game, relative to the other companies,

18:21.560 --> 18:24.560
 it's actually not that aggressive.

18:24.560 --> 18:26.560
 Relative to the other big pharma companies.

18:26.560 --> 18:27.560
 Yes, yes.

18:27.560 --> 18:31.560
 I hope we can quickly get back to whether or not they're playing by the rules,

18:31.560 --> 18:36.560
 but in general, but let's just look at the question of advertising specifically.

18:36.560 --> 18:40.560
 I think that's a good example of what it looks like from within that culture

18:40.560 --> 18:44.560
 and from outside that culture.

18:44.560 --> 18:49.560
 He's saying that we follow the law on our advertising.

18:49.560 --> 18:53.560
 We state the side effects and we state the FDA approved indications

18:53.560 --> 18:57.560
 and we do what the law says we have to do for advertising.

18:57.560 --> 19:02.560
 And I have not been an expert in litigation for a few years

19:02.560 --> 19:04.560
 and I don't know what's going on currently,

19:04.560 --> 19:06.560
 but let's take him at his word.

19:06.560 --> 19:07.560
 It could be true.

19:07.560 --> 19:09.560
 It might not be, but it could be.

19:09.560 --> 19:17.560
 But if that's true in his world, in his culture, that's ethical business behavior.

19:17.560 --> 19:21.560
 From a common sense person's point of view,

19:21.560 --> 19:26.560
 a drug company paying highly skilled media folks

19:26.560 --> 19:33.560
 to take the information about the drug and create the illusion, the emotional impact

19:33.560 --> 19:37.560
 and the takeaway message for viewers of advertisements

19:37.560 --> 19:42.560
 that grossly exaggerate the benefit of the drug and minimize the harms.

19:42.560 --> 19:49.560
 It's sociopathic behavior to have viewers of ads leave the ad

19:49.560 --> 19:55.560
 with an unrealistic impression of the benefits and harms of the drug.

19:55.560 --> 19:58.560
 And yet he's playing by the rules.

19:58.560 --> 20:04.560
 He's doing his job as CEO to maximize the effect of his advertising.

20:04.560 --> 20:07.560
 And if he doesn't do it, this is a key point.

20:07.560 --> 20:11.560
 If he doesn't do it, he'll get fired and the next guy will.

20:11.560 --> 20:13.560
 So the people that survive in the company,

20:13.560 --> 20:17.560
 the people that get raises in the company and move up in the company

20:17.560 --> 20:21.560
 are the ones that play by the rules and that's how the game solidifies itself.

20:21.560 --> 20:24.560
 But the game is within the bounds of the law.

20:24.560 --> 20:26.560
 Sometimes, most of the time, not always.

20:26.560 --> 20:28.560
 We'll return to that question.

20:28.560 --> 20:33.560
 I'm actually more concerned about the effect of advertisement

20:33.560 --> 20:42.560
 in a kind of much larger scale on the people that are getting funded

20:42.560 --> 20:45.560
 by the advertisement in self censorship.

20:45.560 --> 20:52.560
 Just like more subtle, more passive pressure to not say anything negative.

20:52.560 --> 20:57.560
 Because I've seen this and I've been saddened by it

20:57.560 --> 21:02.560
 that people sacrifice integrity in small ways

21:02.560 --> 21:05.560
 when they're being funded by a particular company.

21:05.560 --> 21:08.560
 They don't see themselves as doing so.

21:08.560 --> 21:12.560
 But you could just clearly see that the space of opinions

21:12.560 --> 21:14.560
 that they're willing to engage in

21:14.560 --> 21:17.560
 or a space of ideas they're willing to play with

21:17.560 --> 21:25.560
 is one that doesn't include anything that could possibly be negative about the company.

21:25.560 --> 21:28.560
 They just choose not to because, you know, why?

21:28.560 --> 21:33.560
 And that's really sad to me that if you give me a hundred bucks

21:33.560 --> 21:36.560
 I'm less likely to say something negative about you.

21:36.560 --> 21:39.560
 That makes me sad.

21:39.560 --> 21:43.560
 Because the reason I wouldn't say something negative about you, I prefer,

21:43.560 --> 21:47.560
 is the pressure of friendship and human connection, those kinds of things.

21:47.560 --> 21:49.560
 So I understand that.

21:49.560 --> 21:51.560
 That's also a problem, by the way.

21:51.560 --> 21:55.560
 Start having dinners and shaking hands and, oh, aren't we friends?

21:55.560 --> 21:59.560
 But the fact that money has that effect is really sad to me.

21:59.560 --> 22:06.560
 On the news media, on the journalists, on scientists, that's scary to me.

22:06.560 --> 22:09.560
 But of course the direct advertisement to consumers, like you said,

22:09.560 --> 22:11.560
 is a potentially very negative effect.

22:11.560 --> 22:16.560
 I wanted to ask what you think is the most negative impact of advertisement.

22:16.560 --> 22:19.560
 Is it that direct to consumer on television?

22:19.560 --> 22:22.560
 Is it advertisement to doctors?

22:22.560 --> 22:28.560
 Which I'm surprised to learn I was vaguely looking at is more than the advertisement.

22:28.560 --> 22:32.560
 More is spent on advertising to doctors than to consumers.

22:32.560 --> 22:35.560
 That's really confusing to me. It's fascinating, actually.

22:35.560 --> 22:40.560
 And then also, obviously, the law side of things is the lobbying dollars,

22:40.560 --> 22:42.560
 which I think is less than all of those.

22:42.560 --> 22:44.560
 But anyway, it's in the ballpark.

22:44.560 --> 22:46.560
 What concerns you most?

22:46.560 --> 22:49.560
 Well, it's the whole nexus of influence.

22:49.560 --> 22:55.560
 There's not one thing, and they don't put all their eggs in one basket.

22:55.560 --> 23:00.560
 It's a whole surround sound program here.

23:00.560 --> 23:05.560
 But in terms of advertisements, let's take the advertisement.

23:05.560 --> 23:12.560
 Trulicity is a diabetes drug for type 2 diabetes, an injectable drug.

23:12.560 --> 23:17.560
 And it lowers blood sugar just about as well as Metformin does.

23:17.560 --> 23:21.560
 Metformin costs about $4 a month.

23:21.560 --> 23:25.560
 Trulicity costs, I think, $6,200 a year.

23:25.560 --> 23:28.560
 So $48 a year versus $6,200.

23:28.560 --> 23:34.560
 Trulicity has distinguished itself because the manufacturer did a study

23:34.560 --> 23:40.560
 that showed that it significantly reduces the risk of cardiovascular disease in diabetics.

23:40.560 --> 23:44.560
 And they got approval on the basis of that study,

23:44.560 --> 23:47.560
 that very large study being statistically significant.

23:47.560 --> 23:53.560
 So the ad's obviously extoll the virtues of trulicity

23:53.560 --> 23:56.560
 because it reduces the risk of heart disease and stroke,

23:56.560 --> 24:01.560
 and that's one of the major morbidities, risks of type 2 diabetes.

24:01.560 --> 24:05.560
 What the ad doesn't say is that you have to treat 323 people

24:05.560 --> 24:11.560
 to prevent one nonfatal event at a cost of $2.7 million.

24:11.560 --> 24:15.560
 And even more importantly than that, what the ad doesn't say

24:15.560 --> 24:21.560
 is that the evidence shows that engaging in an active, healthy lifestyle program

24:21.560 --> 24:28.560
 reduces the risk of heart disease and strokes far more than trulicity does.

24:28.560 --> 24:31.560
 Now, to be fair to the company, the sponsor,

24:31.560 --> 24:39.560
 there's never been a study that compared trulicity to lifestyle changes.

24:39.560 --> 24:42.560
 But that's part of the problem of our advertising.

24:42.560 --> 24:49.560
 You would think in a rational society that was way out on a limb as a lone country,

24:49.560 --> 24:53.560
 besides New Zealand, that allows direct to consumer advertising,

24:53.560 --> 25:00.560
 that part of allowing direct to consumer advertising would be to mandate

25:00.560 --> 25:05.560
 that the companies establish whether their drug is better than, say,

25:05.560 --> 25:11.560
 healthy lifestyle adoption to prevent the problems that they claim to be preventing.

25:11.560 --> 25:13.560
 But we don't require that.

25:13.560 --> 25:17.560
 So the companies can afford to do very large studies

25:17.560 --> 25:21.560
 so that very small differences become statistically significant.

25:21.560 --> 25:25.560
 And their studies are asking the question, how can we sell more drug?

25:25.560 --> 25:30.560
 They're not asking the question, how can we prevent cardiovascular disease

25:30.560 --> 25:32.560
 in people with type 2 diabetes?

25:32.560 --> 25:34.560
 And that's how we get off in this.

25:34.560 --> 25:39.560
 We're now in the extreme arm of this distortion of our medical knowledge

25:39.560 --> 25:45.560
 of studying how to sell more drugs than how to make people more healthy.

25:45.560 --> 25:50.560
 That's a really great thing to compare to is lifestyle changes.

25:50.560 --> 25:52.560
 That should be the bar.

25:52.560 --> 25:57.560
 If you do some basic diet, exercise, all those kinds of things,

25:57.560 --> 25:59.560
 how does this drug compare to that?

25:59.560 --> 26:00.560
 Right.

26:00.560 --> 26:03.560
 And that study was done, actually, in the 90s.

26:03.560 --> 26:05.560
 It's called the Diabetes Prevention Program.

26:05.560 --> 26:12.560
 It was federally funded by the NIH so that there wasn't this drug company imperative

26:12.560 --> 26:15.560
 to just try to prove your drug was better than nothing.

26:15.560 --> 26:21.560
 And it was a very well designed study, randomized controlled trial

26:21.560 --> 26:26.560
 in people who were at high risk of diabetes, so called prediabetics,

26:26.560 --> 26:29.560
 and they were randomized to three different groups.

26:29.560 --> 26:33.560
 A placebo group, a group that got treated with metformin,

26:33.560 --> 26:38.560
 and a group that got treated with intensive lifestyle counseling.

26:38.560 --> 26:44.560
 So this study really tested whether you can get people in a randomized controlled trial

26:44.560 --> 26:49.560
 assigned to intensive lifestyle changes, whether that works.

26:49.560 --> 26:55.560
 Now, the common wisdom amongst physicians, and I think in general,

26:55.560 --> 26:57.560
 is that you can't get people to change.

26:57.560 --> 26:58.560
 You can do whatever you want.

26:58.560 --> 26:59.560
 You can stand on your head.

26:59.560 --> 27:00.560
 You can beg and plead.

27:00.560 --> 27:01.560
 People won't change.

27:01.560 --> 27:05.560
 So give it up and let's just move on with the drugs and not waste any time.

27:05.560 --> 27:10.560
 Except this study that was published in the New England Journal, I think in 2002,

27:10.560 --> 27:15.560
 shows that's wrong, that the people who were in the intensive lifestyle group

27:15.560 --> 27:20.560
 ended up losing 10 pounds, exercising five times a week, maintaining it,

27:20.560 --> 27:27.560
 and reduced the risk of getting diabetes by 58% compared to the metformin group,

27:27.560 --> 27:31.560
 which reduced its risk of getting diabetes by 31%.

27:31.560 --> 27:38.560
 So that exact study was done and it showed that lifestyle intervention is the winner.

27:38.560 --> 27:44.560
 Who, as a small tangent, is the leader?

27:44.560 --> 27:48.560
 Who is supposed to fight for the side of lifestyle changes?

27:48.560 --> 27:54.560
 Where is the big pharma version of lifestyle changes?

27:54.560 --> 27:59.560
 Who is supposed to have the big bully pulpit, the big money behind lifestyle changes?

27:59.560 --> 28:05.560
 In your sense, because that seems to be missing in a lot of our discussions about health policy.

28:05.560 --> 28:06.560
 Right.

28:06.560 --> 28:07.560
 That's exactly right.

28:07.560 --> 28:15.560
 And the answer is that we assume that the market has to solve all of these problems.

28:15.560 --> 28:18.560
 And the market can't solve all of these problems.

28:18.560 --> 28:26.560
 There needs to be some way of protecting the public interest for things that aren't financially driven.

28:26.560 --> 28:31.560
 So that the overriding question has to be how best to improve Americans health,

28:31.560 --> 28:40.560
 and not companies funding studies to try and prove that their new and expensive drug is better and should be used.

28:40.560 --> 28:45.560
 Well, some of that is also people sort of like yourself.

28:45.560 --> 28:48.560
 I mean, it's funny, you spoke with Joe Rogan.

28:48.560 --> 28:50.560
 He constantly espouses lifestyle changes.

28:50.560 --> 29:03.560
 So some of it is almost like understanding the problems that big farmers creating society and then sort of these influential voices speaking up against it.

29:03.560 --> 29:07.560
 So whether they're scientists or just regular communicators.

29:07.560 --> 29:12.560
 Yeah, I think you got to tip your hat to Joe for getting that message out.

29:12.560 --> 29:16.560
 And he clearly believes it and does his best.

29:16.560 --> 29:33.560
 But it's not coming out in the legitimate avenues, in the legitimate channels that are evidence based medicine and from the sources that the docs are trained to listen to and modify their patient care on.

29:33.560 --> 29:35.560
 Now, it's not 100%.

29:35.560 --> 29:41.560
 I mean, there are articles in the big journals about the benefits of lifestyle,

29:41.560 --> 29:51.560
 but they don't carry the same gravitas as the randomized controlled trials that test this drug against placebo or this drug against another drug.

29:51.560 --> 29:54.560
 So the Joe Rogan's of the world keep going.

29:54.560 --> 30:03.560
 You know, I tip my hat, but it's not going to carry the day for most of the people until it has the legitimacy of the medical establishment.

30:03.560 --> 30:06.560
 Yeah, like something that the doctors really pay attention to.

30:06.560 --> 30:10.560
 Well, there's an entire mechanism established for testing drugs.

30:10.560 --> 30:17.560
 There's not an entire mechanism established for in terms of scientific rigor of testing lifestyle changes.

30:17.560 --> 30:19.560
 I mean, it's more difficult.

30:19.560 --> 30:26.560
 I mean, everything is difficult in science with science that involves humans, especially.

30:26.560 --> 30:29.560
 But it's just these studies are very expensive.

30:29.560 --> 30:31.560
 They're difficult.

30:31.560 --> 30:34.560
 It's difficult to find conclusions to control all the variables.

30:34.560 --> 30:40.560
 And so it's very easy to dismiss them unless you really do a huge study that's very well funded.

30:40.560 --> 30:47.560
 And so maybe the doctors just lean towards the simpler studies over and over, which is what the drug companies fund.

30:47.560 --> 30:50.560
 They can control more variables.

30:50.560 --> 31:00.560
 See, but the control there is sometimes by hiding things too, right?

31:00.560 --> 31:08.560
 So sometimes you can just say that this is a well controlled study by pretending there's a bunch of other stuff.

31:08.560 --> 31:16.560
 Just ignoring the stuff that could be correlated or could be the real cause of the effects you're seeing, all that kind of stuff.

31:16.560 --> 31:21.560
 So money can buy ignorance, I suppose, in science.

31:21.560 --> 31:27.560
 It buys kind of blinders that are on that don't look outside the reductionist model.

31:27.560 --> 31:41.560
 And that's another issue is that we kind of nobody says to doctors in training only listen to reductionist studies and conclusions and methods of promoting health.

31:41.560 --> 31:43.560
 Nobody says that explicitly.

31:43.560 --> 31:49.560
 But the respectable science has to do with controlling the factors.

31:49.560 --> 31:53.560
 And I mean, it just doesn't make sense to me.

31:53.560 --> 32:00.560
 I'm going to pick on trilicity because it's such an obvious example, but it's not more egregious than many others.

32:00.560 --> 32:11.560
 It doesn't make sense to me to allow a drug to be advertised as preventing cardiovascular disease when you haven't included lifestyle changes as an arm in the study.

32:11.560 --> 32:17.560
 It's just so crystal clear that the purpose of that study is to sell trilicity.

32:17.560 --> 32:20.560
 It's not to prevent cardiovascular disease.

32:20.560 --> 32:33.560
 You know, if we were in charge, I would try to convince you that anywhere that study, the results of that study were presented to physicians, it would be stamped in big red letters.

32:33.560 --> 32:37.560
 This study did not compare trilicity to lifestyle changes.

32:37.560 --> 32:39.560
 They need to know that.

32:39.560 --> 32:46.560
 And the docs are kind of trained, these blinders get put on, and they're trained to kind of forget that that's not there.

32:46.560 --> 32:58.560
 So first of all, that's a small or big change to advertisement that seems obvious to say, like in force that it should be compared to lifestyle changes.

32:58.560 --> 33:05.560
 Do you think advertisements period in the United States for pharmaceutical drugs should be banned?

33:05.560 --> 33:07.560
 I think they can't be banned.

33:07.560 --> 33:10.560
 So it doesn't matter what I think.

33:10.560 --> 33:11.560
 Okay.

33:11.560 --> 33:15.560
 Let's say you were a dictator and two, why can't they be banned?

33:15.560 --> 33:18.560
 Answer either one.

33:18.560 --> 33:41.560
 I believe, I've been told by lawyers who I trust that the freedom of speech in the U.S. Constitution is such that you can't ban them, that you could ban cigarettes and alcohol, which have no therapeutic use, but drugs have a therapeutic use and advertisements about them can't be banned.

33:41.560 --> 33:55.560
 Let's assume that they can't be, because we know they won't be anyway, but let's assume they can't be, and especially our Supreme Court now would be unlikely to take that seriously.

33:55.560 --> 33:57.560
 But that's not the issue.

33:57.560 --> 34:13.560
 The issue is that if the drug companies want to spend their money advertising, they should have to have independent analysis of the message that the viewers are left with about the drug, so that it's realistic.

34:13.560 --> 34:15.560
 What's the chance the drug will help them?

34:15.560 --> 34:18.560
 Well, in Trilicity, it's one out of 323.

34:18.560 --> 34:24.560
 322 people aren't going to benefit from the cardiovascular reduction, risk reduction.

34:24.560 --> 34:27.560
 What's the true cost?

34:27.560 --> 34:42.560
 When drugs advertise that you may be able to get this for a $25 copay or something, tens of thousands of dollars a year drug for a $25 copay, what an enormous disservice that is to misrepresent the cost to society.

34:42.560 --> 34:44.560
 That should not be allowed.

34:44.560 --> 34:55.560
 You should have to make it clear to the viewers how many people are going to benefit, what's your chance of benefiting, how does it compare to lifestyle changes or less expensive therapies?

34:55.560 --> 34:59.560
 What do you give up if you use a less expensive therapy or gain, perhaps?

34:59.560 --> 35:01.560
 And how much it costs?

35:01.560 --> 35:02.560
 How much it costs?

35:02.560 --> 35:17.560
 Well, that can go either way because if you say, humor costs $72,000 and it's no more effective as a first line drug than methotrexate, which costs $480, people might say, I want the expensive drug because I can get it for $25 copay.

35:17.560 --> 35:21.560
 So you'd have to temper that a little bit.

35:21.560 --> 35:25.560
 Oh, you mean people are so, they don't care.

35:25.560 --> 35:26.560
 They don't care.

35:26.560 --> 35:31.560
 Their insurance is going to cover it and it's a $25 copay, but we could figure out how to deal with that.

35:31.560 --> 35:55.560
 The main point is that if we assume that advertisements are going to keep going and they are, we could require that there be outside evaluation of the message that reasonable unbiased viewers take away from the ads and the ads would have to tell the truth about the drug.

35:55.560 --> 36:15.560
 And the truth should have like sub truth guardrails, meaning like the cost that we talked about, the effects compared to things that actually, you know, lifestyle changes, just these details, very strict guardrails of what actually has to be specified.

36:15.560 --> 36:22.560
 And I would make it against the law to have family picnics or dogs catching Frisbees in the ads.

36:22.560 --> 36:27.560
 So you mean 95% of the ads.

36:27.560 --> 36:28.560
 Yes.

36:28.560 --> 36:42.560
 I mean, there's something dark and authentic about those advertisements, but they see, I mean, I'm sure they're being done because they work for the target audience.

36:42.560 --> 36:45.560
 And then the doctors too.

36:45.560 --> 36:48.560
 Can you really buy a doctor's opinion?

36:48.560 --> 36:51.560
 Why does it have such an effect on doctors?

36:51.560 --> 36:53.560
 Advertisement to doctors.

36:53.560 --> 36:58.560
 You as a physician, again, like from everything I've seen, people love you.

36:58.560 --> 37:08.560
 And I've just, people should definitely look you off from, there's a bunch of videos of you giving talks on YouTube.

37:08.560 --> 37:18.560
 And it's just, it's so refreshing to hear just the clarity of thought about health policy, about health care.

37:18.560 --> 37:20.560
 Just the way you think throughout the years.

37:20.560 --> 37:21.560
 Thank you.

37:21.560 --> 37:28.560
 So like, it's easy to think about like, maybe you're criticizing Big Pharma, that's one part of the message that you're talking about.

37:28.560 --> 37:35.560
 But, you know, that's not like, your brilliance actually shines in the positive, in the solutions and how to do it.

37:35.560 --> 37:40.560
 So as a doctor, what affects your mind?

37:40.560 --> 37:41.560
 Yeah.

37:41.560 --> 37:42.560
 And how does Big Pharma affect your mind?

37:42.560 --> 37:43.560
 Yeah.

37:43.560 --> 37:56.560
 One, the information that comes through legitimate sources that doctors have been taught to rely on, evidence based medicine, the articles in peer reviewed journals, the guidelines that are issued.

37:56.560 --> 38:12.560
 Now, those are problematic because when an article is peer reviewed and published in a respected journal, people and doctors obviously assume that the peer reviewers

38:12.560 --> 38:17.560
 have had access to the data and they've independently analyzed the data.

38:17.560 --> 38:27.560
 And they corroborate the findings in the manuscript that was submitted, or they give feedback to the authors and say, we disagree with you on this point.

38:27.560 --> 38:30.560
 And would you please check our analysis?

38:30.560 --> 38:32.560
 And if you agree with us, make it.

38:32.560 --> 38:36.560
 That's what they assume the peer review process is, but it's not.

38:36.560 --> 38:38.560
 The peer reviewers don't have the data.

38:38.560 --> 38:50.560
 The peer reviewers have the manuscript that's been submitted by the usually in conjunction with or by the drug company that manufactures the drug.

38:50.560 --> 39:04.560
 So peer reviewers are unable to perform the job that doctors think they're performing to vet the data to assure that it's accurate and reasonably complete.

39:04.560 --> 39:06.560
 They can't do it.

39:06.560 --> 39:18.560
 And then we have the clinical practice guidelines, which are increasingly more important as the information, the flow of information keeps getting brisker and brisker.

39:18.560 --> 39:21.560
 And docs need to get to the bottom line quickly.

39:21.560 --> 39:25.560
 Clinical practice guidelines become much more important.

39:25.560 --> 39:38.560
 And we assume that the authors of those clinical practice guidelines have independently analyzed the data from the clinical trials and make their recommendations that set the standards of care based on their analysis.

39:38.560 --> 39:40.560
 That's not what happens.

39:40.560 --> 39:55.560
 The experts who write the clinical trials rely almost entirely on the publications presenting the results of the clinical trials, which are peer reviewed, but the peer reviewers haven't had access to the data.

39:55.560 --> 40:10.560
 So we've got a system of the highest level of evidence that doctors have been trained over and over again to rely on to practice evidence based medicine to be good doctors that has not been verified.

40:10.560 --> 40:25.560
 Do you think that data that's coming from the pharma companies, do you think there, what level of manipulation is going on with that data? Is it at the study design level?

40:25.560 --> 40:44.560
 Is it at literally, there's some data that you just keep off, you know, keep out of the charts, keep out of the aggregate analysis that you then publish, or is it the worst case, which has just changed some of the numbers?

40:44.560 --> 40:51.560
 It happened. All three happened. I can't, I don't know what the denominator is, but I spent about 10 years in litigation.

40:51.560 --> 41:10.560
 And for example, in Vioxx, which was withdrawn from the market in 2004 in the biggest drug recall in American history, the problem was that it got recalled when a study that Merck sponsored showed that Vioxx doubled the risk,

41:10.560 --> 41:16.560
 more than doubled the risk of heart attacks, strokes, and blood clots, serious blood clots.

41:16.560 --> 41:33.560
 It got pulled then. But there was a study, a bigger study that had been published in 2000 in the New England Journal of Medicine that showed that Vioxx was a better drug for arthritis and pain, not because it was more effective.

41:33.560 --> 41:45.560
 It's no more effective than a leave or Advil, but because it was less likely to cause serious GI complications, bleeds and perforations in the gut.

41:45.560 --> 41:58.560
 Now, in that study that was published in the New England Journal that was never corrected, it was a little bit modified 15 months after the drug was taken off the market, but never corrected.

41:58.560 --> 42:05.560
 Merck left out three heart attacks. And the FDA knew that Merck left out three heart attacks.

42:05.560 --> 42:16.560
 And the FDA's analysis of the data from that study said that the FDA wasn't going to do the analysis without the three heart attacks in it.

42:16.560 --> 42:26.560
 And the important part of this story is that there were 12 authors listed on that study in the New England Journal. Two were Merck employees.

42:26.560 --> 42:29.560
 They knew about the three heart attacks that had been omitted.

42:29.560 --> 42:37.560
 The other 10 authors, the academic authors, didn't know about it. They hadn't seen that data.

42:37.560 --> 42:46.560
 So Merck just – they had an excuse. It's complicated and the FDA didn't accept it, so there's no reason to go into it.

42:46.560 --> 42:53.560
 But Merck just left out the three heart attacks. And the three heart attacks – it may seem three heart attacks in a 10,000 person study may seem like nothing,

42:53.560 --> 42:59.560
 except they completely changed the statistics so that had the three heart attacks been included,

42:59.560 --> 43:05.560
 the only conclusion that Merck could have made was that Vox significantly increased the risk of heart attack.

43:05.560 --> 43:13.560
 And they abbreviated their endpoint from heart attacks, strokes, and blood clots to just heart attacks.

43:13.560 --> 43:23.560
 So those are maybe, in their mind, they're also playing by the rules because of some technical excuse that you mentioned that was rejected. How can this –

43:23.560 --> 43:33.560
 No, let me interrupt. No, that's not true. The study was completed. The blind was broken, meaning they looked at the data.

43:33.560 --> 43:45.560
 In March of 2000 – the article was published in the New England Journal in November of 2000 – in March of 2000, there was an email by the head scientist

43:45.560 --> 43:57.560
 that was published in the Wall Street Journal that said the day that the data were unblinded, that it's a shame that the cardiovascular events are there,

43:57.560 --> 44:05.560
 but the drug will do well and we will do well.

44:05.560 --> 44:18.560
 But removing the three heart attacks, how does that happen? Like, who has to convince themselves? Is this pure malevolence?

44:18.560 --> 44:31.560
 You have to be the judge of that. But the person who was in charge of the Data Safety Monitoring Board issued a letter that said they'll stop counting cardiovascular events

44:31.560 --> 44:37.560
 a month before the trial is over and they'll continue counting GI events.

44:37.560 --> 44:50.560
 And that person got a contract to consult with Merck for $5,000 a day, I think for 12 days a year for one or two years, that was signed –

44:50.560 --> 45:00.560
 that contract was signed within two weeks of the decision to stop counting heart attacks.

45:00.560 --> 45:12.560
 I won't understand that man or woman. I've been reading a lot about Nazi Germany and thinking a lot about the good Germans

45:12.560 --> 45:23.560
 because I want to understand so that we can each encourage each other to take the small heroic actions that prevents that

45:23.560 --> 45:35.560
 because it feels to me removing malevolence from the table, where it's just a pure psychopathic person, that there's just a momentum created by the game, like you mentioned.

45:35.560 --> 45:46.560
 And so it takes reversing the momentum within a company, I think requires many small acts of heroism.

45:46.560 --> 45:56.560
 Not gigantic, I'm going to leave and become a whistleblower and publish a book about it, but small, quiet acts of pressuring against this.

45:56.560 --> 46:04.560
 Like, what are we doing here? We're trying to help people. Is this the right thing to do? Looking in the mirror constantly and asking, is this the right thing to do?

46:04.560 --> 46:15.560
 I mean, that's what integrity is. Acknowledging the pressures you're under and then still be able to zoom out and think, what is the right thing to do here?

46:15.560 --> 46:28.560
 But the data, hiding the data makes it too easy to live in ignorance. So, like, inside those companies.

46:28.560 --> 46:35.560
 So your idea is that the reviewers should see the data. That's one step.

46:35.560 --> 46:46.560
 So to even push back on that idea is, I assume you mean that data remains private except to the peer reviewers.

46:46.560 --> 46:54.560
 The problem, of course, as you probably know, is the peer review process is not perfect. You know, it's individuals.

46:54.560 --> 46:59.560
 It feels like there should be a lot more eyes on the data than just the peer reviewers.

46:59.560 --> 47:09.560
 Yes. This is not a hard problem to solve. When a study is completed, a clinical study report is made.

47:09.560 --> 47:24.560
 And it's usually several thousand pages. And what it does is it takes the raw patient data and it tabulates it in the ways it's supposedly and usually in the ways that the company has pre specified.

47:24.560 --> 47:30.560
 So that you then end up with a searchable, let's say, 3000 page document.

47:30.560 --> 47:38.560
 As I became more experienced as an expert in litigation, I could go through those documents pretty quickly.

47:38.560 --> 47:43.560
 Quickly may mean 20 hours or 40 hours, but it doesn't mean three months of my work.

47:43.560 --> 47:58.560
 And see if the company's, if the way the company has analyzed the data is consistent with the way, with their statistical analysis plan and their pre specified outcome measures.

47:58.560 --> 48:08.560
 It's not hard. And I think you're right. Peer reviewers, I don't peer review clinical trials, but I peer review other kinds of articles.

48:08.560 --> 48:15.560
 I have to do one on the airplane and the way home. And it's hard. I mean, we're just ordinary mortal people volunteering.

48:15.560 --> 48:18.560
 Unpaid. The motivation is not clear.

48:18.560 --> 48:36.560
 The motivation is to keep, to be a good citizen in the medical community and to be unfriendly terms with the journals so that if you want to get published, there's sort of an unspoken incentive.

48:36.560 --> 48:43.560
 As somebody who enjoys game theory, I feel like that motivation is good, but could be a lot better.

48:43.560 --> 48:52.560
 Yes, you should get more recognition or in some way, academic credit for it. It should go to your career advancement.

48:52.560 --> 49:10.560
 If it's an important paper and you recognize it's an important paper as a great peer reviewer, that this is not in that area where it's like clearly piece of crap paper or clearly an awesome paper that doesn't have controversial aspects to it.

49:10.560 --> 49:14.560
 And it's just a beautiful piece of work. Okay, those are easy.

49:14.560 --> 49:26.560
 And then there is like the very difficult gray area, which may require many, many days of work on your part as a peer reviewer. So it's not, you know, it's not just a couple hours, but really seriously reading.

49:26.560 --> 49:35.560
 Like some papers can take months to really understand. So if you really want to struggle, there has to be an incentive for that struggle.

49:35.560 --> 49:40.560
 Yes. And billions of dollars right on some of these studies.

49:40.560 --> 49:44.560
 And lies. That's not right. Not to mention.

49:44.560 --> 50:06.560
 Right. But it would be easy to have full time statisticians hired by the journals or shared by the journals who were independent of any other financial incentive to go over these kind of methodological issues and take responsibility for the...

50:06.560 --> 50:13.560
 for certifying the analyses that are done and then pass it on to the volunteer peer reviewers.

50:13.560 --> 50:29.560
 See, I believe even in this, in the sort of capitalism or even social capital, after watching Twitter in the time of COVID and just looking at people that investigate themselves, I believe in the citizenry.

50:29.560 --> 50:38.560
 People, if you give them access to the data, like these like citizen scientists arise, a lot of them on the, it's kind of funny.

50:38.560 --> 50:42.560
 A lot of people that are just really used to working with data.

50:42.560 --> 50:57.560
 They don't know anything about medicine and they don't have actually the biases that a lot of doctors and medical and a lot of the people that read these papers, they'll just go raw into the data and look at it with like they're bored almost and they do incredible analysis.

50:57.560 --> 51:08.560
 So I, you know, there's some argument to be made for a lot of this data to become public, like deanonymized, no, sorry, anonymized, all that kind of stuff.

51:08.560 --> 51:16.560
 But for a lot of it to be public, especially when you're talking about things as impactful as some of these drugs.

51:16.560 --> 51:21.560
 I agree 100%. So let's turn the micros... let's get a little bit more granular.

51:21.560 --> 51:22.560
 Sure.

51:22.560 --> 51:27.560
 On the peer review issue, we're talking about pre publication transparencies.

51:27.560 --> 51:29.560
 And that is critically important.

51:29.560 --> 51:36.560
 Once a paper is published, the horses are out of the barn and docs are going to read it, take it as evidence based medicine.

51:36.560 --> 51:43.560
 The economists call what then happens as stickiness, that the docs hold on to their beliefs.

51:43.560 --> 51:54.560
 My own voice inside says once doctors start doing things to their patients bodies, they're really not too enthusiastic about hearing it was wrong.

51:54.560 --> 51:57.560
 Yeah, that's the stickiness of human nature.

51:57.560 --> 52:04.560
 So that bar, once it's published, the doctors, that's when the stickiness emerges as well.

52:04.560 --> 52:07.560
 Yeah, it's hard to put that toothpaste back in the tube.

52:07.560 --> 52:12.560
 Now, that's pre publication transparency, which is essential.

52:12.560 --> 52:28.560
 And you could have whoever saw that data pre publication could sign confidentiality agreements so that the drug companies couldn't argue that we're just opening the spigots of our data and people can copy it and all the excuses they make.

52:28.560 --> 52:32.560
 You could argue that you didn't have to, but let's just let them do it.

52:32.560 --> 52:36.560
 Let the peer reviewers sign confidentiality agreements and they won't leak the data.

52:36.560 --> 52:53.560
 But then you have to go to post publication transparency, which is what you were just getting at, to let the data free and let citizens and citizen scientists and other doctors who are interested have at it.

52:53.560 --> 52:57.560
 Kind of like Wikipedia, have at it.

52:57.560 --> 53:01.560
 Let it out and let people criticize each other.

53:01.560 --> 53:08.560
 Okay, so speaking of the data, the FDA asked 55 years to release Pfizer vaccine data.

53:08.560 --> 53:11.560
 This is also something I raised with Albert Berla.

53:11.560 --> 53:13.560
 What did he say?

53:13.560 --> 53:16.560
 There's several things I didn't like about what he said.

53:16.560 --> 53:23.560
 So some things are expected and some of it is just revealing the human being, which is what I'm interested in doing.

53:23.560 --> 53:27.560
 But he said he wasn't aware of the 75 and the 55.

53:27.560 --> 53:31.560
 I'm sorry, he wasn't aware of the how long.

53:31.560 --> 53:33.560
 So here I'll explain.

53:33.560 --> 53:49.560
 Do you know that since you spoke to him, Pfizer has petitioned the judge to join the suit in behalf of the FDA's request to release that data over 55 or 75 years.

53:49.560 --> 53:51.560
 Pfizer's fully aware of what's going on.

53:51.560 --> 53:52.560
 He's aware.

53:52.560 --> 53:55.560
 I'm sure he's aware in some formulation.

53:55.560 --> 53:58.560
 The exact years he might have not been aware.

53:58.560 --> 54:13.560
 But the point is that there is, that is the FDA, the relationship with Pfizer and the FDA in terms of me being able to read human beings was the thing he was most uncomfortable with.

54:13.560 --> 54:16.560
 That he didn't want to talk about the FDA.

54:16.560 --> 54:32.560
 And that it was clear that there was a relationship there that if the words you use may do a lot of harm, potentially because like you're saying there might be lawsuits going on, there's litigation, there's legal stuff, all that kind of stuff.

54:32.560 --> 54:35.560
 And then there's a lot of games being played in this space.

54:35.560 --> 54:52.560
 So I don't know how to interpret it if he's actually aware or not, but the deeper truth is that he's deeply uncomfortable bringing light to this part of the game.

54:52.560 --> 54:53.560
 Yes.

54:53.560 --> 54:59.560
 And I'm going to read between the lines and Albert Borla certainly didn't ask me to speak for him.

54:59.560 --> 55:02.560
 But I think, but when did you speak to him?

55:02.560 --> 55:03.560
 How long ago?

55:03.560 --> 55:06.560
 Wow, time flies when you're having fun two months ago.

55:06.560 --> 55:07.560
 Two months ago.

55:07.560 --> 55:18.560
 So that was just recently it's come out just in the past week it's come out that Pfizer isn't battling the FDA.

55:18.560 --> 55:32.560
 Pfizer has joined the FDA in the opposition to the request to release these documents in the same amount of time that the FDA took to evaluate them.

55:32.560 --> 55:33.560
 Yeah.

55:33.560 --> 55:53.560
 So Pfizer is offering to help the FDA to petition the judge to not enforce the timeline that he seems to be moving towards.

55:53.560 --> 56:06.560
 So for people who are not familiar, we're talking about the Freedom of Information Act request to release the Pfizer vaccine data study data to release as much of the data as possible.

56:06.560 --> 56:10.560
 Like the raw data, the details or actually not even the raw data.

56:10.560 --> 56:11.560
 It's data.

56:11.560 --> 56:12.560
 It doesn't matter.

56:12.560 --> 56:13.560
 There's details to it.

56:13.560 --> 56:23.560
 And I think the response from the FDA is that, of course, yes, of course.

56:23.560 --> 56:29.560
 But, you know, we can only publish like some X number of pages a day.

56:29.560 --> 56:30.560
 500 pages.

56:30.560 --> 56:32.560
 500 pages of data.

56:32.560 --> 56:33.560
 It's not a day though.

56:33.560 --> 56:34.560
 It's whatever.

56:34.560 --> 56:35.560
 A week, I think.

56:35.560 --> 56:39.560
 The point is whatever they're able to publish is ridiculous.

56:39.560 --> 56:47.560
 Like my printer can only print three pages a day and we cannot afford a second printer.

56:47.560 --> 56:54.560
 So it's some kind of bureaucratic language for, you know, there's a process to this.

56:54.560 --> 57:08.560
 You know, and now you're saying that Pfizer is obviously more engaged in helping this kind of bureaucratic process prosper in its full absurdity, Kafkaesque absurdity.

57:08.560 --> 57:11.560
 So what is this?

57:11.560 --> 57:13.560
 This really bothered people.

57:13.560 --> 57:14.560
 This really...

57:14.560 --> 57:15.560
 This is really troublesome.

57:15.560 --> 57:24.560
 And just to put it in just plain English terms, Pfizer's making the case that it can't...

57:24.560 --> 57:29.560
 The FDA and Pfizer together are making the case that they can't go through the documents.

57:29.560 --> 57:44.560
 It's going to take them some number of hundreds of folds more time to go through the documents than the FDA required to go through the documents to approve the vaccines, to give the vaccines full FDA approval.

57:44.560 --> 57:54.560
 And the FDA's argument, talk about Kafkaesque, is that to do it more rapidly would cost them $3 million.

57:54.560 --> 58:01.560
 $3 million equals one hour of vaccine sales over two years.

58:01.560 --> 58:05.560
 One hour of sales and they can't come up with the money.

58:05.560 --> 58:12.560
 And now Pfizer has joined the suit to help the FDA fight off this judge, this mean judge who thinks they ought to release the data.

58:12.560 --> 58:16.560
 But evidently, Pfizer isn't offering to come up with the $3 million either.

58:16.560 --> 58:24.560
 So, but for $3 million, I mean, maybe the FDA should do a GoFundMe thing.

58:24.560 --> 58:27.560
 Well, obviously the money thing...

58:27.560 --> 58:34.560
 I mean, I'm sure if Elon Musk comes along and says, I'll give you $100 million, publish it now.

58:34.560 --> 58:37.560
 I think they'll come up with another.

58:37.560 --> 58:43.560
 So, I mean, it's clear that there is cautiousness.

58:43.560 --> 58:46.560
 I don't know the source of it from the FDA.

58:46.560 --> 58:54.560
 Well, there's only one explanation that I can think of, which is that the FDA and Pfizer don't want to release the data.

58:54.560 --> 59:02.560
 They don't want to release the three or 500,000 pages of documents.

59:02.560 --> 59:04.560
 And I don't know what's in there.

59:04.560 --> 59:07.560
 I want to say one thing very clearly.

59:07.560 --> 59:09.560
 I am not an antivaxxer.

59:09.560 --> 59:11.560
 I believe the vaccines work.

59:11.560 --> 59:14.560
 I believe everybody should get vaccinated.

59:14.560 --> 59:20.560
 The evidence is clear that if you're vaccinated, you reduce your risk of dying of COVID by 20 fold.

59:20.560 --> 59:22.560
 And we've got new sub variants coming along.

59:22.560 --> 59:25.560
 And I just want to be very clear about this.

59:25.560 --> 59:40.560
 That said, there's something I would give you 10 to 1 odds on a bet that there's something in that data that is going to be embarrassing to either FDA or Pfizer or both.

59:40.560 --> 59:41.560
 So there's two options.

59:41.560 --> 59:43.560
 I agree with you 100%.

59:43.560 --> 59:45.560
 One is they know of embarrassing things.

59:45.560 --> 59:47.560
 That's option one.

59:47.560 --> 59:53.560
 And option two, they haven't invested enough to truly understand the data.

59:53.560 --> 59:59.560
 I mean, it's a lot of data that they have a sense there might be something embarrassing in there.

59:59.560 --> 1:00:08.560
 And if we release it, surely the world will discover the embarrassing and to do a sort of distillment in our argument.

1:00:08.560 --> 1:00:16.560
 They'll take the small, the press, the people will take the small embarrassing things and blow them up into big things.

1:00:16.560 --> 1:00:19.560
 Yes, and support the antivaxx campaign.

1:00:19.560 --> 1:00:22.560
 I think that's all possible.

1:00:22.560 --> 1:00:27.560
 Nonetheless, the data are about the original clinical trial.

1:00:27.560 --> 1:00:35.560
 And the emergency youth's authorization was based on the first few months of the data from that trial.

1:00:35.560 --> 1:00:37.560
 And it was a two year trial.

1:00:37.560 --> 1:00:40.560
 The rest of that data has not been opened up.

1:00:40.560 --> 1:00:47.560
 And there was not an advisory committee meeting to look at that data when the FDA granted full authorization.

1:00:47.560 --> 1:00:49.560
 Again, I am pro vaccine.

1:00:49.560 --> 1:00:52.560
 I am not making an antivaxx argument here.

1:00:52.560 --> 1:00:57.560
 But I suspect that there's something pretty serious in that data.

1:00:57.560 --> 1:01:16.560
 And the reason why I'm not an antivaxxer, having not been able to see the data that the FDA and Pfizer seem to willing not just to put effort into preventing the release of, but seem to have quite a bit of energy in investing, quite a bit of energy in not releasing that data.

1:01:16.560 --> 1:01:25.560
 The reason why that doesn't tip me over into the antivaxxer side is because that's clinical trial data, early clinical trial data that involved several thousand people.

1:01:25.560 --> 1:01:30.560
 We now have millions of data points from people who have had the vaccine.

1:01:30.560 --> 1:01:35.560
 This is real world data showing the efficacy of the vaccines.

1:01:35.560 --> 1:01:44.560
 And so far, knock on wood, there aren't side effects that overcome the benefits of vaccine.

1:01:44.560 --> 1:02:04.560
 So I'm with you. I'm now, I guess, three shots of the vaccine. But there's a lot of people that are kind of saying, well, even the data on the real, the real world use large scale data has, is messy.

1:02:04.560 --> 1:02:13.560
 The way it's being reported, the way it's being interpreted, well, one thing is clear to me that it is being politicized.

1:02:13.560 --> 1:02:21.560
 I mean, if you just look objectively, don't have to go to at the shallow surface level.

1:02:21.560 --> 1:02:31.560
 It seems like there's two groups that I can't even put a term to it because it's not really pro vaccine versus anti vaccine.

1:02:31.560 --> 1:02:44.560
 Because it's pro vaccine, triple mask, Democrat, liberal, and then anti mandate, whatever, whatever those groups are.

1:02:44.560 --> 1:02:54.560
 I can't quite, because they're changing, anti mask, but not really the kind of, so those two groups that feel political and nature, not scientific in nature.

1:02:54.560 --> 1:03:03.560
 It's their bickering. And then it's clear that this data is being interpreted by the different groups differently.

1:03:03.560 --> 1:03:14.560
 And it's very difficult for me as a human being to understand where the truth lies, especially given how much money is flying around on all sides.

1:03:14.560 --> 1:03:24.560
 So the anti vaxxers can make a lot of money too. Let's not forget this. From the individual perspective, you can become famous being an anti vaxxer.

1:03:24.560 --> 1:03:34.560
 And so there's a lot of incentives on all sides here. And there's real human emotion and fear and also credibility.

1:03:34.560 --> 1:03:51.560
 Scientists don't want to ruin their reputation if they speak out and whatever, speak their opinion or they look at some slides of the data and begin to interpret it in some kind of way.

1:03:51.560 --> 1:03:56.560
 It's clear that fear is dominating the discourse here, especially in the scientific community.

1:03:56.560 --> 1:04:06.560
 So I don't know what to make of that. And the only happy people here is Pfizer.

1:04:06.560 --> 1:04:21.560
 It's just plowing all ahead. I mean, with every single variant, there's very, I would say, outside of arguably a very flawed system,

1:04:21.560 --> 1:04:32.560
 there's a lot of incredible scientific and engineering work being done in constantly developing new, like antiviral drugs, new vaccines to deal with the variants.

1:04:32.560 --> 1:04:43.560
 So they're happily being a capitalist machine. And it's very difficult to know what to do with that.

1:04:43.560 --> 1:04:51.560
 And let's just put this in perspective for folks. The bestselling drug in the world has been Humira for a number of years.

1:04:51.560 --> 1:04:57.560
 It's approved for the treatment of rheumatoid arthritis and eight other indications.

1:04:57.560 --> 1:05:06.560
 And it's sold about $20 billion globally over the past few years. It leveled out. It peaked at that level.

1:05:06.560 --> 1:05:15.560
 Pfizer expects to sell $65 billion of vaccine in the first two years of the pandemic.

1:05:15.560 --> 1:05:23.560
 So this is by far the biggest selling and most profitable drug that's ever come along.

1:05:23.560 --> 1:05:33.560
 Can I ask you a difficult question here? In the fog that we're operating in here,

1:05:33.560 --> 1:05:45.560
 on the Pfizer BioNTech vaccine, what was done well and what was done badly that you can see now?

1:05:45.560 --> 1:05:49.560
 It seems like we'll know more decades from now.

1:05:49.560 --> 1:05:50.560
 Yes.

1:05:50.560 --> 1:06:02.560
 But now in the fog of today, with the $65 billion flying around, where do you land?

1:06:02.560 --> 1:06:15.560
 So we're going to get to what I think is one of the key problems with the pharmaceutical industry model in the United States about being profit driven.

1:06:15.560 --> 1:06:25.560
 So in 2016, the NIH did the key infrastructure work to make mRNA vaccines.

1:06:25.560 --> 1:06:35.560
 That gets left out of the discussion a lot. And Pfizer BioNTech actually paid royalties voluntarily to the NIH.

1:06:35.560 --> 1:06:38.560
 I don't know how much it was. I don't think it was a whole lot of money.

1:06:38.560 --> 1:06:49.560
 But I think they wanted to avoid the litigation that Moderna got itself into by just taking that 2016 knowledge and having that be the foundation of their product.

1:06:49.560 --> 1:06:58.560
 So Pfizer took that and they paid for their R&D having received that technology.

1:06:58.560 --> 1:07:10.560
 And when they got the genetic code from China about the virus, they very quickly made a vaccine and the vaccine works.

1:07:10.560 --> 1:07:17.560
 And President Trump, to his credit, launched Operation Warp Speed and just threw money at the problem.

1:07:17.560 --> 1:07:23.560
 They just said, we spent five times more per person than the EU early on.

1:07:23.560 --> 1:07:31.560
 Just pay them whatever they want. Let's just get this going. And Americans were vaccinated more quickly.

1:07:31.560 --> 1:07:40.560
 We paid a lot of money. The one mistake that I think the federal government made was they were paying these guaranteed fortunes.

1:07:40.560 --> 1:07:49.560
 And they didn't require that the companies participate in a program to do global vaccinations.

1:07:49.560 --> 1:07:56.560
 So the companies doing their business model distributed the vaccines where they would make the most money.

1:07:56.560 --> 1:07:59.560
 And obviously they would make the most money in the first world.

1:07:59.560 --> 1:08:05.560
 And almost I think 85% of the vaccines early on went to the first world.

1:08:05.560 --> 1:08:10.560
 And very, very few vaccinations went to the third world.

1:08:10.560 --> 1:08:18.560
 So what happened is there was such a low vaccination rate in May of 2021.

1:08:18.560 --> 1:08:34.560
 There was all hands on deck cry for help from the World Trade Organization, the World Health Organization, the IMF and the World Bank made a plea for $50 billion.

1:08:34.560 --> 1:08:43.560
 So that we could get to 40% vaccination rate in the third world by the end of 2021.

1:08:43.560 --> 1:08:48.560
 And it was unrequited. Nobody answered.

1:08:48.560 --> 1:08:53.560
 And now Africa has about a 8.9% vaccination rate.

1:08:53.560 --> 1:08:56.560
 India is coming up, but it's been very low.

1:08:56.560 --> 1:09:04.560
 The problem with all this is I believe those mRNA vaccines are excellent vaccines.

1:09:04.560 --> 1:09:20.560
 But if we leave the third world unvaccinated, we're going to have a constant supply of variants of COVID that are going to come back into the United States and harm Americans exactly like Delta and Omicron have.

1:09:20.560 --> 1:09:27.560
 So we've made a great drug. It reduces the risk of mortality in Americans who get it by a lot.

1:09:27.560 --> 1:09:32.560
 But we're not doing what we need to do to protect Americans from Omicron.

1:09:32.560 --> 1:09:36.560
 You don't have to be an idealist and worry about global vaccine equity.

1:09:36.560 --> 1:09:46.560
 If you just ordinary selfish people like most of us are and you're worried about the health of Americans, you would ensure global vaccine distribution.

1:09:46.560 --> 1:09:48.560
 Let me just make one more point.

1:09:48.560 --> 1:10:03.560
 That $50 billion that was requested by the four organizations back in May of 2021, 32 billionaires made $50 billion from the vaccines at that point, took it into their private wealth.

1:10:03.560 --> 1:10:16.560
 So what had been taken, this enormous amount of money that had been taken into private wealth was enough to do what those organizations said needed to be done to prevent the sub variants from coming back and doing what they're doing.

1:10:16.560 --> 1:10:28.560
 The money was there. But how does the motivation, the money driven motivation of Big Pharma lead to that kind of allocation of vaccines?

1:10:28.560 --> 1:10:31.560
 Because they can make more money in the United States.

1:10:31.560 --> 1:10:34.560
 They're going to distribute their vaccines where they can make the most money.

1:10:34.560 --> 1:10:52.560
 Right. Is there a malevolent aspect to this where, boy, I don't like saying this, but that they don't see it as a huge problem, that variants will come back to the United States.

1:10:52.560 --> 1:11:07.560
 I think it's the issue we were talking about earlier on where they're in a different culture. And their culture is that their moral obligation, as Milton Friedman would say, is to maximize the profits that they return to shareholders.

1:11:07.560 --> 1:11:10.560
 Yeah. And don't think about the bigger picture.

1:11:10.560 --> 1:11:12.560
 The collateral damage. Don't think about the collateral damage.

1:11:12.560 --> 1:11:25.560
 And also kind of believe, convince yourself that if we give into this capitalist machine, in this very narrow sense of capitalism, that in the end they'll do the most good.

1:11:25.560 --> 1:11:32.560
 This kind of belief that if we just maximize profits, we'll do the most good.

1:11:32.560 --> 1:11:39.560
 Yeah. That's an orthodoxy of several decades ago. And I don't think people can really say that in good faith.

1:11:39.560 --> 1:11:50.560
 When you're talking about vaccinating the third world so we don't get hurt, it's a little bit hard to make the argument that the world's a better place because the profits of the investors went up.

1:11:50.560 --> 1:11:57.560
 Yeah. But at the same time, I think that's a belief you can hold.

1:11:57.560 --> 1:12:09.560
 I mean, I've interacted with a bunch of folks that kind of, I don't want to mischaracterize Ayn Rand. I respect a lot of people, but there's a belief that can take hold.

1:12:09.560 --> 1:12:15.560
 If I just focus on this particular maximization, it will do the most good for the world.

1:12:15.560 --> 1:12:30.560
 The problem is when you choose what to maximize and you put blinders on, it's too easy to start making gigantic mistakes that have a big negative impact on society. So it really matters what you're maximizing.

1:12:30.560 --> 1:12:43.560
 Right. And if we had a true democracy and everybody had one vote, everybody got decent information and had one vote, Ayn Rand's position would get some votes, but not many.

1:12:43.560 --> 1:12:48.560
 And it would be way outvoted by the common people.

1:12:48.560 --> 1:13:00.560
 Let me ask you about this very difficult topic I'm talking to Mark Zuckerberg of Metta.

1:13:00.560 --> 1:13:13.560
 The topic of censorship. I don't know if you've heard, but there's a guy named Robert Malone and Peter McCullough that were removed from many platforms for speaking about the COVID vaccine as being risky.

1:13:13.560 --> 1:13:17.560
 They were both on Joe Rogan's program.

1:13:17.560 --> 1:13:34.560
 What do you think about censorship in this space, in this difficult space where so much is controlled by, not controlled, but influenced by advertisements from Big Pharma.

1:13:34.560 --> 1:13:38.560
 And science can even be influenced by Big Pharma.

1:13:38.560 --> 1:14:01.560
 Where do you lean on this? Should we allow, should we lean towards freedom and just allow all the voices, even those that go against the scientific consensus, is that one way to fight the science that is funded by Big Pharma?

1:14:01.560 --> 1:14:14.560
 Or is that do more harm than good, having too many voices that are contending here? Should the ultimate battle be fought in the space of scientific publications?

1:14:14.560 --> 1:14:26.560
 And particularly in the era of COVID, where there are large public health ramifications to this public discourse, the ante is way up.

1:14:26.560 --> 1:14:37.560
 So I don't have a simple answer to that. I think everyone's allowed their own opinion. I don't think everyone's allowed their own scientific facts.

1:14:37.560 --> 1:14:53.560
 And how we develop a mechanism that's other than an open internet where whoever is shouting the loudest gets the most clicks and rage creates value on the internet.

1:14:53.560 --> 1:15:01.560
 I think that's not a good mechanism for working this out. And I don't think we have one. I don't have a solution to this.

1:15:01.560 --> 1:15:18.560
 I mean, ideally, if we had a philosopher king, we could have a panel of people who were not conflicted by rigid opinions decide on what the boundaries of public discourse might be.

1:15:18.560 --> 1:15:33.560
 I don't think it should be fully open. I don't think people who are making, who are committed to an anti vaccine position and will tailor their interpretation of complex scientific data to support their opinion.

1:15:33.560 --> 1:15:40.560
 I think that can be harmful. Constraining their speech can be harmful as well. So I don't have an answer here.

1:15:40.560 --> 1:15:57.560
 But yeah, I tend to believe that it's more dangerous to censor anti vax messages. The way to defeat anti vax messages is by being great communicators, by being great scientific communicators.

1:15:57.560 --> 1:16:13.560
 So it's not that we need to censor the things we don't like. We need to be better communicating the things we do like or the things that we do believe represent the deep scientific truth.

1:16:13.560 --> 1:16:27.560
 Because I think if you censor, you get worse at doing science and you give the wrong people power.

1:16:27.560 --> 1:16:46.560
 So I tend to believe that you should give power to the individual scientists and also give them the responsibility of being better educators, communicators, expressors of scientific ideas, put pressure on them to release data, to release that data in a way that's easily consumable.

1:16:46.560 --> 1:17:02.560
 Not just like a very difficult to understand, but in a way that can be understood by a large number of people. So the battle should be fought in the open space of ideas versus in the quiet space of journals.

1:17:02.560 --> 1:17:18.560
 I think we no longer have that comfort, especially at the highest of stakes. So this kind of idea that a couple of peer reviewers decide the fate of billions doesn't seem to be sustainable.

1:17:18.560 --> 1:17:41.560
 Especially given a very real observation now that the reason Robert Malone has a large following is there's a deep distrust of institutions, deep distrust of scientists, of science as an institution, of power centers, of companies, of everything.

1:17:41.560 --> 1:17:58.560
 Perhaps rightfully so. But the way to defend against that is not for the powerful to build a bigger wall. It's for the powerful to be authentic and maybe do a lot of them to get fired and for new minds, for new fresh scientists,

1:17:58.560 --> 1:18:16.560
 ones who are more authentic, more real, better communicators to step up. So I fear censorship because it feels like censorship is an even harder job to do it well than being good communicators.

1:18:16.560 --> 1:18:28.560
 And it seems like it's always the C students that end up doing the censorship. It's always the incompetent people and not just the incompetent, but the biggest whiners.

1:18:28.560 --> 1:18:47.560
 So like what happens is the people that get the most emotional and the most outrage will drive the censorship. And it doesn't seem like reason drives the censorship. That's just objectively observing how censorship seems to work in this current.

1:18:47.560 --> 1:18:58.560
 So there's so many forms of censorship. You look at the Soviet Union with a propaganda or Nazi Germany is a very different level of censorship. People tend to conflate all of these things together.

1:18:58.560 --> 1:19:18.560
 You know, social media trying desperately to have trillions or hundreds of billions of exchanges a day and like try to make sure that their platform is has some semblance of like, quote, healthy conversations like people just don't go insane.

1:19:18.560 --> 1:19:34.560
 They actually like using the platform and they they censor based on that. That's a different level of censorship. But even there, you can really run afoul of the people they get the the the whiny C students controlling too much of the censorship.

1:19:34.560 --> 1:19:46.560
 I believe that you should you should actually put the responsibility on the self proclaimed holders of truth, aka scientists at being better communicators.

1:19:46.560 --> 1:20:02.560
 I agree with that. I'm not advocating for any kind of censorship. But Marshall McLuhan was very influential when I was in college and his that meme, the medium is the message.

1:20:02.560 --> 1:20:27.560
 It's a little bit hard to understand when you're comparing radio to TV and saying radio is hotter or TV is hotter or something. But we now have the medium is the message in a way that we've never seen. We've never imagined before where rage and anger and polarization are what drives the traffic on the internet.

1:20:27.560 --> 1:20:37.560
 And we don't know. It's a question of building the commons. Ideally, I don't know how to get there. So I'm not pretending to have a solution.

1:20:37.560 --> 1:21:00.560
 But the commons of discourse about this particular issue about vaccines is has been largely destroyed by the edges by the drug companies and the advocates on the one side and the people who just criticize and think that even though the data are flawed that there's no way vaccines can be beneficial.

1:21:00.560 --> 1:21:21.560
 And to have those people screaming at each other does nothing to improve the health of the 95% of the people in the middle who want to know what the rational way to go forward is and protect their families from COVID and live a good life and be able to participate in the economy.

1:21:21.560 --> 1:21:25.560
 And that's the problem. I don't have a solution.

1:21:25.560 --> 1:21:38.560
 Well, there's a difficult problem for Spotify and YouTube. I don't know if you heard this is a thing that Joe Rogan is currently going through as a platform, whether to censor the conversation that, for example, Joe was having.

1:21:38.560 --> 1:21:53.560
 So I don't know if you heard, but Neil Young and other musicians have kind of spoke out and saying they're going to leave the platform because Joe Rogan is allowed to be on this platform having these kinds of conversations with the likes of Robert Malone.

1:21:53.560 --> 1:22:02.560
 And it's clear to me that Spotify and YouTube are being significantly influenced by these extreme voices I can mention on each side.

1:22:02.560 --> 1:22:15.560
 And it's also clear to me that Facebook is the same and it was going back and forth. In fact, that's why Facebook has been oscillating on the censorship is like one group gets louder than the other, depending on whether it's an election year.

1:22:15.560 --> 1:22:38.560
 There's several things to say here. So one, it does seem I think you put it really well. It would be amazing if these platforms could find mechanisms to listen to the center to the to the big center that's actually going to be affected by the results of the our pursuit of scientific truth.

1:22:38.560 --> 1:22:53.560
 Right. And listen to those voices. I also believe that most people are intelligent enough to process information and to make up their own minds. Like they're not in terms of this.

1:22:53.560 --> 1:23:14.560
 It's complicated, of course, because we've just been talking about advertising and how people can be influenced. But I feel like if you have raw, long form podcasts or programs where people express their mind and express their argument in full, I think people can hear it to make up their own mind.

1:23:14.560 --> 1:23:29.560
 And if those arguments have a platform on which they can live, then other people could provide better arguments if they disagree with it. And now we as human beings as rational as intelligent human beings can look at both and make up our minds.

1:23:29.560 --> 1:23:47.560
 And that's where social media can be very good at like this collective intelligence. We together listen to all of these voices and make up our mind, humble ourselves actually often. You know, you think you know, like you're an expert, say you have a PhD in a certain thing.

1:23:47.560 --> 1:24:06.560
 Say there's this confidence that comes with that. And the collective intelligence uncensored allows you to humble yourself eventually. Like as you discovery, you know, all it takes is a few times, you know, looking back five years later, realizing I was wrong.

1:24:06.560 --> 1:24:30.560
 And that's really healthy for scientists. That's really healthy for anybody to go through and only through having that open discourse. Can you really have that? That said, Spotify also, just like Pfizer is a company, which is why this podcast, I don't know if you know what RSS feeds are, but podcasts can't be censored.

1:24:30.560 --> 1:24:40.560
 So Joe is in the unfortunate position. He only lives on Spotify. So Spotify has been actually very good at saying we're staying out of it for now.

1:24:40.560 --> 1:24:55.560
 But RSS, this is pirate radio. Nobody can censor. It's the internet. So financially, in terms of platforms, this cannot be censored, which is why podcasts are really beautiful.

1:24:55.560 --> 1:25:11.560
 And so if Spotify or YouTube wants to be the host of podcasts, I think where they flourish is free expression, no matter how crazy.

1:25:11.560 --> 1:25:36.560
 Yes. But I do want to push back a little bit on what you're saying. I have anti facts friends who I love. They're dear cherished friends. And they'll send me stuff. And it'll take me an hour to go through what they sent to see if it is credible.

1:25:36.560 --> 1:25:57.560
 And usually it's not. It's not a random sample of the anti facts argument. I'm not saying I can disprove the anti facts argument. But I am saying that it's almost like we were talking about how medical science clinical trials, the presentation of clinical trials to physicians could be improved.

1:25:57.560 --> 1:26:15.560
 And the first thing we came up with is to have pre publication transparency in the peer review process. So bad information, biased information doesn't get out as if it's legitimate. And you can't put it back, recapture it once it gets out.

1:26:15.560 --> 1:26:33.560
 So I think there's an element of that in the arguments that are going on about vaccines and they're on both sides. But I think the anti facts side puts out more units of information claiming to show that the vaccines don't work.

1:26:33.560 --> 1:26:52.560
 And I guess in an ideal situation, there would be real time fact checking by independent people, not to censor it, but to just say that study was set up to do this. And this is what the conclusions were. So the way it was stated is on one side of this argument.

1:26:52.560 --> 1:27:05.560
 And that's what I'm arguing. I agree with you. What I'm arguing is that this big network of humans that we have that is the collective intelligence can do that real time. If you allow it to if you encourage people to do it.

1:27:05.560 --> 1:27:22.560
 And the scientists, as opposed to listen, I interact with a lot of colleagues, a lot of friends, their scientists, they roll their eyes, their responses like, like they don't want to interact with this. But that's just not the right response.

1:27:22.560 --> 1:27:38.560
 When a huge number of people believe this, it is your job as communicators to defend your ideas. It is no longer the case that you go to a conference and defend your ideas to two other nerves that have been working on the same problem forever.

1:27:38.560 --> 1:27:52.560
 I mean, sure, you can do that, but then you're rejecting the responsibility you have explicitly or implicitly accepted when you go into this field, that you will defend the ideas of truth.

1:27:52.560 --> 1:27:58.560
 And the way to defend them is in the open battlefield of ideas and become a better communicator.

1:27:58.560 --> 1:28:14.560
 And I believe that when you have a lot, you said you invested one or two hours in this particular, but that's the little ants interacting at scale. I think that allows us to progress towards truth, at least, you know, at least I hope so.

1:28:14.560 --> 1:28:25.560
 I think you're an optimist. I want to work with you a little bit on this. Let's say a person like Joe Rogan, who, by the way, had me on his podcast.

1:28:25.560 --> 1:28:28.560
 It's an amazing conversation. I really enjoyed it.

1:28:28.560 --> 1:28:32.560
 Well, thank you. I did too. And I didn't know Joe. I didn't know much about his podcast.

1:28:32.560 --> 1:28:35.560
 And he pushed back on Joe a bunch, which is great.

1:28:35.560 --> 1:28:46.560
 And he was a gentleman. And we had it out. In fact, he put one clip. At one point, he said something that was a little bit wrong and I corrected him. And he had the guy who...

1:28:46.560 --> 1:28:47.560
 Jamie.

1:28:47.560 --> 1:28:56.560
 He had Jamie check it and was very forthright in saying, you know, John got it right here. We got to modify this. In any event. In any event.

1:28:56.560 --> 1:28:57.560
 You got him.

1:28:57.560 --> 1:29:00.560
 Well, I wasn't trying to get him.

1:29:00.560 --> 1:29:06.560
 No, no, no. You totally was. There's a beautiful exchange. There's so much respect in the room, pushing back and forth. It was great.

1:29:06.560 --> 1:29:16.560
 Yeah. So I respect him. And I think when he has somebody on who's a died in the wool anti faxer,

1:29:16.560 --> 1:29:27.560
 the question is, how can you balance if it needs balance in real time? I'm not talking about afterwards. I'm talking in real time.

1:29:27.560 --> 1:29:37.560
 Maybe you record... Well, he does record it, obviously. But maybe when there's a statement made that is made as if it's fact based,

1:29:37.560 --> 1:29:53.560
 maybe that statement should be checked by some folks who... Imaginary folks who are trustworthy. And in real time, as that discussion is being played on the podcast,

1:29:53.560 --> 1:29:58.560
 to show what independent experts say about that claim.

1:29:58.560 --> 1:30:07.560
 That's really interesting idea. By the way, for some reason, this idea popped into my head now is... I think real time is very difficult. And it's not difficult,

1:30:07.560 --> 1:30:14.560
 but it kind of ruins the conversation because you want the idea to breathe. I think what's very possible is before it's published,

1:30:14.560 --> 1:30:24.560
 it's the pre publication, before it's published, you let a bunch of people review it and they can add their voices in post, before it's published.

1:30:24.560 --> 1:30:36.560
 They can add arguments, arguments against certain parts. That's very interesting. As one podcast, publish addendums.

1:30:36.560 --> 1:30:44.560
 Publish the peer review together with the publication. That's very interesting. I might actually do that. That's really interesting.

1:30:44.560 --> 1:30:54.560
 Because I've been doing more debates at the same time, have multiple people, which has a different dynamic because both people...

1:30:54.560 --> 1:31:05.560
 It's really nice to have the time to pause by yourself, to fact check, to look at the study that was mentioned, to understand what's going on.

1:31:05.560 --> 1:31:14.560
 So the peer review process, to have a little bit of time. That's really interesting. I'd like to try that.

1:31:14.560 --> 1:31:25.560
 To agree with you on some point in terms of anti vax, I've been fascinated by listening to arguments from this community of folks that's been quite large called flat earthers.

1:31:25.560 --> 1:31:39.560
 The people that believe the earth is flat. I don't know if you've ever listened to them or read their arguments, but it's fascinating how consistent and convincing it all sounds when you just kind of take it in.

1:31:39.560 --> 1:32:04.560
 Just take it in like listening normally. It's all very logical. If you don't think very... Well, no. The reality is, at the very basic human level with our limited cognitive capabilities, the earth is pretty flat when you go outside and you look flat.

1:32:04.560 --> 1:32:16.560
 So when you use common sense reasoning, it's very easy to play to that to convince you that the earth is flat, plus there's powerful organizations that want to manipulate you and so on.

1:32:16.560 --> 1:32:25.560
 But then there's the whole progress of science and physics of the past, but that's difficult to integrate into your thought process.

1:32:25.560 --> 1:32:41.560
 So it's very true that the people should listen to flat earthers because it was very revealing to me how easy it is to be convinced of basically anything by charismatic arguments.

1:32:41.560 --> 1:32:52.560
 Right. And if we're arguing about whether the earth is flat or not, as long as we're not navigating airplanes and doing other kinds of things, trying to get satellites to do transmission,

1:32:52.560 --> 1:33:05.560
 it's not that important, what I believe. But if we're arguing about how we approach the worst public health crisis in, I don't know how long, I think we're getting worse than the Spanish flu now.

1:33:05.560 --> 1:33:12.560
 I don't know what the total global deaths with Spanish flu were, but in the United States, we certainly have more deaths than we had from Spanish flu.

1:33:12.560 --> 1:33:22.560
 It's the economic pain and suffering. Yes. Yes. And the damage to the kids in school and so forth. We got a problem and it's not going away, unfortunately.

1:33:22.560 --> 1:33:33.560
 So when we get a problem like that, it's not just an interesting bar room conversation about whether the earth is flat. There are millions of lives involved.

1:33:33.560 --> 1:33:50.560
 Let me ask you yet another question that issue I raised with Pfizer CO Albert Burla. It's the question of revolving doors, that there seems to be a revolving door between Pfizer, FDA and CDC.

1:33:50.560 --> 1:33:59.560
 People that have worked at the FDA now work at Pfizer and vice versa, including the CDC and so on.

1:33:59.560 --> 1:34:10.560
 What do you think about that? So first of all, his response once again is there's rules, very strict rules and we follow them. Do you think that's a problem?

1:34:10.560 --> 1:34:18.560
 And also, maybe this is a good time to talk about this Pfizer play by the rules.

1:34:18.560 --> 1:34:20.560
 One at a time. One at a time.

1:34:20.560 --> 1:34:24.560
 Okay. And this isn't even about Pfizer, but it's an answer to the question.

1:34:24.560 --> 1:34:30.560
 So there's this drug Agihilm that was approved by the FDA maybe six months ago.

1:34:30.560 --> 1:34:37.560
 It's a drug to prevent the progression of low grade Alzheimer's disease.

1:34:37.560 --> 1:34:51.560
 The target for drug development for Alzheimer's disease has been the amyloid, reducing the amyloid plaques in the brain, which correlate with the progression of Alzheimer's.

1:34:51.560 --> 1:35:00.560
 And Biogen showed that its drug Agihilm reduces amyloid plaques in the brain.

1:35:00.560 --> 1:35:09.560
 They did two clinical trials to determine the clinical efficacy and they found that neither trial showed a meaningful benefit.

1:35:09.560 --> 1:35:21.560
 And in those two trials, 33% more people in the Agihilm group develop symptomatic brain swelling and bleeding than people in the placebo group.

1:35:21.560 --> 1:35:34.560
 There was an advisory committee convene to debate the and determine how they felt about the approvability of Agihilm, given those facts.

1:35:34.560 --> 1:35:40.560
 And those facts aren't in dispute. They're in biogen slides as well as FDA documents.

1:35:40.560 --> 1:35:49.560
 The advisory committee voted 10 against approval and one abstain.

1:35:49.560 --> 1:35:55.560
 So that's essentially universal, unanimous vote against approving Agihilm.

1:35:55.560 --> 1:36:02.560
 Now, the advisory committees have been pretty much cleansed of financial conflicts of interest.

1:36:02.560 --> 1:36:08.560
 So this advisory committee votes 10, no, one abstention.

1:36:08.560 --> 1:36:16.560
 And the FDA overrules the unanimous opinion of its advisory committee and approves the drug.

1:36:16.560 --> 1:36:20.560
 Three of the members of the advisory committee resign.

1:36:20.560 --> 1:36:30.560
 They say, we're not going to depart. If the FDA is not going to listen to a unanimous vote against approving this drug, which shows more harm than benefit, undisputed,

1:36:30.560 --> 1:36:33.560
 we're not going to participate in this.

1:36:33.560 --> 1:36:42.560
 And the argument against approval is that the surrogate endpoint, the reduction of amyloid, the progression of amyloid plaques,

1:36:42.560 --> 1:36:47.560
 is known by the FDA not to be a valid clinical indicator.

1:36:47.560 --> 1:36:53.560
 It doesn't correlate. 27 studies have shown it doesn't correlate with clinical progression.

1:36:53.560 --> 1:37:01.560
 Corrupting the amyloid plaques doesn't mean that your Alzheimer's doesn't get worse.

1:37:01.560 --> 1:37:11.560
 So it seems like it's a slam dunk and the FDA made a mistake and they should do whatever they do to protect their bureaucratic reputation.

1:37:11.560 --> 1:37:24.560
 So the head of the Bureau of the FDA, the Center for Drug Evaluation and Research that approves new drugs, who had spent 16 years as an executive in the pharmaceutical industry,

1:37:24.560 --> 1:37:40.560
 issued a statement and said, what we should do in this situation is to loosen the prohibition of financial ties of interest with the drug companies so we get less emotional responses.

1:37:40.560 --> 1:37:45.560
 Said this, it's in print.

1:37:45.560 --> 1:37:50.560
 People are just too emotional about this.

1:37:50.560 --> 1:37:57.560
 People were just too emotional, the 10 people who voted against it and the no people who voted for it, it's all too emotional.

1:37:57.560 --> 1:38:01.560
 So this gets back, this is a long answer to your short question.

1:38:01.560 --> 1:38:14.560
 I think this is a wonderful window into the thinking of the FDA that financial conflicts of interest don't matter in a situation when I think it's obvious that they would matter.

1:38:14.560 --> 1:38:17.560
 But there's not a direct financial conflict of interest.

1:38:17.560 --> 1:38:31.560
 It's kind of like Albert said, there's rules. I mean, you're not allowed to have direct financial conflict of interest. It's indirect.

1:38:31.560 --> 1:38:46.560
 Right, but what I'm saying is, I'm not denying what he said is true, but the FDA, a high official in the FDA is saying that we need to allow conflicts of interest in our advisory committee meetings.

1:38:46.560 --> 1:38:52.560
 And that she wants to change the rules.

1:38:52.560 --> 1:39:02.560
 So Albert Borla would still be playing by the rules, but it just shows how one sided the thinking here is.

1:39:02.560 --> 1:39:09.560
 But you think that's influenced by the fact that there were pharmaceutical executives working at the FDA and vice versa.

1:39:09.560 --> 1:39:11.560
 And they think that's a great idea.

1:39:11.560 --> 1:39:16.560
 Who gets to fix this? Do you think it should be just banned?

1:39:16.560 --> 1:39:18.560
 I don't know. Two separate questions.

1:39:18.560 --> 1:39:24.560
 One is, should the officials at the FDA come from pharma and vice versa?

1:39:24.560 --> 1:39:26.560
 That's one question.

1:39:26.560 --> 1:39:32.560
 And the other question is, should advisory committee members be allowed to have financial conflicts of interest?

1:39:32.560 --> 1:39:41.560
 I think in my opinion, and people might say I'm biased, I think advisory committee people should not have conflicts of interest.

1:39:41.560 --> 1:39:44.560
 I think their only interest ought to be the public interest.

1:39:44.560 --> 1:39:48.560
 And that was true from my understanding of the situation.

1:39:48.560 --> 1:39:50.560
 It's the afterward in my book.

1:39:50.560 --> 1:39:53.560
 I spent some time studying it about Agilom.

1:39:53.560 --> 1:39:57.560
 I think it's a slam dunk that there ought to be no conflicts of interest.

1:39:57.560 --> 1:40:06.560
 Now, the head of Cedar, Center for Drug Evaluation Research, thinks that that's going to give you a biased result because we don't have company influence.

1:40:06.560 --> 1:40:13.560
 And that, I think, shows how biased their thinking is.

1:40:13.560 --> 1:40:18.560
 That not having company influence is a bias.

1:40:18.560 --> 1:40:20.560
 Let me try to load that in.

1:40:20.560 --> 1:40:27.560
 I'm trying to empathize with the belief that companies should have a voice at the table.

1:40:27.560 --> 1:40:29.560
 I mean, yeah, it's part of the game.

1:40:29.560 --> 1:40:33.560
 They've convinced themselves that this is how it should be played.

1:40:33.560 --> 1:40:35.560
 But they have a voice at the table.

1:40:35.560 --> 1:40:37.560
 They've designed the studies.

1:40:37.560 --> 1:40:38.560
 That's their voice.

1:40:38.560 --> 1:40:40.560
 They analyze the data.

1:40:40.560 --> 1:40:42.560
 I mean, what bigger voice do you deserve?

1:40:42.560 --> 1:40:50.560
 But I do also think on the more challenging question, I do think that there should be a ban.

1:40:50.560 --> 1:41:00.560
 If you work at a pharmaceutical company, you should not be allowed to work at any regulatory agency.

1:41:00.560 --> 1:41:01.560
 Yes.

1:41:01.560 --> 1:41:02.560
 You should not.

1:41:02.560 --> 1:41:06.560
 I mean, going back and forth, even if it's 30 years later.

1:41:06.560 --> 1:41:07.560
 I agree.

1:41:07.560 --> 1:41:10.560
 And I have another nomination for a ban.

1:41:10.560 --> 1:41:17.560
 We're in this crazy situation where Medicare is not allowed to negotiate the price of drugs with the drug companies.

1:41:17.560 --> 1:41:20.560
 So the drug companies get a patent on a new drug.

1:41:20.560 --> 1:41:23.560
 Unlike every other developed country, they can charge whatever they want.

1:41:23.560 --> 1:41:29.560
 So they have a monopoly on a utility because no one else can make the drug.

1:41:29.560 --> 1:41:31.560
 Charge whatever they want and Medicare has to pay for it.

1:41:31.560 --> 1:41:36.560
 And you say, how did we get in this crazy situation?

1:41:36.560 --> 1:41:52.560
 So how we got here is that in 2003, when Medicare Part D was passed, Billy Towson was head of the Ways and Means Committee in the House, played a key role in ushering this through with the nonnegotiation clause of it.

1:41:52.560 --> 1:41:57.560
 And after it was passed, Billy Towson did not finish out his term in Congress.

1:41:57.560 --> 1:42:02.560
 He went to pharma for a $2 million a year job.

1:42:02.560 --> 1:42:05.560
 This is incredible.

1:42:05.560 --> 1:42:09.560
 I think that a ban on that would be a good idea.

1:42:09.560 --> 1:42:13.560
 I spoke with Francis Collins, head of the NIH on this podcast.

1:42:13.560 --> 1:42:21.560
 He and NIH have a lot of power over funding in science.

1:42:21.560 --> 1:42:23.560
 What are they doing right?

1:42:23.560 --> 1:42:28.560
 What are they doing wrong in this interplay with big pharma?

1:42:28.560 --> 1:42:31.560
 How connected are they?

1:42:31.560 --> 1:42:33.560
 Again, returning to the question.

1:42:33.560 --> 1:42:35.560
 What are they doing right?

1:42:35.560 --> 1:42:37.560
 What are they doing wrong in your view?

1:42:37.560 --> 1:42:44.560
 So my knowledge of the NIH is not as granular as my knowledge of pharma.

1:42:44.560 --> 1:42:53.560
 That said, in broad brushstrokes, the NIH is doing the infrastructure work for all drug development.

1:42:53.560 --> 1:43:01.560
 I think they've participated in 100% of the drugs that have been approved by the FDA over the past 10 years or so.

1:43:01.560 --> 1:43:03.560
 They've done infrastructure work.

1:43:03.560 --> 1:43:21.560
 And what they do is not work on particular drugs, but they develop work on drug targets, on targets in the human body that can be affected by drugs and might be beneficial to turn on or off.

1:43:21.560 --> 1:43:36.560
 And then the drug companies, when they find a target that is mutable and potentially beneficial, then the drug companies can take the research and choose to invest in the development of the specific drug.

1:43:36.560 --> 1:43:38.560
 That's our model.

1:43:38.560 --> 1:43:54.560
 So 96% of the research that's done in clinical trials in the United States is about drugs and devices, and only a fraction of the 4% that's left over is about preventive medicine and how to make Americans healthier.

1:43:54.560 --> 1:44:15.560
 I think, again, from the satellite view, the NIH is investing more in science that can lead to commercial development rather than, as you said at the beginning of the podcast, there's no big fitness and lifestyle industry that can counter pharma.

1:44:15.560 --> 1:44:30.560
 So I think at the NIH level, that countering can be done. And the Diabetes Prevention Program study that we talked about before where lifestyle was part of a randomized trial and was shown to be more effective than metformin at preventing the development of diabetes.

1:44:30.560 --> 1:44:37.560
 That is absolute proof positive that investing in that kind of science can produce good results.

1:44:37.560 --> 1:44:49.560
 So I think that we're aimed at drug development and what we ought to be aimed at is an epidemiological approach to improving the health of all Americans.

1:44:49.560 --> 1:44:58.560
 We rank 68th in the world in healthy life expectancy, despite spending an extra trillion and a half dollars a year.

1:44:58.560 --> 1:45:15.560
 And I believe strongly that the reason why we've gotten in this crazy position is because the knowledge that we're producing is about new drugs and devices, and it's not about improving population health.

1:45:15.560 --> 1:45:22.560
 In this problem, the NIH is the perfect institution to play a role in rebalancing our research agenda.

1:45:22.560 --> 1:45:40.560
 And some of that is on the leadership side with Francis Collins and Anthony Fauci, not just speaking about basically everything that just leads to drug development, vaccine development, but also speaking about healthy lifestyles and speaking about health, not just sickness.

1:45:40.560 --> 1:45:53.560
 Yes, and investing, investing in health.

1:45:53.560 --> 1:46:13.560
 And that leads to you getting props for investing in health and then you can invest in health more and more and that communicates, I mean, everything that Anthony Fauci says or Francis Collins says has an impact on scientists.

1:46:13.560 --> 1:46:26.560
 It's the sad thing about leaders, forgive me for saying the word, but mediocre leaders, is they don't see themselves as part of a game.

1:46:26.560 --> 1:46:32.560
 They don't see the momentum. It's like a fish in the water. They don't see the water.

1:46:32.560 --> 1:46:45.560
 Great leaders stand up and reverse the direction of how things are going and I actually put a lot of responsibility. Some people say too much, but whatever, I think leaders carry the responsibility.

1:46:45.560 --> 1:47:05.560
 I put a lot of responsibility on Anthony Fauci and Francis Collins for not actually speaking a lot more about health, not in bigger, inspiring people in the power and the trustworthiness of science.

1:47:05.560 --> 1:47:11.560
 You know, that's on the shoulders of Anthony Fauci.

1:47:11.560 --> 1:47:15.560
 I'm going to abstain from that because I'm not expert enough.

1:47:15.560 --> 1:47:17.560
 Neither am I, but I'm opinionated.

1:47:17.560 --> 1:47:20.560
 I am too, but not on camera.

1:47:20.560 --> 1:47:21.560
 Yes.

1:47:21.560 --> 1:47:37.560
 No, but seriously, the problem is pretty simple, that we're investing 96% of our clinical funding of clinical research and drugs and devices and 80% of our health is determined by how we live our lives.

1:47:37.560 --> 1:47:38.560
 Yes.

1:47:38.560 --> 1:47:49.560
 And this is ridiculous where the United States is going further and further behind the other wealthy countries in terms of our health.

1:47:49.560 --> 1:47:59.560
 We ranked 38th in healthy life expectancy in 2000 and now we're spending a trillion and a half dollars extra and we ranked 68th. We've gone down.

1:47:59.560 --> 1:48:09.560
 You have this excellent, there's a few charts that I'll overlay that tell the story in really powerful ways.

1:48:09.560 --> 1:48:26.560
 So one is the health care spending as percentage of GDP that on the X axis is years and the Y axis is percentage and the United States as compared to other countries on average has been much larger and growing.

1:48:26.560 --> 1:48:27.560
 Right.

1:48:27.560 --> 1:48:35.560
 We're spending 7% more of our GDP, 17.7% versus 10.7% on health care.

1:48:35.560 --> 1:48:40.560
 7% and I think GDP is the fairest way to compare health care spending.

1:48:40.560 --> 1:48:48.560
 Per person in dollars, we're spending even, the difference is even greater, but other costs vary with GDP.

1:48:48.560 --> 1:48:51.560
 So let's stick with the conservative way to do it.

1:48:51.560 --> 1:49:04.560
 17.7% or 18% of GDP, 18% of GDP spent on health care, 7% higher than the comparable country average.

1:49:04.560 --> 1:49:05.560
 Right.

1:49:05.560 --> 1:49:09.560
 17.7% versus 10.7%, 7% higher.

1:49:09.560 --> 1:49:10.560
 Right.

1:49:10.560 --> 1:49:18.560
 And 7% of $23 trillion GDP is more than $1.5 trillion a year in excess.

1:49:18.560 --> 1:49:24.560
 And then you have another chart that shows health care system performance compared to spending.

1:49:24.560 --> 1:49:29.560
 And there's a cloud, a point cloud of different countries.

1:49:29.560 --> 1:49:40.560
 The X axis being health care spending is a percentage of GDP, which we just talked about that US is, you know, 7% higher than everyone, the average.

1:49:40.560 --> 1:49:43.560
 And then on the Y axis is performance.

1:49:43.560 --> 1:49:47.560
 So X axis spending, Y axis performance.

1:49:47.560 --> 1:49:59.560
 And there's a point cloud, we'll overlay this if you're watching on YouTube, of a bunch of countries that have high performance for what they're spending.

1:49:59.560 --> 1:50:10.560
 And then US is all alone on the right bottom side of the chart where it's low performance and high spending.

1:50:10.560 --> 1:50:12.560
 Correct.

1:50:12.560 --> 1:50:22.560
 So this is a system that is abiding by spending that is directed by the most profitable ways to deliver health care.

1:50:22.560 --> 1:50:31.560
 So you put that in the hands of big pharma, is you maximize for profit, you're going to decrease performance and increase spending?

1:50:31.560 --> 1:50:32.560
 Yes.

1:50:32.560 --> 1:50:37.560
 But I want to qualify that and say it's not all big pharma's fault.

1:50:37.560 --> 1:50:44.560
 They're not responsible for all the problems in our health care system, they're not responsible for the administrative costs, for example.

1:50:44.560 --> 1:50:51.560
 But they are the largest component of the rising, our rising health care costs.

1:50:51.560 --> 1:50:54.560
 And it has to do with this knowledge issue.

1:50:54.560 --> 1:51:05.560
 Controlling the knowledge that doctors have makes it so that doctors can live with this situation believing that it's optimal when it's a wreck.

1:51:05.560 --> 1:51:18.560
 Let me ask you the big, so as a physician, so everything you've seen, we've talked about 80% of the impact on health is lifestyle.

1:51:18.560 --> 1:51:20.560
 How do we live longer?

1:51:20.560 --> 1:51:22.560
 What advice would you give to general people?

1:51:22.560 --> 1:51:30.560
 What space of ideas result in living longer and higher quality lives?

1:51:30.560 --> 1:51:31.560
 Right.

1:51:31.560 --> 1:51:34.560
 This is a very simple question to answer.

1:51:34.560 --> 1:51:40.560
 Exercise for at least a half hour, at least five times a week.

1:51:40.560 --> 1:51:42.560
 Number one.

1:51:42.560 --> 1:51:45.560
 Number two, don't smoke.

1:51:45.560 --> 1:51:49.560
 Number three, maintain a reasonably healthy body weight.

1:51:49.560 --> 1:51:54.560
 Some people argue that being lower than a BMI of 25 is healthy.

1:51:54.560 --> 1:52:01.560
 I think that may be true, but I think getting above 30 is unhealthy and that ought to be.

1:52:01.560 --> 1:52:09.560
 Now, that's largely impacted by socioeconomic status, and we don't want to blame the victims here.

1:52:09.560 --> 1:52:22.560
 So we've got to understand that when we talk about all of these things, not cigarettes, but exercise and a good diet and maintaining a healthy body weight,

1:52:22.560 --> 1:52:33.560
 we have to include in doing those things the impediments to people of lower socioeconomic status being able to make those changes.

1:52:33.560 --> 1:52:43.560
 We've got to understand that personal responsibility accounts for some of this, but also social circumstances accounts for some of it.

1:52:43.560 --> 1:52:53.560
 And back to your fishbowl analogy, if you're swimming in a fishbowl, if you live in a fish tank that's not being properly maintained,

1:52:53.560 --> 1:52:57.560
 the approach wouldn't be to treat individual sick fish.

1:52:57.560 --> 1:53:08.560
 It would be to fix your fish tank to get the bacteria out of it and whatever bad stuff is in there and make your fish tank healthier.

1:53:08.560 --> 1:53:13.560
 Well, we invest far less than the other wealthy countries do.

1:53:13.560 --> 1:53:14.560
 We're flipped.

1:53:14.560 --> 1:53:21.560
 We have the mirror image in the spending on social determinants of health and medical determinants of health.

1:53:21.560 --> 1:53:23.560
 We have exactly the wrong order.

1:53:23.560 --> 1:53:31.560
 And not only does that choke off social determinants of health, which are very important, but actually just the ratio.

1:53:31.560 --> 1:53:41.560
 If we raise the social spending and raise our medical spending in proportion, it's the ratio of social spending to medical spending.

1:53:41.560 --> 1:53:42.560
 That's the problem.

1:53:42.560 --> 1:53:44.560
 And why do we do that?

1:53:44.560 --> 1:53:57.560
 Well, the answer is perfectly obvious that the way to transfer money from working Americans to investors is through the biomedical model, not through the social health model.

1:53:57.560 --> 1:54:01.560
 And that's the problem.

1:54:01.560 --> 1:54:07.560
 I'd like to discuss this because the market isn't going to get us to a reasonable allocation.

1:54:07.560 --> 1:54:25.560
 All the other wealthy countries that are so much healthier than we are and spending so much less than we are have some form of government intervention in the quality of the health data that's available in the budgeting of health and social factors.

1:54:25.560 --> 1:54:30.560
 And we don't work kind of the Wild West and we let the market determine those allocations.

1:54:30.560 --> 1:54:34.560
 And it's an awful failure.

1:54:34.560 --> 1:54:36.560
 It's a horrendous failure.

1:54:36.560 --> 1:54:51.560
 So one argument against government or sorry, an alternative to the government intervention is the market can work better if the citizenry has better information.

1:54:51.560 --> 1:55:03.560
 So one argument is that communicators like podcasts and so on, but other channels of communication will be the way to fight Big Pharma.

1:55:03.560 --> 1:55:20.560
 Your book is the way to, by providing information, the alternative to the government intervention on every aspect of this, including communication with the doctors is to provide them other information and not allow the market to provide that information by basically

1:55:20.560 --> 1:55:32.560
 making it exciting to buy books, to make better and better communicators on Twitter, through books, through op eds, through podcasts, through so on.

1:55:32.560 --> 1:55:39.560
 So basically, because there's a lot of incentive to communicate against the messages of Big Pharma.

1:55:39.560 --> 1:55:50.560
 There's incentive because people want to understand what's good for their lives and they're willing to listen to charismatic people that are able to clearly explain what is good for them.

1:55:50.560 --> 1:55:51.560
 And they do.

1:55:51.560 --> 1:55:59.560
 And more than 80% of people think that drugs cost too much and the drug industry is too interested in profits.

1:55:59.560 --> 1:56:01.560
 But they still get influenced.

1:56:01.560 --> 1:56:05.560
 You can't get the vote through Congress.

1:56:05.560 --> 1:56:16.560
 Democrats and Republicans alike are taking money from Congress and somehow it just doesn't work out that these even small changes.

1:56:16.560 --> 1:56:28.560
 I mean, the pared down part of Medicare, the plan for increasing Medicare negotiation drug costs in Build Back Better.

1:56:28.560 --> 1:56:41.560
 It's literally going to reduce the number of new drugs that are beneficial, uniquely beneficial by about one new drug or two new drugs over 30 years.

1:56:41.560 --> 1:56:47.560
 It will have virtually an indecipherable impact.

1:56:47.560 --> 1:56:53.560
 And yet Pharma is talking about the impact on innovation.

1:56:53.560 --> 1:57:09.560
 And if you vote for this, if you let your Congressman vote for this, you're going to severely slow down drug innovation and that's going to affect the quality of your life.

1:57:09.560 --> 1:57:26.560
 Let me ask you about over medication that we've been talking about from different angles, but one difficult question for me, I'll just pick one of the difficult topics, depression.

1:57:26.560 --> 1:57:36.560
 So depression is a serious, painful condition that leads to a lot of people suffering in the world.

1:57:36.560 --> 1:57:41.560
 And yet it is likely they were over prescribing antidepressants.

1:57:41.560 --> 1:57:52.560
 So as a doctor, as a patient, as a healthcare system, as a society, what do we do with that fact that people suffer?

1:57:52.560 --> 1:57:56.560
 There's a lot of people suffering from depression.

1:57:56.560 --> 1:58:01.560
 And there's also people suffering from over prescribing of antidepressants.

1:58:01.560 --> 1:58:20.560
 So a paper in the New England Journal by Eric Turner showed that the data, if you put all the data together from antidepressants, you find out that antidepressants are not effective for people who are depressed but don't have a major depression.

1:58:20.560 --> 1:58:24.560
 Major depression is a serious problem.

1:58:24.560 --> 1:58:27.560
 People can't function normally.

1:58:27.560 --> 1:58:34.560
 They have a hard time getting out performing their normal social roles.

1:58:34.560 --> 1:58:49.560
 But what's happened is that the publicity, I mean, Prozac Nation was a good example of making the argument that why should people settle for normal happiness when they can have better than normal happiness.

1:58:49.560 --> 1:58:53.560
 And if you're not having normal happiness, you should take a drug.

1:58:53.560 --> 1:59:04.560
 Well, that concept that serotonin metabolism is the root cause of depression is really a destructive one.

1:59:04.560 --> 1:59:13.560
 We have drugs that change serotonin metabolism, but we don't know if that's why antidepressants work on major depression.

1:59:13.560 --> 1:59:16.560
 And they certainly don't work on everybody with major depression.

1:59:16.560 --> 1:59:23.560
 I forget what the number needed to treat is, I think it's around four, one out of four people have significant improvement.

1:59:23.560 --> 1:59:27.560
 But the people without major depression don't get better.

1:59:27.560 --> 1:59:33.560
 And the vast majority of these drugs are used for people without major depression.

1:59:33.560 --> 1:59:47.560
 So what's happened is that the feelings of life satisfaction, of happiness and not sadness have been medicalized, the normal range of feelings have been medicalized.

1:59:47.560 --> 1:59:50.560
 And that's not to say that they shouldn't be attended to.

1:59:50.560 --> 2:00:01.560
 But the evidence shows that attending to them by giving somebody a medicine doesn't help accept that they feel like somebody cares about them and believes that they're suffering.

2:00:01.560 --> 2:00:09.560
 But there are problems in living that give rise to much of this symptomatology of less than major depression.

2:00:09.560 --> 2:00:19.560
 And let's call it what it is and figure out a way to help people in visual therapy, group therapy, maybe lifestyle modification would work.

2:00:19.560 --> 2:00:21.560
 We got to try that.

2:00:21.560 --> 2:00:37.560
 But let's call it what it is instead of saying, oh, you're in this vast basket of people who are depressed, so we'll give you an antidepressant, even though the evidence shows that people who are suffering from your level of depression don't get better.

2:00:37.560 --> 2:00:46.560
 And that's a consequence of not focusing on preventative medicine, the lifestyle changes, all that kind of stuff.

2:00:46.560 --> 2:00:55.560
 Well, yes, but it's really a consequence of the drug companies creating the impression that if you're sad, take a pill.

2:00:55.560 --> 2:01:02.560
 If you're nonmajor depression, how do you overcome depression?

2:01:02.560 --> 2:01:05.560
 Well, you have to talk about what the problem is.

2:01:05.560 --> 2:01:09.560
 So talk therapy, lifestyle changes.

2:01:09.560 --> 2:01:18.560
 Well, no, I'm not jumping to that. I'm saying that you ought to A, the way you feel must be respected.

2:01:18.560 --> 2:01:20.560
 Yeah, acknowledge that you're suffering.

2:01:20.560 --> 2:01:26.560
 Acknowledge that you're suffering and deal with healthcare providers who acknowledge that you're suffering.

2:01:26.560 --> 2:01:29.560
 So let's take that first step.

2:01:29.560 --> 2:01:31.560
 Big first step also.

2:01:31.560 --> 2:01:43.560
 Big first step, yeah. Family docs are pretty good at that. That's kind of the arena that caused me to go into family medicine, the subjective experience of the patient.

2:01:43.560 --> 2:01:51.560
 Okay, so you're a person who is not getting the enjoyment out of their life that they feel they ought to be getting.

2:01:51.560 --> 2:02:01.560
 Now, let's figure out why and whether that means some time with a social worker, some time with a psychiatrist, some time with a psychiatric nurse.

2:02:01.560 --> 2:02:06.560
 I'm not sure how you'd best do that most effectively and efficiently, but that's what you need to do.

2:02:06.560 --> 2:02:20.560
 And it may be that there's a marital problem and there's something going on and one of the spouses can't find satisfaction in the life they have to live within the relationship.

2:02:20.560 --> 2:02:27.560
 Maybe there's a past history of trauma or abuse that somebody is projecting onto their current situation.

2:02:27.560 --> 2:02:35.560
 Maybe there's socioeconomic circumstances where they can't find a job that gives them self respect and enough money to live.

2:02:35.560 --> 2:02:41.560
 An infinite range of things, but let's figure out, make a diagnosis first.

2:02:41.560 --> 2:02:47.560
 The diagnosis isn't that the person feels sadder than they want to feel.

2:02:47.560 --> 2:02:53.560
 The diagnosis is why does the person feel sadder than they want to feel?

2:02:53.560 --> 2:03:00.560
 You mentioned this is what made you want to get into family medicine.

2:03:00.560 --> 2:03:08.560
 As a doctor, what do you think about the saying, save one life, save the world?

2:03:08.560 --> 2:03:21.560
 This was always moving to me about doctors because you have this human in front of you and your time is worth money,

2:03:21.560 --> 2:03:28.560
 what you prescribe and your efforts after the visit are worth money.

2:03:28.560 --> 2:03:38.560
 And it seems like the task of the doctor is to not think about any of that or not the task,

2:03:38.560 --> 2:03:47.560
 but it seems like a great doctor despite all that just forgets it all and just cares about the one human.

2:03:47.560 --> 2:03:55.560
 And somehow that feels like the love and effort you put into helping one person is the thing that will save the world.

2:03:55.560 --> 2:04:04.560
 It's not like some economic argument or some political argument or financial argument.

2:04:04.560 --> 2:04:12.560
 It's a very human drive that ultimately is behind all of this that will do good for the world.

2:04:12.560 --> 2:04:15.560
 Yes, I think that's true.

2:04:15.560 --> 2:04:33.560
 And at the same time, I think it's equally true that all physicians need to have a sense of responsibility about how the common resources are allocated to serve all the whole population's interest best.

2:04:33.560 --> 2:04:36.560
 That's a tension that you have as a physician.

2:04:36.560 --> 2:04:49.560
 Let's take the extreme example. Let's say you had a patient in front of you who if you gave a $10 billion pill to, you would save their life.

2:04:49.560 --> 2:05:03.560
 I would just be tortured by that as a physician because I know that $10 billion spent properly in an epidemiologically guided way is going to save a whole lot more lives than one life.

2:05:03.560 --> 2:05:08.560
 So it's also your responsibility as a physician to walk away from that patient.

2:05:08.560 --> 2:05:16.560
 I wouldn't say that. I think it's your responsibility to be tortured by it. That's exactly right.

2:05:16.560 --> 2:05:22.560
 The human condition. That's a tough job.

2:05:22.560 --> 2:05:27.560
 But to maintain your humanity through it all.

2:05:27.560 --> 2:05:38.560
 But you've been asking at different points in this conversation why are doctors so complacent about the tremendous amount of money we're spending?

2:05:38.560 --> 2:05:44.560
 Why do they accept knowledge from different sources that may not pan out when they really know the truth?

2:05:44.560 --> 2:05:50.560
 And the answer is that they're trying to do their best for their patients.

2:05:50.560 --> 2:06:00.560
 And it's the same kind of torture to figure out what the hell is going on with the data.

2:06:00.560 --> 2:06:03.560
 And that's a sort of future project.

2:06:03.560 --> 2:06:09.560
 And maybe people will read my book and maybe they'll get a little more excited about it, become more legitimate in practice.

2:06:09.560 --> 2:06:13.560
 I would feel like my life was worthwhile if that happened.

2:06:13.560 --> 2:06:18.560
 But at the same time, they've got to do something with the patient in front of them.

2:06:18.560 --> 2:06:20.560
 They've got to make a decision.

2:06:20.560 --> 2:06:28.560
 And probably there are not many weirdos like me who invest their life in figuring out what's behind the data.

2:06:28.560 --> 2:06:31.560
 They're trying to get through the day and do the right thing for their patient.

2:06:31.560 --> 2:06:34.560
 So they're tortured by that decision too.

2:06:34.560 --> 2:06:49.560
 And so if you're not careful, big pharma can manipulate that drive to try to help the patient, that humanity of dealing with the uncertainty of it all.

2:06:49.560 --> 2:06:51.560
 What is the best thing to do?

2:06:51.560 --> 2:06:55.560
 Big pharma can step in and use money to manipulate that humanity.

2:06:55.560 --> 2:06:57.560
 I would state it quite differently.

2:06:57.560 --> 2:07:00.560
 It's sort of an opt out rather than an opt in.

2:07:00.560 --> 2:07:07.560
 Big pharma will do that and you need to opt out of it.

2:07:07.560 --> 2:07:13.560
 What advice would you give to a young person today in high school or college,

2:07:13.560 --> 2:07:21.560
 stepping into this complicated world full of advertisements of big powerful institutions,

2:07:21.560 --> 2:07:30.560
 of big rich companies, how to have a positive impact in the world, how to live a life they can be proud of?

2:07:30.560 --> 2:07:37.560
 I would say should that person who has only good motives go into medicine?

2:07:37.560 --> 2:07:41.560
 They have an inclination to go into medicine and they've asked me what I think about that,

2:07:41.560 --> 2:07:47.560
 given what I know about the undermining of American healthcare at this point.

2:07:47.560 --> 2:07:51.560
 And my answer is if you got the calling, you should do it.

2:07:51.560 --> 2:07:55.560
 You should do it because nobody's going to do it better than you.

2:07:55.560 --> 2:08:02.560
 And if you don't have the calling and you're in it for the money, you're not going to be proud of yourself.

2:08:02.560 --> 2:08:20.560
 How do you prevent yourself from letting the system change you over years and years, like letting the game of pharmaceutical influence affect you?

2:08:20.560 --> 2:08:35.560
 It's a very hard question because the sociologic norms are to be affected and to trust the sources of information that are largely controlled by the drug industry.

2:08:35.560 --> 2:08:51.560
 And that's why I wrote Sickening is to try and help those people in the medical profession to understand that what's going on right now looks normal, but it's not.

2:08:51.560 --> 2:08:54.560
 The health of Americans is going downhill.

2:08:54.560 --> 2:09:09.560
 Our society is getting ruined by the money that's getting pulled out of other socially beneficial uses to pay for healthcare that is not helping us.

2:09:09.560 --> 2:09:18.560
 So fundamentally, the thing that is normal, not question the normal.

2:09:18.560 --> 2:09:24.560
 If you conform, conform hesitantly.

2:09:24.560 --> 2:09:26.560
 Well, you have to conform.

2:09:26.560 --> 2:09:30.560
 You can't become a doctor without conforming.

2:09:30.560 --> 2:09:34.560
 I just made it through.

2:09:34.560 --> 2:09:39.560
 But there aren't many and it's hard work.

2:09:39.560 --> 2:09:51.560
 But you have to conform and even with my colleagues in my own practice, I couldn't convince them that some of the beliefs they had about how best to practice weren't accurate.

2:09:51.560 --> 2:10:07.560
 Because one scene, a younger physician had prescribed hormone replacement therapy, this back in 2000, 2001, had prescribed hormone replacement therapy for one of my patients who happened to be a really good personal friend.

2:10:07.560 --> 2:10:17.560
 And I saw that patient covering for my colleague at one point and I saw that her hormone replacement therapy had been renewed.

2:10:17.560 --> 2:10:21.560
 And I said, are you having hot flashes or any problem?

2:10:21.560 --> 2:10:22.560
 No, no, no, no.

2:10:22.560 --> 2:10:26.560
 But Dr. so and so said it's better for my health.

2:10:26.560 --> 2:10:28.560
 And I said, no, it's not.

2:10:28.560 --> 2:10:30.560
 The research is showing that it's not.

2:10:30.560 --> 2:10:33.560
 It's harmful for your health and I think you should stop it.

2:10:33.560 --> 2:10:39.560
 So my colleague approached me when she saw the chart and said, wait a minute, that's my patient.

2:10:39.560 --> 2:10:42.560
 Maybe your friend, but it's my patient.

2:10:42.560 --> 2:10:50.560
 It's at my from my alma mater medical school and they said that healthy people should be given hormone replacement.

2:10:50.560 --> 2:10:54.560
 And I said, there's got to be drug companies involved in this.

2:10:54.560 --> 2:10:57.560
 And she said, no, no, no, it was at my university.

2:10:57.560 --> 2:10:59.560
 It was it was not a drug company thing.

2:10:59.560 --> 2:11:01.560
 We didn't go to a Caribbean island.

2:11:01.560 --> 2:11:03.560
 I said, do you have the syllabus?

2:11:03.560 --> 2:11:04.560
 She said, yeah.

2:11:04.560 --> 2:11:09.560
 And she went and got the syllabus and sure enough, it was sponsored by a drug company.

2:11:09.560 --> 2:11:10.560
 They're everywhere.

2:11:10.560 --> 2:11:11.560
 They're everywhere.

2:11:11.560 --> 2:11:18.560
 And it's back to Coon that groups of experts share unspoken assumptions.

2:11:18.560 --> 2:11:24.560
 And in order to be included in that group of experts, you have to share those unspoken assumptions.

2:11:24.560 --> 2:11:40.560
 And what I'm hoping to do with my book sickening and being here having this wonderful conversation with you is to create an alternative to this normal that people can pursue.

2:11:40.560 --> 2:11:46.560
 And practice better medicine and also prevent burnout.

2:11:46.560 --> 2:11:50.560
 I mean, about half the doctors complain that they're burned out and they've had it.

2:11:50.560 --> 2:11:53.560
 And I think that this is a subjective.

2:11:53.560 --> 2:11:54.560
 I don't have data on this.

2:11:54.560 --> 2:11:56.560
 This is just my opinion.

2:11:56.560 --> 2:12:07.560
 But I think that a lot of that burnout is so called moral injury from practicing in a way that the docs know isn't working.

2:12:07.560 --> 2:12:11.560
 It's not actually providing an alternative to the normal.

2:12:11.560 --> 2:12:14.560
 It's expanding the normal, it's shifting the normal just like with Coon.

2:12:14.560 --> 2:12:30.560
 I mean, you're basically looking for to shift the way medicine is done to the original, I mean, to the intent that it represents the ideal of medicine, of healthcare.

2:12:30.560 --> 2:12:46.560
 Yeah, in Coonian terms to have a revolution and that revolution would be to practice medicine in a way that will be epidemiologically most effective, not most profitable for the people who are providing you with what's called knowledge.

2:12:46.560 --> 2:12:58.560
 You helped a lot of people as a doctor, as an educator, live better lives, live longer, but you yourself are a mortal being.

2:12:58.560 --> 2:13:01.560
 Do you think about your own mortality?

2:13:01.560 --> 2:13:03.560
 Do you think about your death?

2:13:03.560 --> 2:13:04.560
 Are you afraid of death?

2:13:04.560 --> 2:13:06.560
 I'm not.

2:13:06.560 --> 2:13:11.560
 I've faced it been close.

2:13:11.560 --> 2:13:12.560
 Yourself?

2:13:12.560 --> 2:13:13.560
 Yeah.

2:13:13.560 --> 2:13:14.560
 Yeah.

2:13:14.560 --> 2:13:16.560
 How do you think about it?

2:13:16.560 --> 2:13:19.560
 What wisdom do you gain from having come close to death?

2:13:19.560 --> 2:13:22.560
 The fact that the whole thing ends?

2:13:22.560 --> 2:13:24.560
 It's liberating.

2:13:24.560 --> 2:13:26.560
 It's very liberating.

2:13:26.560 --> 2:13:28.560
 I'm serious.

2:13:28.560 --> 2:13:33.560
 I was close and not too long ago.

2:13:33.560 --> 2:13:41.560
 And it was a sense of, you know, this may be the way it ends.

2:13:41.560 --> 2:13:45.560
 And I've done my best.

2:13:45.560 --> 2:13:47.560
 It's not been perfect.

2:13:47.560 --> 2:13:50.560
 And if it ends here, it ends here.

2:13:50.560 --> 2:13:53.560
 The people around me are trying to do their best.

2:13:53.560 --> 2:14:00.560
 And in fact, I got pulled out of it, but it didn't look like I was going to get pulled out of it.

2:14:00.560 --> 2:14:07.560
 Are you ultimately grateful for the ride, even though it ends?

2:14:07.560 --> 2:14:12.560
 Well, it's a little, I think so.

2:14:12.560 --> 2:14:17.560
 If I know, you know, you can't take the ride if you know what the, it's going to end well.

2:14:17.560 --> 2:14:19.560
 It's not the real ride.

2:14:19.560 --> 2:14:21.560
 It's just a ride.

2:14:21.560 --> 2:14:30.560
 But I, having gone through the whole thing, I definitely freed me of a sense of anxiety about death.

2:14:30.560 --> 2:14:34.560
 And it said to me, do you best every day?

2:14:34.560 --> 2:14:37.560
 Because it's going to end sometime.

2:14:37.560 --> 2:14:50.560
 I apologize for the ridiculously big question, but what do you think is the meaning of life, of our human existence?

2:14:50.560 --> 2:14:56.560
 I think it's to care about something and do your best with it.

2:14:56.560 --> 2:15:05.560
 Whether it's being a doctor and trying to make sure that the greatest number of people get the best healthcare,

2:15:05.560 --> 2:15:13.560
 or it's a gardener who wants to have the most beautiful plants, or it's a grandparent who wants to have a good relationship with their grandchildren.

2:15:13.560 --> 2:15:24.560
 But whatever it is that gives you a sense of meaning, as long as it doesn't hurt other people, to really commit yourself to it.

2:15:24.560 --> 2:15:29.560
 That commitment, that being in that commitment for me is the meaning of life.

2:15:29.560 --> 2:15:32.560
 Put your whole heart and soul into the thing.

2:15:32.560 --> 2:15:33.560
 Yup.

2:15:33.560 --> 2:15:34.560
 What is it?

2:15:34.560 --> 2:15:38.560
 The Bukowski poem, Go All The Way.

2:15:38.560 --> 2:15:43.560
 John, you're an incredible human being, incredible educator.

2:15:43.560 --> 2:15:45.560
 Like I said, I recommend people listen to your lectures.

2:15:45.560 --> 2:15:49.560
 It's so refreshing to see that clarity of thought and brilliance.

2:15:49.560 --> 2:15:58.560
 And obviously your criticism of Big Pharma or your illumination of the mechanisms of Big Pharma is really important at this time.

2:15:58.560 --> 2:16:07.560
 So I really hope people read your book, Sickening That's Out Today, or depending on when this comes out.

2:16:07.560 --> 2:16:11.560
 Thank you so much for spending your extremely valuable time with me today.

2:16:11.560 --> 2:16:12.560
 It was amazing.

2:16:12.560 --> 2:16:15.560
 Well, Lex, I want to back to you.

2:16:15.560 --> 2:16:27.560
 Thanks for engaging in this conversation, for creating the space to have it, and creating a listenership that is interested in understanding serious ideas.

2:16:27.560 --> 2:16:29.560
 And I really appreciate the conversation.

2:16:29.560 --> 2:16:33.560
 And I should mention that offline, you told me you listened to the Gilbert Strang episode.

2:16:33.560 --> 2:16:38.560
 So for anyone who don't know Gilbert Strang, another epic human being that should check out.

2:16:38.560 --> 2:16:42.560
 If you don't know anything about mathematics or linear algebra, go look him up.

2:16:42.560 --> 2:16:46.560
 He's one of the great mathematics educators of all time.

2:16:46.560 --> 2:16:53.560
 So of all the people you mentioned to me, I appreciate that you mentioned him because he is a rock star of mathematics.

2:16:53.560 --> 2:16:55.560
 John, thank you so much for talking to us.

2:16:55.560 --> 2:16:56.560
 This was awesome.

2:16:56.560 --> 2:16:57.560
 Great.

2:16:57.560 --> 2:16:58.560
 Thank you.

2:16:58.560 --> 2:17:00.560
 Thanks for listening to this conversation with John Abramson.

2:17:00.560 --> 2:17:04.560
 To support this podcast, please check out our sponsors in the description.

2:17:04.560 --> 2:17:09.560
 And now let me leave you some words from Marcus Aurelius.

2:17:09.560 --> 2:17:14.560
 Waste no time arguing about what a good man should be.

2:17:14.560 --> 2:17:16.560
 Be one.

2:17:16.560 --> 2:17:31.560
 Thank you for listening and hope to see you next time.

