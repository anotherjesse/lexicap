WEBVTT

00:00.000 --> 00:05.280
 The following is a conversation with Lisa Feldman Barrett, a professor of psychology at

00:05.280 --> 00:10.400
 Northeastern University and one of the most brilliant and bold thinkers and scientists

00:10.400 --> 00:15.120
 I've ever had the pleasure of speaking with. She is the author of a book that revolutionized

00:15.120 --> 00:20.880
 our understanding of emotion in the brain called How Emotions Are Made and she's coming out with

00:20.880 --> 00:28.240
 a new book called Seven and a Half Lessons About the Brain that you can and should preorder now.

00:28.240 --> 00:32.720
 I got a chance to read it already and it's one of the best short

00:32.720 --> 00:38.960
 whirlwind introductions to the human brain I've ever read. It comes out on November 17th but again

00:38.960 --> 00:43.520
 if there's anybody worth supporting it's Lisa so please do preorder the book now.

00:44.160 --> 00:49.440
 Lisa and I agreed to speak once again around the time of the book release especially because we

00:49.440 --> 00:55.200
 felt that this first conversation is good to release now since we talk about the divisive time

00:55.200 --> 01:01.200
 we're living through in the United States leading up to the election and she gives me a whole new

01:01.200 --> 01:07.040
 way to think about it from a neuroscience perspective that is ultimately inspiring of empathy,

01:07.040 --> 01:12.880
 compassion and love. Quick mention of each sponsor followed by some thoughts related

01:12.880 --> 01:19.440
 to this episode. First sponsor is Athletic Greens the all in one drink that I start every day with

01:19.440 --> 01:23.920
 to cover all my nutritional bases that I don't otherwise get through my diet naturally.

01:23.920 --> 01:30.240
 Second is Magic Spoon low carb keto friendly delicious cereal that I reward myself with

01:30.240 --> 01:36.640
 after a productive day. The Cocoa Flavor is my favorite. Third sponsor is Cash App the app I

01:36.640 --> 01:43.040
 use to send money to friends for food, drinks and unfortunately for the many bets I've lost to them.

01:43.760 --> 01:48.640
 Please check out these sponsors in the description to get a discount and to support this podcast.

01:48.640 --> 01:55.040
 As a side note, let me say that the bold first principles way that Lisa approaches our study

01:55.040 --> 02:00.640
 of the brain is something that has inspired me ever since I learned about her work and in fact,

02:00.640 --> 02:06.160
 I invited her to speak at the AGI series I organized at MIT several years ago,

02:06.720 --> 02:11.440
 but as a little twist instead of a lecture, we did a conversation in front of the class.

02:12.080 --> 02:16.560
 I think that was one of the early moments that led me to start this very podcast.

02:16.560 --> 02:23.040
 It was scary and gratifying, which is exactly what life is all about. And it's kind of funny how

02:23.040 --> 02:28.240
 life turns on little moments like these that at the time don't seem to be anything out of the

02:28.240 --> 02:32.960
 ordinary. If you enjoy this thing, subscribe on YouTube, review it with five stars on Apple

02:32.960 --> 02:39.360
 podcast, follow on Spotify, support on Patreon or connect with me on Twitter at Lex Freedman.

02:39.360 --> 02:47.440
 And now here's my conversation with Lisa Feldman Barrett. Since we'll talk a lot about the brain

02:47.440 --> 02:52.400
 today, let's ask the craziest question. Do you think there's other intelligent life out there in

02:52.400 --> 02:58.240
 the universe? Honestly, I've been asking myself lately if there's intelligent life on this planet.

02:59.520 --> 03:08.960
 You know, I have to think probabilities suggest yes and also secretly I think I just hope that's

03:08.960 --> 03:15.760
 true. It would be really, I know scientists aren't supposed to have hopes and dreams, but I think it

03:15.760 --> 03:22.080
 would be really cool. And I also think it would be really sad if it wasn't the case. If we really

03:22.080 --> 03:31.440
 were alone, that would seem profoundly sad, I think. So it's exciting to you and that's scary?

03:31.440 --> 03:43.200
 Yeah, no, you know, I take a lot of comfort and curiosity. It's a great resource for dealing

03:43.200 --> 03:53.040
 with stress. So I'm learning all about mushrooms and octopuses and all kinds of stuff. And so for

03:53.040 --> 04:00.080
 me, this counts, I think, in the realm of awe. But also, I think I'm somebody who cultivates awe

04:00.080 --> 04:07.040
 deliberately on purpose to feel like a speck. You know, I find it a relief occasionally.

04:07.040 --> 04:07.840
 To feel small.

04:07.840 --> 04:12.880
 To feel small in a profoundly large and interesting universe.

04:13.680 --> 04:19.600
 So maybe to dig more technically on the question of intelligence, do you think it's

04:19.600 --> 04:25.360
 difficult for intelligent life to arise like it did on Earth? From everything you've written and

04:25.360 --> 04:33.680
 studied about the brain, how magical of a thing is it in terms of the odds it takes to arise?

04:33.680 --> 04:42.320
 Yeah, so, you know, magic is just, don't get me wrong. I mean, I like a magic show as much as

04:42.320 --> 04:48.320
 the next person. My husband was a magician at one time. But, you know, magic is just a bunch of

04:48.320 --> 04:52.640
 stuff that we don't really understand how it works yet. So I would say from what I understand,

04:52.640 --> 05:00.080
 there are some major steps in the course of evolution that at the beginning of life,

05:00.080 --> 05:05.200
 the step from single cell to multicellular organisms, things like that, which are really

05:05.200 --> 05:15.760
 not known. I think for me, the question is not so much, what's the likelihood that it would

05:15.760 --> 05:25.040
 happen again as much as what are the steps and how long would it take? And if it were to happen

05:25.040 --> 05:33.360
 again on Earth, would we end up with the same, you know, menu of life forms that we currently

05:33.360 --> 05:38.400
 have now? And I think the answer is probably no, right? There's just so much about evolution that

05:38.400 --> 05:44.800
 is stochastic and driven by chance. But the question is whether that menu would be equally

05:44.800 --> 05:52.000
 delicious, meaning like there'd be rich complexity of the kind of, like, would we get dolphins and

05:52.000 --> 05:58.480
 humans or whoever else falls in that category of weirdly intelligent, seemingly intelligent.

05:59.040 --> 06:05.760
 However, we define that. Well, I think that has to be true if you just look at the range of creatures

06:05.760 --> 06:11.360
 who've gone extinct. I mean, if you look at the range of creatures that are on the Earth now,

06:11.360 --> 06:16.160
 it's incredible. And, you know, it's sort of tried to say that, but it actually is really

06:16.160 --> 06:24.240
 incredible. Particularly, I don't know, I mean, animals, there are animals that seem

06:25.120 --> 06:29.360
 really ordinary until you watch them closely and then they become miraculous, you know,

06:29.360 --> 06:37.120
 like certain types of birds, which do very miraculous things, build, you know, bowers

06:37.120 --> 06:43.280
 and do dances and all these really funky things that are hard to explain with a standard evolutionary

06:43.280 --> 06:48.320
 story, although, you know, people have them. Birds are weird. They do a lot of formating

06:48.320 --> 06:55.280
 purposes. They have a concept of beauty that I haven't quite, maybe you know much better, but

06:55.280 --> 07:00.160
 it doesn't seem to fit evolutionary arguments well. It does fit. Well, it depends, right? So,

07:00.160 --> 07:05.360
 I think you're talking about the evolution of beauty, the book that was written recently by,

07:05.360 --> 07:09.760
 was it from, was that his name? Richard From, I think, at Yale.

07:09.760 --> 07:12.960
 Oh, actually, no, I didn't. Oh, it's a great book. It's very controversial,

07:12.960 --> 07:19.360
 though, because he is, he's making an argument that the question about birds and some other

07:19.360 --> 07:28.480
 animals is why would they engage in such metabolically costly displays when it doesn't improve their

07:28.480 --> 07:34.560
 fitness at all? And the answer that he gives is the answer that Darwin gave, which is sexual

07:34.560 --> 07:40.160
 selection, not natural selection, but, you know, selection can occur for all kinds of reasons.

07:40.160 --> 07:45.440
 There could be artificial selection, which is when we breed animals, right, which is actually how

07:45.440 --> 07:50.240
 Darwin, that observation helped Darwin come to the idea of natural selection.

07:50.240 --> 07:50.880
 Oh, I see.

07:51.760 --> 07:57.440
 And then there's sexual selection, meaning, and the argument that, that I think his name is from

07:57.440 --> 08:06.080
 makes is that, that it's the pleasure, the selection pressure is the pleasure of female birds,

08:06.800 --> 08:13.120
 which as a woman, and as someone who studies affect, that's a great answer. I actually think

08:13.120 --> 08:16.880
 there probably is natural, I think there is an aspect of natural selection to it, which he maybe

08:16.880 --> 08:23.440
 hasn't considered. But you were saying the reason we brought up birds is the life we got now seems

08:23.440 --> 08:28.880
 to be quite incredible. Yeah, so you peek into the ocean, peek into the sky, there are miraculous

08:28.880 --> 08:35.280
 creatures, look at creatures who've gone extinct and, you know, in science fiction stories, you

08:35.280 --> 08:43.680
 couldn't dream up something as interesting. So my guess is that, you know, intelligent life evolves

08:43.680 --> 08:49.120
 in, in many different ways, even on this planet, there isn't one form of intelligence, there's

08:49.120 --> 08:52.960
 not one brain that gives you intelligence, there are lots of different brain structures that can

08:52.960 --> 09:00.800
 give you intelligence. So my guess is that the menagerie might not look exactly the way that

09:00.800 --> 09:08.160
 it looks now, but it would certainly be as, as interesting. But if we look at the human brain

09:08.160 --> 09:14.240
 versus the brains, or whatever you call them, the mechanisms of intelligence in our ancestors,

09:14.240 --> 09:18.240
 even early ancestors, that you write about, for example, in your, in your new book,

09:18.240 --> 09:26.640
 what, what's the difference between the fanciest brain we got, which is the human brain,

09:27.200 --> 09:33.360
 and the ancestor brains that it came from? Yeah, I think it depends on how far back you

09:33.360 --> 09:40.160
 want to go. You go all the way back, right, in your book. So what's the interesting comparison,

09:40.160 --> 09:44.560
 would you say? Well, first of all, I wouldn't say that the human brain is the fanciest brain we've

09:44.560 --> 09:50.400
 got. I mean, an octopus brain is pretty different and pretty fancy, and they can do some pretty

09:50.400 --> 09:55.920
 amazing things that we cannot do. You know, we can't grow back limbs, we can't change color

09:55.920 --> 10:01.440
 and texture, we can't comport ourselves and squeeze ourselves into a little crevice. I mean,

10:01.440 --> 10:06.000
 these are things that we invent. These are like superhero abilities that we invent in stories,

10:06.000 --> 10:10.000
 right? We can't do any of those things. And so the human brain is certainly,

10:10.000 --> 10:16.960
 we can certainly do some things that other animals can't do. That seemed pretty impressive to us.

10:17.760 --> 10:23.440
 But, but I would say that there, there are a number of animal brains, which seem pretty

10:23.440 --> 10:28.720
 impressive to me that can do interesting things and really impressive things that we can't do.

10:28.720 --> 10:34.640
 I mean, with your work on how emotions are made and so on, you, you kind of repaint the view of

10:34.640 --> 10:43.600
 the brain as, as less glamorous, I suppose, than you would otherwise think. Or like, I guess you

10:43.600 --> 10:49.440
 draw a thread that connects all brains together in terms of homeostasis and all that kind of stuff.

10:50.080 --> 10:56.560
 Yeah, I wouldn't say that the, that the human brain is any less miraculous than anybody else

10:56.560 --> 11:02.080
 would say. I just think that there are other brain structures, which are also miraculous.

11:02.080 --> 11:05.440
 And I also think that there are a number of things about the human brain, which

11:06.400 --> 11:12.320
 we share with other, other vertebrates, other animals with backbones, but

11:14.160 --> 11:19.280
 that are, that we share these miraculous things. But we can do some things in abundance. And we

11:19.280 --> 11:27.120
 can also do some things with our brains together, working together that other animals can't do,

11:27.120 --> 11:31.200
 or at least we haven't discovered their ability to do it.

11:31.200 --> 11:34.560
 Yeah, this social thing, how, I mean, that's one of the things you write about.

11:35.680 --> 11:44.080
 What's, how do you make sense of the fact, like the book sapiens and the fact that we're able to

11:44.080 --> 11:49.840
 kind of connect, like network our brains together, like you write about, I'll try, I'll try to stop

11:49.840 --> 11:59.280
 saying that. Is that, is that like some kind of feature that's built into there? Is that unique

11:59.280 --> 12:01.280
 to our human brains? Like, how do you make sense of that?

12:02.000 --> 12:07.120
 What I would say is that our ability to coordinate with each other is not unique

12:08.560 --> 12:18.320
 to humans. There are lots of animals who can do that. And we, but what we do with that coordination

12:18.880 --> 12:25.440
 is unique because of some of the structural features in our brains. And

12:25.440 --> 12:31.200
 it's not that other animals don't have those structural features, it's we have them in abundance.

12:31.200 --> 12:40.480
 So, you know, the human brain is not larger than you would expect it to be for a primate of our

12:40.480 --> 12:48.960
 size. If you took a chimpanzee and you, you grew it to the size of a human, that chimpanzee would

12:48.960 --> 12:54.880
 have a brain that was the size of a human brain. So there's nothing special about that.

12:54.880 --> 12:59.040
 There's nothing special about our brain in terms of its size. There's nothing special about our

12:59.040 --> 13:08.720
 brain in terms of the, the basic blueprint that builds our brain from an embryo is the basic

13:08.720 --> 13:16.240
 blueprint that builds all mammalian brains and maybe even all vertebrate brains. It's just that

13:16.240 --> 13:21.600
 because of its size, and particularly because of the size of the cerebral cortex, which is the

13:21.600 --> 13:28.160
 part that people mistakenly attribute to rationality.

13:28.160 --> 13:32.160
 Yeah, mistakenly. Is that where all the clever stuff happens?

13:32.160 --> 13:37.920
 Well, no, it really isn't. And I will also say that lots of clever stuff happens in animals who

13:37.920 --> 13:44.640
 don't have a cerebral cortex. But, but, but because of the size of the cerebral cortex,

13:44.640 --> 13:52.640
 and because of some of the features that are enhanced by that size, that gives us the capacity to

13:52.640 --> 13:59.040
 do things like build civilizations and coordinate with each other, not just to

14:00.480 --> 14:08.240
 manipulate the physical world, but to add to it in very profound ways. Like, you know, other animals

14:08.240 --> 14:14.720
 can cooperate with each other and use tools. We draw a line in the sand, and we make countries,

14:14.720 --> 14:20.720
 and we even then we create, you know, we create citizens and immigrants.

14:20.720 --> 14:25.920
 But also ideas. I mean, the countries are centered around the concept of like ideas.

14:25.920 --> 14:31.680
 Well, what do you think a citizen is and an immigrant? Those are ideas. Those are ideas

14:31.680 --> 14:38.240
 that we impose on reality and make them real. And then they have very, very serious and real

14:38.240 --> 14:40.800
 effects, physical effects on people.

14:40.800 --> 14:45.360
 What do you think about the idea that a bunch of people have written about? Dawkins with memes,

14:46.000 --> 14:53.040
 which is like ideas are breeding. Like, we're just like the canvas for ideas to breed

14:53.920 --> 14:59.840
 in our brains. So this kind of network that you talk about of brains is just a little canvas for

14:59.840 --> 15:03.120
 ideas to then competing against each other and so on.

15:03.120 --> 15:10.720
 I think as a rhetorical tool, it's cool to think that way. So I think it was Michael Pollan.

15:10.720 --> 15:15.440
 I don't remember if it was in the botany of desire, but it was in one of his early books on

15:17.680 --> 15:26.160
 botany and gardening, where he wrote about, and he wrote about, you know,

15:26.160 --> 15:32.480
 plants sort of utilizing humans for their own, you know, evolutionary purposes,

15:32.480 --> 15:39.440
 which is kind of interesting. You can think about a human gut, in a sense, as a propagation

15:39.440 --> 15:44.320
 device for the seeds of, you know, tomatoes and what have you. So it's kind of cool.

15:45.680 --> 15:50.480
 So I think, I think rhetorically, it's an interesting device, but, you know, ideas are,

15:50.480 --> 16:00.320
 as far as I know, invented by humans, propagated by humans. So, you know, I don't think they're

16:00.320 --> 16:06.240
 separate from human brains in any way, although it is interesting to think about it that way.

16:06.240 --> 16:11.440
 Well, of course, the ideas that are using your brain to communicate and write excellent books,

16:11.440 --> 16:20.560
 and they basically pick you, Lisa, as an effective communicator, and thereby are winning.

16:21.280 --> 16:26.880
 So that's an interesting worldview to think that there's particular aspects of your brain

16:28.160 --> 16:32.800
 that are conducive to certain sets of ideas, and maybe those ideas will win out.

16:33.360 --> 16:38.000
 Yeah, I think the way that I would say it really, though, is that there are many species of animals

16:38.000 --> 16:42.400
 that influence each other's nervous systems, that regulate each other's nervous systems,

16:42.400 --> 16:48.560
 and they mainly do it by physical means. They do it by chemicals, scent. They do it by, you know,

16:48.560 --> 16:59.360
 so termites and ants and bees, for example, use chemical scents. Mammals like rodents use scent,

16:59.360 --> 17:06.080
 and they also use hearing, audition, and that little bit of vision. Primates, you know,

17:06.080 --> 17:12.320
 nonhuman primates add vision, right? And I think everybody uses touch.

17:13.360 --> 17:20.320
 Humans, as far as I know, are the only species that use ideas and words to regulate each other,

17:20.320 --> 17:23.680
 right? I can text something to someone halfway around the world.

17:23.680 --> 17:24.320
 That's fascinating.

17:24.320 --> 17:27.600
 They don't have to hear my voice. They don't have to see my face,

17:27.600 --> 17:34.000
 and I can have an effect on their nervous system. And ideas, the ideas that we communicate with

17:34.000 --> 17:39.040
 words. I mean, words are, in a sense, a way for us to do mental telepathy with each other, right?

17:39.040 --> 17:45.360
 I mean, I'm not the first person to say that, obviously. But how do I control your heart rate?

17:45.360 --> 17:51.120
 How do I control your breathing? How do I control your actions with words? It's because those words

17:51.120 --> 17:58.000
 are communicating ideas. So you also write, I think, let's go back to the brain. You write

17:58.000 --> 18:04.240
 that Plato gave us the idea that the human brain has three brains in it, three forces,

18:05.280 --> 18:11.120
 which is kind of a compelling notion. You disagree. First of all, what are the three

18:11.120 --> 18:19.760
 parts of the brain and why do you disagree? So Plato's description of the psyche,

18:20.480 --> 18:25.760
 which for the moment, we'll just assume is the same as a mind. There are some scholars who would

18:25.760 --> 18:30.560
 say a soul, a psyche, a mind, those aren't actually all the same thing in ancient Greece,

18:30.560 --> 18:39.600
 but we'll just for now gloss over that. So Plato's idea was that, and it was a description of really

18:39.600 --> 18:46.320
 about moral behavior and moral responsibility in humans. So the idea was that the human psyche

18:46.320 --> 18:56.080
 can be described with a metaphor of two horses and a charioteer. So one horse for instincts,

18:57.520 --> 19:06.160
 like feeding and fighting and fleeing and reproduction. I'm trying to control my salty

19:06.160 --> 19:12.960
 language, which apparently they print in England. Like I actually tossed off of

19:12.960 --> 19:20.000
 really Fs. Yeah. Okay. Yeah. Yeah. I was like, you printed that. I couldn't believe you printed

19:20.000 --> 19:23.760
 that without like the stars or whatever. Oh, no, no, no, there was full print. You know,

19:23.760 --> 19:30.000
 they also printed the a b word and it was really white. Yeah. We should, we should,

19:30.000 --> 19:35.440
 we should learn something from England. Indeed. Anyways, but instincts and then the other horse

19:35.440 --> 19:41.520
 represents emotions. And then the charioteer represents rationality, which controls, you know,

19:41.520 --> 19:52.400
 the two beasts, right? And fast forward, you know, a couple of centuries. And in the middle

19:52.400 --> 19:59.680
 of the 20th century, there was a very popular view of brain evolution, which suggested that

19:59.680 --> 20:08.240
 you have this reptilian core, like a lizard brain, an inner lizard brain for instincts,

20:08.240 --> 20:15.920
 and then wrapped around that evolved on layer on top of that evolved a limbic system for in mammals,

20:15.920 --> 20:23.200
 was the novelty was in a mammalian brain, which bestowed mammals with gave them emotions,

20:23.200 --> 20:33.280
 the capacity for motions. And then on top of that evolved a cerebral cortex, which in,

20:33.280 --> 20:46.480
 in largely in primates, but, but very large in humans. And it's not that I personally disagree.

20:46.480 --> 20:54.240
 It's that as far back as the 1960s, but really by the 1970s, it was shown pretty clearly with

20:54.240 --> 21:01.760
 evidence for molecular genetics. So peering into cells in the brain to look at the molecular makeup

21:01.760 --> 21:14.800
 of genes that the brain did not evolve that way. And the irony is that the idea of the three layered

21:14.800 --> 21:22.480
 brain with an inner lizard that hijacks your behavior and causes you to do and say things

21:22.480 --> 21:30.800
 that you would otherwise not or maybe that you will regret later, that idea became very popular,

21:30.800 --> 21:39.600
 was popularized by Carl Sagan in The Dragons of Eden, which won a Pulitzer Prize in 1977,

21:40.640 --> 21:46.560
 when it was already known pretty much in evolutionary neuroscience that the whole narrative was a myth.

21:47.600 --> 21:54.080
 So what the narrative is on the way it evolved, but do you, I mean, again, it's that problem of

21:54.080 --> 22:02.800
 it being a useful tool of conversation to say like, there's a lizard brain and there's a,

22:03.440 --> 22:09.840
 like if I get overly emotional on Twitter, that was the lizard brain and so on. But do you

22:09.840 --> 22:16.000
 know, I don't think it's useful. I think it's a, I think that is it, is it, is it useful? Is it

22:16.000 --> 22:22.000
 accurate? I don't think it's accurate. And therefore I don't think it's useful. So here's what I would

22:22.000 --> 22:31.360
 say, you know, I think that the way I think about philosophy and science is that they are useful

22:31.360 --> 22:43.840
 tools for living. And in order to be useful tools for living, they have to help you make good

22:43.840 --> 22:50.720
 decisions. The triune brain, as it's called this, this three layer brain, the idea that your brain

22:50.720 --> 22:56.240
 is like an already baked cake. And, you know, the cortex cerebral cortex just layered on top

22:56.240 --> 23:06.320
 like icing. The idea, that idea is the foundation of the law in most Western countries. It's the

23:06.320 --> 23:14.720
 foundation of economic theory. And it large, and it's a great narrative, it sort of fits our

23:14.720 --> 23:23.840
 intuitions about how we work. But it also, it's in addition to being wrong, it lets people off

23:23.840 --> 23:32.720
 the hook for, for nasty behavior, you know, and it also suggests that emotions can't be a source

23:32.720 --> 23:39.680
 of wisdom, which they often are. In fact, you would not want to be around someone who didn't

23:39.680 --> 23:45.760
 have emotions. That would be, that's a psychopath. Right. I mean, that's not someone you, you know,

23:45.760 --> 23:52.640
 want to, want to really have, have that person deciding your outcome. So I guess my, and I

23:52.640 --> 24:00.960
 could sort of go on and on and on. But my point is that I don't think, I don't think it's a useful

24:00.960 --> 24:07.520
 narrative in the end. What's the more accurate view of the brain that we should use when we're

24:07.520 --> 24:11.680
 thinking about it? I'll answer that in a second. But I'll say that even our notion of what an

24:11.680 --> 24:18.320
 instinct is or what a reflex is, it's not quite right. Right. So if you look at evidence from

24:20.560 --> 24:26.240
 ecology, for example, and you look at animals in their ecological context, what you can see

24:26.240 --> 24:35.360
 is that even things which are reflexes are very context sensitive. The brains of those animals

24:35.360 --> 24:41.280
 are executing so called instinctual actions in a very, very context sensitive way.

24:42.080 --> 24:47.680
 And so, you know, even when a physician, you know, takes the, you know, it's like the idea of your

24:47.680 --> 24:53.200
 patellar reflex where they hit, you know, your patellar tendon on your knee and you, you kick.

24:54.240 --> 24:59.680
 The force with which you kick and so on is influenced by all kinds of things. It's,

24:59.680 --> 25:10.480
 it's a reflex isn't like a robotic response. And so I think a better way is a way that to think

25:10.480 --> 25:17.280
 about how brains work is the way that matches our best understanding, our best scientific

25:17.280 --> 25:25.440
 understanding, which I think is really cool because it's really counterintuitive. So how I came to

25:25.440 --> 25:30.560
 this view, and it's, I'm certainly not the only one who holds this view. I was reading work in,

25:30.560 --> 25:37.120
 on neuroanatomy and the, the view that I'm about to tell you was strongly suggested by that. And

25:37.120 --> 25:41.520
 then I was reading work in signal processing, like by engineering, electrical engineering.

25:41.520 --> 25:47.520
 And similarly, it, the work suggested that, that the research suggested that the brain

25:47.520 --> 25:52.240
 worked this way. And I'll just say that I was reading across multiple literatures and they were,

25:52.240 --> 25:58.000
 who don't speak to each other and they were all pointing in this direction. And so far,

25:58.720 --> 26:05.840
 although some of the details are still up for grabs, the general gist, I think, is I've not

26:05.840 --> 26:13.360
 come across anything yet, which really violates and I'm looking. And so the idea is something like

26:13.360 --> 26:21.040
 this, it's very counterintuitive. So the way to describe it is to say that your brain doesn't

26:21.040 --> 26:27.440
 react to things in the world. It's not, to us, it feels like our eyes and our, our windows on the

26:27.440 --> 26:34.640
 world, we see things, we hear things, we, we react to them. In psychology, we call this stimulus

26:34.640 --> 26:43.440
 response. So your face is, your voice is a stimulus to me, I receive input, and then I react to it.

26:43.440 --> 26:52.400
 And I might react very automatically, you know, system one. And, but I also might execute some

26:52.400 --> 27:00.480
 control where I maybe stop myself from saying something or doing something, and more in a more

27:00.480 --> 27:07.120
 reflective way, execute a different action, right, that system too. The way the brain works, though,

27:07.120 --> 27:14.000
 is, it's predicting all the time. It's constantly talking to itself, constantly talking to your

27:14.000 --> 27:21.520
 body. And it's constantly predicting what's going on in the body and what's going on in the world,

27:21.520 --> 27:29.360
 and making predictions. And the information from your body and from the world really confirm

27:29.360 --> 27:34.960
 or correct those predictions. So fundamentally, the thing that the brain does most of the time,

27:34.960 --> 27:40.960
 the brain does most of the time is just predict, like talking to itself and predicting stuff about

27:40.960 --> 27:46.000
 the world, not like this dumb thing that just senses and responds, senses and response.

27:46.000 --> 27:49.360
 Yeah. So the way to, the way to think about it is like this, you know, your brain is

27:50.240 --> 27:54.400
 trapped in a dark silent box. Yeah. That's very romantic of you.

27:55.840 --> 28:04.000
 Which is your skull. And the only information that it receives from your body and from the world,

28:04.000 --> 28:10.160
 right, is through the senses, through the sense organs, your eyes, your ears. And you have

28:11.200 --> 28:17.760
 sensory data that comes from your body that you're largely unaware of to your brain,

28:17.760 --> 28:22.960
 which we call interoceptive, as opposed to exteroceptive, which is the world around you.

28:22.960 --> 28:34.720
 And, but your brain is receiving sense data continuously, which are the effect of some set

28:34.720 --> 28:43.040
 of causes. Your brain doesn't know the cause of these sense data. It's only receiving the

28:43.040 --> 28:48.000
 effects of those causes, which are the data themselves. And so your brain has to solve

28:48.000 --> 28:53.440
 what philosophers call an inverse inference problem. How do you know when you only receive

28:53.440 --> 28:57.280
 the effects of something, how do you know what caused those effects? So when there's a flash

28:57.280 --> 29:05.520
 of light or a change in air pressure or a tug somewhere in your body, how does your brain know

29:06.480 --> 29:13.600
 what caused those events so that it knows what to do next to keep you alive and well?

29:13.600 --> 29:20.960
 And the answer is that your brain has one other source of information available to it,

29:20.960 --> 29:30.160
 which is your past experience. It can reconstitute in its wiring past experiences,

29:30.160 --> 29:38.160
 and it can combine those past experiences in novel ways. And so we have lots of names for this

29:38.160 --> 29:43.600
 in psychology. We call it memory. We call it perceptual inference. We call it simulation.

29:45.840 --> 29:52.080
 It's also, we call it concepts or conceptual knowledge. We call it prediction. Basically,

29:52.080 --> 29:58.400
 if we were to stop the world right now, stop time, your brain is in a state

29:58.400 --> 30:07.760
 and it's representing what it believes is going on in your body and in the world,

30:08.320 --> 30:14.160
 and it's predicting what will happen next based on past experience, probabilistically,

30:14.160 --> 30:25.360
 what's most likely to happen. And it begins to prepare your action, and it begins to

30:25.360 --> 30:33.840
 prepare your experience. So it's anticipating the sense data it's going to receive.

30:35.520 --> 30:41.760
 And then when those data come in, they either confirm that prediction and your action executes

30:42.400 --> 30:50.560
 because the plan's already been made, or there's some sense data that your brain

30:50.560 --> 30:55.440
 didn't predict that's unexpected, and your brain takes it in, we say encodes it,

30:55.440 --> 31:01.520
 we have a fancy name for that, we call it learning. Your brain learns, and it updates its

31:02.560 --> 31:08.640
 storehouse of knowledge, which we call an internal model, so that you can predict better next time.

31:08.640 --> 31:12.320
 And it turns out that predicting and correcting, predicting and correcting

31:13.200 --> 31:18.560
 is a much more metabolically efficient way to run a system than constantly reacting all the time.

31:18.560 --> 31:23.120
 Because if you're constantly reacting, it means you can't anticipate in any way what's going to

31:23.120 --> 31:29.840
 happen. And so the amount of uncertainty that you have to deal with is overwhelming to a nervous

31:29.840 --> 31:35.760
 system. Metabolically costly, I like it. And so what is a reflex? A reflex is when

31:35.760 --> 31:44.560
 your brain doesn't check against the sense data, that the potential cost to you is so great,

31:44.560 --> 31:51.600
 maybe because, you know, your life is threatened, that your brain makes the prediction and executes

31:51.600 --> 31:57.920
 the action without checking. Yeah, but prediction is still at the core. That's a beautiful vision

31:57.920 --> 32:04.560
 of the brain. I wonder from almost an AI perspective, but just computationally, is the brain just

32:04.560 --> 32:11.440
 mostly a prediction machine then? Like, is the perception just the nice little feature added

32:11.440 --> 32:20.480
 on top, like the integration of new perceptual information? I wonder how big of an impressive

32:20.480 --> 32:27.520
 system is that relative to just the big predictor model construct? Well, I think that we can look

32:27.520 --> 32:34.880
 to evolution for that one answer, which is that when you go back 550 million years, give or take,

32:34.880 --> 32:40.640
 we, you know, the world was populated by creatures, really ruled by creatures without brains.

32:42.960 --> 32:47.840
 And, you know, that's a biological statement, not a political statement.

32:48.880 --> 32:51.280
 You're calling dinosaurs dumb? You're talking about like...

32:51.280 --> 32:56.080
 Oh, no, I'm not talking about dinosaurs, honey. I'm talking way back, further back than that.

32:56.640 --> 33:02.800
 Really, there are these little creatures called amphyoxys, which is the modern,

33:02.800 --> 33:09.200
 it's a, or a lancet. That's the modern animal. But it's an animal that scientists believe is very

33:09.200 --> 33:17.040
 similar to our common, the common ancestor that we share with invertebrates, because,

33:18.480 --> 33:24.160
 basically, because of the tracing back the molecular genetics in cells. And that animal

33:25.200 --> 33:31.600
 had no brain. It had some cells that would later turn into a brain, but in that animal,

33:31.600 --> 33:36.720
 there's no brain. But that animal also had no head, and it had no eyes, and it had no ears,

33:36.720 --> 33:43.280
 and it had really, really no senses, for the most part. It had very, very limited sense of touch.

33:43.840 --> 33:51.360
 It had an eye spot for, not for seeing, but just for in training to circadian rhythm to light and

33:51.360 --> 33:57.680
 dark. And it had no hearing. It had a vestibular cell so that it could keep upright in the water.

33:57.680 --> 34:06.320
 At the time, we're talking evolutionary scale here, so give or take some 100 million years or

34:06.320 --> 34:11.840
 something. But at the time, what are the vertebrate, like when a backbone evolved,

34:11.840 --> 34:19.520
 and a brain evolved, a full brain, that was when a head evolved with sense organs, and when

34:20.640 --> 34:25.760
 that's when your viscera, like internal systems involved. So the answer I would say is that

34:25.760 --> 34:33.360
 that senses, motor neuroscientists, people who study the control of motor behavior,

34:34.800 --> 34:45.040
 believe that senses evolved in the service of motor action. So the idea is that, like, what

34:45.040 --> 34:51.120
 triggered the, what triggered, what was the big evolutionary change? What was the big pressure

34:51.120 --> 34:58.400
 that made it useful to have eyes and ears, and a visual system, and an auditory system,

34:58.400 --> 35:06.560
 and a brain, basically. And the answer that is commonly entertained right now is that it was

35:06.560 --> 35:14.880
 predation. That when, at some point, an animal evolved that deliberately ate another animal,

35:14.880 --> 35:22.480
 and this launched an arms race between predators and prey, and it became very

35:22.480 --> 35:28.160
 useful to have senses. So these little amphyoxy, these little amphyoxy,

35:30.400 --> 35:37.360
 don't really have, they don't have, they're not aware of their environment very much, really.

35:37.360 --> 35:51.120
 And so being able to look up ahead and ask yourself, should I eat that, or will it eat me,

35:52.320 --> 36:00.960
 is a very useful thing. So the idea is that sense data is not there for consciousness,

36:00.960 --> 36:06.480
 it didn't evolve for the purposes of consciousness, it didn't evolve for the purposes of experiencing

36:06.480 --> 36:16.480
 anything. It evolved to be in the service of motor control. However, maybe it's useful.

36:17.920 --> 36:26.240
 This is why scientists sometimes avoid questions about why things evolved, that this is what

36:26.240 --> 36:33.200
 philosophers call this teleology. You might be able to say something about how things evolve,

36:33.200 --> 36:40.240
 but not necessarily why. We don't really know the why. That's all speculation.

36:40.240 --> 36:46.080
 But the why is kind of nice here. The interesting thing is that was the first element of social

36:46.080 --> 36:51.120
 interaction is, am I going to eat you, or are you going to eat me? And for that,

36:53.520 --> 36:59.840
 it's useful to be able to see each other, sense each other. That's kind of fascinating that

36:59.840 --> 37:05.840
 there was a time when life didn't eat each other. Or they did by accident. So in Amphioxis, for

37:05.840 --> 37:16.160
 example, it kind of gyrates in the water and then it plants itself in the sand like a living

37:16.160 --> 37:23.600
 blade of grass and then it just filters whatever comes into its mouth. So it is eating, but it's

37:23.600 --> 37:34.560
 not actively hunting. And when the concentration of food decreases, the Amphioxis can sense this,

37:35.200 --> 37:43.760
 and so it basically wriggles itself randomly to some other spot, which probabilistically will

37:43.760 --> 37:51.520
 have more food than wherever it is. So it's not really, it's not guiding its actions on the basis

37:51.520 --> 37:58.960
 of, we would say there is no real intentional action in the traditional sense. Speaking of

37:58.960 --> 38:06.080
 intentional action and if the brain, if prediction is indeed a core component of the brain, let me

38:06.080 --> 38:14.320
 ask you a question that scientists also hate is about free will. So how does, do you think about

38:14.320 --> 38:20.480
 free will much? How does that fit into your view of the brain? Why does it feel like

38:20.480 --> 38:27.040
 we make decisions in this world? This is a hard question. We scientists hate this because it's

38:27.040 --> 38:32.480
 a hard question. We don't have the answer to it. Are you taking a side? I think I have taken

38:32.480 --> 38:39.760
 a side, but I don't put a lot of stock in my own intuitions or anybody's intuitions about the cause

38:39.760 --> 38:45.120
 of things. One thing we know about the brain for sure is that the brain creates experiences for

38:45.120 --> 38:51.120
 us. My brain creates experiences for me. Your brain creates experiences for you in a way that lures

38:51.120 --> 38:56.880
 you to believe that those experiences actually reveals the way that it works, but it doesn't.

38:59.520 --> 39:02.560
 So you don't trust your own intuition about free will?

39:02.560 --> 39:08.960
 Not really. No, I mean, no, but I am also somewhat persuaded by, I think Dan Dennett wrote at one

39:08.960 --> 39:17.600
 point, like the philosopher Dan Dennett wrote at one point that it's, I can't say it as eloquently

39:17.600 --> 39:24.480
 as him, but people obviously have free will. They are obviously making choices. So there is

39:24.480 --> 39:30.640
 this observation that we're not robots and we can do some things like a little more sophisticated

39:30.640 --> 39:40.160
 than an amphyoxys. So here's what I would say. I would say that your predictions, your internal

39:40.160 --> 39:47.200
 model that's running right now, your ability to understand the sounds that I'm making and attach

39:47.200 --> 39:55.760
 them to ideas is based on the fact that you have years of experience knowing what these sounds mean

39:55.760 --> 40:03.040
 in a particular statistical pattern. Right? I mean, that's how you can understand the words

40:03.040 --> 40:10.000
 that are coming out of my mouth. Right. I think we did this once before too, didn't we, when we were?

40:10.000 --> 40:14.480
 I don't know. I would have to access my memory module. I think when I was in your class,

40:14.480 --> 40:20.720
 yeah, I think we did it just like that actually. So bravo. Wow. Yeah. I have to go look back to

40:20.720 --> 40:29.920
 the tape. Yeah. Anyways, the idea though is that your brain is using past experience and it can

40:29.920 --> 40:36.800
 use past experience in, so it's remembering, but you're not consciously remembering. It's basically

40:36.800 --> 40:42.240
 reimplementing prior experiences as a way of predicting what's going to happen next. And it

40:42.240 --> 40:48.160
 can do something called conceptual combination, which is it can take bits and pieces of the past

40:48.160 --> 40:56.320
 and combine it in new ways. So you can experience and make sense of things that you've never

40:56.320 --> 41:00.320
 encountered before because you've encountered something similar to them.

41:04.000 --> 41:14.080
 And so a brain in a sense is not just, doesn't just contain information, it is information

41:14.080 --> 41:20.160
 gaining, meaning it can create new information by this generative process. So in a sense,

41:20.160 --> 41:25.040
 you could say, well, that maybe that's a source of free will. But I think really where free will

41:25.040 --> 41:30.080
 comes from or the kind of free will that I think is worth having a conversation about is,

41:32.160 --> 41:39.440
 involves cultivating experiences for yourself that change your internal model.

41:39.440 --> 41:47.360
 When you were born and you were raised in a particular context, that your brain wired itself

41:47.920 --> 41:53.600
 to your surroundings, to your physical surroundings and also to your social surroundings. So you were

41:54.240 --> 42:03.360
 handed an internal model basically. But when you grow up, the more control you have over your,

42:03.360 --> 42:10.880
 where you are and what you do, you can cultivate new experiences for yourself. And those new

42:10.880 --> 42:19.360
 experiences can change your internal model. And you can actually practice those experiences

42:19.360 --> 42:26.000
 in a way that makes them automatic, meaning it makes it easier for the brain, your brain,

42:26.000 --> 42:34.480
 your brain to make them again. And I think that that is something like what you would call free

42:34.480 --> 42:43.520
 will. You aren't responsible for the model that you were handed that someone, your caregivers

42:45.440 --> 42:49.200
 cultivated a model in your brain. You're not responsible for that model,

42:49.200 --> 42:55.680
 but you are responsible for the one you have now. You can choose, you choose what you expose

42:55.680 --> 43:02.480
 yourself to, you choose how you spend your time. Not everybody has choice over everything,

43:02.480 --> 43:11.760
 but everybody has a little bit of choice. And so I think that is something that I think is

43:11.760 --> 43:18.240
 arguably called free will. Yeah, there's like the ripple effects of the billions of decisions

43:18.240 --> 43:29.440
 you make early on in life have are so great that even if it's not, even if it's like all deterministic,

43:30.240 --> 43:38.640
 just the amount of possibilities that are created and then the focusing on those possibilities into

43:38.640 --> 43:47.200
 a single trajectory that somewhere within that, that's free will, even if it's all deterministic,

43:47.200 --> 43:53.440
 that might as well be just the number of choices that are possible. And the fact that you just

43:53.440 --> 43:58.880
 make one trajectory through a set of choices seems to be like something like they'll be called free

43:58.880 --> 44:04.240
 will, but it's still kind of sad to think like there doesn't seem to be a place where there's

44:04.240 --> 44:10.560
 magic in there or it is all just the computer. Well, there's lots of magic, I would say so far,

44:10.560 --> 44:18.080
 because we don't really understand how all of this is exactly played out at a...

44:20.560 --> 44:27.120
 I mean, scientists are working hard and disagree about some of the details under the hood of what

44:27.120 --> 44:33.840
 I just described, but I think there's quite a bit of magic actually. And also, there's also

44:33.840 --> 44:44.400
 stochastic firing of... Neurons don't... They're not purely digital in the sense that there is...

44:44.960 --> 44:49.760
 There's also analog communication between neurons, not just digital. So it's not just with

44:49.760 --> 44:56.480
 not just with firing of axons. And some of that, there are other ways to communicate. And also,

44:56.480 --> 45:04.720
 there's noise in the system. And the noise is there for a really good reason. And that is

45:05.840 --> 45:14.560
 the more variability there is, the more potential there is for your brain to be able to be information

45:14.560 --> 45:23.760
 bearing. So basically, there are some animals that have clusters of cells. The only job is to

45:23.760 --> 45:30.160
 inject noise into their neural patterns. So maybe noise is the source of free will.

45:30.160 --> 45:36.640
 So you can think about stochasticity or noise as a source of free will,

45:36.640 --> 45:43.680
 or you can think of conceptual combination as a source of free will. You can certainly think about

45:44.560 --> 45:53.520
 cultivating... You can't reach back into your past and change your past. People try by psychotherapy

45:53.520 --> 46:00.640
 and so on. But what you can do is change your present, which becomes your past.

46:02.000 --> 46:07.120
 Well, let me think about that sentence. So one way to think about it is that you're

46:07.120 --> 46:10.720
 continuously... This is a colleague of mine, a friend of mine said,

46:10.720 --> 46:16.080
 so what you're saying is that people are continually cultivating their past. And I was like,

46:16.080 --> 46:22.480
 that's very poetic. Yes, you are continually cultivating your past as a means of controlling

46:22.480 --> 46:31.200
 your future. So you think, yeah, I guess the construction of the mental model that you use

46:31.200 --> 46:37.760
 for prediction ultimately contains within it your perception of the past, like the way you

46:37.760 --> 46:42.400
 interpret the past, or even just the entirety of your narrative about the past. So you're constantly

46:42.400 --> 46:50.320
 rewriting the story of your past. Oh boy, yeah. That's one poetic and also just awe inspiring.

46:50.320 --> 46:57.920
 What about the other thing you talk about? You've mentioned about sensory perception as a thing that

46:59.200 --> 47:06.160
 is just... You have to infer about the sources of the thing that you have perceived through your

47:06.160 --> 47:14.960
 senses. So let me ask another ridiculous question. Is anything real at all? Like, how do we know it's

47:14.960 --> 47:20.560
 real? How do we make sense of the fact that just like you said, there's this brain sitting alone

47:20.560 --> 47:24.640
 in the darkness trying to perceive the world. How do we know that the world is out there

47:26.240 --> 47:30.960
 to be perceived? Yeah, so I don't think that you should be asking questions like that without

47:30.960 --> 47:36.800
 passing a joint. Right, no, for sure. I actually did before this, so I apologize. Okay, no, well,

47:36.800 --> 47:41.120
 that's okay. I apologize for not sharing. That's okay. So, I mean, here's what I would say. What

47:41.120 --> 47:47.280
 I would say is that the reason why we can be pretty sure that there's a there there is that the

47:48.480 --> 47:54.640
 structure of the information in the world, what we call statistical regularities in sights and

47:54.640 --> 47:59.280
 sounds and so on, and the structure of the information that comes from your body, it's not

47:59.280 --> 48:04.960
 random stuff. There's a structure to it. There's a spatial structure and a temporal structure,

48:04.960 --> 48:12.080
 and that spatial and temporal structure wires your brain. So, an infant brain is not a miniature

48:12.080 --> 48:18.160
 adult brain. It's a brain that is waiting for wiring instructions from the world,

48:19.040 --> 48:25.440
 and it must receive those wiring instructions to develop in a typical way. So, for example,

48:25.440 --> 48:37.280
 when a newborn is born, when a newborn is born, when a baby is born, that baby can't see very well

48:37.280 --> 48:45.840
 because the visual system in that baby's brain is not complete. The retina of your eye, which

48:45.840 --> 48:51.520
 actually is part of your brain, has to be stimulated with photons of light. If it's not,

48:51.520 --> 48:57.920
 the baby won't develop normally to be able to see in a neurotypical way. Same thing is true for

48:57.920 --> 49:06.400
 hearing. The same thing is true really for all your senses. So, the point is that the physical

49:06.400 --> 49:12.240
 world, the sense data from the physical world, wires your brain so that you have an internal

49:12.240 --> 49:18.400
 model of that world so that your brain can predict well to keep you alive and well and allow you to

49:18.400 --> 49:25.760
 thrive. That's fascinating that the brain is waiting for a very specific kind of set of

49:25.760 --> 49:31.760
 instructions from the world, not the specific but a very specific kind of instructions.

49:31.760 --> 49:39.200
 So, scientists call it expectable input. The brain needs some input in order to develop normally,

49:39.200 --> 49:47.200
 and we are genetically, as I say in the book, we have the kind of nature that requires nurture.

49:47.200 --> 49:54.560
 We can't develop normally without sensory input from the world and from the body.

49:54.560 --> 50:02.880
 And what's really interesting about humans, and some other animals too, but really seriously in

50:02.880 --> 50:14.400
 humans, is the input that we need is not just physical, it's also social. In order for a human

50:14.400 --> 50:22.160
 infant to develop normally, that infant needs eye contact, touch, it needs certain types of

50:22.160 --> 50:34.160
 smells, it needs to be cuddled, it needs… So, without social input, the brain… That infant's

50:34.160 --> 50:41.120
 brain will not wire itself in a neurotypical way. And again, I would say there are lots of

50:41.120 --> 50:48.800
 cultural patterns of caring for an infant. It's not like the infant has to be cared for in one way.

50:50.240 --> 50:57.280
 Whatever the social environment is for an infant, that it will be reflected in that infant's

50:58.240 --> 51:01.680
 internal model. So, we have lots of different cultures, lots of different ways of rearing

51:01.680 --> 51:07.200
 children, and that's an advantage for our species, although we don't always experience it that way.

51:07.200 --> 51:14.640
 That is an advantage for our species. But if you just feed and water a baby

51:15.840 --> 51:24.880
 without all the extra social doodads, what you get is a profoundly impaired human.

51:25.440 --> 51:30.480
 But nevertheless, you're kind of saying that the physical reality has a

51:30.480 --> 51:40.960
 consistent thing throughout that keeps feeding these set of sensory information that our brains

51:40.960 --> 51:47.040
 are constructed for. Yeah, the cool thing, though, is that if you change the consistency,

51:47.040 --> 51:52.000
 if you change the statistical regularities, so prediction error, your brain can learn it.

51:52.000 --> 51:56.240
 It's expensive for your brain to learn it, and it takes a while for the brain to get really

51:56.240 --> 52:02.240
 automated with it. But you had a wonderful conversation with David Eulman, who just published

52:02.240 --> 52:08.320
 a book about this and gave lots and lots of really very, very cool examples, some of which

52:08.320 --> 52:12.800
 I actually discussed in how emotions were made, but not obviously to the extent that he did

52:13.440 --> 52:21.440
 in his book. It's a fascinating book, but it speaks to the point that your internal model

52:21.440 --> 52:29.520
 is always under construction. And therefore, you always can modify your experience.

52:30.240 --> 52:36.160
 I wonder what the limits are. If we put it on Mars or if we put it in virtual reality,

52:36.160 --> 52:41.680
 or if we sit at home during a pandemic and we spend most of our day on Twitter and TikTok,

52:41.680 --> 52:52.160
 I wonder where the breaking point, the limitations of the brain's capacity to properly continue

52:52.160 --> 52:57.520
 wiring itself. Well, I think what I would say is that there are different ways to

52:58.720 --> 53:02.880
 specify your question. One way to specify it would be the way that David

53:02.880 --> 53:13.120
 phrases it, which is, can we create a new sense? Can we create a new sensory modality?

53:13.920 --> 53:22.160
 How hard would that be? What are the limits in doing that? But another way to say it is,

53:22.160 --> 53:28.160
 what happens to a brain when you remove some of those statistical regularities? What happens

53:28.160 --> 53:36.000
 to a brain? What happens to an adult brain when you remove some of the statistical patterns that

53:36.000 --> 53:40.160
 were there and they're not there anymore? Are you talking about in the environment or in the

53:40.160 --> 53:47.040
 actual, like, you remove eyesight, for example? Well, either way. I mean, basically, one way to

53:47.040 --> 53:54.960
 limit the inputs to your brain are to stay home and protect yourself. Another way is to put someone

53:54.960 --> 54:03.440
 in solitary confinement. Another way is to stick them in a nursing home. Well, not all nursing

54:03.440 --> 54:12.560
 homes, but there are some, which really are where people are somewhat impoverished in the

54:12.560 --> 54:19.360
 interactions and the variety of sensory stimulation that they get. Another way is that you lose a

54:19.360 --> 54:30.320
 sense, right? But the point is, I think that the human brain really likes variety to say it in a

54:33.760 --> 54:40.320
 sort of Cartesian way. Variety is a good thing for a brain and

54:40.320 --> 54:51.920
 there are risks that you take when you restrict what you expose yourself to.

54:53.920 --> 55:00.320
 Yeah. There's always talk of diversity. The brain loves it to the fullest definition and

55:00.320 --> 55:06.160
 degree of diversity. Yeah. I mean, I would say the only thing, basically, human brains thrive on

55:06.160 --> 55:11.680
 diversity. The only place where we seem to have difficulty with diversity is with each other.

55:14.240 --> 55:18.880
 Who wants to eat the same food every day? You never would. Who wants to wear the same clothes

55:18.880 --> 55:22.480
 every day? I mean, my husband, if you ask him to close his eyes, he won't be able to tell you

55:22.480 --> 55:28.800
 what he's wearing. He'll buy seven shirts of exactly the same style in different colors,

55:28.800 --> 55:31.760
 but they are in different colors, right? It's not like he's wearing.

55:31.760 --> 55:37.840
 How would you then explain my brain, which is terrified of choice and therefore wear the same

55:37.840 --> 55:42.640
 thing every time? Well, you must be getting your diversity. Well, first of all, you are a fairly

55:42.640 --> 55:48.320
 sharp dresser, so there is that. So you're getting some reinforcement for dressing the way you do.

55:48.320 --> 55:58.560
 But no, your brain must get diversity in other places. But I think the two most expensive things

55:58.560 --> 56:10.000
 your brain can do, metabolically speaking, is move your body and learn something new. So novelty,

56:10.000 --> 56:18.240
 that is diversity, comes at a cost, a metabolic cost, but it's an investment that gives returns.

56:19.120 --> 56:25.040
 And in general, people vary in how much they like novelty, unexpected things. Some people

56:25.040 --> 56:29.200
 really like it. Some people really don't like it, and there's everybody in between.

56:29.200 --> 56:36.160
 But in general, we don't eat the same thing every day. We don't usually do exactly the same thing

56:36.160 --> 56:43.040
 in exactly the same order, in exactly the same place every day. The only place we have difficulty

56:43.920 --> 56:51.280
 with diversity is in each other. And then we have considerable problems there, I would say,

56:51.280 --> 56:57.040
 as a species. Let me ask, I don't know if you're familiar with Donald Hoffman's work about

56:57.920 --> 57:04.800
 the questions of reality. What are your thoughts of the possibility that the very thing we've

57:04.800 --> 57:12.800
 been talking about, of the brain wiring itself from birth to a particular set of inputs,

57:12.800 --> 57:18.800
 is just a little slice of reality, that there is something much bigger out there that we humans

57:18.800 --> 57:24.880
 without cognition, cognitive capabilities, is just not even perceiving. The thing we're perceiving

57:24.880 --> 57:35.200
 is just the crappy Windows 95 interface onto a much bigger, richer set of complex physics

57:35.200 --> 57:41.200
 that we're not even in touch with. Well, without getting too metaphysical about it,

57:41.200 --> 57:47.680
 I think we know for sure. It doesn't have to be the crappy version of anything,

57:47.680 --> 57:54.960
 but we definitely have a limited, we have a set of senses that are limited in very physical ways,

57:54.960 --> 58:00.000
 and we're clearly not perceiving everything there is to perceive. That's clear. I mean,

58:00.000 --> 58:04.880
 it's just, it's not that hard. We can't without special, why do we invent scientific tools?

58:04.880 --> 58:10.240
 It's so that we can overcome our senses and experience things that we couldn't otherwise,

58:10.240 --> 58:15.280
 whether they are different parts of the visual spectrum, the light spectrum, or

58:15.280 --> 58:21.600
 things that are too microscopically small for us to see, or too far away for us to see.

58:22.880 --> 58:36.880
 Clearly, we're only getting a slice, and that slice, the interesting or potentially sad thing

58:36.880 --> 58:43.280
 about humans is that whatever we experience, we think there's a natural reason for experiencing it,

58:43.280 --> 58:49.360
 and we think it's obvious and natural, and it must be this way, and that all the other stuff

58:49.360 --> 58:56.400
 isn't important. And that's clearly not true. Many of the things that we think of as natural

58:56.400 --> 59:02.080
 are anything but we've, they're certainly real, but we've created them. They certainly have very

59:02.080 --> 59:07.520
 real impacts, but we've created those impacts. And we also know that there are many things

59:07.520 --> 59:14.080
 outside of our awareness that have tremendous influence on what we experience and what we do.

59:14.080 --> 59:20.720
 So there's no question that that's true. I mean, just it's, it's, but the extent is how

59:20.720 --> 59:24.720
 fantastic, you know, really the question is how fantastical is it? Yeah, like what, you know,

59:24.720 --> 59:29.600
 a lot of people ask me, I'm not allowed to say this, I think I'm allowed to say this. I've

59:29.600 --> 59:34.480
 eaten shrooms a couple of times, but I haven't gone the full, I'm talking to a few researchers

59:34.480 --> 59:40.400
 in psychedelics. It's an interesting scientifically place. Like what is the portal you're entering

59:40.400 --> 59:45.120
 when you take psychedelics? Or another way to ask is like dreams, what are,

59:45.120 --> 59:50.320
 So let me tell you what I think, which is based on nothing, like this is based on my like, right?

59:50.320 --> 59:57.280
 So I don't, your intuition, it's based on my, it's based on my, I'm guessing now, based on what

59:57.280 --> 1:00:02.960
 I do know, I would say. But I think that, well, think about what happens. So you're running,

1:00:02.960 --> 1:00:07.200
 your brain's running this internal model, and it's all outside of your awareness. You see the,

1:00:07.200 --> 1:00:12.480
 you feel the products, but you don't, you don't sense the, you have no awareness of the mechanics

1:00:12.480 --> 1:00:19.040
 of it, right? And it's going on all the time. And so one thing that's going on all the time

1:00:19.040 --> 1:00:25.600
 that you're completely unaware of is that when your brain, your brain is basically asking itself,

1:00:25.600 --> 1:00:30.800
 figuratively speaking, not literally, right? Like how is the sense given the last time I was in

1:00:30.800 --> 1:00:35.840
 this sensory array with this stuff going on in my body? And I, and that this chain of events,

1:00:35.840 --> 1:00:41.840
 which just occurred, what did I do next? What did I feel next? What did I see next? And so

1:00:41.840 --> 1:00:46.560
 it doesn't come up with one answer. It comes up with a distribution of possible answers.

1:00:47.200 --> 1:00:54.480
 And then there has to be some selection process. And so you have a network in your brain, a sub

1:00:54.480 --> 1:01:01.920
 network in your brain, a population of neurons that helps to choose. It's not, I'm not talking

1:01:01.920 --> 1:01:09.120
 about a homunculus in your brain or anything silly like that. This is not the soul. It's

1:01:09.120 --> 1:01:18.560
 not the center of yourself or anything like that. But there is a set of neurons that

1:01:18.560 --> 1:01:28.960
 weighs the probabilities and helps to select or narrow the field. And that network is working

1:01:28.960 --> 1:01:33.920
 all the time. It's actually called the control network, the executive control network, or you

1:01:33.920 --> 1:01:38.960
 can call it a frontal parietal because the regions of the brain that make it up are in the frontal

1:01:38.960 --> 1:01:44.720
 lobe and the parietal lobe. There are also parts that belong to the subcortical parts of your brain.

1:01:44.720 --> 1:01:48.400
 It doesn't really matter. The point is that there is this network and it is working all the

1:01:48.400 --> 1:01:52.560
 time. Whether or not you feel in control, whether or not you feel like you're expending effort,

1:01:52.560 --> 1:02:00.320
 doesn't really matter. It's on all the time, except when you sleep. When you sleep, it's

1:02:00.320 --> 1:02:06.720
 a little bit relaxed. And so think about what's happening when you sleep. When you sleep,

1:02:06.720 --> 1:02:15.920
 the external world recedes, the sense data. So basically your model becomes a little bit,

1:02:15.920 --> 1:02:25.760
 the tethers from the world are loosened. And this network, which is involved in maybe weeding out

1:02:25.760 --> 1:02:34.640
 unrealistic things, is a little bit quiet. So your dreams are really your internal model that's

1:02:34.640 --> 1:02:44.240
 unconstrained by the immediate world. So you can do things that you can't do in real life

1:02:44.240 --> 1:02:50.160
 in your dreams. You can fly. For example, when I fly on my back in a dream, I'm much faster than

1:02:50.160 --> 1:02:54.720
 when I fly on my front. Don't ask me why. I don't know. When you're laying on your back in your

1:02:54.720 --> 1:03:00.880
 dream. No. When I'm in my dream and flying in a dream, I am much faster flyer in the air. Fly

1:03:00.880 --> 1:03:06.880
 often? Not often. You talk about it like I don't think I've flown for many years. Well, you must

1:03:06.880 --> 1:03:15.200
 try it. I've flown, I've fallen. That's scary. Yeah. But you're talking about like airplane.

1:03:15.200 --> 1:03:22.480
 I fly my dreams and I'm way faster on my back, way faster. Now you can say, well, you know,

1:03:22.480 --> 1:03:27.600
 you never flew in your life. Right. It's conceptual combination. I mean, I've flown in an airplane

1:03:27.600 --> 1:03:34.160
 and I've seen birds fly and I've watched movies of people flying and I know Superman probably flies.

1:03:34.160 --> 1:03:40.000
 I don't know if he flies faster on his back. He's flying on his front, right? But yeah. But

1:03:40.000 --> 1:03:47.040
 anyways, my point is that, you know, all of this stuff really, all these experiences really become

1:03:47.040 --> 1:03:53.360
 part of your internal model. The thing is that when you're asleep, your internal model is still

1:03:53.360 --> 1:03:59.760
 being constrained by your body. Your brain's always attached to your body. It's always receiving

1:03:59.760 --> 1:04:07.120
 sense data from your body. You're mostly never aware of it unless you run out the stairs or,

1:04:07.120 --> 1:04:13.440
 you know, maybe you are ill in some way. But you're mostly not aware of it, which is a really good

1:04:13.440 --> 1:04:18.320
 thing because if you were, you know, you'd never pay attention to anything outside your own skin

1:04:18.320 --> 1:04:23.600
 ever again. Like right now, you seem like you're sitting there very calmly, but you have a virtual

1:04:23.600 --> 1:04:31.840
 whole thing going on. Drama, right? It's like an opera going on inside your body. And so I think

1:04:31.840 --> 1:04:40.640
 that one of the things that happens when people take psilocybin or take, you know, catamine,

1:04:40.640 --> 1:04:51.200
 for example, is that the tethers are completely removed. Yeah. That's fascinating. And that's

1:04:51.200 --> 1:04:58.560
 why it's helpful to have a guide, right? Because the guide is giving you sense data to steer that

1:04:58.560 --> 1:05:03.680
 internal model so that it doesn't go completely off the rails. Yeah. I know there's, again,

1:05:03.680 --> 1:05:11.120
 that wiring to the other brain that's the guide is at least a tiny little tether. Exactly. Yeah.

1:05:11.120 --> 1:05:17.920
 Let's talk about emotion a little bit if we could. Emotion comes up often and I have never

1:05:17.920 --> 1:05:26.640
 spoken with anybody who has a clarity about emotion from a biological and neuroscience

1:05:26.640 --> 1:05:36.960
 perspective that you do. And I'm not sure I fully know how to, as I mentioned this way too much,

1:05:36.960 --> 1:05:42.320
 but as somebody who was born in the Soviet Union and romanticizes basically everything,

1:05:42.320 --> 1:05:49.520
 talks about love nonstop, you know, emotion is a, I don't know what to make of it. I don't know what

1:05:50.880 --> 1:05:55.600
 so maybe let's just try to talk about it. I mean, from a neuroscience perspective,

1:05:56.240 --> 1:06:01.200
 we talked about a little bit last time, your book covers it, how emotions are made, but

1:06:01.200 --> 1:06:10.720
 what are some misconceptions we writers of poetry, we romanticizing humans have about emotion that

1:06:10.720 --> 1:06:18.880
 we should move away from before to think about emotion from both a scientific and an engineering

1:06:18.880 --> 1:06:27.920
 perspective. Yeah. So there is a common view of emotion in the West. The caricature of that view

1:06:27.920 --> 1:06:36.800
 is that, you know, we have an inner beast, right, your limbic system, your inner lizard.

1:06:36.800 --> 1:06:43.120
 We have an inner beast and that comes baked in to the brain at birth. So you've got circuits for

1:06:43.120 --> 1:06:47.280
 anger, sadness, fear, it's interesting that they all have English names, these circuits.

1:06:49.280 --> 1:06:55.680
 And they're there and they're triggered by things in the world and then they cause you to do and say,

1:06:57.280 --> 1:07:06.480
 when your fear circuit is triggered, you widen your eyes, you gasp, your heart rate goes up,

1:07:06.480 --> 1:07:16.080
 you prepare to flee or to freeze. And these are modal responses. They're not the only responses

1:07:16.080 --> 1:07:22.320
 that you give, but on average, they're the prototypical responses. That's the view. And

1:07:23.840 --> 1:07:29.120
 that's the view of emotion in the law. That's the view, you know, that emotions are these profoundly

1:07:29.120 --> 1:07:40.880
 unhelpful things that are obligatory, kind of like reflexes. The problem with that view is that it

1:07:40.880 --> 1:07:47.680
 doesn't comport to the evidence. And it doesn't really matter. The evidence actually lines up

1:07:47.680 --> 1:07:51.520
 beautifully with each other. It just doesn't line up with that view. And it doesn't matter whether

1:07:51.520 --> 1:07:55.120
 you're measuring people's faces, facial movements, or you're measuring their body movements,

1:07:55.120 --> 1:07:59.920
 or you're measuring their peripheral physiology, or you're measuring their brains or their voices

1:07:59.920 --> 1:08:05.360
 or whatever. Pick any output that you want to measure and, you know, any system you want to

1:08:05.360 --> 1:08:12.080
 measure. And you don't really find strong evidence for this. And I say this as somebody who not only

1:08:12.080 --> 1:08:18.640
 has reviewed really thousands of articles and run, you know, big meta analyses, which are statistical

1:08:18.640 --> 1:08:27.200
 summaries of published papers, but also as someone who has sent teams of researchers to small scale

1:08:28.400 --> 1:08:38.480
 cultures, you know, remote cultures, which are very different from urban, large scale cultures

1:08:38.480 --> 1:08:47.120
 like ours. And one culture that we visited, and I say we euphemistically because I myself didn't go

1:08:47.120 --> 1:08:53.120
 because I only had two research permits. And I gave them to my students because I felt like it was

1:08:54.000 --> 1:08:58.400
 better for them to have that experience and more formative for them to have that experience.

1:08:59.120 --> 1:09:06.640
 But I was in contact with them every day by satellite phone. And this was to visit the

1:09:06.640 --> 1:09:15.120
 Hadza hunter gatherers in Tanzania, who are not an ancient people, they're a modern culture,

1:09:15.120 --> 1:09:23.440
 but they live in circumstances hunting and foraging circumstances that are very similar

1:09:24.400 --> 1:09:32.960
 in similar conditions to our ancestors hunting gathering ancestors, when expressions of emotion

1:09:32.960 --> 1:09:41.440
 were supposed to have evolved, at least by one view of, okay. So, you know, for many years,

1:09:41.440 --> 1:09:47.520
 I was sort of struggling with this set of observations, right, which is that I feel emotion,

1:09:48.480 --> 1:09:56.240
 and I see, I perceive emotion in other people, but scientists can't find a single marker,

1:09:56.240 --> 1:10:03.120
 a single biomarker, not a single individual measure or pattern of measures that can predict

1:10:04.000 --> 1:10:08.320
 how someone, what kind of emotional state they're in. How could that possibly be,

1:10:08.320 --> 1:10:16.720
 how can you possibly make sense of those two things? And through a lot of reading and a lot of

1:10:16.720 --> 1:10:24.720
 and immersing myself in different literatures, I came to the hypothesis that the brain is

1:10:24.720 --> 1:10:31.920
 constructing these instances out of more basic ingredients. So, when I tell you that the brain,

1:10:31.920 --> 1:10:37.840
 when I suggest to you that what your brain is doing is making a prediction and it's asking

1:10:37.840 --> 1:10:45.840
 itself, figuratively speaking, the last time I was in this situation and this, you know, physical

1:10:45.840 --> 1:10:52.240
 state, what did I do next? What did I see next? What did I hear next? It's basically asking,

1:10:52.240 --> 1:11:00.960
 what in my past is similar to the present? Things which are similar to one another

1:11:00.960 --> 1:11:08.400
 are called a category, a group of things which are similar to one another's category.

1:11:09.280 --> 1:11:15.920
 And a mental representation of a category is a concept. So, your brain is constructing

1:11:15.920 --> 1:11:20.880
 categories or concepts on the fly continuously. So, you really want to understand what a brain

1:11:20.880 --> 1:11:26.240
 is doing. You don't, using machine learning like classification models is not going to help you

1:11:26.240 --> 1:11:32.800
 because the brain doesn't classify. It's doing category construction and the categories change

1:11:33.440 --> 1:11:39.520
 or you could say it's doing concept construction. It's using past experience to conjure a concept

1:11:39.520 --> 1:11:48.640
 which is a prediction. And if it's using past experiences of emotion, then it's constructing

1:11:48.640 --> 1:12:03.520
 an emotion concept. Your concept will be, the content of it is changes depending on the situation

1:12:03.520 --> 1:12:09.040
 that you're in. So, for example, if your brain uses past experiences of anger that you have

1:12:09.760 --> 1:12:16.480
 learned either because somebody labeled them for you, taught them to you, you observed them

1:12:16.480 --> 1:12:23.120
 in movies and so on, in one situation could be very different from your concept of for anger

1:12:23.120 --> 1:12:31.120
 than another situation. And this is how anger, instances of anger are what we call a population

1:12:31.120 --> 1:12:36.880
 of variable instances. Sometimes when you're angry, you scowl. Sometimes when you're angry,

1:12:36.880 --> 1:12:44.160
 you might smile. Sometimes when you're angry, you might cry. Sometimes your heart rate will go up,

1:12:44.160 --> 1:12:49.440
 it will go down, it will stay the same. It depends on what action you're about to take

1:12:49.440 --> 1:12:57.520
 because the way prediction, and I should say the idea that physiology is yoked to action is a very

1:12:57.520 --> 1:13:03.760
 old idea in the study of the peripheral nervous system that's been known for really decades.

1:13:04.880 --> 1:13:09.760
 And so, if you look at what the brain is doing, if you just look at the anatomy and you,

1:13:09.760 --> 1:13:14.400
 what, here's the hypothesis that you would come up with. And I can go into the details.

1:13:15.760 --> 1:13:22.000
 I've published these details in scientific papers and they also appear somewhat in how

1:13:22.000 --> 1:13:26.800
 emotions are made, my first book. They are not in the seven and a half lessons because

1:13:27.360 --> 1:13:33.840
 that book is really not pitched at that level of explanation. It's just giving,

1:13:33.840 --> 1:13:40.240
 it's really just a set of little essays. But the evidence, but what I'm about to say is actually

1:13:40.240 --> 1:13:48.560
 based on scientific evidence. When your brain begins to make, form a prediction, the first

1:13:48.560 --> 1:13:56.000
 thing it's doing is it's making a prediction of how to change the internal systems of your body,

1:13:56.560 --> 1:14:00.880
 your heart, your cardiovascular system, the control of your heart, control of your lungs,

1:14:00.880 --> 1:14:07.280
 right? A flush of cortisol, which is not a stress hormone. It's a hormone that gets glucose into

1:14:07.280 --> 1:14:14.080
 your bloodstream very fast because your brain is predicting you need to do something metabolically

1:14:16.640 --> 1:14:27.200
 expensive. And so, so either that means either move or learn. Okay. And so your brain is preparing

1:14:27.200 --> 1:14:33.920
 your body, the internal systems of your body to execute some actions, to move in some way.

1:14:35.200 --> 1:14:45.040
 And then it infers based on those motor predictions and what we call viscera motor predictions,

1:14:45.040 --> 1:14:51.920
 meaning the changes in the viscera that your brain is preparing to execute.

1:14:51.920 --> 1:15:01.040
 And your brain makes an inference about what you will sense based on those motor movements.

1:15:01.600 --> 1:15:07.840
 So your experience of the world and your experience of your own body

1:15:09.360 --> 1:15:15.600
 are a consequence of those predictions, those concepts. When your brain makes a concept for

1:15:15.600 --> 1:15:23.120
 emotion, it's constructing an instance of that emotion. And that is how emotions are made.

1:15:24.160 --> 1:15:29.520
 And those concepts load in the predictions that are made include

1:15:31.760 --> 1:15:39.280
 contents inside the body, contents outside the body. And it includes other humans. So just

1:15:39.280 --> 1:15:47.120
 this construction of a concept includes the variables that are much richer than just some

1:15:48.080 --> 1:15:53.600
 sort of simple notion. Yeah. So our colloquial notion of a concept where

1:15:58.160 --> 1:16:02.640
 where I say, well, what's the concept of a bird? And then you list a set of features off to me.

1:16:02.640 --> 1:16:06.320
 That's that's people's understanding, you know, typically of what a concept is. But if you go

1:16:06.320 --> 1:16:13.520
 into the literature in cognitive science, what you'll see is that the way that scientists have

1:16:13.520 --> 1:16:18.400
 understood what a concept is has really changed over the years. So people used to think about a

1:16:18.400 --> 1:16:25.280
 concept as philosophers and scientists used to think about a concept as a dictionary definition

1:16:25.280 --> 1:16:33.600
 for a category. So there's a set of things which are similar out in the world. And your concept

1:16:33.600 --> 1:16:40.560
 for for that category is a dictionary definition of the features, the necessary insufficient

1:16:40.560 --> 1:16:48.400
 features of that of those instances. So for a bird, you know, would be wings, feathers,

1:16:49.440 --> 1:16:56.480
 right, a beak, if lies, whatever. Okay. That's called the classical category. And scientists

1:16:56.480 --> 1:17:03.760
 discovered, observed that actually, not all instances of birds have feathers and not all instances

1:17:03.760 --> 1:17:10.960
 of birds fly. And so the idea was that you don't have a single representation of necessary

1:17:10.960 --> 1:17:15.680
 insufficient features stored in your brain somewhere. Instead, what you have is a prototype,

1:17:15.680 --> 1:17:20.560
 a prototype, meaning you still have a single representation for the category one.

1:17:20.560 --> 1:17:27.200
 But the features are like of the most typical instance of the category, or maybe the most

1:17:27.200 --> 1:17:32.080
 frequent instance, but not all instances of the category have all the features, right? They

1:17:32.080 --> 1:17:45.680
 have some graded similarity to the prototype. And then, you know, what I'm going to like

1:17:45.680 --> 1:17:52.000
 incredibly simplify now, a lot of work to say that then a series of experiments were done to

1:17:52.000 --> 1:17:58.160
 show that in fact, what your brain seems to be doing is coming up with a single

1:17:59.920 --> 1:18:08.960
 exemplar or instance of the category and reading off the features when I ask you for the concept.

1:18:08.960 --> 1:18:18.560
 So if we were in a pet store and I asked you what are the features of a bird, tell me the

1:18:18.560 --> 1:18:26.240
 concept of bird, you would be more likely to give me features of a good pet. And if we were in a

1:18:26.240 --> 1:18:31.680
 restaurant, you would be more likely, you know, like a budgie, right? Or a canary. If we were in

1:18:31.680 --> 1:18:36.160
 a restaurant, you would be more likely to give me the features of a bird that you would eat,

1:18:36.160 --> 1:18:43.520
 like a chicken. And if we were in a park, you'd be more likely to give me, in this country,

1:18:43.520 --> 1:18:48.960
 you know, the features of a sparrow or a robin. Whereas if we were in South America,

1:18:48.960 --> 1:18:55.920
 you would probably give me the features of a peacock, because that's more common. Or it's

1:18:55.920 --> 1:19:00.400
 more common there than here that you would see a peacock in such circumstances. So

1:19:00.400 --> 1:19:12.640
 the idea was that really what your brain was doing was conjuring a concept on the fly

1:19:13.280 --> 1:19:25.120
 that meets the function that the category is being put to. Okay? Okay. Then people started

1:19:25.120 --> 1:19:36.480
 ad hoc concepts, meaning concepts that where the instances don't share any physical features,

1:19:36.480 --> 1:19:42.320
 but the function of the instances are the same. So for example, think about all the things that

1:19:42.320 --> 1:19:47.840
 can protect you from the rain. What are all the things that can protect you from the rain?

1:19:47.840 --> 1:20:03.280
 Umbrella, like this apartment, not giving a damn, like a mindset.

1:20:05.200 --> 1:20:11.360
 So the idea is that the function of the instances is the same in a given situation,

1:20:11.360 --> 1:20:17.120
 even if they look different, sound different, smell different. This is called an abstract

1:20:17.120 --> 1:20:27.760
 concept or a conceptual concept. Now, the really cool thing about conceptual categories or conceptual

1:20:27.760 --> 1:20:34.240
 concept or conceptual category or conceptual as a category of things that are held together by

1:20:34.240 --> 1:20:40.000
 a function, which is called an abstract concept or a conceptual category, because the things don't

1:20:40.000 --> 1:20:45.360
 share physical features, they share functional features. There are two really cool things about

1:20:45.360 --> 1:20:58.000
 this. One is that's what Darwin said a species was. So Darwin is known for discovering natural

1:20:58.000 --> 1:21:04.640
 selection. But the other thing he really did, which was really profound, which he's less

1:21:04.640 --> 1:21:11.920
 celebrated for, is understanding that all biological categories have inherent variation,

1:21:11.920 --> 1:21:23.200
 inherent variation. Darwin wrote in The Origin of Species about before Darwin's book, a species was

1:21:23.200 --> 1:21:31.280
 thought to be a classical category where all the instances of dogs were the same, had the exactly

1:21:31.280 --> 1:21:40.640
 same features and any variation from that perfect platonic instance was considered to be error.

1:21:40.640 --> 1:21:50.320
 And Darwin said, no, it's not error, it's meaningful. Nature selects on the basis of that variation.

1:21:52.080 --> 1:21:57.360
 The reason why natural selection is powerful and can exist is because there is variation

1:21:58.640 --> 1:22:06.560
 in a species. And in dogs, we talk about that variation in terms of the size of the dog and

1:22:06.560 --> 1:22:12.560
 the amount of fur the dog has and the color and how long is the tail and how long is the snout.

1:22:14.080 --> 1:22:21.600
 In humans, we talk about that variation in all kinds of ways, including in cultural ways.

1:22:24.640 --> 1:22:29.360
 So that's one thing that's really interesting about conceptual categories is that Darwin was

1:22:29.360 --> 1:22:35.200
 basically saying a species is a conceptual category. And in fact, if you look at modern

1:22:35.200 --> 1:22:41.920
 debates about what is a species, you can't find anybody agreeing on what the criteria are for

1:22:41.920 --> 1:22:47.600
 a species, because they don't all share the same genome. We don't all share, we don't,

1:22:47.600 --> 1:22:55.040
 there isn't a single human genome. There's a population of genomes, but they're variable.

1:22:56.080 --> 1:23:01.920
 It's not unbounded variation, but they are variable, right? And the other thing that's

1:23:01.920 --> 1:23:12.800
 really cool about conceptual categories is that they are the categories that we use to make

1:23:12.800 --> 1:23:23.440
 civilization. So think about money, for example. What are all the physical things that make

1:23:23.440 --> 1:23:29.200
 something a currency? Is there any physical feature that all the currencies in all the

1:23:29.200 --> 1:23:36.720
 worlds that's ever been used by humans share? Well, certainly, right. But what is it? Is it

1:23:36.720 --> 1:23:44.720
 definable? So it's getting to the point that you make its function. It's the function. It's

1:23:44.720 --> 1:23:51.840
 that we trade it for material goods. And we have to agree. We all impose on whatever it is, salt,

1:23:51.840 --> 1:23:57.440
 barley, little shells, big rocks in the ocean that can't move, Bitcoin, pieces of plastic,

1:23:57.440 --> 1:24:01.200
 mortgages, which are basically a promise of something in the future, nothing more.

1:24:02.240 --> 1:24:09.760
 All of these things, we impose value on them. And we all agree that we can exchange them for

1:24:09.760 --> 1:24:15.440
 material goods. Yeah. And yes, that's brilliant. By the way, you're attributing some of that to

1:24:15.440 --> 1:24:20.640
 Darwin that he thought. No, I'm saying that. Because it's a brilliant view of what a species is,

1:24:20.640 --> 1:24:27.280
 is the function. Yeah. What I'm saying is that what Darwin, Darwin really talked about variation

1:24:27.280 --> 1:24:33.120
 in, so if you read, for example, the biologist Ernst Mayer, who was an evolutionary biologist,

1:24:33.120 --> 1:24:40.720
 and then when he retired, became a historian and philosopher of biology. And his suggestion is

1:24:41.520 --> 1:24:47.920
 that Darwin, Darwin did talk about variation. He vanquished what's called essentialism,

1:24:47.920 --> 1:24:59.200
 the idea that there's a single set of features that define any species. And out of that grew

1:25:01.760 --> 1:25:07.040
 really discussions of the function, like some of the functional features that species have,

1:25:07.040 --> 1:25:12.480
 like they can reproduce, they can have offspring, the individuals of a species can have offspring.

1:25:12.480 --> 1:25:20.480
 Well, it turns out that's not a perfect criterion to use, but it's a functional criterion.

1:25:20.480 --> 1:25:24.480
 So what I'm saying is that in cognitive science, people came up with the idea,

1:25:24.480 --> 1:25:30.720
 they discovered the idea of conceptual categories or ad hoc concepts, these concepts that can change

1:25:30.720 --> 1:25:40.000
 based on the function they're serving. And it's there, it's in Darwin, and it's also in

1:25:40.000 --> 1:25:44.800
 the philosophy of social reality. You can, the way that philosophers talk about social reality,

1:25:44.800 --> 1:25:50.000
 just look around you. I mean, we impose, we're treating a bunch of things as similar, which

1:25:50.000 --> 1:25:55.760
 are physically different. And sometimes we take things that are physically the same,

1:25:55.760 --> 1:26:02.160
 and we treat them as separate categories. But it feels like the number of variables involved

1:26:02.160 --> 1:26:06.640
 in that kind of categorization is nearly infinite. No, I don't think so, because

1:26:06.640 --> 1:26:13.600
 there is a physical constraint. You and I could agree that we can fly in real life,

1:26:13.600 --> 1:26:19.440
 but we can't. That's a physical constraint that we can't break. You and I could agree

1:26:19.440 --> 1:26:24.080
 that we could walk through the walls, but we can't. We could agree that we could eat glass.

1:26:24.080 --> 1:26:28.560
 Oh, there's a lot of constraints. We could agree that the virus doesn't exist,

1:26:28.560 --> 1:26:36.480
 and we don't have to wear masks. But physical reality still holds the Trump card, right?

1:26:37.040 --> 1:26:41.440
 But still, there's a lot of... The Trump card. Well, pun unintended.

1:26:41.440 --> 1:26:44.320
 Pun completely unintended, but there you go. That's a predicting brain for you.

1:26:45.920 --> 1:26:52.480
 But there is a tremendous amount of leeway. Yes. Yeah, that's the point. So what I'm saying

1:26:52.480 --> 1:26:59.360
 is that emotions are like money. Basically, they're like money. They're like countries. They're like

1:27:00.400 --> 1:27:06.160
 kings and queens and presidents. They're like everything that we construct that we impose

1:27:06.160 --> 1:27:12.000
 meaning on. We take these physical signals and we give them meanings that they don't otherwise

1:27:12.000 --> 1:27:19.200
 have by their physical nature. And because we agree, they have that function.

1:27:19.200 --> 1:27:26.560
 But the beautiful thing, so maybe unlike money, I love the similarities. It's not obvious to me

1:27:26.560 --> 1:27:32.720
 that this kind of emergent agreement should happen with emotion, because our experiences are so

1:27:32.720 --> 1:27:38.400
 different for each of us humans, and yet we kind of converge. Well, in a culture, we converge,

1:27:38.400 --> 1:27:43.520
 but not across cultures. There are huge, huge differences. There are huge differences in what

1:27:43.520 --> 1:27:54.960
 concepts exist, what they look like. So what I would say is that what we're doing with our young

1:27:54.960 --> 1:28:04.160
 children as their brains become wired to their physical and their social environment is that

1:28:04.160 --> 1:28:11.600
 we are curating for them. We are bootstrapping into their brains a set of emotion concepts.

1:28:11.600 --> 1:28:15.920
 That's partly what they're learning. And we curate those for infants just the way we curate

1:28:15.920 --> 1:28:22.640
 for them. What is a dog? What is a cat? What is a truck? We sometimes explicitly label and we

1:28:22.640 --> 1:28:31.280
 sometimes just use mental words when your kid is throwing Cheerios on the floor instead of eating

1:28:31.280 --> 1:28:38.800
 them or your kid is crying when she won't put herself to sleep or whatever. We use mental words

1:28:38.800 --> 1:28:48.720
 and for infants, words are these really special things that they help infants learn abstract

1:28:48.720 --> 1:28:55.760
 categories. There's a huge literature showing that children can take things that don't look

1:28:55.760 --> 1:29:03.440
 infants, like infants, really young infants, preverbal infants, can take, if you label, if I

1:29:03.440 --> 1:29:14.320
 say to you, and you're an infant, okay, so I say Lexi, this is a bling. And I put it down and the

1:29:14.320 --> 1:29:23.360
 bling makes a squeaky noise. And then I say Lexi, this is a bling and I put it down and it makes

1:29:23.360 --> 1:29:34.240
 a squeaky noise. And then I say, Lexi, this is a bling. You, as young as four months old, will

1:29:34.240 --> 1:29:41.760
 expect this to make a noise, a squeaky noise. And if you don't, if it doesn't, you'll be surprised

1:29:41.760 --> 1:29:48.560
 because it violated your expectation, right? I'm building for you an internal model of a bling.

1:29:48.560 --> 1:29:55.440
 Yeah. Okay. Infants can do this really, really at a young age. And so there's no reason to believe

1:29:55.440 --> 1:30:02.880
 that they couldn't learn emotion categories and concepts in the same way. And in one, and what

1:30:02.880 --> 1:30:09.680
 happens when you go to a new culture, when you go to a new culture, you have to do what's called

1:30:09.680 --> 1:30:14.960
 emotion acculturation. So my colleague, Bacchia Mesquita in Belgium studies emotion acculturation.

1:30:14.960 --> 1:30:20.800
 She studies how when people move from one culture to another, how do they learn the emotion concepts

1:30:20.800 --> 1:30:27.120
 of that culture? How do they learn to make sense of their own internal sensations and also the

1:30:27.120 --> 1:30:32.480
 movements, you know, the rays of an eyebrow, the tilt of a head, how do they learn to make sense

1:30:32.480 --> 1:30:39.520
 of cues from other people using concepts they don't have, but have to make on the fly?

1:30:39.520 --> 1:30:46.320
 So that's the difference in cultures. Let me open another door. I'm not sure I want to open,

1:30:46.320 --> 1:30:52.880
 but the difference between men and women, is there a difference between the emotional lives

1:30:53.760 --> 1:30:56.800
 of those two categories of biological systems?

1:30:58.160 --> 1:31:05.920
 So here's what I would say. You know, we did a series of studies in the 1990s where we asked men

1:31:05.920 --> 1:31:12.160
 and women to tell us about their emotional lives. And women describe themselves as much more emotional

1:31:12.160 --> 1:31:17.520
 than men. They believed that they were more emotional men and men agreed. Women are much

1:31:17.520 --> 1:31:24.560
 more emotional than men. Okay. Okay. And then we gave them little handheld computers. These were

1:31:24.560 --> 1:31:29.360
 little Hewlett Packard computers. They fit in the palm of your hand. They weighed a couple of

1:31:29.360 --> 1:31:35.920
 pounds. So this was like pre palm pilot even, like this was, you know, 1990s and like early.

1:31:36.720 --> 1:31:47.600
 And we asked them, we would, you know, ping them like 10 times a day and just ask them to report

1:31:47.600 --> 1:31:54.160
 how they were feeling, which is called experience sampling. So we experienced sampled. And

1:31:54.160 --> 1:32:01.040
 and then at the end, and then we looked at their reports and what we found is that men and women

1:32:01.040 --> 1:32:06.880
 basically didn't differ. And there were some people who were really had many more instances of

1:32:06.880 --> 1:32:16.160
 emotion. So they were, you know, they were treading water in a tumultuous sea of emotion. And then

1:32:16.160 --> 1:32:21.680
 there were other people who were like floating tranquilly, you know, in a lake. It was really

1:32:21.680 --> 1:32:28.080
 not perturbed very often and everyone in between. But there were no difference between men and women.

1:32:28.080 --> 1:32:32.240
 And the really interesting thing is at the end of the sampling period, we asked people,

1:32:33.520 --> 1:32:39.120
 so reflect over the past two weeks and tell it. So, you know, we've been now pinging people like

1:32:39.120 --> 1:32:44.560
 again and again and again, right? So tell us how, how emotional do you think you are? No change

1:32:44.560 --> 1:32:50.960
 from the beginning. So men and women believe that they are, they believe that they are different.

1:32:50.960 --> 1:32:57.520
 And when they are looking at other people, they make different inferences about emotion.

1:32:57.520 --> 1:33:03.600
 If a man, if a man is scowling, like if you and I were together and some, so somebody's watching

1:33:03.600 --> 1:33:12.720
 this. Okay. And yeah, hey, hey. By the way, people love it when you look at the camera.

1:33:12.720 --> 1:33:20.560
 If you and I make exactly the same set of facial movements,

1:33:22.560 --> 1:33:27.600
 when people look at you, both men and women look at you, they are more likely to think,

1:33:27.600 --> 1:33:34.160
 oh, he's reacting to the situation. And when they look at me, they'll say, oh, she's having an

1:33:34.160 --> 1:33:45.280
 emotion. She's, you know, yeah. And I wrote about this actually right before the 2016 election.

1:33:46.480 --> 1:33:51.520
 You know what? Maybe I could confess. Let me try to carefully confess.

1:33:51.520 --> 1:33:59.600
 But you are really going to. Yeah. That I'm, that when I, that there is an element when I

1:33:59.600 --> 1:34:08.640
 see Hillary Clinton, that there was something annoying about her to me. And I, just that feeling,

1:34:09.280 --> 1:34:17.360
 and then I tried to reduce that to what, what is that? Because I think the same attributes that

1:34:17.360 --> 1:34:23.520
 are annoying about her, when I see in other people wouldn't be annoying. So I was trying to understand

1:34:23.520 --> 1:34:29.920
 what is it? Because it certainly does feel like that concept that I've constructed in my mind.

1:34:29.920 --> 1:34:35.440
 Well, I'll tell you that I think, well, let me just say that, that, that what you would predict

1:34:35.440 --> 1:34:42.000
 about, for example, the performance of the two of them in the debates. And I wrote an op ed for

1:34:42.000 --> 1:34:48.720
 the New York Times actually, before the second debate. And it played out really pretty much as

1:34:48.720 --> 1:34:53.120
 I thought that it would based on research is not like I'm like a great fortune teller or anything.

1:34:53.120 --> 1:35:01.360
 It's just, I was just applying the research, which was that when a woman, a woman's people make

1:35:01.360 --> 1:35:07.040
 internal attributions, it's called they, they infer that the facial movements and body posture

1:35:07.040 --> 1:35:12.720
 and vocalizations of a woman reflect her interstate. But for a man, they're more likely to assume

1:35:12.720 --> 1:35:16.880
 that they reflect his response to the situation. It doesn't say anything about him. It says something

1:35:16.880 --> 1:35:21.920
 about the situation he's in. That's brilliant. Now, for the thing that you are, that you were

1:35:21.920 --> 1:35:28.960
 describing about Hillary Clinton, I think a lot of people experienced, but it's also in line with

1:35:28.960 --> 1:35:35.520
 research, which shows and particularly research actually on in about teaching evaluations is

1:35:35.520 --> 1:35:41.680
 one place that you really see it, where the expectation is that a woman will be nurtured

1:35:42.880 --> 1:35:48.240
 and that a man, there's just no expectation for him to be nurtured. So he's, you know,

1:35:48.240 --> 1:35:54.880
 if he is nurtured and he gets points, if he's not, he gets points. They're just different

1:35:54.880 --> 1:36:00.640
 points, right? Whereas for a woman, especially a woman who's an authority figure, she's really

1:36:00.640 --> 1:36:08.880
 in a catch 22. Because if she's serious, she's a bitch. And if she's empathic, then she's weak.

1:36:09.520 --> 1:36:15.200
 That's brilliant. I mean, one of the bigger questions to ask here. So that's one example

1:36:15.200 --> 1:36:23.120
 where our construction of concepts gets in trouble. But remember, I said science is a

1:36:23.120 --> 1:36:30.480
 science and philosophy are like tools for living. So I learned recently that if you asked me,

1:36:30.480 --> 1:36:37.360
 what is my intuition about what regulates my eating? I will say carbohydrates. I love carbohydrates.

1:36:37.360 --> 1:36:44.640
 I love pasta. I love bread. I love, I just love carbohydrates. But actually research shows and

1:36:44.640 --> 1:36:51.040
 it's beautiful research. I love this research because it so violates my own like deeply, deeply

1:36:51.040 --> 1:36:58.080
 held beliefs about myself that most animals on this planet who have been studied and there are many

1:36:59.840 --> 1:37:07.120
 actually eat to regulate their protein intake. So you will overeat carbohydrates if you,

1:37:07.120 --> 1:37:13.600
 in order to get enough protein. And this research has been done with human, very beautiful research

1:37:13.600 --> 1:37:18.000
 with humans, with crickets, with like, you know, bonobos, I mean, just like all these

1:37:18.000 --> 1:37:24.480
 different animals, not bonobos, but I think like baboons. Now, I have no intuition about that.

1:37:24.480 --> 1:37:31.680
 And I, even now as I regulate my eating, I still, I just have no intuition. It just, I can't,

1:37:31.680 --> 1:37:35.680
 I can't feel it. What I feel is only about the carbohydrates.

1:37:35.680 --> 1:37:38.640
 It feels like you're regulating around carbohydrates, not the protein.

1:37:38.640 --> 1:37:44.080
 Yeah. But in fact, actually, what I am doing, if I am like most animals on the planet, I am

1:37:44.080 --> 1:37:51.440
 regulating around protein. So knowing this, what do I do? I correct my behavior to eat,

1:37:51.440 --> 1:37:59.680
 to actually deliberately try to focus on the protein that this is the idea behind bias training,

1:37:59.680 --> 1:38:13.280
 right? Like if you, I also did not experience Hillary Clinton as the warmest candidate. However,

1:38:14.400 --> 1:38:21.920
 you can use consistent science, consistent scientific findings to

1:38:21.920 --> 1:38:28.240
 organize your behavior. That doesn't mean that rationality is the absence of emotion,

1:38:28.240 --> 1:38:34.240
 because sometimes emotion or sent any feelings in general, not the same thing as emotion.

1:38:35.440 --> 1:38:42.720
 That's another topic. But, you know, our source of information and their wisdom and helpful.

1:38:42.720 --> 1:38:46.800
 So I'm not saying that, but what I am saying is that if you have a deeply held belief and

1:38:46.800 --> 1:38:51.680
 the evidence shows that you're wrong, then you're wrong. It doesn't really matter how confident

1:38:51.680 --> 1:38:57.280
 you feel. You, that confidence could be also explained by science, right? So it would be

1:38:57.280 --> 1:39:02.720
 the same thing as if I, regardless of whether someone is like Charlie Baker, right? Regardless

1:39:02.720 --> 1:39:08.000
 of whether somebody is a Republican or a Democrat, if that person has a record that you can see

1:39:09.200 --> 1:39:14.400
 is consistent with what you believe, then that is information that you can act on.

1:39:15.600 --> 1:39:20.960
 Yeah. And then, so try to, I mean, this is kind of what empathy is in open mindedness.

1:39:20.960 --> 1:39:27.760
 It's try to consider that the set of concepts that your brain has constructed through which

1:39:27.760 --> 1:39:34.000
 you are now perceiving the world is not painting the full picture. I mean, this is now true for

1:39:34.000 --> 1:39:38.800
 basically every, it doesn't have to be men and women. It could be basically the prism through

1:39:38.800 --> 1:39:44.080
 which we perceive actually the political discourse, right? Absolutely. So here's what I would say.

1:39:44.080 --> 1:39:53.520
 The, you know, there are people who, scientists who will talk to you about cognitive empathy

1:39:53.520 --> 1:40:01.840
 and emotional empathy. And I prefer to think of it, I think the evidence is more consistent

1:40:01.840 --> 1:40:08.960
 with what I'm about to say, which is that your brain is always making predictions using your

1:40:08.960 --> 1:40:14.000
 own past experience and what you've learned from, you know, books and movies and other

1:40:14.000 --> 1:40:21.760
 people telling you about their experiences and so on. And if your brain cannot make a concept

1:40:22.640 --> 1:40:26.880
 to make sense of those, anticipate what those sense data are and make sense of them,

1:40:27.520 --> 1:40:34.160
 you will be experientially blind. So, you know, when I'm giving lectures to people,

1:40:34.160 --> 1:40:40.560
 I'll show them like a blobby black and white image. And they're experientially blind

1:40:41.200 --> 1:40:46.480
 to the image. They can't see anything in it. And then I show them a photograph and then I show them

1:40:46.480 --> 1:40:51.280
 the image again, the blobby image, and then they see actually an object in it. But the

1:40:52.080 --> 1:40:57.680
 image is the same. It's there, they're actually adding, their predictions now are adding, right?

1:40:57.680 --> 1:41:07.840
 Or anybody who's learned a language, a second language after their first language also has

1:41:07.840 --> 1:41:14.000
 this experience of things that initially sound like sounds that they can't quite make sense of

1:41:14.000 --> 1:41:19.040
 eventually come to make, they eventually come to make sense of them. And in fact, there are really

1:41:19.040 --> 1:41:27.520
 cool examples of people who are like born blind because they have cataracts or they have corneal

1:41:27.520 --> 1:41:36.960
 damage so that no light is reaching the brain. And then they have an operation and then light reaches

1:41:36.960 --> 1:41:46.560
 the brain and they can't see for days and weeks and sometimes years they are experientially blind

1:41:46.560 --> 1:41:53.760
 to certain things. So, what happens with empathy, right, is that your brain is making a prediction.

1:41:53.760 --> 1:42:06.480
 And if it doesn't have the capacity to make, if you don't share, if you're not similar, remember,

1:42:06.480 --> 1:42:12.400
 you mean, you know, categories are instances which are similar in some way. If you are not

1:42:12.400 --> 1:42:18.000
 similar enough to that person, you will have a hard time making a prediction about what they feel.

1:42:18.000 --> 1:42:28.000
 You will be experientially blind to what they feel. In the United States, children of color

1:42:28.000 --> 1:42:38.560
 are underprescribed medicine by their physicians. This has been documented. It's not that the

1:42:38.560 --> 1:42:50.000
 physicians are racist, necessarily, but they might be experientially blind.

1:42:51.360 --> 1:42:56.720
 The same thing is true of male physicians with female patients. I could tell you some

1:42:56.720 --> 1:43:03.760
 hair raising stories, really, that where people die as a consequence of a physician making

1:43:03.760 --> 1:43:15.760
 the wrong inference, the wrong prediction, because of being experientially blind. So, we are – empathy

1:43:15.760 --> 1:43:25.200
 is not magic. We make inferences about each other, about what each other is feeling and thinking.

1:43:25.200 --> 1:43:32.160
 In this culture, more than – there are some cultures where people have what's called opacity

1:43:32.160 --> 1:43:36.000
 of mind, where they will make a prediction about someone else's actions, but they're not inferring

1:43:36.000 --> 1:43:42.080
 anything about the internal state of that person. But in our culture, we're constantly making

1:43:42.080 --> 1:43:46.560
 inferences. What is this person thinking? What is – and we're not doing it necessarily consciously,

1:43:46.560 --> 1:43:52.720
 but we're just doing it really automatically using our predictions, what we know. And if you

1:43:52.720 --> 1:44:00.160
 expose yourself to information which is very different from somebody else, I mean, really what

1:44:00.160 --> 1:44:06.800
 we have is – we have different cultures in this country right now that are – there are a number

1:44:06.800 --> 1:44:11.600
 of reasons for this. I mean, part of it is, I don't know if you saw the social dilemma,

1:44:11.600 --> 1:44:12.800
 the Netflix.

1:44:12.800 --> 1:44:14.480
 I heard about it.

1:44:14.480 --> 1:44:18.800
 Yeah. It's a great – it's really great documentary.

1:44:18.800 --> 1:44:22.400
 Well, it's what social networks are doing to our society.

1:44:22.400 --> 1:44:22.880
 Yeah.

1:44:22.880 --> 1:44:34.800
 Yeah. But nothing – no phenomenon has a simple single cause. There are multiple small causes

1:44:34.800 --> 1:44:43.680
 which all add up to a perfect storm. That's just how most things work. And so, the fact that

1:44:43.680 --> 1:44:49.520
 machine learning algorithms are serving people up information on social media that is consistent

1:44:49.520 --> 1:44:56.800
 with what they've already viewed and making – is part of the reason that you have these

1:44:56.800 --> 1:45:01.840
 silos. But it's not the only reason why you have these silos, I think. There are other

1:45:03.120 --> 1:45:13.120
 things afoot that enhance people's inability to even have a decent conversation.

1:45:13.120 --> 1:45:18.720
 Yeah. I mean, okay. So many things you said are just brilliant. So, the experiment – experiential

1:45:18.720 --> 1:45:26.560
 blindness. But also, from my perspective, I preach and I try to practice empathy a lot.

1:45:27.120 --> 1:45:33.520
 And something about the way you've explained it makes me almost see it as a kind of exercise

1:45:33.520 --> 1:45:39.760
 that we should all do, like to train, like to add experiences to the brain to expand this

1:45:39.760 --> 1:45:42.560
 capacity to predict more effectively.

1:45:42.560 --> 1:45:43.360
 Absolutely.

1:45:43.360 --> 1:45:50.000
 So, what I do is kind of like a method acting thing which is I imagine what the life of a

1:45:50.000 --> 1:45:55.920
 person is like. Just think. I mean, this is something you see with Black Lives Matter

1:45:55.920 --> 1:46:03.760
 and police officers. It feels like they're both – not both, but because martial arts and so on,

1:46:03.760 --> 1:46:14.000
 I have a lot of friends who are cops. They don't necessarily have empathy or visualize the experience

1:46:14.000 --> 1:46:19.280
 of the other. Certainly, currently, unfortunately, people aren't doing that with police officers.

1:46:19.280 --> 1:46:25.680
 They're not imagining – they're not empathizing or putting themselves in the shoes of a police

1:46:25.680 --> 1:46:31.280
 officer to realize how difficult that job is, how dangerous it is, how difficult it is to maintain

1:46:31.280 --> 1:46:34.960
 calm and under so much uncertainty, all those kinds of things.

1:46:34.960 --> 1:46:40.720
 But there's more – that's all that's true, but I think that there's even more to be said

1:46:40.720 --> 1:46:46.960
 there. I mean, from a predicting brain standpoint, there's even more that can be said there.

1:46:46.960 --> 1:46:50.880
 So, I don't know if you want to go down that path or you want to stick on empathy, but I will also

1:46:50.880 --> 1:46:57.280
 say that one of the things that I was most gratified by, I still am receiving – it's been

1:46:57.280 --> 1:47:01.840
 more than three and a half years since How Motions Are Made came out, and I'm still receiving

1:47:02.400 --> 1:47:09.520
 daily emails from people. So, that's gratifying. But one of the most gratifying emails I received

1:47:09.520 --> 1:47:16.800
 was from a police officer in Texas who told me that he thought that How Motions Are Made

1:47:16.800 --> 1:47:28.720
 contained information that would be really helpful to resolving some of these difficulties.

1:47:28.720 --> 1:47:37.440
 And he hadn't even read my op ed piece about when is a gun not a gun and using what we know

1:47:37.440 --> 1:47:42.880
 about the science of perception from a prediction standpoint, like the brain is a predictor,

1:47:42.880 --> 1:47:48.800
 to understand a little differently what might be happening in these circumstances.

1:47:52.240 --> 1:47:58.320
 It's hard to talk about because everyone gets mad at you when you talk about this.

1:48:00.400 --> 1:48:08.720
 There is a way to understand this which has profound empathy for the suffering of people of

1:48:08.720 --> 1:48:17.920
 color and that definitely is in line with Black Lives Matter at the same time as understanding

1:48:17.920 --> 1:48:24.160
 the really difficult situation that police officers find themselves in. And I'm not talking

1:48:24.160 --> 1:48:28.800
 about this bad apple or that bad apple. I'm not talking about police officers who are necessarily

1:48:28.800 --> 1:48:34.320
 shooting people in the back as they run away. I'm talking about the cases of really good

1:48:34.320 --> 1:48:40.800
 well meaning cops who have the kind of predicting brain that everybody else has.

1:48:42.400 --> 1:48:53.280
 They're in a really difficult situation that I think both they and the people who are harmed

1:48:53.280 --> 1:48:58.880
 don't realize. The way that these situations are constructed, I think it's just,

1:48:59.600 --> 1:49:02.640
 there's a lot to be said there, I guess, is what I want to say.

1:49:02.640 --> 1:49:08.560
 Is there something we can try to say in a sense, like from the perspective of the

1:49:08.560 --> 1:49:16.560
 predictive brain, which is a fascinating perspective to take on this, all the protests

1:49:16.560 --> 1:49:21.600
 that are going on, there seems to be a concept of a police officer being built.

1:49:22.320 --> 1:49:24.720
 No, I think that concept is there.

1:49:24.720 --> 1:49:32.080
 But it's gaining strength, so it's being re... I mean, sure, it is there.

1:49:32.080 --> 1:49:35.840
 Yeah, for sure. But I think, yeah, for sure. I think that that's right. I think that

1:49:38.480 --> 1:49:45.360
 there's a shift in the stereotype of what I would say is a stereotype. There's a stereotype of

1:49:46.400 --> 1:49:51.840
 Black man in this country that's always in movies and television, not always, but largely,

1:49:51.840 --> 1:50:00.880
 that many people watch. I mean, you think you're watching a 10 o clock drama and all you're doing

1:50:00.880 --> 1:50:06.960
 is kicking back and relaxing, but actually, you're having certain predictions reinforced

1:50:06.960 --> 1:50:14.560
 and others not. And what's happening now with police is the same thing, that there are certain

1:50:14.560 --> 1:50:20.000
 stereotypes of a police officer that are being abandoned and other stereotypes that are being

1:50:20.000 --> 1:50:26.480
 reinforced by what you see happening. All I'll say is that if you remember, I mean,

1:50:26.480 --> 1:50:32.960
 there's a lot to say about this, really, that regardless of whether it makes people mad or

1:50:32.960 --> 1:50:43.360
 not, the science is what it is. Just remember what I said. The brain makes predictions about

1:50:43.360 --> 1:50:51.360
 internal changes in the body first, and then it starts to prepare motor action, and then it makes

1:50:51.360 --> 1:51:00.240
 a prediction about what you will see and hear and feel based on those actions. It's also the case

1:51:00.240 --> 1:51:06.560
 that we didn't talk about is that sensory sampling, like your brain's ability to sample what's out

1:51:06.560 --> 1:51:14.160
 there is yoked to your heart rate. It's yoked to your heartbeats. There are certain phases of the

1:51:14.160 --> 1:51:20.560
 heartbeat where it's easier for you to see what's happening in the world than in others. And so,

1:51:20.560 --> 1:51:29.920
 if your heart rate goes through the roof, you will be more likely to just go with your prediction

1:51:29.920 --> 1:51:37.520
 and not correct based on what's out there because you're actually literally not seeing as well.

1:51:39.040 --> 1:51:41.680
 Or you will see things that aren't there, basically.

1:51:43.600 --> 1:51:52.400
 Is there something that we could say by way of advice for when this episode is released

1:51:52.400 --> 1:52:00.800
 in the chaos of emotion? Sorry, I don't know about a term that's just flying around on social

1:52:00.800 --> 1:52:09.040
 media. Well, actually, I think it is emotion in the following sense. It sounds a little bit like

1:52:13.680 --> 1:52:17.360
 artificial in the way that I'm about to say it, but I really think that this is what's

1:52:17.360 --> 1:52:25.120
 happening. One thing we haven't talked about is brains evolved, didn't evolve for you to see,

1:52:25.120 --> 1:52:28.960
 they didn't evolve for you to hear, they didn't evolve for you to feel, they evolved to control

1:52:28.960 --> 1:52:33.280
 your body. That's why you have a brain. You have a brain so that it can control your body.

1:52:34.160 --> 1:52:40.400
 And the metaphor, the scientific term for predictively controlling your body is allostasis.

1:52:40.400 --> 1:52:47.040
 Your brain is attempting to anticipate the needs of your body and meet those needs

1:52:47.040 --> 1:52:54.400
 before they arise so that you can act as you need to act. And the metaphor that I use is a body

1:52:54.400 --> 1:52:59.040
 budget. Your brain is running a budget for your body. It's not budgeting money, it's budgeting

1:52:59.040 --> 1:53:05.920
 glucose and salt and water. And instead of having one or two bank accounts, it has

1:53:05.920 --> 1:53:09.520
 gazillions. There are all these systems in your body that have to be kept in balance.

1:53:09.520 --> 1:53:18.320
 And it's monitoring very closely, it's making predictions about when is it good to spend and

1:53:18.320 --> 1:53:22.560
 when is it good to save and what would be a good investment and am I going to get a return on my

1:53:22.560 --> 1:53:27.920
 investment. Whenever people talk about reward or reward prediction error or anything to do with

1:53:27.920 --> 1:53:33.840
 reward or punishment, they're talking about the body budget. They're talking about your brain's

1:53:33.840 --> 1:53:44.560
 predictions about whether or not there will be a deposit or withdrawal. So, when your brain is

1:53:44.560 --> 1:53:50.320
 running a deficit in your body budgets, you have some kind of metabolic imbalance,

1:53:51.920 --> 1:53:58.720
 you experience that as discomfort. You experience that as distress. When your brain,

1:53:58.720 --> 1:54:06.720
 when things are chaotic, you can't predict what's going to happen next. So, I have this

1:54:06.720 --> 1:54:15.520
 absolutely brilliant scientist working in my lab. His name is Jordan Terrio and he's published this

1:54:15.520 --> 1:54:23.280
 really terrific paper on a sense of should. Why do we have social rules? Why do we

1:54:23.280 --> 1:54:32.800
 adhere to social norms? It's because if I make myself predictable to you, then you are predictable

1:54:32.800 --> 1:54:39.600
 to me. And if you're predictable to me, that's good because that is less metabolically expensive

1:54:39.600 --> 1:54:48.880
 for me. Novelty or unpredictability at the extreme is expensive. And if it goes on for long enough,

1:54:48.880 --> 1:54:55.360
 what happens is, first of all, you will feel really jittery and antsy, which we describe as

1:54:55.360 --> 1:55:04.480
 anxiety. It isn't necessarily anxiety. It could be just something is not predictable and you are

1:55:05.120 --> 1:55:12.000
 experiencing arousal because the chemicals that help you learn increase your feeling of arousal,

1:55:12.000 --> 1:55:16.240
 basically. But if it goes on for long enough, you will become depleted.

1:55:16.240 --> 1:55:23.520
 And you will start to feel really, really, really distressed. So, what we have is a culture full of

1:55:23.520 --> 1:55:32.240
 people right now who are, their body budgets are just decimated and there's a tremendous amount of

1:55:32.240 --> 1:55:41.280
 uncertainty. When you talk about it as depression and anxiety, it makes you think that it's not

1:55:41.280 --> 1:55:46.880
 about your metabolism, that it's not about your body budgeting, that it's not about getting enough

1:55:46.880 --> 1:55:54.880
 sleep or about eating well or about making sure that you have social connections. You think that

1:55:54.880 --> 1:55:59.280
 it's something separate from that. But depression and anxiety are just a way of being in the world.

1:56:00.800 --> 1:56:05.840
 They're a way of being in the world when things aren't quite right with your predictions.

1:56:05.840 --> 1:56:16.560
 That's such a deep way of thinking. The brain is maintaining homeostasis.

1:56:16.560 --> 1:56:23.120
 It's actually allostasis. Allostasis, I'm sorry. And it's constantly making predictions and

1:56:23.120 --> 1:56:28.800
 metabolically speaking, it's very costly to make novel, constantly be learning to making

1:56:28.800 --> 1:56:39.040
 adjustments. And then over time, there's costs to be paid if you're just in a place of chaos,

1:56:39.040 --> 1:56:46.720
 where there's constant need for adjusting and learning and experience novel things.

1:56:46.720 --> 1:56:51.840
 And so, part of the problem here, there are a couple of things. Like I said, it's a perfect

1:56:51.840 --> 1:56:56.880
 storm. There isn't a single cause. There are multiple cause, multiple things that combine

1:56:56.880 --> 1:57:06.400
 together. It's a complex system, multiple things. Part of it is that people are metabolically

1:57:06.400 --> 1:57:13.840
 encumbered and they're distressed. And in order to try to have empathy for someone who is very

1:57:13.840 --> 1:57:23.760
 much unlike you, you have to forage for information. You have to explore information that is novel to

1:57:23.760 --> 1:57:32.400
 you and unexpected. And that's expensive. And at a time when people feel, what do you do when you

1:57:32.400 --> 1:57:38.480
 are running a deficit in your bank account? You stop spending. What does it mean for a brain to

1:57:38.480 --> 1:57:45.920
 stop spending? A brain stops moving very much, stops moving the body, and it stops learning.

1:57:45.920 --> 1:57:55.600
 It just goes with its internal model. So, empathy requires, to have empathy for someone who is

1:57:55.600 --> 1:58:05.600
 unlike you, requires learning and practice, foraging for information. I mean, it is something

1:58:05.600 --> 1:58:09.600
 I talk about in the book in seven and a half lessons about the brain. I think it's really

1:58:09.600 --> 1:58:24.080
 important. It's hard for people to be curious about views that are unlike their own when they

1:58:24.080 --> 1:58:31.040
 feel so encumbered. And I'll just tell you, I had this epiphany really. I was listening to

1:58:31.040 --> 1:58:40.480
 Robert Reisch's The System. He was talking about oligarchy versus democracy. So oligarchy is where

1:58:40.480 --> 1:58:50.160
 very wealthy people, like extremely wealthy people, shift power so that they become even

1:58:50.160 --> 1:58:56.080
 more wealthy and even more insulated from the pressures of the common person.

1:58:56.080 --> 1:59:03.520
 It's actually the kind of system that leads to the collapse of civilizations, if you believe Jared

1:59:03.520 --> 1:59:09.040
 Diamond, just say that. But anyways, I'm listening to this. And I'm listening to him describe,

1:59:09.040 --> 1:59:18.320
 in fairly decent detail, how the CEOs of these companies, there's been a shift in what it means

1:59:18.320 --> 1:59:24.880
 to be a CEO and no longer being a steward of the community and so on. But in the 1980s,

1:59:24.880 --> 1:59:32.800
 it sort of shifted to this other model of being like an oligarch. And he's talking about how it

1:59:32.800 --> 1:59:45.520
 used to be the case that CEOs made 20 times what their employees made. And now they make about

1:59:45.520 --> 1:59:51.440
 300 times on average what their employees made. So where did that money come from? It came from

1:59:51.440 --> 1:59:57.840
 it came from the pockets of the employees. And they don't know about it, right? No one knows

1:59:57.840 --> 2:00:03.440
 about it. They just know they can't feed their children, they can't pay for health care, they

2:00:03.440 --> 2:00:08.160
 can't take care of their family, and they worry about what's going to happen to their, you know,

2:00:08.160 --> 2:00:13.360
 they're living like, you know, months a month, basically, any one big bill could completely,

2:00:13.360 --> 2:00:17.760
 you know, put them out on the street. So there are a huge number of people living like this.

2:00:17.760 --> 2:00:21.520
 So all they, what they're experiencing, they don't know why they're experiencing it. So it's,

2:00:22.160 --> 2:00:28.000
 and then someone comes along and gives them a narrative. Yeah. Well, somebody else butted

2:00:28.000 --> 2:00:34.080
 in line in front of you. And that's why you're this way. That's why you experience what you're

2:00:34.080 --> 2:00:43.680
 experiencing. Just for a minute, I was thinking, I had deep empathy for people who have beliefs

2:00:43.680 --> 2:00:53.600
 that are really, really, really different from mine. But I was trying really hard to see it

2:00:53.600 --> 2:01:02.480
 through their eyes. And did it cost me something metabolically? I'm sure. I'm sure. But you had

2:01:02.480 --> 2:01:08.480
 something in the gas tank. Well, I, in order to allocate that, I mean, that's the question is like,

2:01:08.480 --> 2:01:14.560
 where did you, what resources did your brain draw on in order to actually make that effort?

2:01:14.560 --> 2:01:19.440
 Well, I'll tell you something honestly, Lex, I don't have that much in the gas tank right now.

2:01:21.200 --> 2:01:29.120
 Right. So I am surfing the stress that, you know, stress is just what is stress? Stress is

2:01:29.120 --> 2:01:33.440
 your brain is preparing for a big metabolic outlay and it just keeps preparing and preparing

2:01:33.440 --> 2:01:39.600
 and preparing and preparing. You as a professor, you as a human. Both, right? It's, for me,

2:01:39.600 --> 2:01:45.600
 this is a moment of existential crisis as much as anybody else, democracy, all of these things. So

2:01:47.360 --> 2:01:53.920
 in many of my roles, so I guess what I'm trying to say is that I get up every morning and I

2:01:53.920 --> 2:02:00.640
 exercise. I run, I row, I lift weights, right? You exercise in the middle of the day. I saw

2:02:00.640 --> 2:02:06.720
 your like, you know, daily thing. I'm obsessed with it. Yeah. I hate it actually. You love it,

2:02:06.720 --> 2:02:14.880
 right? You get it. No, I hate it. I hate it, but I do it religiously. Yeah. Why? Because it's a

2:02:14.880 --> 2:02:20.640
 really good investment. It's an expenditure that is a really good investment. And so

2:02:24.800 --> 2:02:30.240
 when I was exercising, I was listening to the book and when I realized the insights that I was

2:02:30.240 --> 2:02:34.720
 sort of like playing around with, like, is this, does this make sense? Does this make sense? I

2:02:34.720 --> 2:02:41.280
 didn't immediately plunge into it. I basically wrote some stuff down, I set it aside, and then I

2:02:41.280 --> 2:02:47.280
 did what I prepared myself to make an expenditure. I don't know what you do before you exercise.

2:02:47.280 --> 2:02:52.960
 I always have a protein shake, always have a protein shake because I need to fuel up before

2:02:52.960 --> 2:02:59.120
 I make this really big expenditure. And so I did the same thing. I didn't have a protein drink,

2:02:59.120 --> 2:03:05.040
 but I did the same thing. And fueling up can mean lots of different things. It can mean talking to

2:03:05.040 --> 2:03:10.480
 a friend about it. It can mean, you know, it can mean making sure you get a good night's sleep

2:03:10.480 --> 2:03:19.120
 before you do it. It can mean lots of different things, but I guess I think we have to do these

2:03:19.120 --> 2:03:25.520
 things. Yeah. I'm going to re listen to this conversation several times. This is brilliant,

2:03:25.520 --> 2:03:35.600
 but I do think about, you know, I've encountered so many people that can't possibly imagine that

2:03:35.600 --> 2:03:43.840
 a good human being can vote for Donald Trump. And I've also encountered people that can't imagine

2:03:43.840 --> 2:03:51.920
 that an intelligent person can possibly vote for Democrat. And I look at both these people,

2:03:51.920 --> 2:03:59.440
 many of whom are friends. And let's just say after this conversation, I can see as they're

2:03:59.440 --> 2:04:06.080
 predicting brains not willing to invest the resources to empathize with the other side.

2:04:06.080 --> 2:04:13.440
 And I think you have to, in order to be able to, like, to see the obvious common humanity

2:04:13.440 --> 2:04:18.880
 in us. I don't know what the system is that's creating this division. We can put it like you

2:04:18.880 --> 2:04:23.120
 said, it's a perfect storm. It might be the social media. I don't know what the hell it is.

2:04:23.120 --> 2:04:25.840
 I think it's a bunch of things. I think it's just coming together.

2:04:25.840 --> 2:04:33.440
 There's an economic system which is disadvantaging large numbers of people. There's a use of social

2:04:33.440 --> 2:04:39.520
 media. Like if you, you know, if I had to orchestrate or architect a system that would

2:04:40.080 --> 2:04:45.440
 screw up a human body budget, it would be the one that we live in. You know, we don't sleep enough,

2:04:45.440 --> 2:04:52.800
 we eat pseudo food basically. We are on social media too much, which is full of ambiguity,

2:04:52.800 --> 2:04:57.440
 which is really hard for a human nervous system, right? Really, really hard, right?

2:04:57.440 --> 2:05:02.240
 Ambiguity with no context to predict in. I mean, it's like, really. And then, you know,

2:05:02.240 --> 2:05:06.640
 there are the economic concerns that affect large swaths of people in this country. I mean, it's

2:05:06.640 --> 2:05:12.880
 really, I'm not saying everything is reducible to metabolism. Not everything is reducible to

2:05:12.880 --> 2:05:19.680
 metabolism, but there, if you combine all these things together, it's helpful to think of it that

2:05:19.680 --> 2:05:27.280
 way. Then somehow it's also, somehow it reduces the entirety of the human experience, the same

2:05:27.280 --> 2:05:32.000
 kind of obvious logic like we should exercise every day in the same kind of way we should,

2:05:32.720 --> 2:05:37.600
 we should empathize every day. Yeah. You know, there are these really wonderful,

2:05:37.600 --> 2:05:44.560
 wonderful programs for teens and sometimes also for parents of people who've lost

2:05:44.560 --> 2:05:51.440
 children in wars and in conflicts, in political conflicts, where they go to a bucolic setting

2:05:51.440 --> 2:05:57.200
 and they talk to each other about their experiences. And miraculous things happen,

2:05:57.200 --> 2:06:10.800
 you know? So, you know, it's easy to, it's easy to sort of shrug this stuff off as kind of

2:06:10.800 --> 2:06:18.160
 Pollyanna ish, you know, like, what's this really going to do? But you have to think about

2:06:18.160 --> 2:06:28.400
 when my daughter went to college, I gave her advice, I said, try to be around people

2:06:29.360 --> 2:06:37.280
 who let you be the kind of person you want to be. You were back to free will. You have a choice.

2:06:38.560 --> 2:06:44.160
 You have a choice. It might seem like a really hard choice. It might seem like an unimaginably

2:06:44.160 --> 2:06:54.400
 difficult choice. You have a choice. Do you want to be somebody who is wrapped in fury and agony?

2:06:54.400 --> 2:07:00.320
 Or do you want to be somebody who extends a little empathy to somebody else and in the

2:07:00.320 --> 2:07:08.720
 process maybe learn something? Curiosity is the thing that protects you. Curiosity is the thing

2:07:08.720 --> 2:07:17.520
 it's curative curiosity. On social media, the thing I recommend to people, at least that's the way

2:07:17.520 --> 2:07:23.360
 I've been approaching social media, it doesn't need to be the common approach, but I basically

2:07:25.760 --> 2:07:32.800
 give love to people who seem to also give love to others. So, it's the same similar concept of

2:07:32.800 --> 2:07:40.320
 surrounding yourself by the people you want to become. I ignore sometimes block, but just ignore.

2:07:40.320 --> 2:07:47.040
 I don't add aggression to people who are just constantly full of aggression and negativity

2:07:47.040 --> 2:07:55.600
 and toxicity. There's a certain desire when somebody says something mean to say something,

2:07:55.600 --> 2:08:03.040
 say why, or try to alleviate the meanness and so on. But what you're doing essentially is

2:08:03.920 --> 2:08:09.680
 you're now surrounding yourself by that group of folks that have that negativity. So, even just

2:08:09.680 --> 2:08:19.920
 the conversation. I think it's just so powerful to put yourself amongst people who are, yeah,

2:08:19.920 --> 2:08:26.800
 whose basic mode of interaction is kindness. Because, I mean, I don't know what it is,

2:08:26.800 --> 2:08:32.640
 but maybe it's the way I'm built, is that to me is energizing for the gas tank of

2:08:32.640 --> 2:08:38.480
 that then I can pull to when I start reading The Rise and Fall of the Third Reich and start

2:08:38.480 --> 2:08:45.120
 thinking about Nazi Germany. I can empathize with everybody involved. I can start to make these

2:08:45.120 --> 2:08:51.360
 difficult thinking that's required to understand our little planet Earth.

2:08:51.920 --> 2:08:56.640
 Well, there is research to back up what you said. There's research that's consistent with

2:08:56.640 --> 2:09:03.840
 your intuition there. There's research that shows that being kind to other people,

2:09:03.840 --> 2:09:12.320
 doing something nice for someone else is like making a deposit to some extent. Because I think

2:09:12.320 --> 2:09:21.760
 making a deposit not only in their body budgets, but also in yours. People feel good when they

2:09:21.760 --> 2:09:28.160
 do good things for other people. We are social animals. We regulate each other's nervous systems

2:09:28.160 --> 2:09:35.120
 for better and for worse. The best thing for a human nervous system is another human.

2:09:35.120 --> 2:09:44.000
 The worst thing for a human nervous system is another human. You decide. Do you want to be

2:09:44.000 --> 2:09:52.240
 somebody who makes people feel better or do you want to be somebody who causes people pain?

2:09:54.240 --> 2:10:01.840
 We are more responsible for one another than we might like or than we might want.

2:10:01.840 --> 2:10:09.840
 But remember what we said about social reality. There are lots of different cultural

2:10:11.840 --> 2:10:21.840
 norms about independence or collective nature of people. But the fact is we have

2:10:22.560 --> 2:10:28.640
 socially dependent nervous systems. We evolved that way as a species. In this country,

2:10:28.640 --> 2:10:37.600
 we prize individual rights and freedoms. That is a dilemma that we have to grapple with.

2:10:38.640 --> 2:10:42.400
 We have to do it in a way, if we're going to be productive about it, we have to do it in a way

2:10:43.040 --> 2:10:53.520
 that requires engaging with each other, which is what I understand the founding members of this

2:10:53.520 --> 2:11:02.240
 country intended. Beautifully put, let me ask a few final silly questions. One,

2:11:04.000 --> 2:11:11.440
 talk a bit about love. It's fun to ask somebody like you who can effectively, from at least

2:11:11.440 --> 2:11:16.320
 neuroscience perspective, disassemble some of these romantic notions. But what do you make of

2:11:16.320 --> 2:11:25.120
 romantic love? Why do human beings seem to fall in love, at least a bunch of 80s hair bands have

2:11:25.120 --> 2:11:34.160
 written about it? Is that a nice feature to have? Is that a bug? What is it? I'm really happy that

2:11:34.160 --> 2:11:40.400
 I fell in love. I wouldn't want it any other way. Is that you, the person speaking, or the

2:11:40.400 --> 2:11:46.480
 neuroscientist? Well, that's me, the person speaking. But I would say as a neuroscientist,

2:11:47.360 --> 2:11:52.640
 babies are born not able to regulate their own body budgets because their brains aren't fully

2:11:52.640 --> 2:12:02.960
 wired yet. When you feed a baby, when you cuddle a baby, when everything you do with a baby impacts

2:12:02.960 --> 2:12:06.480
 that baby's body budget and helps to wire that baby's body budget,

2:12:06.480 --> 2:12:13.520
 it has to wire that baby's brain to manage eventually her own body budget to some extent.

2:12:13.520 --> 2:12:17.040
 That's the basis biologically of attachment.

2:12:20.320 --> 2:12:31.360
 Humans evolved as a species to be socially dependent, meaning you cannot manage your body

2:12:31.360 --> 2:12:41.440
 budget on your own without attacks that eventually you pay many years later in terms of some

2:12:41.440 --> 2:12:48.640
 metabolic illness. Loneliness, when you break up with someone that you love or you lose them,

2:12:50.080 --> 2:12:55.520
 you feel like it's going to kill you, but it doesn't. But loneliness will kill you. It will

2:12:55.520 --> 2:13:01.440
 kill you approximately seven years earlier. I can't remember exactly the exact number. It's

2:13:01.440 --> 2:13:08.480
 actually in the web notes to seven and a half lessons. But social isolation and loneliness

2:13:08.480 --> 2:13:15.680
 will kill you earlier than you would otherwise die. The reason why is that you didn't evolve

2:13:15.680 --> 2:13:22.240
 to manage your nervous system on your own. When you do, you pay a little tax and that tax accrues

2:13:22.240 --> 2:13:29.040
 very slightly over time, over a long period of time, so that by the time you're in middle age

2:13:29.040 --> 2:13:35.600
 or a little older, you are more likely to die sooner from some metabolic illness, from heart

2:13:35.600 --> 2:13:40.800
 disease, from diabetes, from depression. You're more likely to develop Alzheimer's disease.

2:13:43.280 --> 2:13:51.200
 It takes a long time for that tax to accrue, but it does. Yes, I think it's a good thing for people

2:13:51.200 --> 2:13:59.760
 to fall in love. But I think the funny view of it is that it's clear that humans need the social

2:14:00.480 --> 2:14:09.120
 attachment to what is it, manage their nervous system as you're describing, and the reason

2:14:09.120 --> 2:14:15.200
 you want to stay with somebody for a long time is so you don't have, is the novelty is very costly

2:14:15.200 --> 2:14:21.920
 for... Well, now you're mixing. Now you're mixing things. Now you have to decide whether. But what

2:14:21.920 --> 2:14:30.000
 I would say is when you lose someone you love, it feels like you've lost a part of you. And that's

2:14:30.000 --> 2:14:37.920
 because you have. You've lost someone who was contributing to your body budget. We are the

2:14:37.920 --> 2:14:46.000
 caretakers of one another's nervous systems, like it or not. And out of that comes very deep

2:14:46.000 --> 2:14:55.760
 feelings of attachment, some of which are romantic love. Are you afraid of your own mortality?

2:14:55.760 --> 2:15:03.600
 We're two humans sitting here. Do you ponder your mortality? I mean, some of you think about

2:15:03.600 --> 2:15:13.120
 your brain a lot. It seems one of the more terrifying or, I don't know, I don't know how

2:15:13.120 --> 2:15:17.680
 to feel about it, but it seems to be one of the most definitive aspects of life is that it ends.

2:15:18.400 --> 2:15:23.440
 It's a complicated answer, but I think the best I can do in a short snippet would be to say,

2:15:23.440 --> 2:15:34.160
 for a very long time, I did not fear my own mortality. I feared pain and suffering. So

2:15:35.040 --> 2:15:39.600
 that's what I feared. I feared being harmed or dying in a way that would be painful.

2:15:39.600 --> 2:15:55.520
 But I didn't fear having my life be over. Now, as a mother, I fear dying before my daughter

2:15:55.520 --> 2:16:11.520
 is ready to be without me. That's what I fear. That's really what I fear. And frankly, honestly,

2:16:11.520 --> 2:16:15.280
 I fear my husband dying before me much more than I fear my own death.

2:16:16.560 --> 2:16:19.120
 There's that love and social attachment again.

2:16:19.120 --> 2:16:25.520
 Yeah, because I know it's just going to, I'm going to feel like I wish I was dead.

2:16:25.520 --> 2:16:30.560
 Yeah. A final question about life. What do you think is the meaning of it all?

2:16:32.080 --> 2:16:33.120
 What's the meaning of life?

2:16:36.240 --> 2:16:40.960
 Yeah, I think that there isn't one meaning of life. There's like many meanings of life,

2:16:40.960 --> 2:16:44.320
 and you use different ones on different days. But for me,

2:16:44.320 --> 2:16:48.640
 depending on the day. Depending on the day. But for me, I would say

2:16:50.480 --> 2:16:56.240
 sometimes the meaning of life is to understand, to make meaning, actually. The meaning of life

2:16:56.240 --> 2:17:05.040
 is to make meaning. Sometimes it's that. Sometimes it's to leave the world just slightly a little

2:17:05.040 --> 2:17:21.840
 bit better than the Johnny Appleseed view. Sometimes the meaning of life is to clear the path for my

2:17:21.840 --> 2:17:29.920
 daughter or for my students. So sometimes it's that. And sometimes it's just,

2:17:29.920 --> 2:17:43.840
 even in moments where you're looking at the sky or you're by the ocean, or sometimes for me,

2:17:43.840 --> 2:17:54.480
 it's even like I'll see a weed poking out of a crack in a sidewalk. And you just have this

2:17:54.480 --> 2:18:06.880
 overwhelming sense of the wonder of the world. The world is just like, the physical world is so

2:18:08.400 --> 2:18:17.440
 wondrous. And you just get very immersed in the moment, like the sensation of the moment.

2:18:18.000 --> 2:18:22.320
 Sometimes that's the meaning of life. I don't think there's one meaning of life. I think it's a

2:18:22.320 --> 2:18:29.600
 population of instances, just like any other category. I don't think there's a better way to

2:18:29.600 --> 2:18:37.920
 end it. Lisa, the first time we spoke is, I think, if not the, then one of, I think it's the first

2:18:38.880 --> 2:18:42.960
 conversation I had that basically launched this podcast. Yeah, that's actually the first

2:18:42.960 --> 2:18:48.480
 conversation I've had that launched this podcast. Oh, wow. And now we get to finally do it the right

2:18:48.480 --> 2:18:54.160
 way. So it's a huge honor to talk to you that you've spent time with me. I can't wait for,

2:18:54.160 --> 2:19:00.000
 hopefully, the many more books you'll write. Certainly can't wait to, I already read this

2:19:00.000 --> 2:19:05.280
 book, but I can't wait to listen to it because as you said offline, that you're reading it.

2:19:05.840 --> 2:19:09.600
 And I think you have a great voice. You have a great, I don't know, what's the nice way to

2:19:09.600 --> 2:19:16.240
 put it, but maybe NPR voice in the best version of what that is. So thanks again for talking to

2:19:16.240 --> 2:19:21.760
 me today. Oh, it's my pleasure. Thank you so much for having me back. Thank you for listening to

2:19:21.760 --> 2:19:27.520
 this conversation with Lisa Feldman Barrett. And thank you to our sponsors, Athletic Greens,

2:19:27.520 --> 2:19:34.160
 which is an all in one nutritional drink, Magic Spoon, which is a low carb keto friendly cereal,

2:19:34.160 --> 2:19:39.680
 and Cash App, which is an app for sending money to your friends. Please check out these sponsors

2:19:39.680 --> 2:19:45.200
 in the description to get a discount and to support this podcast. If you enjoy this thing,

2:19:45.200 --> 2:19:50.080
 subscribe on YouTube, review it with five stars on Apple Podcasts, follow on Spotify,

2:19:50.080 --> 2:19:56.720
 support on Patreon, or connect with me on Twitter, Alex Friedman. And now let me leave you with some

2:19:56.720 --> 2:20:03.600
 words from Lisa Feldman Barrett. It takes more than one human brain to create a human mind.

2:20:03.600 --> 2:20:16.400
 Thank you for listening. I hope to see you next time.

