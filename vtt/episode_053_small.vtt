WEBVTT

00:00.000 --> 00:03.800
 The following is a conversation with Noam Chomsky.

00:03.800 --> 00:06.760
 He's truly one of the great minds of our time

00:06.760 --> 00:08.400
 and is one of the most cited scholars

00:08.400 --> 00:10.840
 in the history of our civilization.

00:10.840 --> 00:13.400
 He has spent over 60 years at MIT

00:13.400 --> 00:16.280
 and recently also joined the University of Arizona

00:16.280 --> 00:18.600
 where we met for this conversation.

00:18.600 --> 00:21.760
 But it was at MIT about four and a half years ago

00:21.760 --> 00:23.400
 when I first met Noam.

00:23.400 --> 00:24.720
 In my first few days there,

00:24.720 --> 00:27.400
 I remember getting into an elevator status center,

00:27.400 --> 00:29.480
 pressing the button for whatever floor,

00:29.480 --> 00:32.080
 looking up and realizing it was just me

00:32.080 --> 00:35.480
 and Noam Chomsky riding the elevator.

00:35.480 --> 00:38.400
 Just me and one of the seminal figures of linguistics,

00:38.400 --> 00:40.000
 cognitive science, philosophy,

00:40.000 --> 00:43.920
 and political thought in the past century, if not ever.

00:43.920 --> 00:46.600
 I tell that silly story because I think

00:46.600 --> 00:49.200
 life is made up of funny little defining moments

00:49.200 --> 00:51.520
 that you never forget for reasons

00:51.520 --> 00:54.880
 that may be too poetic to try and explain.

00:54.880 --> 00:56.140
 That was one of mine.

00:57.320 --> 00:59.320
 Noam has been an inspiration to me

00:59.320 --> 01:00.920
 and millions of others.

01:00.920 --> 01:02.560
 It was truly an honor for me

01:02.560 --> 01:04.600
 to sit down with him in Arizona.

01:04.600 --> 01:07.480
 I traveled there just for this conversation.

01:07.480 --> 01:10.120
 And in a rare heartbreaking moment,

01:10.120 --> 01:12.680
 after everything was set up and tested,

01:12.680 --> 01:14.480
 the camera was moved and accidentally

01:14.480 --> 01:15.920
 the recording button was pressed,

01:15.920 --> 01:17.160
 stopping the recording.

01:18.520 --> 01:20.360
 So I have good audio of both of us,

01:20.360 --> 01:22.160
 but no video of Noam.

01:22.160 --> 01:25.120
 Just the video of me and my sleep deprived

01:25.120 --> 01:27.960
 but excited face that I get to keep

01:27.960 --> 01:30.480
 as a reminder of my failures.

01:30.480 --> 01:32.440
 Most people just listen to this audio version

01:32.440 --> 01:35.760
 for the podcast as opposed to watching it on YouTube.

01:35.760 --> 01:39.000
 But still, it's heartbreaking for me.

01:39.000 --> 01:40.960
 I hope you understand and still enjoy

01:40.960 --> 01:43.120
 this conversation as much as I did.

01:43.120 --> 01:45.320
 The depth of intellect that Noam showed

01:45.320 --> 01:48.320
 and his willingness to truly listen to me,

01:48.320 --> 01:51.160
 a silly looking Russian in a suit.

01:51.160 --> 01:54.640
 It was humbling and something I'm deeply grateful for.

01:55.560 --> 01:56.840
 As some of you know,

01:56.840 --> 01:59.640
 this podcast is a side project for me.

01:59.640 --> 02:03.600
 Where my main journey and dream is to build AI systems

02:03.600 --> 02:05.480
 that do some good for the world.

02:05.480 --> 02:07.840
 This latter effort takes up most of my time,

02:07.840 --> 02:10.560
 but for the moment has been mostly private.

02:10.560 --> 02:12.840
 But the former, the podcast,

02:12.840 --> 02:15.400
 is something I put my heart and soul into.

02:15.400 --> 02:18.600
 And I hope you feel that, even when I screw things up.

02:19.560 --> 02:21.160
 I recently started doing ads

02:21.160 --> 02:22.880
 at the end of the introduction.

02:22.880 --> 02:25.680
 I'll do one or two minutes after introducing the episode

02:25.680 --> 02:27.440
 and never any ads in the middle

02:27.440 --> 02:29.760
 that break the flow of the conversation.

02:29.760 --> 02:31.200
 I hope that works for you.

02:31.200 --> 02:34.000
 It doesn't hurt the listening experience.

02:34.000 --> 02:37.240
 This is the Artificial Intelligence Podcast.

02:37.240 --> 02:39.840
 If you enjoy it, subscribe on YouTube,

02:39.840 --> 02:41.880
 give it five stars on Apple Podcast,

02:41.880 --> 02:43.280
 support it on Patreon,

02:43.280 --> 02:45.440
 or simply connect with me on Twitter.

02:45.440 --> 02:49.480
 Alex Friedman, spelled F R I D M A N.

02:49.480 --> 02:51.760
 This show is presented by Cash App,

02:51.760 --> 02:54.280
 the number one finance app in the App Store.

02:54.280 --> 02:56.840
 I personally use Cash App to send money to friends,

02:56.840 --> 02:58.800
 but you can also use it to buy, sell,

02:58.800 --> 03:01.360
 and deposit Bitcoin in just seconds.

03:01.360 --> 03:04.200
 Cash App also has a new investing feature.

03:04.200 --> 03:05.800
 You can buy fractions of a stock,

03:05.800 --> 03:09.240
 say $1 worth, no matter what the stock price is.

03:09.240 --> 03:12.000
 Brokerage services are provided by Cash App Investing,

03:12.000 --> 03:15.600
 a subsidiary of Square, and member SIPC.

03:15.600 --> 03:17.680
 I'm excited to be working with Cash App

03:17.680 --> 03:20.920
 to support one of my favorite organizations called the First,

03:20.920 --> 03:24.240
 best known for their first robotics and Lego competitions.

03:24.240 --> 03:27.600
 They educate and inspire hundreds of thousands of students

03:27.600 --> 03:29.520
 in over 110 countries

03:29.520 --> 03:31.720
 and have a perfect rating on Charity Navigator,

03:31.720 --> 03:34.240
 which means the donated money is used

03:34.240 --> 03:36.440
 to maximum effectiveness.

03:36.440 --> 03:38.600
 When you get Cash App from the App Store,

03:38.600 --> 03:42.720
 Google Play, and use code LEX Podcast,

03:42.720 --> 03:47.040
 you'll get $10 and Cash App will also donate $10 to First,

03:47.040 --> 03:49.680
 which again is an organization that I've personally seen

03:49.680 --> 03:54.440
 inspire girls and boys to dream of engineering a better world.

03:54.440 --> 03:59.720
 And now, here's my conversation with Noam Chomsky.

03:59.720 --> 04:04.040
 I apologize for the absurd philosophical question,

04:04.040 --> 04:08.080
 but if an alien species were to visit Earth,

04:08.080 --> 04:10.840
 do you think we would be able to find a common language

04:10.840 --> 04:13.600
 or protocol of communication with them?

04:13.600 --> 04:18.240
 There are arguments to the effect that we could.

04:18.240 --> 04:22.400
 In fact, one of them was Marv Minsky's.

04:22.400 --> 04:24.680
 Back about 20 or 30 years ago,

04:24.680 --> 04:30.000
 he performed a brief experiment with a student of his,

04:30.000 --> 04:35.000
 Dan Bobrow, who essentially ran the simplest possible

04:35.000 --> 04:39.520
 touring machines, just for you to see what would happen.

04:39.520 --> 04:42.520
 And most of them crashed,

04:42.520 --> 04:47.720
 either got into an infinite loop or stopped.

04:47.720 --> 04:53.680
 The few that persisted essentially gave something

04:53.680 --> 04:59.920
 like arithmetic, and his conclusion from that was that

04:59.920 --> 05:05.760
 if some alien species developed higher intelligence,

05:05.760 --> 05:07.440
 they would at least have arithmetic.

05:07.440 --> 05:12.880
 They would at least have what the simplest computer would do.

05:12.880 --> 05:16.000
 And in fact, he didn't know that at the time,

05:16.000 --> 05:20.720
 but the core principles of natural language

05:20.720 --> 05:26.200
 are based on operations which yield something like arithmetic

05:26.200 --> 05:29.320
 in the limiting case and the minimal case.

05:29.320 --> 05:34.000
 So it's conceivable that a mode of communication

05:34.000 --> 05:38.520
 could be established based on the core properties

05:38.520 --> 05:41.440
 of human language and the core properties of arithmetic,

05:41.440 --> 05:44.880
 which maybe are universally shared.

05:44.880 --> 05:46.680
 So it's conceivable.

05:46.680 --> 05:50.800
 What is the structure of that language,

05:50.800 --> 05:55.160
 of language as an internal system inside our mind

05:55.160 --> 05:58.920
 versus an external system as it's expressed?

05:58.920 --> 06:00.880
 It's not an alternative.

06:00.880 --> 06:02.920
 It's two different concepts of language.

06:02.920 --> 06:03.680
 Different.

06:03.680 --> 06:07.240
 It's a simple fact that there's something about you,

06:07.240 --> 06:11.680
 a trait of yours, part of the organism you,

06:11.680 --> 06:14.600
 that determines that you're talking English

06:14.600 --> 06:17.000
 and not Tagalog, let's say.

06:17.000 --> 06:19.480
 So there is an inner system.

06:19.480 --> 06:22.960
 It determines the sound and meaning

06:22.960 --> 06:27.120
 of the infinite number of expressions of your language.

06:27.120 --> 06:28.680
 It's localized.

06:28.680 --> 06:30.360
 It's not in your foot, obviously.

06:30.360 --> 06:31.760
 It's in your brain.

06:31.760 --> 06:35.240
 If you look more closely, it's in specific configurations

06:35.240 --> 06:36.480
 of your brain.

06:36.480 --> 06:40.560
 And that's essentially like the internal structure

06:40.560 --> 06:44.960
 of your laptop, whatever programs it has are in there.

06:44.960 --> 06:47.800
 Now, one of the things you can do with language,

06:47.800 --> 06:53.360
 it's a marginal thing, in fact, is use it to externalize

06:53.360 --> 06:54.800
 what's in your head.

06:54.800 --> 06:56.640
 Actually, most of your use of language

06:56.640 --> 06:58.760
 is thought, internal thought.

06:58.760 --> 07:00.920
 But you can do what you and I are now doing.

07:00.920 --> 07:02.640
 We can externalize it.

07:02.640 --> 07:05.640
 Well, the set of things that we're externalizing

07:05.640 --> 07:11.120
 are an external system that there are noises in the atmosphere.

07:11.120 --> 07:14.320
 And you can call that language in some other sense of the word.

07:14.320 --> 07:16.760
 But it's not a set of alternatives.

07:16.760 --> 07:18.960
 These are just different concepts.

07:18.960 --> 07:23.480
 So how deep do the roots of language go in our brain?

07:23.480 --> 07:24.400
 Our mind.

07:24.400 --> 07:26.760
 Is it yet another feature like vision,

07:26.760 --> 07:29.240
 or is it something more fundamental from which everything

07:29.240 --> 07:31.480
 else springs in the human mind?

07:31.480 --> 07:33.680
 Well, in a way, it's like vision.

07:33.680 --> 07:38.600
 And there's something about our genetic endowment

07:38.600 --> 07:41.960
 that determines that we have a mammalian rather

07:41.960 --> 07:44.720
 than an insect visual system.

07:44.720 --> 07:48.080
 And there's something in our genetic endowment

07:48.080 --> 07:51.480
 that determines that we have a human language faculty.

07:51.480 --> 07:55.200
 No other organism has anything remotely similar.

07:55.200 --> 07:58.280
 So in that sense, it's internal.

07:58.280 --> 08:00.200
 Now, there is a long tradition, which I think

08:00.200 --> 08:04.800
 is valid going back centuries, to the early scientific

08:04.800 --> 08:09.320
 revolution, at least, that holds that language

08:09.320 --> 08:13.640
 is the core of human cognitive nature.

08:13.640 --> 08:14.600
 It's the source.

08:14.600 --> 08:18.080
 It's the mode for constructing thoughts

08:18.080 --> 08:19.640
 and expressing them.

08:19.640 --> 08:22.760
 That is what forms thought.

08:22.760 --> 08:27.200
 And it's got fundamental creative capacities.

08:27.200 --> 08:31.280
 It's free, independent, unbounded, and so on.

08:31.280 --> 08:34.840
 And undoubtedly, I think the basis

08:34.840 --> 08:42.920
 for our creative capacities and the other remarkable human

08:42.920 --> 08:47.480
 capacities that lead to the unique achievements

08:47.480 --> 08:51.280
 and not so great achievements of the species.

08:51.280 --> 08:53.600
 The capacity to think and reason.

08:53.600 --> 08:56.200
 Do you think that's deeply linked with language?

08:56.200 --> 08:59.840
 Do you think the way the internal language system

08:59.840 --> 09:03.000
 is essentially the mechanism by which we also reason

09:03.000 --> 09:04.120
 internally?

09:04.120 --> 09:06.920
 It is undoubtedly the mechanism by which we reason.

09:06.920 --> 09:10.840
 There may also be other fact there are undoubtedly

09:10.840 --> 09:14.720
 other faculties involved in reasoning.

09:14.720 --> 09:17.520
 We have a kind of scientific faculty.

09:17.520 --> 09:18.800
 Nobody knows what it is.

09:18.800 --> 09:20.880
 But whatever it is that enables us

09:20.880 --> 09:25.440
 to pursue certain lines of endeavor and inquiry

09:25.440 --> 09:29.720
 and to decide what makes sense and doesn't make sense

09:29.720 --> 09:32.960
 and to achieve a certain degree of understanding

09:32.960 --> 09:37.400
 of the world, that uses language but goes beyond it.

09:37.400 --> 09:42.000
 Just as using our capacity for arithmetic

09:42.000 --> 09:44.880
 is not the same as having the capacity.

09:44.880 --> 09:49.360
 The idea of capacity, our biology, evolution,

09:49.360 --> 09:52.520
 you've talked about it defining essentially our capacity,

09:52.520 --> 09:55.200
 our limit, and our scope.

09:55.200 --> 09:58.840
 Can you try to define what limit and scope are?

09:58.840 --> 10:01.640
 And the bigger question, do you think

10:01.640 --> 10:07.560
 it's possible to find the limit of human cognition?

10:07.560 --> 10:09.640
 Well, that's an interesting question.

10:09.640 --> 10:13.080
 It's commonly believed, most scientists believe,

10:13.080 --> 10:19.360
 that a human intelligence can answer any question in principle.

10:19.360 --> 10:21.800
 I think that's a very strange belief.

10:21.800 --> 10:26.280
 If we're biological organisms, which are not angels,

10:26.280 --> 10:33.240
 then our capacities ought to have scope and limits,

10:33.240 --> 10:34.920
 which are interrelated.

10:34.920 --> 10:36.640
 Can you define those two terms?

10:36.640 --> 10:40.840
 Well, let's take a concrete example.

10:40.840 --> 10:44.040
 Your genetic endowment determines

10:44.040 --> 10:47.960
 that you can have a male in visual system, arms and legs

10:47.960 --> 10:50.040
 and so on.

10:50.040 --> 10:53.480
 And therefore become a rich, complex organism.

10:53.480 --> 10:56.280
 But if you look at that same genetic endowment,

10:56.280 --> 11:00.040
 it prevents you from developing in other directions.

11:00.040 --> 11:02.040
 There's no kind of experience which

11:02.040 --> 11:08.800
 would yield the embryo to develop an insect visual system

11:08.800 --> 11:12.040
 or to develop wings instead of arms.

11:12.040 --> 11:18.520
 So the very endowment that confers richness and complexity

11:18.520 --> 11:23.600
 also sets bounds on what can be attained.

11:23.600 --> 11:27.440
 Now, I assume that our cognitive capacities

11:27.440 --> 11:29.720
 are part of the organic world.

11:29.720 --> 11:32.280
 Therefore, they should have the same properties.

11:32.280 --> 11:36.600
 If they had no built in capacity to develop

11:36.600 --> 11:41.920
 a rich and complex structure, we would have understand nothing.

11:41.920 --> 11:47.080
 Just as if your genetic endowment did not

11:47.080 --> 11:50.320
 compel you to develop arms and legs,

11:50.320 --> 11:54.000
 you would just be some kind of a random amoeboid creature

11:54.000 --> 11:56.080
 with no structure at all.

11:56.080 --> 12:00.200
 So I think it's plausible to assume that there are limits.

12:00.200 --> 12:03.680
 And I think we even have some evidence as to what they are.

12:03.680 --> 12:06.640
 So for example, there's a classic moment

12:06.640 --> 12:09.080
 in the history of science.

12:09.080 --> 12:13.880
 At the time of Newton, there was from Galileo to Newton,

12:13.880 --> 12:18.120
 modern science, developed on a fundamental assumption, which

12:18.120 --> 12:22.440
 Newton also accepted, namely that the world,

12:22.440 --> 12:26.320
 as the entire universe, is a mechanical object.

12:26.320 --> 12:29.000
 And by mechanical, they meant something

12:29.000 --> 12:31.600
 like the kinds of artifacts that were being developed

12:31.600 --> 12:35.800
 by skilled artisans all over Europe, the Gears, the Leavers,

12:35.800 --> 12:37.120
 and so on.

12:37.120 --> 12:39.760
 And their belief was, well, the world

12:39.760 --> 12:42.960
 is just a more complex variant of this.

12:42.960 --> 12:48.400
 Newton, to his astonishment and distress,

12:48.400 --> 12:50.960
 proved that there are no machines,

12:50.960 --> 12:54.320
 that there's interaction without contact.

12:54.320 --> 12:57.680
 His contemporaries, like Leibniz and Huygens,

12:57.680 --> 13:02.560
 just dismissed this as returning to the mysticism

13:02.560 --> 13:04.000
 of the Neoscholastics.

13:04.000 --> 13:05.880
 And Newton agreed.

13:05.880 --> 13:08.280
 He said, it is totally absurd.

13:08.280 --> 13:11.120
 No person of any scientific intelligence

13:11.120 --> 13:13.760
 could ever accept this for a moment.

13:13.760 --> 13:15.320
 In fact, he spent the rest of his life

13:15.320 --> 13:20.360
 trying to get around it somehow, as did many other scientists.

13:20.360 --> 13:24.080
 That was the very criterion of intelligibility,

13:24.080 --> 13:29.280
 for say, Galileo or Newton theory did not

13:29.280 --> 13:31.640
 produce an intelligible world unless you

13:31.640 --> 13:34.080
 get duplicated in a machine.

13:34.080 --> 13:35.120
 He said, you can't.

13:35.120 --> 13:36.400
 There are no machines.

13:36.400 --> 13:41.240
 And finally, after a long struggle, took a long time,

13:41.240 --> 13:45.200
 scientists just accepted this as common sense.

13:45.200 --> 13:47.360
 But that's a significant moment.

13:47.360 --> 13:49.320
 That means they abandoned the search

13:49.320 --> 13:51.760
 for an intelligible world.

13:51.760 --> 13:54.760
 And the great philosophers of the time

13:54.760 --> 13:57.000
 understood that very well.

13:57.000 --> 14:02.280
 So for example, David Hume, in his encomium to Newton,

14:02.280 --> 14:05.520
 wrote that he was the greatest thinker ever and so on.

14:05.520 --> 14:10.480
 He said that he unveiled many of the secrets of nature.

14:10.480 --> 14:15.840
 But by showing the imperfections of the mechanical philosophy,

14:15.840 --> 14:19.240
 mechanical science, he left us with,

14:19.240 --> 14:23.520
 he showed that there are mysteries which ever will remain.

14:23.520 --> 14:26.720
 And science just changed its goals.

14:26.720 --> 14:28.520
 It abandoned the mystery.

14:28.520 --> 14:29.760
 He said, can't solve it.

14:29.760 --> 14:31.400
 We'll put it aside.

14:31.400 --> 14:34.720
 We only look for intelligible theories.

14:34.720 --> 14:36.680
 Newton's theories were intelligible.

14:36.680 --> 14:39.080
 It's just what they described wasn't.

14:39.080 --> 14:42.800
 Well, Locke said the same thing.

14:42.800 --> 14:44.800
 I think they're basically right.

14:44.800 --> 14:47.840
 And if so, that should something about the limits

14:47.840 --> 14:49.800
 of human cognition.

14:49.800 --> 14:54.560
 We cannot attain the goal of understanding

14:54.560 --> 14:58.400
 the world, of finding an intelligible world.

14:58.400 --> 15:03.640
 This mechanical philosophy, Galileo to Newton,

15:03.640 --> 15:06.360
 this good case can be made that that's

15:06.360 --> 15:11.000
 our instinctive conception of how things work.

15:11.000 --> 15:17.160
 So if say infants are tested with things that, if this moves,

15:17.160 --> 15:20.480
 and then this moves, they kind of invent something

15:20.480 --> 15:23.000
 that must be invisible that's in between them

15:23.000 --> 15:24.920
 that's making the move and so on.

15:24.920 --> 15:26.520
 Yeah, we like physical contact.

15:26.520 --> 15:28.920
 Something about our brain seeks.

15:28.920 --> 15:31.560
 Makes us want a world like that.

15:31.560 --> 15:36.640
 Just like it wants a world that has regular geometric figures.

15:36.640 --> 15:38.920
 So for example, Descartes pointed this out,

15:38.920 --> 15:45.160
 that if you have an infant who's never seen a triangle before

15:45.160 --> 15:48.360
 and you draw a triangle, the infant

15:48.360 --> 15:52.280
 will see a distorted triangle.

15:52.280 --> 15:56.360
 Not whatever crazy figure it actually is.

15:56.360 --> 15:58.440
 Three lines not coming quite together.

15:58.440 --> 16:00.320
 One of them a little bit curved and so on.

16:00.320 --> 16:04.520
 We just impose a conception of the world

16:04.520 --> 16:09.320
 in terms of geometric, perfect geometric objects.

16:09.320 --> 16:12.160
 It's now been shown that goes way beyond that.

16:12.160 --> 16:15.440
 That if you show on a tachistoscope,

16:15.440 --> 16:18.560
 let's say a couple of lights shining,

16:18.560 --> 16:20.880
 you do it three or four times in a row,

16:20.880 --> 16:25.280
 what people actually see is a rigid object in motion,

16:25.280 --> 16:28.200
 not whatever is there.

16:28.200 --> 16:31.840
 We all know that from a television set basically.

16:31.840 --> 16:35.920
 So that gives us hints of potential limits to our cognition.

16:35.920 --> 16:39.400
 I think it does, but it's a very contested view.

16:39.400 --> 16:43.720
 If you do a poll among scientists, it's impossible.

16:43.720 --> 16:46.320
 We can understand anything.

16:46.320 --> 16:48.680
 Let me ask and give me a chance with this.

16:48.680 --> 16:52.520
 So I just spent a day at a company called Neuralink.

16:52.520 --> 16:57.800
 And what they do is try to design what's called a brain machine,

16:57.800 --> 16:59.600
 brain computer interface.

16:59.600 --> 17:03.320
 So they try to do thousands readings in the brain,

17:03.320 --> 17:05.600
 be able to read what the neurons are firing,

17:05.600 --> 17:08.560
 and then stimulate back, so two way.

17:08.560 --> 17:14.400
 Do you think their dream is to expand the capacity of the brain

17:14.400 --> 17:18.160
 to attain information, sort of increase the bandwidth

17:18.160 --> 17:22.480
 to which we can search Google kind of thing?

17:22.480 --> 17:24.960
 Do you think our cognitive capacity

17:24.960 --> 17:28.280
 might be expanded, our linguistic capacity,

17:28.280 --> 17:30.360
 our ability to reason might be expanded

17:30.360 --> 17:33.200
 by adding a machine into the picture?

17:33.200 --> 17:35.640
 It can be expanded in a certain sense,

17:35.640 --> 17:40.320
 but a sense that was known thousands of years ago.

17:40.320 --> 17:44.080
 A book expands your cognitive capacity.

17:44.080 --> 17:46.080
 So this could expand it too.

17:46.080 --> 17:47.960
 But it's not a fundamental expansion.

17:47.960 --> 17:51.000
 It's not totally new things could be understood.

17:51.000 --> 17:56.480
 Well, nothing that goes beyond our native cognitive capacities,

17:56.480 --> 17:58.640
 just like you can't turn the visual system

17:58.640 --> 18:00.680
 into an insect system.

18:00.680 --> 18:06.840
 Well, I mean, the thought is perhaps you can't directly,

18:06.840 --> 18:08.400
 but you can map.

18:08.400 --> 18:12.400
 You could, but we already know that without this experiment.

18:12.400 --> 18:16.720
 You could map what a bee sees and present it in a form

18:16.720 --> 18:17.960
 so that we could follow it.

18:17.960 --> 18:21.000
 In fact, every bee scientist does it.

18:21.000 --> 18:25.400
 But you don't think there's something greater than bees

18:25.400 --> 18:29.720
 that we can map and then all of a sudden discover something,

18:29.720 --> 18:33.800
 be able to understand a quantum world, quantum mechanics,

18:33.800 --> 18:36.040
 be able to start to be able to make sense.

18:36.040 --> 18:41.680
 Students at MIT study and understand quantum mechanics.

18:41.680 --> 18:45.160
 But they always reduce it to the infant, the physical.

18:45.160 --> 18:46.880
 I mean, they don't really understand it.

18:46.880 --> 18:48.240
 Oh, there's a thing.

18:48.240 --> 18:50.840
 That may be another area where there's just

18:50.840 --> 18:52.720
 a limit to understanding.

18:52.720 --> 18:56.720
 We understand the theories, but the world that it describes

18:56.720 --> 18:58.440
 doesn't make any sense.

18:58.440 --> 19:02.360
 So the experiment, Schrodinger's cat, for example,

19:02.360 --> 19:03.680
 can understand the theory.

19:03.680 --> 19:09.280
 But as Schrodinger pointed out, it's an unintelligible world.

19:09.280 --> 19:12.320
 One of the reasons why Einstein was always

19:12.320 --> 19:15.760
 very skeptical about quantum theory.

19:15.760 --> 19:21.360
 He described himself as a classical realist in one's

19:21.360 --> 19:23.040
 intelligibility.

19:23.040 --> 19:27.440
 He has something in common with infants in that way.

19:27.440 --> 19:30.960
 So back to linguistics.

19:30.960 --> 19:34.000
 If you could humor me, what are the most beautiful

19:34.000 --> 19:36.680
 or fascinating aspects of language or ideas

19:36.680 --> 19:38.720
 in linguistics or cognitive science

19:38.720 --> 19:42.040
 that you've seen in a lifetime of studying language

19:42.040 --> 19:44.160
 and studying the human mind?

19:44.160 --> 19:50.160
 Well, I think the deepest property of language

19:50.160 --> 19:52.840
 and puzzling property that's been discovered

19:52.840 --> 19:57.560
 is what is sometimes called structure dependence.

19:57.560 --> 19:59.600
 We now understand it pretty well,

19:59.600 --> 20:01.960
 but it was puzzling for a long time.

20:01.960 --> 20:03.600
 I'll give you a concrete example.

20:03.600 --> 20:09.960
 So suppose you say the guy who fixed the car carefully

20:09.960 --> 20:14.720
 packed his tools, it's ambiguous, he could fix the car

20:14.720 --> 20:17.920
 carefully or carefully pack his tools.

20:17.920 --> 20:21.040
 Suppose you put carefully in front,

20:21.040 --> 20:25.840
 carefully the guy who fixed the car packed his tools,

20:25.840 --> 20:29.360
 then it's carefully packed, not carefully fixed.

20:29.360 --> 20:32.280
 And in fact, you do that even if it makes no sense.

20:32.280 --> 20:39.320
 So suppose you say carefully the guy who fixed the car is tall.

20:39.320 --> 20:41.840
 You have to interpret it as carefully he's tall,

20:41.840 --> 20:44.280
 even though that doesn't make any sense.

20:44.280 --> 20:47.200
 And notice that that's a very puzzling fact,

20:47.200 --> 20:50.360
 because you're relating carefully not

20:50.360 --> 20:55.480
 to the linearly closest verb, but to the linearly more

20:55.480 --> 20:57.480
 remote verb.

20:57.480 --> 21:02.320
 Linear approach closeness is an easy computation.

21:02.320 --> 21:04.000
 But here you're doing much more of what

21:04.000 --> 21:06.800
 looks like a more complex computation.

21:06.800 --> 21:10.200
 You're doing something that's taking you essentially

21:10.200 --> 21:11.560
 to the more remote thing.

21:14.680 --> 21:17.880
 If you look at the actual structure of the sentence,

21:17.880 --> 21:20.680
 where the phrases are and so on, turns out

21:20.680 --> 21:24.200
 you're picking out the structurally closest thing,

21:24.200 --> 21:27.960
 but the linearly more remote thing.

21:27.960 --> 21:32.520
 But notice that what's linear is 100% of what you hear.

21:32.520 --> 21:34.080
 You never hear structure.

21:34.080 --> 21:35.160
 Can't.

21:35.160 --> 21:37.920
 So what you're doing is, instantly,

21:37.920 --> 21:42.120
 this is universal, all constructions, all languages.

21:42.120 --> 21:44.840
 And what we're compelled to do is

21:44.840 --> 21:48.680
 carry out what looks like the more complex computation

21:48.680 --> 21:52.240
 on material that we never hear.

21:52.240 --> 21:55.400
 And we ignore 100% of what we hear

21:55.400 --> 21:57.520
 and the simplest computation.

21:57.520 --> 22:00.080
 But by now, there's even a neural basis

22:00.080 --> 22:02.880
 for this that's somewhat understood.

22:02.880 --> 22:05.000
 And there's good theories by now that explain

22:05.000 --> 22:06.800
 why it's true.

22:06.800 --> 22:11.000
 That's a deep insight into the surprising nature

22:11.000 --> 22:14.120
 of language with many consequences.

22:14.120 --> 22:17.560
 Let me ask you about a field of machine learning,

22:17.560 --> 22:18.960
 deep learning.

22:18.960 --> 22:22.080
 There's been a lot of progress in neural networks based,

22:22.080 --> 22:26.400
 neural network based machine learning in the recent decade.

22:26.400 --> 22:28.200
 Of course, neural network research

22:28.200 --> 22:30.800
 goes back many decades.

22:30.800 --> 22:35.600
 What do you think are the limits of deep learning,

22:35.600 --> 22:38.480
 of neural network based machine learning?

22:38.480 --> 22:41.160
 Well, to give a real answer to that,

22:41.160 --> 22:45.040
 you'd have to understand the exact processes that

22:45.040 --> 22:46.000
 are taking place.

22:46.000 --> 22:47.960
 And those are pretty opaque.

22:47.960 --> 22:52.160
 So it's pretty hard to prove a theorem about what can be done

22:52.160 --> 22:54.080
 and what can't be done.

22:54.080 --> 22:56.840
 But I think it's reasonably clear.

22:56.840 --> 22:59.200
 I mean, putting technicalities aside,

22:59.200 --> 23:05.360
 what deep learning is doing is taking huge numbers of examples

23:05.360 --> 23:07.720
 and finding some patterns.

23:07.720 --> 23:11.960
 OK, that could be interesting in some areas it is.

23:11.960 --> 23:15.080
 But we have to ask here a certain question.

23:15.080 --> 23:18.200
 Is it engineering or is it science?

23:18.200 --> 23:20.560
 Engineering in the sense of just trying

23:20.560 --> 23:22.840
 to build something that's useful,

23:22.840 --> 23:24.520
 or science in the sense that it's

23:24.520 --> 23:28.760
 trying to understand something about elements of the world.

23:28.760 --> 23:31.800
 So it takes a Google parser.

23:31.800 --> 23:34.040
 We can ask that question.

23:34.040 --> 23:35.360
 Is it useful?

23:35.360 --> 23:36.840
 It's pretty useful.

23:36.840 --> 23:39.360
 I use a Google translator.

23:39.360 --> 23:43.400
 So on engineering grounds, it's kind of worth having,

23:43.400 --> 23:45.680
 like a bulldozer.

23:45.680 --> 23:49.000
 Does it tell you anything about human language?

23:49.000 --> 23:50.920
 Zero.

23:50.920 --> 23:51.560
 Nothing.

23:51.560 --> 23:54.920
 And in fact, it's very striking.

23:54.920 --> 24:00.360
 From the very beginning, it's just totally remote from science.

24:00.360 --> 24:02.640
 So what is a Google parser doing?

24:02.640 --> 24:05.480
 It's taking an enormous text, let's say,

24:05.480 --> 24:09.000
 the Wall Street Journal corpus, and asking,

24:09.000 --> 24:14.120
 how close can we come to getting the right description

24:14.120 --> 24:16.440
 of every sentence in the corpus?

24:16.440 --> 24:18.520
 Well, every sentence in the corpus

24:18.520 --> 24:21.560
 is essentially an experiment.

24:21.560 --> 24:24.760
 Each sentence that you produce is an experiment,

24:24.760 --> 24:27.800
 which is, am I a grammatical sentence?

24:27.800 --> 24:29.680
 The answer is usually yes.

24:29.680 --> 24:33.240
 So most of the stuff in the corpus is grammatical sentences.

24:33.240 --> 24:36.880
 But now ask yourself, is there any science

24:36.880 --> 24:40.440
 which takes random experiments, which

24:40.440 --> 24:43.760
 are carried out for no reason whatsoever,

24:43.760 --> 24:46.560
 and tries to find out something from them?

24:46.560 --> 24:49.680
 Like if you're, say, a chemistry PhD student,

24:49.680 --> 24:52.000
 you want to get a thesis, can you say, well,

24:52.000 --> 24:57.440
 I'm just going to mix a lot of things together, no purpose.

24:57.440 --> 24:59.720
 And maybe I'll find something.

24:59.720 --> 25:02.480
 It'd be left out of the department.

25:02.480 --> 25:06.560
 Science tries to find critical experiments, ones

25:06.560 --> 25:09.160
 that answer some theoretical question.

25:09.160 --> 25:13.000
 Doesn't care about coverage of millions of experiments.

25:13.000 --> 25:16.240
 So it just begins by being very remote from science,

25:16.240 --> 25:18.280
 and it continues like that.

25:18.280 --> 25:21.360
 So the usual question that's asked

25:21.360 --> 25:25.240
 about, say, a Google parser, is how well does it do,

25:25.240 --> 25:28.360
 or some parser, how well does it do on a corpus?

25:28.360 --> 25:31.160
 But there's another question that's never asked.

25:31.160 --> 25:33.840
 How well does it do on something that violates

25:33.840 --> 25:36.120
 all the rules of language?

25:36.120 --> 25:38.720
 So for example, take the structure dependence case

25:38.720 --> 25:39.720
 that I mentioned.

25:39.720 --> 25:42.240
 Suppose there was a language in which

25:42.240 --> 25:49.080
 you used linear proximity as the mode of interpretation.

25:49.080 --> 25:51.760
 These deep learning would work very easily on that.

25:51.760 --> 25:54.840
 In fact, much more easily on an actual language.

25:54.840 --> 25:55.960
 Is that a success?

25:55.960 --> 25:57.640
 No, that's a failure.

25:57.640 --> 26:00.760
 From a scientific point of view, it's a failure.

26:00.760 --> 26:03.520
 It shows that we're not discovering

26:03.520 --> 26:07.000
 the nature of the system at all, because it does just as well,

26:07.000 --> 26:09.840
 or even better on things that violate the structure

26:09.840 --> 26:10.920
 of the system.

26:10.920 --> 26:12.760
 And it goes on from there.

26:12.760 --> 26:14.800
 It's not an argument against doing it.

26:14.800 --> 26:17.200
 It is useful to have devices like this.

26:17.200 --> 26:21.560
 So yes, neural networks are kind of approximators that look.

26:21.560 --> 26:24.360
 There's echoes of the behavioral debates, right?

26:24.360 --> 26:26.160
 Behavioralism.

26:26.160 --> 26:27.600
 More than echoes.

26:27.600 --> 26:30.080
 Many of the people in deep learning

26:30.080 --> 26:34.560
 say they've vindicated Terry Sanyosky, for example,

26:34.560 --> 26:36.320
 in his recent books.

26:36.320 --> 26:39.520
 This vindicates skinnerian behaviors.

26:39.520 --> 26:41.440
 It doesn't have anything to do with it.

26:41.440 --> 26:45.720
 Yes, but I think there's something actually fundamentally

26:45.720 --> 26:48.280
 different when the data set is huge.

26:48.280 --> 26:51.160
 But your point is extremely well taken.

26:51.160 --> 26:55.400
 But do you think we can learn, approximate,

26:55.400 --> 26:58.800
 that interesting complex structure of language

26:58.800 --> 27:01.320
 with neural networks that will somehow help us

27:01.320 --> 27:03.640
 understand the science?

27:03.640 --> 27:04.480
 It's possible.

27:04.480 --> 27:08.720
 I mean, you find patterns that you hadn't noticed, let's say.

27:08.720 --> 27:09.760
 Could be.

27:09.760 --> 27:13.600
 In fact, it's very much like a kind of linguistics

27:13.600 --> 27:18.080
 that's done, what's called corpus linguistics.

27:18.080 --> 27:22.560
 When you suppose you have some language where all the speakers

27:22.560 --> 27:25.120
 have died out, but you have records.

27:25.120 --> 27:28.560
 So you just look at the records and see

27:28.560 --> 27:30.560
 what you can figure out from that.

27:30.560 --> 27:32.440
 It's much better than, it's much better

27:32.440 --> 27:36.040
 to have actual speakers where you can do critical experiments.

27:36.040 --> 27:38.480
 But if they're all dead, you can't do them.

27:38.480 --> 27:39.920
 So you have to try to see what you

27:39.920 --> 27:43.800
 can find out from just looking at the data that's around.

27:43.800 --> 27:45.000
 You can learn things.

27:45.000 --> 27:48.400
 Actually, paleoanthropology is very much like that.

27:48.400 --> 27:50.560
 You can't do a critical experiment

27:50.560 --> 27:53.480
 on what happened two million years ago.

27:53.480 --> 27:56.480
 So you kind of force just to take what data is around

27:56.480 --> 27:59.200
 and see what you can figure out from it.

27:59.200 --> 28:01.400
 OK, it's a serious study.

28:01.400 --> 28:05.560
 So let me venture into another whole body of work

28:05.560 --> 28:08.400
 and philosophical question.

28:08.400 --> 28:13.040
 You've said that evil in society arises from institutions,

28:13.040 --> 28:15.520
 not inherently from our nature.

28:15.520 --> 28:17.760
 Do you think most human beings are good?

28:17.760 --> 28:19.560
 They have good intent?

28:19.560 --> 28:22.840
 Or do most have the capacity for intentional evil

28:22.840 --> 28:24.560
 that depends on their upbringing,

28:24.560 --> 28:27.160
 depends on their environment, on context?

28:27.160 --> 28:30.920
 I wouldn't say that they don't arise from our nature.

28:30.920 --> 28:33.960
 Anything we do arises from our nature.

28:33.960 --> 28:38.040
 And the fact that we have certain institutions, not others,

28:38.040 --> 28:43.680
 is one mode in which human nature has expressed itself.

28:43.680 --> 28:46.240
 But as far as we know, human nature

28:46.240 --> 28:50.200
 could yield many different kinds of institutions.

28:50.200 --> 28:53.120
 The particular ones that have developed

28:53.120 --> 28:58.040
 have to do with historical contingency, who conquered whom,

28:58.040 --> 29:00.200
 and that sort of thing.

29:00.200 --> 29:04.320
 They're not rooted in our nature in the sense

29:04.320 --> 29:06.720
 that they're essential to our nature.

29:06.720 --> 29:11.360
 So it's commonly argued that these days that something

29:11.360 --> 29:15.640
 like market systems is just part of our nature.

29:15.640 --> 29:18.600
 But we know from a huge amount of evidence

29:18.600 --> 29:19.440
 that that's not true.

29:19.440 --> 29:21.680
 There's all kinds of other structures.

29:21.680 --> 29:26.200
 It's a particular fact of a moment of modern history.

29:26.200 --> 29:30.680
 Others have argued that the roots of classical liberalism

29:30.680 --> 29:34.360
 actually argue that what's called sometimes

29:34.360 --> 29:37.440
 an instinct for freedom, an instinct

29:37.440 --> 29:42.120
 to be free of domination by illegitimate authority

29:42.120 --> 29:43.600
 is the core of our nature.

29:43.600 --> 29:45.600
 That would be the opposite of this.

29:45.600 --> 29:47.480
 And we don't know.

29:47.480 --> 29:52.200
 We just know that human nature can accommodate both kinds.

29:52.200 --> 29:55.240
 If you look back at your life, is there

29:55.240 --> 29:59.040
 a moment in your intellectual life, or life in general,

29:59.040 --> 30:02.040
 that jumps from memory that brought you happiness,

30:02.040 --> 30:05.080
 that you would love to relive again?

30:05.080 --> 30:06.440
 Sure.

30:06.440 --> 30:10.160
 Falling in love, having children.

30:10.160 --> 30:13.840
 What about, so you have put forward into the world

30:13.840 --> 30:17.640
 a lot of incredible ideas in linguistics,

30:17.640 --> 30:22.280
 in cognitive science, in terms of ideas

30:22.280 --> 30:26.040
 that just excites you when it first came to you,

30:26.040 --> 30:28.880
 that you would love to relive those moments?

30:28.880 --> 30:33.000
 Well, I mean, when you make a discovery about something

30:33.000 --> 30:38.960
 that's exciting, like, say, even the observation

30:38.960 --> 30:42.680
 of structured dependence and on from that,

30:42.680 --> 30:44.400
 the explanation for it.

30:44.400 --> 30:49.480
 But the major things just seem like common sense.

30:49.480 --> 30:53.160
 So if you go back to take your question

30:53.160 --> 30:55.800
 about external and internal language,

30:55.800 --> 31:01.320
 you go back to, say, the 1950s, almost entirely languages

31:01.320 --> 31:06.280
 regarded an external object, something outside the mind.

31:06.280 --> 31:10.720
 It just seemed obvious that that can't be true.

31:10.720 --> 31:13.240
 Like I said, there's something about you

31:13.240 --> 31:18.600
 that determines you're talking English, not Swahili or something.

31:18.600 --> 31:20.280
 But that's not really a discovery.

31:20.280 --> 31:24.240
 That's just an observation that's transparent.

31:24.240 --> 31:30.680
 You might say it's kind of like the 17th century,

31:30.680 --> 31:33.480
 the beginnings of modern science, 17th century.

31:33.480 --> 31:38.600
 They came from being willing to be puzzled about things

31:38.600 --> 31:40.400
 that seemed obvious.

31:40.400 --> 31:44.560
 So it seems obvious that a heavy ball of ladle

31:44.560 --> 31:47.560
 fall faster than a light ball of ladle.

31:47.560 --> 31:50.880
 But Galileo was not impressed by the fact

31:50.880 --> 31:52.680
 that it seemed obvious.

31:52.680 --> 31:54.920
 So he wanted to know if it's true.

31:54.920 --> 31:59.120
 He carried out experiments, actually thought experiments,

31:59.120 --> 32:01.440
 never actually carried them out, which

32:01.440 --> 32:04.480
 could that can't be true.

32:04.480 --> 32:11.360
 And out of things like that, observations of that kind,

32:11.360 --> 32:15.760
 why does a ball fall to the ground instead of rising,

32:15.760 --> 32:18.480
 let's say, seems obvious.

32:18.480 --> 32:20.040
 Do you start thinking about it?

32:20.040 --> 32:23.920
 Because why does it, why does steam rise, let's say?

32:23.920 --> 32:27.600
 And I think the beginnings of modern linguistics, roughly

32:27.600 --> 32:30.040
 in the 50s, are kind of like that,

32:30.040 --> 32:33.800
 just being willing to be puzzled about phenomena that

32:33.800 --> 32:38.040
 looked, from some point of view, obvious.

32:38.040 --> 32:42.680
 For example, a kind of doctrine, almost official doctrine,

32:42.680 --> 32:46.040
 of structural linguistics in the 50s

32:46.040 --> 32:50.480
 was that languages can differ from one another

32:50.480 --> 32:52.640
 in arbitrary ways.

32:52.640 --> 32:56.440
 And each one has to be studied on its own

32:56.440 --> 32:58.880
 without any presuppositions.

32:58.880 --> 33:02.320
 In fact, there were similar views among biologists

33:02.320 --> 33:05.840
 about the nature of organisms, that each one is,

33:05.840 --> 33:07.760
 they're so different when you look at them,

33:07.760 --> 33:10.960
 that almost anything, you could be almost anything.

33:10.960 --> 33:13.080
 Well, in both domains, it's been learned

33:13.080 --> 33:15.480
 that that's very far from true.

33:15.480 --> 33:17.600
 They're very narrow constraints on what

33:17.600 --> 33:21.560
 could be an organism or what could be a language.

33:21.560 --> 33:26.960
 But these are, that's just the nature of inquiry.

33:26.960 --> 33:29.320
 Science in general, yeah, inquiry.

33:29.320 --> 33:33.360
 So one of the peculiar things about us human beings

33:33.360 --> 33:35.240
 is our mortality.

33:35.240 --> 33:38.160
 Ernest Becker explored it in general.

33:38.160 --> 33:40.400
 Do you ponder the value of mortality?

33:40.400 --> 33:43.360
 Do you think about your own mortality?

33:43.360 --> 33:47.960
 I used to when I was about 12 years old.

33:47.960 --> 33:51.880
 I wondered, I didn't care much about my own mortality,

33:51.880 --> 33:56.320
 but I was worried about the fact that if my consciousness

33:56.320 --> 34:00.240
 disappeared, would the entire universe disappear?

34:00.240 --> 34:01.520
 That was frightening.

34:01.520 --> 34:03.680
 Did you ever find an answer to that question?

34:03.680 --> 34:05.840
 No, nobody's ever found an answer.

34:05.840 --> 34:07.800
 But I stopped being bothered by it.

34:07.800 --> 34:10.360
 It's kind of like Woody Allen in one of his films,

34:10.360 --> 34:14.080
 you may recall, he starts, he goes to a shrink

34:14.080 --> 34:16.520
 when he's a child and the shrink asks him,

34:16.520 --> 34:17.480
 what's your problem?

34:17.480 --> 34:21.600
 He says, I just learned that the universe is expanding.

34:21.600 --> 34:24.320
 I can't handle that.

34:24.320 --> 34:27.200
 And then another absurd question is,

34:27.200 --> 34:32.560
 what do you think is the meaning of our existence here,

34:32.560 --> 34:35.760
 our life on Earth, our brief little moment in time?

34:35.760 --> 34:40.560
 It's something we answer by our own activities.

34:40.560 --> 34:42.320
 There's no general answer.

34:42.320 --> 34:46.560
 We determine what the meaning of it is.

34:46.560 --> 34:48.680
 The action determine the meaning.

34:48.680 --> 34:50.520
 Meaning in the sense of significance,

34:50.520 --> 34:55.360
 not meaning in the sense that a chair means this,

34:55.360 --> 35:01.040
 but the significance of your life is something you create.

35:01.040 --> 35:02.520
 No, thank you so much for talking today.

35:02.520 --> 35:04.120
 It was a huge honor.

35:04.120 --> 35:05.920
 Thank you so much.

35:05.920 --> 35:08.680
 Thanks for listening to this conversation with Noam Chomsky

35:08.680 --> 35:11.960
 and thank you to our presenting sponsor, Cash App.

35:11.960 --> 35:14.760
 Download it, use code LEX Podcast.

35:14.760 --> 35:17.960
 You'll get $10 and $10 will go to first.

35:17.960 --> 35:20.880
 A STEM education nonprofit that inspires hundreds

35:20.880 --> 35:23.200
 of thousands of young minds to learn

35:23.200 --> 35:26.000
 and to dream of engineering our future.

35:26.000 --> 35:28.600
 If you enjoy this podcast, subscribe on YouTube,

35:28.600 --> 35:30.600
 give us five stars on Apple Podcasts,

35:30.600 --> 35:34.240
 support on Patreon, or connect with me on Twitter.

35:34.240 --> 36:01.800
 Thank you for listening and hope to see you next time.

