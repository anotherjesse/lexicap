WEBVTT

00:00.000 --> 00:03.200
 The following is a conversation with Vladimir Vapnik.

00:03.200 --> 00:07.280
 Part two, the second time we spoke on the podcast.

00:07.280 --> 00:09.760
 He's the co inventor of support vector machines,

00:09.760 --> 00:12.080
 support vector clustering, VC theory,

00:12.080 --> 00:14.960
 and many foundational ideas and statistical learning.

00:14.960 --> 00:17.280
 He was born in the Soviet Union,

00:17.280 --> 00:20.240
 worked at the Institute of Control Sciences in Moscow,

00:20.240 --> 00:24.640
 then in the US, worked at AT&T, NEC labs,

00:24.640 --> 00:26.080
 Facebook AI research,

00:26.080 --> 00:29.360
 and now is a professor at Columbia University.

00:29.360 --> 00:32.240
 His work has been cited over 200,000 times.

00:32.880 --> 00:36.400
 The first time we spoke on the podcast was just over a year ago,

00:36.400 --> 00:38.000
 one of the early episodes.

00:38.880 --> 00:41.760
 This time, we spoke after a lecture he gave titled

00:41.760 --> 00:44.240
 Complete Statistical Theory of Learning,

00:44.240 --> 00:49.120
 as part of the MIT series of lectures on deep learning and AI that I organized.

00:50.000 --> 00:52.720
 I'll release the video of the lecture in the next few days.

00:53.520 --> 00:56.720
 This podcast and lecture are independent from each other,

00:56.720 --> 00:59.280
 so you don't need one to understand the other.

00:59.280 --> 01:02.960
 The lecture is quite technical and math heavy,

01:02.960 --> 01:04.240
 so if you do watch both,

01:04.240 --> 01:06.640
 I recommend listening to this podcast first,

01:06.640 --> 01:09.840
 since the podcast is probably a bit more accessible.

01:11.120 --> 01:13.760
 This is the Artificial Intelligence Podcast.

01:13.760 --> 01:15.920
 If you enjoy it, subscribe on YouTube,

01:15.920 --> 01:17.760
 give it five stars on Apple Podcasts,

01:17.760 --> 01:18.960
 support it on Patreon,

01:18.960 --> 01:20.960
 or simply connect with me on Twitter,

01:20.960 --> 01:23.920
 and Lex Friedman spelled F R I D M A N.

01:23.920 --> 01:27.040
 As usual, I'll do one or two minutes of ads now,

01:27.040 --> 01:30.560
 and never any ads in the middle that can break the flow of the conversation.

01:30.560 --> 01:32.080
 I hope that works for you,

01:32.080 --> 01:34.000
 and doesn't hurt the listening experience.

01:35.440 --> 01:37.280
 This show is presented by Cash App,

01:37.280 --> 01:39.520
 the number one finance app in the App Store.

01:39.520 --> 01:42.480
 When you get it, use code LEX Podcast.

01:42.480 --> 01:45.920
 Cash App lets you send money to friends, buy Bitcoin,

01:45.920 --> 01:48.640
 and invest in the stock market with as little as $1.

01:48.640 --> 01:51.680
 Brokerage services are provided by Cash App Investing,

01:51.680 --> 01:55.520
 a subsidiary of Square, and member SIPC.

01:56.240 --> 02:00.320
 Since Cash App allows you to send and receive money digitally peer to peer,

02:00.320 --> 02:03.440
 and security in all digital transactions is very important,

02:03.440 --> 02:06.560
 let me mention the PCI Data Security Standard,

02:06.560 --> 02:11.120
 PCI DSS Level 1, that Cash App is compliant with.

02:12.000 --> 02:15.120
 I'm a big fan of standards for safety and security,

02:15.120 --> 02:18.720
 and PCI DSS is a good example of that,

02:18.720 --> 02:20.800
 where a bunch of competitors got together

02:20.800 --> 02:23.360
 and agreed that there needs to be a global standard

02:23.360 --> 02:24.960
 around the security of transactions.

02:25.680 --> 02:28.720
 Now, we just need to do the same for autonomous vehicles

02:28.720 --> 02:30.160
 and AI systems in general.

02:31.200 --> 02:33.760
 So again, if you get Cash App from the App Store,

02:33.760 --> 02:37.120
 or Google Play, and use the code LEX Podcast,

02:37.120 --> 02:41.040
 you get $10, and Cash App will also donate $10 to first,

02:41.040 --> 02:44.800
 one of my favorite organizations that is helping to advance

02:44.800 --> 02:48.000
 robotics and STEM education for young people around the world.

02:48.000 --> 02:53.840
 And now, here's my conversation with Vladimir Vapnick.

02:55.200 --> 02:58.480
 You and I talked about Alan Turing yesterday, a little bit,

02:59.680 --> 03:02.640
 and that he, as the father of artificial intelligence,

03:02.640 --> 03:05.600
 may have instilled in our field an ethic of engineering,

03:05.600 --> 03:09.440
 and not science, seeking more to build intelligence

03:09.440 --> 03:10.960
 rather than to understand it.

03:12.000 --> 03:14.560
 What do you think is the difference between these two paths

03:14.560 --> 03:20.080
 of engineering intelligence and the science of intelligence?

03:20.960 --> 03:22.560
 It's a completely different story.

03:23.520 --> 03:27.280
 Engineering is a mutation of human activity.

03:28.320 --> 03:34.240
 You have to make a device which behaves as human behavior,

03:35.200 --> 03:38.080
 have all the functions of human.

03:38.960 --> 03:40.640
 It does not matter how you do it.

03:40.640 --> 03:47.280
 But to understand what is intelligence about is quite a different problem.

03:48.880 --> 03:56.080
 So, I think, I believe that it's somehow related to predicate we talked yesterday about,

03:57.840 --> 04:04.640
 because look at the Vladimir Props idea.

04:04.640 --> 04:10.800
 He just found 31 he predicates.

04:12.560 --> 04:19.040
 He called it units, which can explain human behavior,

04:19.040 --> 04:20.640
 at least in Russian tales.

04:20.640 --> 04:24.800
 He looked at Russian tales and derived from that,

04:24.800 --> 04:29.440
 and then people realized that it's more wide than in Russian tales.

04:29.440 --> 04:33.840
 It isn't TV, in movie serials, and so on and so on.

04:33.840 --> 04:39.920
 You're talking about Vladimir Prop, who in 1928 published a book,

04:39.920 --> 04:47.520
 Morphology of the Folktale, describing 31 predicates that have this kind of sequential

04:48.720 --> 04:54.880
 structure that a lot of the stories and narratives follow in Russian folklore and other content.

04:54.880 --> 04:55.920
 We'll talk about it.

04:55.920 --> 04:59.040
 I'd like to talk about predicates in a focused way,

04:59.040 --> 05:07.440
 but if you allow me to stay zoomed out on our friend Alan Turing, and he inspired a generation

05:07.440 --> 05:09.280
 with the imitation game.

05:12.800 --> 05:20.400
 If we can linger on that a little bit longer, do you think learning to imitate

05:20.400 --> 05:24.800
 intelligence can get us closer to understanding intelligence?

05:24.800 --> 05:31.760
 So, why do you think imitation is so far from understanding?

05:32.560 --> 05:36.160
 I think that it is different between you have different goals.

05:37.440 --> 05:44.960
 So, your goal is to create something, something useful, and that is great.

05:45.760 --> 05:52.000
 And you can see how much things was done, and I believe that it will be done even more.

05:52.000 --> 05:56.000
 It's self driving cars and also this business.

05:56.640 --> 06:05.280
 It is great, and it was inspired by Turing vision, but understanding is very difficult.

06:05.280 --> 06:07.520
 It's more or less philosophical category.

06:08.160 --> 06:10.160
 What means understanding the world?

06:11.040 --> 06:18.160
 I believe in a scheme which starts from Plato, that there exists a world of ideas.

06:18.160 --> 06:24.320
 I believe that intelligence, it is a world of ideas, but it is a world of pure ideas.

06:25.040 --> 06:34.560
 And when you combine them with reality things, it creates, as in my case,

06:34.560 --> 06:45.040
 invariance, which is very specific, and that's, I believe, the combination of ideas

06:45.040 --> 06:49.680
 in way to constructing invariant is intelligence.

06:49.680 --> 06:52.640
 But first of all, predicate.

06:53.280 --> 07:00.000
 If you know predicate, and hopefully then, not too much predicate exists.

07:00.640 --> 07:06.000
 For example, 31 predicate for human behavior, it is not a lot.

07:06.000 --> 07:16.320
 Vladimir Prop used 31, you can even call it predicate, 31 predicate to describe stories,

07:16.320 --> 07:16.880
 narratives.

07:17.440 --> 07:23.680
 So you think human behavior, how much of human behavior, how much of our world, our universe,

07:24.320 --> 07:30.640
 all the things that matter in our existence can be summarized in predicates of the kind

07:30.640 --> 07:32.480
 that Prop was working with?

07:32.480 --> 07:36.720
 I think that we have a lot of form of behavior.

07:37.680 --> 07:43.440
 But I think that predicate is much less, because even in these examples, which I gave

07:43.440 --> 07:55.440
 you yesterday, you saw that predicate can be, one predicate can construct many different

07:55.440 --> 08:02.640
 invariance, depending on your data, they're applying to different data, and they give different

08:02.640 --> 08:03.280
 invariance.

08:04.160 --> 08:08.480
 So, but pure ideas, maybe not so much.

08:08.480 --> 08:09.200
 Not so many.

08:09.760 --> 08:11.280
 I don't know about that.

08:11.280 --> 08:18.400
 But my guess, I hope, that's why challenge about digital recognition, how much you need.

08:19.440 --> 08:24.640
 I think we'll talk about computer vision and 2D images a little bit and your challenge.

08:24.640 --> 08:26.480
 That's exactly about intelligence.

08:28.720 --> 08:35.280
 That's exactly about, no, that hopes to be exactly about the spirit of intelligence

08:35.280 --> 08:37.040
 in the simplest possible way.

08:42.560 --> 08:47.680
 Well, there's an open question whether starting at the MNIST digital recognition

08:48.480 --> 08:51.680
 is a step towards intelligence or it's an entirely different thing.

08:51.680 --> 09:00.560
 I think that to beat records using 100, 200 times less examples, you need intelligence.

09:00.560 --> 09:01.360
 You need intelligence.

09:01.360 --> 09:04.400
 So, let's, because you use this term and it'll be nice.

09:05.280 --> 09:08.720
 I'd like to ask simple, maybe even dumb questions.

09:09.760 --> 09:11.040
 Let's start with a predicate.

09:12.720 --> 09:15.840
 In terms of terms and how you think about it, what is a predicate?

09:15.840 --> 09:21.600
 I don't know. I have a feeling, formally, they exist.

09:22.800 --> 09:31.520
 But I believe that predicate for 2D images, one of them is symmetry.

09:32.080 --> 09:32.800
 Hold on a second.

09:32.800 --> 09:35.440
 Sorry, sorry to interrupt and put you back.

09:36.320 --> 09:40.560
 At the simplest level, we're not even, we're not being profound currently.

09:40.560 --> 09:43.600
 A predicate is a statement of something that is true.

09:43.600 --> 09:45.040
 Yes.

09:46.480 --> 09:54.480
 Do you think of predicates as somehow probabilistic in nature or is this binary,

09:54.480 --> 10:00.000
 this is truly constraints of logical statements about the world?

10:00.000 --> 10:03.040
 In my definition, the simplest predicate is function.

10:04.080 --> 10:10.160
 Function and you can use this function to make inner product that is predicate.

10:10.160 --> 10:13.120
 What's the input and what's the output of the function?

10:13.920 --> 10:18.000
 Input is x, something which is input in reality.

10:18.560 --> 10:24.880
 Say, if you consider digit recognition, it's pixel space, input.

10:24.880 --> 10:34.240
 But it is function which in pixel space, but it can be any function from pixel space.

10:34.240 --> 10:40.480
 And you choose, and I believe that there are several functions,

10:41.520 --> 10:45.360
 which is important for understanding of images.

10:46.320 --> 10:48.160
 One of them is symmetry.

10:48.160 --> 10:54.160
 It's not so simple construction as I described with literarity, with all this stuff.

10:54.960 --> 11:02.160
 But another, I believe, I don't know how many, is how well structured is picture.

11:02.160 --> 11:04.000
 Structurized?

11:04.000 --> 11:04.640
 Yeah.

11:04.640 --> 11:06.080
 What do you mean by structurized?

11:06.800 --> 11:08.320
 It is formal definition.

11:08.960 --> 11:16.960
 Say, something heavy on the left corner, not so heavy in the middle and so on.

11:16.960 --> 11:21.760
 You describe in general concept of what you assume.

11:21.760 --> 11:25.120
 Concepts, some kind of universal concepts.

11:25.120 --> 11:29.120
 Yeah, but I don't know how to formalize this.

11:29.120 --> 11:29.760
 Do you?

11:29.760 --> 11:30.720
 So this is the thing.

11:30.720 --> 11:32.720
 There's a million ways we can talk about this.

11:32.720 --> 11:33.920
 I'll keep bringing it up.

11:33.920 --> 11:39.760
 But we humans have such concepts when we look at digits.

11:40.640 --> 11:44.640
 But it's hard to put them, just like you're saying now, it's hard to put them into words.

11:44.640 --> 11:46.880
 You know, that is example.

11:47.680 --> 11:59.120
 When critics in music trying to describe music, they use predicate and not too many predicate.

11:59.120 --> 12:07.280
 But in different combination, but they have some special words for describing music.

12:08.240 --> 12:11.680
 And the same should be for images.

12:12.560 --> 12:19.280
 But maybe there are critics who understand essence of what this image is about.

12:19.280 --> 12:28.240
 Do you think there exists critics who can summarize the essence of images, human beings?

12:29.280 --> 12:34.560
 I hope so, yes, but that explicitly state them on paper.

12:37.360 --> 12:46.080
 The fundamental question I'm asking is, do you think there exists a small set of predicates

12:46.080 --> 12:52.880
 that will summarize images? It feels to our mind, like it does, that the concept of what

12:52.880 --> 12:55.200
 makes a two and a three and a four.

12:55.840 --> 12:56.480
 No, no, no.

12:56.480 --> 12:58.640
 It's not on this level.

13:00.720 --> 13:04.160
 What it should not describe, two, three, four.

13:04.880 --> 13:10.560
 It describes some construction which allow you to create invariance.

13:10.560 --> 13:15.360
 And invariance, sorry to stick on this, but terminology.

13:15.360 --> 13:22.480
 Invariance, it is, it is property of your image.

13:24.720 --> 13:32.800
 Say, I can say, looking at my image, it is more or less symmetric and I can give you

13:32.800 --> 13:40.960
 value of symmetry, say, level of symmetry using this function which I gave yesterday.

13:43.360 --> 13:51.520
 And you can describe that your image has these characteristics.

13:51.520 --> 13:56.400
 Exactly in the way how musical critics describe music.

13:56.400 --> 14:05.920
 So, but this is invariant applied to specific data, to specific music, to something.

14:07.520 --> 14:16.000
 I strongly believe in this plot ideas that there exists world of predicate and world of

14:16.000 --> 14:21.920
 reality and predicate and reality is somehow connected and you have to do that.

14:21.920 --> 14:28.800
 Let's talk about Plato a little bit. So, you draw a line from Plato to Hegel to Wigner to today.

14:29.360 --> 14:30.000
 Yes.

14:30.000 --> 14:35.360
 So, Plato has forms, the theory of forms.

14:35.360 --> 14:40.320
 There's a world of ideas and a world of things as you talk about and there's a connection.

14:40.320 --> 14:47.840
 And presumably the world of ideas is very small and the world of things is arbitrarily big.

14:47.840 --> 14:52.480
 But they're all what Plato calls them like, it's a shadow.

14:52.480 --> 14:54.800
 The real world is a shadow from the world of form.

14:54.800 --> 14:56.080
 Yeah, you have projection.

14:56.640 --> 14:57.280
 Projection.

14:57.280 --> 14:58.560
 Of world of idea.

14:59.120 --> 15:00.560
 Yeah, very poetic.

15:00.560 --> 15:09.200
 In reality, you can realize this projection using invariance because it is projection

15:09.200 --> 15:14.720
 for own specific examples which create specific features of specific objects.

15:14.720 --> 15:24.000
 So, the essence of intelligence is while only being able to observe the world of things,

15:24.640 --> 15:26.880
 try to come up with a world of ideas.

15:26.880 --> 15:27.840
 Exactly.

15:27.840 --> 15:33.360
 Like in this music story, intelligent musical critics knows this all this world and have

15:33.360 --> 15:34.640
 a feeling about what.

15:34.640 --> 15:38.800
 I feel like that's a contradiction, intelligent music critics.

15:38.800 --> 15:47.520
 But I think music is to be enjoyed in all its forms.

15:47.520 --> 15:49.840
 The notion of critic, like a food critic.

15:49.840 --> 15:52.160
 No, I don't want touching motion.

15:52.160 --> 15:53.520
 That's an interesting question.

15:53.520 --> 15:59.120
 There's a motion, there's a certain elements of the human psychology of the human experience

16:00.080 --> 16:04.560
 which seem to almost contradict intelligence and reason.

16:04.560 --> 16:12.720
 Emotion, like emotion, like fear, like love, all of those things, are those not connected

16:12.720 --> 16:16.320
 in any way to the space of ideas?

16:16.320 --> 16:19.600
 Yes, I don't know.

16:19.600 --> 16:27.760
 I just want to be concentrated on very simple story, on digit recognition.

16:27.760 --> 16:31.680
 So, you don't think you have to love and fear death in order to recognize digits?

16:31.680 --> 16:36.080
 I don't know, because it's so complicated.

16:36.080 --> 16:40.800
 It involves a lot of stuff which I never consider.

16:40.800 --> 16:44.000
 But I know about digit recognition.

16:44.000 --> 16:56.480
 And I know that for digit recognition, to get the records from small number of observations,

16:56.480 --> 17:02.400
 you need predicate, but not special predicate for this problem.

17:03.440 --> 17:08.240
 But universal predicate, which understand the world of images.

17:08.240 --> 17:09.760
 Of visual information.

17:09.760 --> 17:10.560
 Visual, yes.

17:11.280 --> 17:21.440
 But on the first step, they understand the world of handwritten digits or characters or something simple.

17:21.440 --> 17:23.840
 So, like you said, symmetry is an interesting one.

17:23.840 --> 17:30.800
 That's what I think one of the predicates related to symmetry, the level of symmetry.

17:30.800 --> 17:32.000
 Okay, degree of symmetry.

17:32.000 --> 17:37.520
 So, you think symmetry at the bottom is a universal notion and there's

17:39.360 --> 17:43.280
 degrees of a single kind of symmetry, or is there many kinds of symmetries?

17:44.000 --> 17:45.280
 Many kinds of symmetries.

17:45.840 --> 17:50.320
 There is a symmetry, anti symmetry, say letter S.

17:50.320 --> 17:56.080
 So, it has vertical anti symmetry.

17:58.320 --> 18:02.560
 And it could be diagonal symmetry, vertical symmetry.

18:02.560 --> 18:06.880
 So, when you cut vertically the letter S.

18:07.680 --> 18:15.200
 Yeah, then the upper part and lower part in different directions.

18:15.200 --> 18:18.320
 Yeah, inverted along the y axis.

18:18.320 --> 18:18.800
 Yeah.

18:18.800 --> 18:21.120
 But that's just like one example of symmetry, right?

18:21.120 --> 18:21.840
 Isn't there like...

18:21.840 --> 18:25.280
 All right, but there is a degree of symmetry.

18:26.240 --> 18:34.160
 If you play all this derivative stuff to do tangent distance,

18:34.160 --> 18:40.400
 but whatever I describe, you can have a degree of symmetry.

18:40.400 --> 18:45.120
 And that is what describing reason of image.

18:45.120 --> 18:54.800
 It is the same as you will describe this image, saying about digits.

18:54.800 --> 19:02.320
 It has anti symmetry, digits three, symmetric, more or less look for symmetry.

19:03.440 --> 19:08.480
 Do you think such concepts like symmetry, predicates like symmetry,

19:08.480 --> 19:12.880
 is it a hierarchical set of concepts?

19:12.880 --> 19:21.200
 Or are these independent, distinct predicates that we want to discover some set of?

19:21.920 --> 19:24.160
 There is a deal of symmetry.

19:24.160 --> 19:25.200
 And you can...

19:25.200 --> 19:35.120
 This idea of symmetry make very general, like degree of symmetry.

19:35.120 --> 19:38.640
 If degree of symmetry can be zero, no symmetry at all.

19:38.640 --> 19:48.160
 Or degree of symmetry, say, more or less symmetrical, but you have one of these descriptions.

19:48.160 --> 19:53.600
 And symmetry can be different, as I told, horizontal, vertical, diagonal,

19:53.600 --> 19:58.960
 and anti symmetry is also concept of symmetry.

19:58.960 --> 20:00.880
 What about shape in general?

20:00.880 --> 20:03.760
 I mean, symmetry is a fascinating notion, but...

20:03.760 --> 20:06.320
 No, no, I'm talking about digit.

20:06.320 --> 20:08.800
 I would like to concentrate on all...

20:08.800 --> 20:12.080
 I would like to know predicate for digit recognition.

20:12.080 --> 20:16.800
 Yes, but symmetry is not enough for digit recognition, right?

20:16.800 --> 20:19.920
 It is not necessarily for digit recognition.

20:19.920 --> 20:36.240
 It helps to create invariant, which you can use when you will have examples for digit recognition.

20:36.240 --> 20:41.520
 When you have problem of digit recognition, you have examples of the first class or second class.

20:41.520 --> 20:45.680
 Plus, you know that there exists concept of symmetry.

20:45.680 --> 20:55.200
 And you apply, when you're looking for decision rule, you will apply concept of symmetry,

20:55.200 --> 21:00.000
 of this level of symmetry, which you estimate from me.

21:00.000 --> 21:06.480
 So let's talk. Everything comes from big convergence.

21:06.480 --> 21:07.680
 What is convergence?

21:07.680 --> 21:09.120
 What is weak convergence?

21:09.120 --> 21:10.480
 What is strong convergence?

21:11.360 --> 21:13.200
 I'm sorry, I'm going to do this to you.

21:13.200 --> 21:14.960
 What are we converging from and to?

21:16.000 --> 21:16.800
 You're converging...

21:18.160 --> 21:19.680
 You would like to have a function.

21:20.400 --> 21:29.840
 The function, which, say, indicator function, which indicate your digit 5, for example.

21:29.840 --> 21:31.360
 A classification task.

21:31.360 --> 21:33.520
 Let's talk only about classification.

21:33.520 --> 21:38.480
 So classification means you will say, whether this is a 5 or not,

21:38.480 --> 21:40.480
 or say which of the 10 digits it is.

21:40.480 --> 21:42.000
 All right, all right.

21:42.000 --> 21:45.200
 I would like to have these functions.

21:46.480 --> 21:52.000
 Then I have some examples.

21:52.000 --> 21:59.760
 I can consider property of these examples.

22:00.960 --> 22:01.840
 Say symmetry.

22:02.480 --> 22:06.240
 And I can measure level of symmetry for every digit.

22:07.840 --> 22:15.680
 And then I can take average from my training data.

22:15.680 --> 22:23.840
 And I will consider only functions of conditional probability,

22:23.840 --> 22:35.680
 which I'm looking for my decision rule, which applying to digits

22:36.320 --> 22:40.480
 will give me the same average as I absorb on training data.

22:40.480 --> 22:47.600
 So actually, this is different level of description of what you want.

22:48.400 --> 22:58.560
 You want not just, you show not one digit, you show this predicate, show general property

22:59.680 --> 23:02.960
 of all digits, which you have in mind.

23:03.520 --> 23:09.520
 If you have in mind digits 3, it gives you property of digits 3.

23:09.520 --> 23:16.000
 And you select as admissible set of function, only function, which keeps this property.

23:16.880 --> 23:19.920
 You will not consider other functions.

23:20.720 --> 23:24.800
 So you're immediately looking for smaller subset of function.

23:24.800 --> 23:26.640
 That's what you mean by admissible functions.

23:26.640 --> 23:28.320
 You look at admissible function, exactly.

23:28.320 --> 23:31.680
 Which is still a pretty large for the number 3.

23:32.480 --> 23:35.600
 It is pretty large, but if you have one predicate.

23:35.600 --> 23:41.520
 But according to, there is a strong and weak convergence.

23:42.640 --> 23:44.960
 Strong convergence is convergence and function.

23:46.240 --> 23:50.880
 You're looking for the function on one function, and you're looking for another function.

23:51.760 --> 23:57.920
 And square difference from them should be small.

23:57.920 --> 24:04.560
 If you take difference in any points, make a square, make an integral, and it should be small.

24:05.520 --> 24:07.840
 That is convergence and function.

24:07.840 --> 24:10.400
 Suppose you have some function, any function.

24:11.200 --> 24:16.640
 So I would say, I say that some function converge to this function.

24:17.760 --> 24:22.160
 If integral from square difference between them is small.

24:22.720 --> 24:24.640
 That's the definition of strong convergence.

24:24.640 --> 24:25.600
 That definition of strong convergence.

24:25.600 --> 24:28.800
 Two functions, the integral of the difference is small.

24:28.800 --> 24:30.640
 It is convergence in functions.

24:32.160 --> 24:35.680
 But you have different convergence in functionals.

24:36.560 --> 24:39.760
 You take any function, you take some function phi,

24:41.040 --> 24:42.480
 and take inner product.

24:42.480 --> 24:49.520
 This function is f function, f0 function, which you want to find.

24:50.240 --> 24:51.760
 And that gives you some value.

24:51.760 --> 25:02.960
 So you say that set of functions converge in inner product to this function.

25:02.960 --> 25:11.600
 If this value of inner product converge to value f0, that is for one phi.

25:12.400 --> 25:19.440
 But phi converges, requires that it converge for any function of Hilbert space.

25:19.440 --> 25:26.080
 If it converge for any function of Hilbert space, then you would say that this is weak convergence.

25:26.960 --> 25:33.680
 You can think that when you take integral, that is property, integral property of function.

25:34.560 --> 25:42.960
 For example, if you will take sine or cosine, it is coefficient of, say, Fourier expansion.

25:42.960 --> 25:54.160
 So if it converge for all coefficients of Fourier expansion, so under some condition,

25:54.160 --> 25:57.040
 it converge to function you're looking for.

25:58.000 --> 26:00.880
 But weak convergence means any property.

26:02.640 --> 26:08.320
 Convergence not point wise, but integral property of function.

26:08.320 --> 26:13.040
 So weak convergence means integral property of functions.

26:13.680 --> 26:22.400
 When I'm talking about predicate, I would like to formulate which integral properties

26:23.120 --> 26:26.160
 I would like to have for convergence.

26:27.840 --> 26:35.200
 So and if I will take one predicate its function, which I measure property,

26:35.200 --> 26:42.800
 if I will use one predicate and say I will consider only function

26:43.760 --> 26:50.560
 which give me the same value as this predicate, I selecting set of functions

26:51.920 --> 26:58.800
 from functions which is admissible in the sense that function which I looking for

26:58.800 --> 27:07.200
 in this set of functions because I checking in training data, it gives the same.

27:08.640 --> 27:11.760
 Yeah, so it always has to be connected to the training data in terms of...

27:12.560 --> 27:20.320
 Yeah, but property, you can know independent on training data and this guy prop.

27:21.120 --> 27:21.760
 Yeah.

27:21.760 --> 27:25.200
 So there is formal property, 31 property and...

27:25.200 --> 27:27.040
 For fairy tale, Russian fairy tale.

27:27.040 --> 27:29.920
 Yeah, but Russian fairy tale is not so interesting.

27:30.480 --> 27:38.000
 More interesting that people apply this to movies, to theater, to different things and

27:38.640 --> 27:41.200
 the same works, they're universal.

27:41.920 --> 27:45.680
 Well, so I would argue that there's a little bit of a difference between

27:47.600 --> 27:53.040
 the kinds of things that were applied to which are essentially stories and digit recognition.

27:54.160 --> 27:55.200
 It is the same story.

27:55.200 --> 27:59.120
 You're saying digits, there's a story within the digit.

27:59.600 --> 28:10.320
 Yeah, so but my point is why I hope that it possible to beat record using not 60,000

28:11.360 --> 28:21.040
 but say 100 times less because instead you will give predicate and you will select your decision

28:21.040 --> 28:26.960
 not from wide set of functions, but from set of function which keeps us predicate.

28:27.920 --> 28:32.160
 But predicate is not related just to digit recognition.

28:32.720 --> 28:33.760
 Right, so...

28:33.760 --> 28:35.040
 Like in Plattus case.

28:37.600 --> 28:41.440
 Do you think it's possible to automatically discover the predicates?

28:42.080 --> 28:48.800
 So you basically said that the essence of intelligence is the discovery of good predicates.

28:48.800 --> 28:53.120
 Yeah, now the natural question is

28:54.960 --> 28:57.760
 you know that's what Einstein was good at doing in physics.

28:58.880 --> 29:03.760
 Can we make machines do these kinds of discovery of good predicates?

29:04.320 --> 29:06.480
 Or is this ultimately a human endeavor?

29:07.600 --> 29:08.400
 That's I don't know.

29:08.400 --> 29:19.760
 I don't think that machine can do because according to theory about weak convergence any function

29:19.760 --> 29:21.760
 from Hilbert space can be predicate.

29:23.120 --> 29:31.840
 So you have infinite number of predicate in upper and before you don't know which predicate is good

29:31.840 --> 29:42.400
 on which but whatever prop show and why people call it breaks through that there is not too many

29:43.520 --> 29:48.480
 predicate which cover most of situation happened in the world.

29:51.200 --> 29:58.320
 So there's a sea of predicates and most of the only a small amount are useful for the kinds of

29:58.320 --> 29:59.680
 things that happen in the world.

29:59.680 --> 30:07.920
 I think that I would say only small part of predicate very useful.

30:08.640 --> 30:10.720
 Useful all of them.

30:11.280 --> 30:15.360
 Only very few are what we should let's call them good predicates.

30:15.360 --> 30:16.560
 Very good predicates.

30:16.560 --> 30:17.520
 Very good predicates.

30:18.160 --> 30:20.720
 So can we linger on it?

30:20.720 --> 30:21.760
 What's your intuition?

30:21.760 --> 30:26.800
 Why is it hard for a machine to discover good predicates?

30:26.800 --> 30:32.560
 I even in my talk described how to do predicate have to find new predicate.

30:32.560 --> 30:34.880
 I'm not sure that it is very good.

30:34.880 --> 30:36.560
 What did you propose in your talk?

30:36.560 --> 30:41.600
 No, in my talk I gave example for diabetes.

30:43.600 --> 30:52.240
 When we achieve some percent so then we're looking for area where some sort of predicate

30:52.240 --> 31:01.200
 which I formulate does not keeps invariant.

31:03.040 --> 31:10.960
 So if it doesn't keep I retain my data I select only function which keeps this invariant

31:10.960 --> 31:14.320
 and when I did it I improve my performance.

31:14.320 --> 31:16.400
 I can looking for this predicate.

31:16.400 --> 31:26.720
 I know technically have to do that and you can of course do it using machine but I'm not

31:26.720 --> 31:30.080
 sure that we will construct the smartest predicate.

31:30.800 --> 31:36.160
 Well this is the allow me to linger on it because that's the essence that's the challenge

31:36.160 --> 31:41.680
 that is artificial that's that's the human level intelligence that we seek is the discovery of

31:41.680 --> 31:49.280
 these good predicates you've talked about deep learning as a way to the predicates they use

31:49.280 --> 31:52.080
 and the functions are mediocre.

31:52.800 --> 31:54.160
 We can find better ones.

31:54.960 --> 31:57.280
 Let's talk about deep learning.

31:57.280 --> 31:58.000
 Sure let's do it.

31:58.000 --> 32:06.560
 I know only Jan Slikun convolutional network and what else I don't know and it's a very

32:06.560 --> 32:07.840
 simple convolution.

32:07.840 --> 32:09.040
 There's not much else to know.

32:09.040 --> 32:15.920
 Left and right yes I can do it like that one is one predicate it is convolution is a single

32:15.920 --> 32:25.280
 predicate it's single it's single predicate yes but you know exactly you take the derivative

32:25.280 --> 32:29.520
 for translation and predicate should be kept.

32:30.960 --> 32:34.560
 So that's a single predicate but humans discovered that one or at least

32:34.560 --> 32:42.880
 not that is a risk not too many predicates and that is big story because Jan did it 25

32:42.880 --> 32:52.960
 years ago and nothing so clear was added to deep network and then I don't understand

32:54.880 --> 33:01.120
 why we should talk about deep network instead of talking about piecewise linear functions

33:01.120 --> 33:02.720
 which keeps us predicated.

33:02.720 --> 33:10.000
 Well the you know a counter argument is that maybe the amount of predicates necessary

33:11.040 --> 33:19.280
 to solve general intelligence say in space of images doing efficient recognition of

33:19.280 --> 33:25.600
 handwritten digits is very small and so we shouldn't be so obsessed about finding

33:25.600 --> 33:31.840
 we'll find other good predicates like convolution for example you know there there has been other

33:32.960 --> 33:38.640
 advancements like if you look at the work with attention there's intentional mechanisms

33:39.360 --> 33:44.240
 in especially used in natural language focusing the the network's ability to

33:45.120 --> 33:47.520
 to learn at which part of the input to look at.

33:47.520 --> 33:53.280
 The thing is there's other things besides predicates that are important for the actual

33:53.280 --> 33:59.760
 engineering mechanism of showing how much you can really do given such these predicates.

34:02.000 --> 34:06.320
 I mean that's essentially the work of deep learning is constructing architectures

34:07.040 --> 34:14.240
 that are able to be given the training data to be able to converge towards

34:17.440 --> 34:21.040
 a function that can approximate can generalize well.

34:21.040 --> 34:24.320
 It's an engineering problem.

34:24.320 --> 34:31.120
 Yeah I understand but let's talk not on emotional level but on a mathematical level.

34:31.760 --> 34:35.120
 You have set of piecewise linear functions.

34:36.320 --> 34:39.680
 It is all possible neural networks.

34:41.840 --> 34:43.840
 It's just piecewise linear functions.

34:43.840 --> 34:45.280
 There's many many pieces.

34:45.280 --> 34:47.520
 Large number of piecewise linear functions.

34:47.520 --> 34:49.280
 Exactly but very large.

34:49.280 --> 34:57.440
 Very large but it's still simpler than say convolution than reproducing

34:57.440 --> 35:00.720
 internal Hilbert space which have a Hilbert set of functions.

35:00.720 --> 35:01.840
 What's Hilbert space?

35:02.800 --> 35:10.800
 It's space with infinite number of coordinates a function for expansion something like that.

35:11.680 --> 35:18.960
 So it's much richer so and when I talking about closed form solution I talking about

35:18.960 --> 35:26.320
 this set of function not piecewise linear set which is particular case.

35:29.440 --> 35:30.720
 It is small part.

35:30.720 --> 35:34.960
 So neural networks is a small part of the space your talk of functions you're talking about.

35:34.960 --> 35:38.400
 Small small say small set of functions.

35:40.400 --> 35:41.360
 But it is fine.

35:41.920 --> 35:42.640
 It is fine.

35:42.640 --> 35:47.760
 I don't want to to discuss the small or big take advantage.

35:47.760 --> 35:49.600
 So you have some set of functions.

35:50.800 --> 35:58.960
 So now when you're trying to create architecture you would like to create admissible set of functions

35:58.960 --> 36:05.520
 all your tricks to use not all functions but some subset of this set of functions.

36:07.120 --> 36:15.200
 Say when you're introducing convolutional net it is way to make this subset useful for you.

36:15.200 --> 36:24.640
 But for my point of view convolutional it is something you want to keep some invariance

36:24.640 --> 36:26.160
 say translation invariance.

36:27.920 --> 36:39.280
 But now if you understand this and you cannot explain on the level of ideas what neural network does

36:39.280 --> 36:48.720
 you should agree that it is much better to have a set of functions and they say this set of functions

36:49.440 --> 36:54.480
 should be admissible it must keep this invariant this invariant and that invariant.

36:55.120 --> 37:00.560
 You know that as soon as you incorporate new invariance set of function because smaller

37:00.560 --> 37:02.000
 and smaller and smaller.

37:02.000 --> 37:05.200
 But all the invariance are specified by you the human.

37:05.200 --> 37:13.840
 Yeah but what I am hope that there is a standard predicate like prop show

37:15.440 --> 37:22.400
 that what that's what I want to find for digit recognition if we start it is completely new

37:22.400 --> 37:30.400
 area what is intelligence about on the level starting from from Plattus idea what is world of ideas.

37:30.400 --> 37:34.480
 So and I believe that it's not too many.

37:35.520 --> 37:41.520
 Yeah but you know it is amusing that mathematician doing something in neural network

37:42.160 --> 37:50.000
 in general function but people from literature from art they use this all the time that's right

37:50.000 --> 37:58.080
 invariance saying say it is great how how people describe music we should learn from that

37:58.080 --> 38:09.680
 and something on this level but so why Vladimir prop who was just theoretical who studied

38:09.680 --> 38:12.000
 theoretical literature he found that.

38:13.120 --> 38:17.200
 You know what let me throw that right back at you because there's a little bit of a

38:17.200 --> 38:23.840
 that's less mathematical and more emotional philosophical Vladimir prop I mean he wasn't

38:23.840 --> 38:32.480
 doing math no and you just said another emotional statement which is you believe that this

38:32.480 --> 38:34.480
 Plato world of ideas is small.

38:35.760 --> 38:43.120
 I hope I hope do you do what's your intuition though if we can linger on it.

38:43.120 --> 38:52.720
 You know it is not just small or big I know exactly then when I introducing

38:54.880 --> 39:02.480
 some predicate I decrease set of functions but my goal to decrease set of function much

39:03.600 --> 39:10.160
 by as much as possible by as much as possible good predicate which does this

39:10.160 --> 39:16.560
 then I should choose next predicate which does this decrease set as much as possible

39:17.120 --> 39:27.680
 so set of good predicate it is such that they decrease this amount of admissible function.

39:27.680 --> 39:32.640
 So if each good predicate significantly reduces the set of admissible functions that

39:32.640 --> 39:35.440
 there naturally should not be that many yeah predicates.

39:35.440 --> 39:44.800
 No but but if you reduce very well the VC dimension of the function of admissible set

39:44.800 --> 39:50.880
 of function is small and you need not too much training data to do well.

39:52.880 --> 39:57.600
 And VC dimension by the way is some measure of capacity of this set of functions.

39:57.600 --> 40:03.840
 Right how roughly speaking how many functions in this set so you're decreasing decreasing

40:03.840 --> 40:08.800
 and it makes it easy for you to find function you're looking for.

40:10.160 --> 40:16.400
 So the most important part to create good admissible set of functions and it probably

40:16.400 --> 40:25.040
 there are many ways but the good predicate is such that that can do that.

40:25.760 --> 40:32.320
 So let's for this duck you should know a little bit about duck because what are the

40:32.320 --> 40:34.480
 what are the three fundamental laws of ducks?

40:35.280 --> 40:38.240
 Looks like a duck swims like a duck and quack like a duck.

40:38.240 --> 40:41.040
 You should know something about ducks to be able to.

40:41.040 --> 40:45.520
 Not necessarily looks like say horse it's also good.

40:46.400 --> 40:49.760
 So it's not it generalizes from ducks.

40:49.760 --> 40:57.280
 And talk like and make sound like horse something and run like horse and moves like horse.

40:57.280 --> 41:05.760
 It is general it is general predicate that this applied to duck but for duck you can say

41:07.120 --> 41:08.240
 play chess like duck.

41:09.760 --> 41:11.440
 You cannot say play chess.

41:11.440 --> 41:11.920
 Why not?

41:12.480 --> 41:15.680
 So you're saying you can but that would not be a good.

41:15.680 --> 41:18.080
 No you will not reduce a lot of.

41:18.080 --> 41:21.600
 You will not do yeah you would not reduce the set of functions.

41:21.600 --> 41:29.120
 So you get the story is formal story mathematical story is that you can use any function you want

41:29.120 --> 41:34.880
 like the predicate but some of them are good some of them are not because some of them reduce a

41:34.880 --> 41:38.640
 lot of functions to admissible set of some of them.

41:39.680 --> 41:44.880
 But the question is I'll probably keep asking this question but how do we find such

41:45.600 --> 41:46.480
 what's your intuition?

41:46.480 --> 41:52.480
 So my hand written hand written recognition how do we find the the answer to your challenge?

41:52.480 --> 41:54.800
 Yeah yeah I understand it like that.

41:55.760 --> 42:01.120
 I understand what what to find what it means I knew predicate.

42:01.680 --> 42:08.720
 Yeah like guy who understand music can say this word which he described when he listened to music.

42:09.440 --> 42:15.440
 He understand music he use not too many different or you can do like prop.

42:15.440 --> 42:22.000
 You can make collection what he talking about music about this about that it's not too many

42:22.000 --> 42:24.320
 different situations he described.

42:24.880 --> 42:26.800
 Because we mentioned Vladimir proper bunch.

42:26.800 --> 42:36.800
 Let me just mention there's a there's a sequence of 31 structural notions that are common in stories

42:36.800 --> 42:40.400
 and I think he called units units and I think they resonate.

42:40.400 --> 42:45.920
 I mean it starts just to give an example of ascension a member of the hero's community

42:45.920 --> 42:50.880
 of family leaves the security of the home environment then it goes to the introduction

42:50.880 --> 42:57.040
 or forbidding edict or command is passed upon the hero don't go there don't do this the hero's

42:57.040 --> 42:58.640
 warrant against some action.

42:58.640 --> 43:06.480
 Then step three violet violation of interdiction breaks you know break the rules break out on

43:06.480 --> 43:12.080
 your own then reconnaissance the villain makes an effort to attain knowledge needing to fulfill

43:12.080 --> 43:20.480
 their plot so on it goes on like this ends ends in a wedding number 31 happily ever after.

43:20.480 --> 43:27.200
 No he he he just gave description of all situations he understands this world.

43:28.000 --> 43:29.200
 Of folk tales.

43:29.200 --> 43:38.640
 Yeah not folk stories and this story is not in just folk tales the stories in in detective

43:38.640 --> 43:46.560
 serials as well and probably in our lives we probably live read this and then they they

43:46.560 --> 43:57.760
 wrote that this predicate is good for different situation from movie from for movie for theater.

43:57.760 --> 44:04.160
 By the way there's also criticism right there's an other way to interpret narratives from

44:07.600 --> 44:13.280
 Claude Levy Strauss I think I don't I I'm not in this business I know I know it's

44:13.280 --> 44:18.480
 theoretical literature but it's looking at paradise it's always the the the the

44:18.480 --> 44:26.400
 discussion yeah yeah but at least there is a unit it's not too many units that can describe

44:26.400 --> 44:34.560
 but that's probably gives another unit or another way exactly another another set of units another

44:34.560 --> 44:44.480
 set of predicates it does not matter but they exist probably my my question is whether given those

44:44.480 --> 44:52.320
 units whether without our human brains to interpret these units they would still hold as much power

44:52.320 --> 45:00.240
 as they have meaning are those units enough when we give them to the alien species let me ask you

45:00.240 --> 45:09.040
 do you understand digit recognize digit images no I don't understand no no no uh when you can

45:09.040 --> 45:16.400
 recognize this digit images it means that you understand yes you understand characters you

45:16.400 --> 45:25.760
 understand no no no no I I it's the it's the imitation versus understanding question because

45:26.560 --> 45:31.840
 I don't understand the mechanism by which I am not talking about I'm talking about predicates

45:32.640 --> 45:38.640
 you understand that it involves symmetry maybe structure maybe something else I cannot formulate

45:38.640 --> 45:45.680
 I just was able to find symmetries so I guess symmetries that's really good so this is a good

45:45.680 --> 45:53.280
 line I feel like I understand the basic elements of what makes a good hand recognition system

45:53.280 --> 46:00.480
 my own like symmetry connects with me it seems like that's a very powerful predicate my question is

46:00.480 --> 46:08.720
 is there a lot more going on that we're not able to introspect maybe I need to be able to understand

46:08.720 --> 46:18.880
 a huge amount in the world of ideas uh thousands of predicates millions of predicates in order to

46:18.880 --> 46:26.800
 do hand recognition I don't think so so you're you're both your hope and your intuition of such

46:26.800 --> 46:36.560
 that let me explain you're using digits you're using examples as well theory says that if you

46:36.560 --> 46:47.680
 will use all possible functions from hilda space all possible predicate you don't need training data

46:48.880 --> 46:58.240
 you just will have admissible set of function which contain one function yes so the tradeoff

46:58.240 --> 47:03.440
 is when you're not using all predicates you're only using a few good predicates you need to

47:03.440 --> 47:09.040
 have some training data yes the more the the more good predicates you have the less training

47:09.040 --> 47:16.640
 data exactly that is intelligent still okay I'm going to keep asking the same dumb question

47:17.360 --> 47:21.920
 handwritten recognition to solve the challenge you kind of propose a challenge that says we

47:21.920 --> 47:30.080
 should be able to get state of the art amnesty error rates by using very few 60 maybe fewer

47:30.080 --> 47:38.640
 examples per digit what kind of predicates do you think that is the challenge so people who will

47:38.640 --> 47:43.680
 solve this problem they will answer they will answer do you think they'll be able to answer it

47:44.640 --> 47:52.480
 in a human explainable way they just need to write function that's it but so can that function

47:52.480 --> 48:00.400
 be written I guess by an automated reasoning system whether we're talking about a neural

48:00.400 --> 48:07.280
 network learning a particular function or another mechanism no narrow I'm not against

48:07.280 --> 48:14.400
 neural network I'm against admissible set of function which create neural network you did it

48:14.400 --> 48:25.280
 by hand you don't you don't do it by invariance by predicate by by by reason but neural networks

48:25.280 --> 48:32.640
 can then reverse do the reverse step of helping you find a function just the task of a neural

48:32.640 --> 48:40.400
 network is is to find a disentangled representation for example what they call is to find that one

48:40.400 --> 48:46.960
 predicate function that's really captures some kind of essence one not the entire essence but

48:46.960 --> 48:53.680
 one very useful essence of this particular visual space do you think that's possible like

48:55.280 --> 49:00.960
 listen I'm grasping hoping there's an automated way to find good predicates right so the question

49:00.960 --> 49:07.840
 is what are the mechanisms of finding good predicates ideas the you think we should pursue

49:07.840 --> 49:16.720
 a young grad student listening right now I gave example so find situation where

49:18.800 --> 49:24.640
 predicate which you're suggesting don't create invariant

49:27.120 --> 49:34.080
 it's like in physics find situation where existing theory cannot explain it

49:34.080 --> 49:39.280
 so you're finding contradictions find contradiction and then remove this contradiction

49:39.280 --> 49:46.640
 but in my case what means contradiction you find function which if you will use this function

49:46.640 --> 50:01.920
 you you're not keeping invariance so really the process of discovering contradictions yeah

50:01.920 --> 50:11.600
 it is like in physics find situation where you have contradiction for one of the property

50:13.040 --> 50:19.680
 for one of the predicate then include this predicate making invariance and solve again

50:19.680 --> 50:24.720
 this problem now you don't have contradiction but it is not

50:24.720 --> 50:34.240
 the best way probably I don't know to looking for predicate that's just one way okay that no no

50:34.240 --> 50:43.200
 it is brute force way the brute force way what about the ideas of some what big umbrella term

50:43.200 --> 50:51.040
 of symbolic AI there's what in 80s with expert systems sort of logic reasoning based systems

50:51.040 --> 51:04.080
 is there hope there to find some through sort of deductive reasoning to find good predicates

51:05.360 --> 51:13.520
 I don't think so I think that just logic is not enough it's kind of a compelling notion though

51:14.240 --> 51:20.240
 you know that when smart people sit in a room and reason through things it seems compelling

51:20.240 --> 51:27.440
 and making our machines do the same is also compelling so everything is very simple

51:29.280 --> 51:38.880
 when you have infinite number of predicate you can choose the the function you want you have

51:38.880 --> 51:50.560
 invariance and you can choose the function you want but you have to have a not too many invariance

51:51.680 --> 52:02.720
 to solve the problem so and half from infinite number of function to select finite number

52:02.720 --> 52:15.680
 and hopefully small fine number of functions which is good enough to extract small set of admissible

52:15.680 --> 52:23.280
 functions so they will be admissible it's for sure because every function just decrease set of

52:23.280 --> 52:29.120
 function and leaving it admissible but it will be small but why do you think logic

52:29.120 --> 52:38.000
 basic systems don't can't help intuition not because you you should know reality you should

52:38.000 --> 52:48.400
 know life this guy like prop he knows something and he tried to to put in invariant his understanding

52:49.200 --> 52:53.440
 that's the human yeah but see you're you're putting too much value into

52:53.440 --> 53:02.480
 you Vladimir props knowing something no it is my story is that what means you know life

53:04.320 --> 53:12.160
 what it means you know common sense no no you know something common sense it is some rules

53:13.280 --> 53:19.840
 you think so common sense is simply rules common sense is every it's

53:19.840 --> 53:29.840
 it's mortality it's no it's it's fear of death it's love it's spirituality it's a happiness and

53:29.840 --> 53:36.720
 sadness all of it is tied up into understanding gravity which is what we think of as common sense

53:36.720 --> 53:44.240
 I don't really to discuss so white I want to discuss understand digitally understand

53:44.240 --> 53:50.160
 digitally recognition anytime I bring up love and death you you bring it back to digital recognition

53:50.160 --> 53:58.000
 I don't like it no you know it is durable because there is a challenge yeah which I see how to solve

53:58.000 --> 54:05.040
 it if I will have a student concentrating this work I will suggest something to solve you mean

54:05.040 --> 54:11.680
 handwritten recognition yeah it's a beautifully simple elegant and yet I think that I know in

54:11.680 --> 54:22.080
 variants which will solve this you do I think so yes but it is not universal it is maybe I want

54:22.080 --> 54:28.400
 some universal in variants which are good not only for digital recognition for image understanding

54:30.560 --> 54:36.800
 so let me ask how hard do you think is 2d image understanding

54:36.800 --> 54:47.600
 so if we we can kind of intuit handwritten recognition how big of a step leap journey is it

54:47.600 --> 54:53.920
 from that if I gave you good if I solved your challenge for handwriting recognition how long

54:53.920 --> 55:00.480
 would my journey then be from that to understanding more general natural images immediate you will

55:00.480 --> 55:09.440
 understand this as soon as you will make a record because it is not for free as soon as you will

55:09.440 --> 55:21.120
 create several in variants which will help you to get the same performance that the best neural

55:21.120 --> 55:30.080
 net did using 100 times maybe more than 100 times less examples you have to have something smart

55:30.080 --> 55:37.440
 to do that and you're saying that it is invariant it is predicate because you should put some idea

55:37.440 --> 55:45.360
 how to do that but okay let me just pause maybe it's a trivial point maybe not but handwritten

55:45.360 --> 55:55.280
 recognition feels like a 2d two dimensional problem and it seems like how much complicated is the fact

55:55.280 --> 56:04.000
 that most images are projection of a three dimensional world onto a 2d plane it feels like

56:04.000 --> 56:09.600
 for a three dimensional world we still we need to start understanding common sense in order to

56:09.600 --> 56:19.120
 understand an image it's no longer visual shape and symmetry it's having to start to understand

56:19.120 --> 56:25.840
 concepts of it understand life yeah yes yes you're you're you're talking that there are

56:25.840 --> 56:33.200
 different invariant different predicates yeah and potentially much larger number you know

56:33.200 --> 56:41.280
 maybe but let's start from simple okay but you said that you know I cannot think yes about things

56:41.280 --> 56:47.600
 which I don't understand this I understand but I'm sure that I don't understand everything there

56:47.600 --> 56:55.520
 yeah yeah that's the difference say do as simple as possible but not simpler and that is exact case

56:56.400 --> 57:02.560
 with handwritten with handwritten yeah but never that's the difference between you and I I I uh

57:04.800 --> 57:10.720
 I welcome and enjoy thinking about things I completely don't understand because to me it's

57:10.720 --> 57:21.200
 a natural extension without having solved handwritten recognition to wonder how how difficult is the

57:21.200 --> 57:29.120
 the the next step of understanding 2d 3d images because ultimately while the science of intelligence

57:29.120 --> 57:34.560
 is fascinating it's also fascinating to see how that maps to the engineering of intelligence

57:34.560 --> 57:44.000
 and recognizing handwritten digits is not doesn't help you it might it may not help you with the

57:44.000 --> 57:49.360
 problem of general intelligence we don't know it'll help you a little bit we don't know it's unclear

57:49.360 --> 57:55.280
 it's unclear yeah it might very much but I would like to make a remark yes I start not from very

57:55.280 --> 58:06.560
 primitive problem make a challenge problem I start with very general problem with plateau

58:07.520 --> 58:15.280
 so you understand and and it comes from plato to to to digit recognition so so you basically took

58:15.280 --> 58:22.800
 play dough and the the world of forms and ideas and mapped and projecting into the

58:22.800 --> 58:29.920
 clearest simplest formulation of that big world you know I would say that I did not understand

58:29.920 --> 58:42.160
 plato until recently and until I consider weak convergence and then predicate and then oh this

58:42.160 --> 58:50.160
 is what plato told me so linger on that like why how do you think about this world of ideas and

58:50.160 --> 58:56.400
 world of things in play dough no it is metaphor it is it's the metaphor for sure it's a compelling

58:56.400 --> 59:03.760
 it's a poetic and a beautiful yeah but what can you but it is a way how you you you should try to

59:03.760 --> 59:14.080
 understand have attack ideas in the world so from my point of view it is very clear but it is lying

59:14.080 --> 59:24.560
 all the time people looking for that say plato's and Hegel whatever reasonable it exists whatever

59:24.560 --> 59:31.360
 exists it is reasonable I don't know what he have in mind reasonable right this philosophers again

59:31.360 --> 59:38.960
 no no no no no no no it is it is next stop of Wigner that what you might understand something

59:38.960 --> 59:46.720
 of reality it is the same plato line and then it comes suddenly to Vladimir prop

59:48.000 --> 59:57.760
 look 31 ideas 31 units and describes everything there's abstractions ideas that represent

59:59.040 --> 1:00:06.080
 our world and we should always try to reach into that yeah but but you should make a projection

1:00:06.080 --> 1:00:15.680
 on reality but understanding is it is abstract ideas you have in your mind several abstract ideas

1:00:15.680 --> 1:00:20.880
 which you can apply to reality and reality in this case sort of if you look at machine learning is

1:00:20.880 --> 1:00:28.160
 data example data data okay let me let me put put this on you because I'm an emotional creature

1:00:28.160 --> 1:00:35.200
 I'm not a mathematical creature like you I find compelling the idea forget this the space the sea

1:00:35.200 --> 1:00:42.080
 of functions there's also a sea of data in the world and I find compelling that there might be

1:00:42.080 --> 1:00:53.280
 like you said teacher small examples of data that are most useful for discovering good whether it's

1:00:53.280 --> 1:01:01.200
 predicates or good functions that the selection of data may be a powerful journey a useful

1:01:01.200 --> 1:01:06.160
 mechanism you know coming up with a mechanism for selecting good data might be useful too

1:01:07.440 --> 1:01:14.960
 do you find this idea of finding the right data set interesting at all or do you kind of take

1:01:14.960 --> 1:01:23.840
 the data set as a given I think that it is you know my scheme is very simple you have huge set of

1:01:23.840 --> 1:01:33.200
 functions if you will apply and you have not too many data right if you will pick up function

1:01:34.000 --> 1:01:42.720
 which describes this data you will do not very well you will randomly pick up yeah you will

1:01:42.720 --> 1:01:50.560
 have a fit here yeah it will be overfitting so you should decrease set of function from which

1:01:50.560 --> 1:02:00.960
 you're picking up one so you should go some half to admissible set of function and this what about

1:02:00.960 --> 1:02:12.960
 weak conversions so but from another point of view to to make admissible set of function

1:02:12.960 --> 1:02:20.960
 you need just a deed you just function which you will take in inner product which you will measure

1:02:22.800 --> 1:02:24.240
 property of your function

1:02:27.360 --> 1:02:35.280
 and that is how it works no I get it I get I understand it but do you the reality is but let

1:02:35.280 --> 1:02:43.680
 let this let let's think about examples you have huge set of function if you have several examples

1:02:44.560 --> 1:02:55.280
 if you just trying to keep take function which satisfies these examples you still will overfit

1:02:56.400 --> 1:03:02.240
 you need decrease you need admissible set of function absolutely but what say you have

1:03:02.240 --> 1:03:09.600
 more data than functions so sort of consider the I mean maybe not more data than functions

1:03:09.600 --> 1:03:15.280
 because that's impossible impossible but what I was trying to be poetic for a second I mean

1:03:15.280 --> 1:03:22.080
 you have a huge amount of data a huge amount of examples but amount of function can be even

1:03:22.640 --> 1:03:27.680
 bigger I understand every single there's always there's always a bigger boat full

1:03:27.680 --> 1:03:37.520
 Hilbert space I got you but okay but you don't you don't find the world of data to be an interesting

1:03:37.520 --> 1:03:41.920
 optimization space like the the optimization should be in the space of functions

1:03:44.880 --> 1:03:51.440
 creating admissible set of fun admissible set of function no you know even from the classical

1:03:51.440 --> 1:04:01.200
 this is sorry from structure risk minimization you should or you should organize function in the way

1:04:02.160 --> 1:04:11.600
 that they will be useful for you right and that is yeah but the the way you're thinking about

1:04:11.600 --> 1:04:21.840
 useful is you're given a small set small small set of function which contain function by looking yeah

1:04:21.840 --> 1:04:29.600
 but as looking for based on the empirical set of small examples yeah but that is another story I

1:04:29.600 --> 1:04:36.560
 don't touch it because I I believe I believe that this small examples it's not too small

1:04:36.560 --> 1:04:44.480
 so 60 per class that law of large numbers works I don't need uniform law the story is that in

1:04:44.480 --> 1:04:52.240
 statistics there are two law law of large numbers uniform law of large numbers so I want to be in

1:04:52.240 --> 1:04:59.600
 situation where I use law of large numbers no but not uniform law of large numbers right so 60 is

1:04:59.600 --> 1:05:07.760
 law of large it's like enough I hope no it's still need some evaluation some bounce so that's it

1:05:07.760 --> 1:05:20.080
 but idea is the following that if you trust that say this average gives you something close to

1:05:20.080 --> 1:05:29.920
 expectations so you can talk about that about this predicate and that is basis of human intelligence

1:05:29.920 --> 1:05:35.200
 right good predicates is the discovery of good predicates is the basis of no no it is

1:05:35.200 --> 1:05:42.960
 discovery of your of your understanding world of your methodology of a distance of understanding

1:05:42.960 --> 1:05:52.560
 world because you have several functions which you will apply to reality can you say that again so

1:05:53.440 --> 1:06:02.000
 your you have several functions yeah predicate but they abstract yes then you will apply them to

1:06:02.000 --> 1:06:09.200
 reality to your data and you will create in this way predicate which is useful for your task

1:06:09.200 --> 1:06:19.040
 but predicate are not related specifically to your task to this your task it is abstract functions

1:06:19.920 --> 1:06:26.400
 which being applying applied to many tasks that you might be interested in it may be many tasks I

1:06:26.400 --> 1:06:34.560
 don't know or different tasks well they should be many tasks right yeah it is like like in probe case

1:06:34.560 --> 1:06:41.680
 yes it was for free details but it's happened everywhere okay so we talked about images a

1:06:41.680 --> 1:06:54.880
 little bit but can we talk about Noam Chomsky for a second I don't know him personally well

1:06:55.520 --> 1:07:01.280
 not personally I don't know his ideas his ideas well let me just say do you think language human

1:07:01.280 --> 1:07:09.920
 language is essential to expressing ideas as Noam Chomsky believes so like language is at the core

1:07:09.920 --> 1:07:18.480
 of our formation of predicates the human language for me language and all the story of language

1:07:18.480 --> 1:07:27.360
 is very complicated I don't understand this and I am not I thought about nobody I'm not ready to

1:07:27.360 --> 1:07:33.920
 work on that because it's so huge it is not for me and I believe not for our century

1:07:35.840 --> 1:07:41.360
 the 21st century not for 21st century so you should learn something a lot of stuff

1:07:42.080 --> 1:07:48.080
 from simple tasks like digit recognition so you think okay you think digital recognition

1:07:48.080 --> 1:07:57.680
 2d image what how would you more abstractly define it digit recognition it's 2d image

1:07:59.600 --> 1:08:08.560
 symbol recognition essentially I mean I like I'm trying to get a sense sort of thinking

1:08:08.560 --> 1:08:16.640
 about it now having worked with MNIST forever how how small of a subset is this of the general

1:08:16.640 --> 1:08:25.840
 vision recognition problem and the general intelligence problem is it yeah is it a giant

1:08:25.840 --> 1:08:35.760
 subset is it not and how far away is language you know let me refer to Einstein take the simplest

1:08:35.760 --> 1:08:42.720
 problem as simple as possible but not simpler and this is challenge is simple problem

1:08:42.720 --> 1:08:54.560
 but it's simple by idea but not simple to to get it when you will do this you will find

1:08:54.560 --> 1:09:03.840
 some predicate which helps it but yeah I mean with Einstein you can you look at general relativity

1:09:03.840 --> 1:09:09.840
 but that doesn't help you with quantum mechanics that's another story you you don't have any

1:09:09.840 --> 1:09:18.240
 universal instrument yes so I'm trying to wonder if uh which space we're in whether the whether

1:09:18.240 --> 1:09:23.120
 handwritten recognition is like general relativity and then language is like quantum mechanics so

1:09:23.120 --> 1:09:32.720
 you're still gonna have to do a lot of mess to to universalize it but uh I'm trying to see

1:09:32.720 --> 1:09:40.480
 one so what's your intuition why handwritten recognition is easier than language

1:09:41.840 --> 1:09:47.280
 just I think a lot of people would agree with that but if you could elucidate sort of the

1:09:47.840 --> 1:09:57.360
 the intuition of why I don't know no I don't think in this direction I just think in

1:09:57.360 --> 1:10:04.720
 direction that this is problem which if we will solve it well

1:10:07.680 --> 1:10:09.600
 we will create

1:10:12.480 --> 1:10:21.360
 some abstract understanding of images maybe not all images I would like to talk to guys who

1:10:21.360 --> 1:10:29.280
 are doing in real images in Columbia University what kind of images unreal so real images real

1:10:29.280 --> 1:10:37.280
 images yeah what their idea is there a predicate what can be predicated I still symmetry will play

1:10:38.080 --> 1:10:46.560
 role in real life images in any real life images 2d images let's talk about 2d images because

1:10:46.560 --> 1:10:57.440
 that's what we know in neural network was created for 2d images so the people I know in

1:10:57.440 --> 1:11:03.280
 vision science for example the people study human vision yeah that they usually go to the world of

1:11:03.840 --> 1:11:09.200
 symbols and like handwritten recognition but not really it's other kinds of symbols to study

1:11:09.200 --> 1:11:15.600
 our visual perception system as far as I know not much predicate type of thinking is understood

1:11:15.600 --> 1:11:21.040
 about our vision system they did not think in this direction they don't yeah they but how do

1:11:21.040 --> 1:11:27.600
 you even begin to think in that direction that says so I would like to discuss with them yeah

1:11:27.600 --> 1:11:33.360
 because if we will be able to show that it is what working

1:11:35.440 --> 1:11:43.200
 and theoretical scheme it's not so bad so the the unfortunate so if we compare to language

1:11:43.200 --> 1:11:49.360
 language has like letters finite set of letters and a finite set of ways you can put together

1:11:49.360 --> 1:11:57.120
 those letters so it feels more amenable to kind of analysis with natural images there is so many

1:11:57.120 --> 1:12:06.880
 pixels no no no letter language is much much more complicated it's involved a lot of different stuff

1:12:06.880 --> 1:12:17.360
 it's not just understanding of very simple class of tasks I would like to see lists of tasks

1:12:18.080 --> 1:12:23.040
 where language involved yes so there's a there's a lot of nice benchmarks now on

1:12:23.040 --> 1:12:29.120
 in natural language processing from the very trivial like understanding the elements of a

1:12:29.120 --> 1:12:34.960
 sentence to question answering to more much more complicated where you talk about open domain dialogue

1:12:34.960 --> 1:12:41.840
 the natural question is with handwritten recognition is really the first step yeah of

1:12:41.840 --> 1:12:52.800
 understanding visual information right but not but but even our records show that we go in wrong

1:12:52.800 --> 1:12:59.840
 direction because we need 60 000 digits so even this first step so forget about talking about the

1:12:59.840 --> 1:13:05.040
 full journey this first step should be taking in the right direction no no in wrong direction because

1:13:05.040 --> 1:13:11.920
 60 000 is unacceptable no I'm saying it should be taken in the in the right direction because 60 000

1:13:11.920 --> 1:13:20.160
 is not acceptable it is you can talk it's great we have half percent of error and hopefully the step

1:13:20.160 --> 1:13:27.520
 from doing hand recognition using very few examples the step towards what babies do when they crawl and

1:13:27.520 --> 1:13:33.760
 understand their physical environment I know you don't know about babies if you will do from very

1:13:33.760 --> 1:13:42.720
 small examples yeah you will find principles that will be different from what we're using now

1:13:44.320 --> 1:13:52.640
 and theoretically it's more or less clear that means that you will use weak convergence not just

1:13:52.640 --> 1:14:00.480
 strong convergence do you think these principles are will naturally be human interpretable

1:14:01.440 --> 1:14:06.240
 oh yeah so like when we will be able to explain them and have a nice presentation to show what

1:14:06.240 --> 1:14:13.760
 those principles are or are they very going to be very kind of abstract kinds of functions

1:14:14.320 --> 1:14:20.880
 for example I talked yesterday about symmetry yes and they gave very simple examples the same will

1:14:20.880 --> 1:14:27.040
 be laying there you gave like a predicate of a basic for for symmetries yes for different symmetries and

1:14:27.040 --> 1:14:35.440
 you have for a degree of symmetry that is important not just symmetry existence doesn't exist a degree

1:14:35.440 --> 1:14:44.960
 of symmetry yeah for handwritten recognition no it's not for handwritten it's for any images

1:14:44.960 --> 1:14:50.560
 but I would like apply to handwritten right it's in theory it's more general okay okay

1:14:55.040 --> 1:15:01.680
 so a lot of things we've been talking about falls we've been talking about philosophy a little bit

1:15:01.680 --> 1:15:08.960
 but also about mathematics and statistics a lot of it falls into this idea a universal idea of

1:15:08.960 --> 1:15:17.520
 statistical theory of learning what is the most beautiful and sort of powerful or essential

1:15:17.520 --> 1:15:23.040
 idea you've come across even just for yourself personally in in the world of statistics or

1:15:23.040 --> 1:15:31.840
 a statistic theory of learning probably uniform convergence which we did with Alexei Chilvonakis

1:15:31.840 --> 1:15:38.480
 can you describe universal convergence you have law of large law of large numbers

1:15:40.000 --> 1:15:46.960
 so for any function expectation of function average of function conversion expectation

1:15:47.920 --> 1:15:55.440
 but if you have set of functions for any function it is true but it should converge simultaneously

1:15:55.440 --> 1:16:07.520
 for all set of functions and for for learning you need uniform convergence just convergence

1:16:07.520 --> 1:16:21.200
 is not enough because when you pick up one which gives minimum you can pick up one function which

1:16:21.200 --> 1:16:27.680
 does not converge in and it will give you the best answer for for this function

1:16:31.360 --> 1:16:36.320
 so you need the uniform convergence to guarantee learning so learning does not

1:16:37.200 --> 1:16:43.040
 really on trivial law large numbers it really on universal but

1:16:43.040 --> 1:16:52.080
 but a deal of weak convergence existing statistics for a long time but

1:16:55.280 --> 1:17:06.240
 it is interesting that as I think about myself how stupid I was 50 years I did not see weak

1:17:06.240 --> 1:17:14.160
 convergence I work on strong convergence but now I think that most powerful is weak convergence

1:17:15.120 --> 1:17:23.600
 because it makes admissible set of functions and even in all in proverbs when people try to

1:17:23.600 --> 1:17:31.520
 understand recognition about dog law looks like a dog and so on they use weak convergence

1:17:31.520 --> 1:17:39.120
 people in language they understand this but when we're trying to create artificial

1:17:39.840 --> 1:17:48.320
 intelligence we want event in different way we just consider strong convergence

1:17:48.960 --> 1:17:54.480
 arguments so reducing a set of admissible functions you think there should be

1:17:56.720 --> 1:18:01.120
 effort put into understanding the properties of weak convergence

1:18:01.120 --> 1:18:08.880
 you know in classical mathematics in Gilbert space there are only two way two

1:18:09.520 --> 1:18:19.360
 form of convergence strong and weak now we can use both that means that we did everything

1:18:19.360 --> 1:18:31.120
 and it so happened then when we use Hilbert space which is very rich space space of continuous

1:18:31.120 --> 1:18:41.440
 functions which has an integral in square so we can apply weak and strong convergence for learning

1:18:41.440 --> 1:18:50.720
 and have closed form solution so for computationally simple for me it is sign that it is right way

1:18:52.160 --> 1:19:01.360
 because you don't need any heuristic yes whatever you want but now the only what left

1:19:02.400 --> 1:19:08.640
 it is concept of what is predicate but it is not statistics by the way I like

1:19:08.640 --> 1:19:13.840
 the fact that you think the heuristics are a mess that should be removed from the system

1:19:14.720 --> 1:19:20.560
 so closed form solution is the ultimate no it so happened then when you're using

1:19:22.320 --> 1:19:25.200
 right instrument you have closed form solution

1:19:25.200 --> 1:19:35.120
 do you think intelligence human level intelligence when we create it will

1:19:37.600 --> 1:19:44.480
 will have something like a closed form solution you know I now I'm looking on

1:19:44.480 --> 1:19:54.400
 bounds which I gave bounds for convergence and when I looking for bounds I thinking

1:19:56.000 --> 1:20:03.920
 what is the most appropriate kernel for this bound would be so you know that in say

1:20:03.920 --> 1:20:14.720
 all our businesses we use radial basis function but looking on the bound I think that I start

1:20:14.720 --> 1:20:22.320
 to understand that maybe we need to make corrections to radial basis function to be closer

1:20:22.320 --> 1:20:32.320
 to work better for these bounds so I'm again trying to understand what type of kernel

1:20:33.760 --> 1:20:42.080
 have best approximation no approximation best fit to this ball

1:20:43.280 --> 1:20:47.200
 sure so there's a there's a lot of interesting work that could be done in discovering better

1:20:47.200 --> 1:20:56.560
 functions and radial basis functions for for yeah but but it still comes from you you're

1:20:56.560 --> 1:21:02.640
 you're looking to mass and trying to understand what from your own mind looking at the yeah but

1:21:02.640 --> 1:21:12.240
 I don't know then I trying to understand what what will be good for that yeah but to me there's

1:21:12.240 --> 1:21:18.880
 still a beauty again maybe I'm a descendant valenturing to heuristics to me ultimately

1:21:19.760 --> 1:21:26.160
 intelligence will be a mess of heuristics and no that's the engineering answer I guess

1:21:26.160 --> 1:21:34.080
 absolutely when when you're doing say self driving cars the great guy who will do this

1:21:34.080 --> 1:21:44.720
 it does not matter what theory behind that who has a better feeling have to apply but by the way

1:21:46.640 --> 1:21:55.200
 it is the same story about predicates because you cannot create rule for situation is much more

1:21:55.200 --> 1:22:06.880
 than you have rule for that but maybe you can have more abstract rule than it will be less

1:22:06.880 --> 1:22:14.720
 this rule it is the same story about ideas and and ideas applied to specific cases

1:22:16.400 --> 1:22:21.440
 but still you should you cannot avoid this yes of course but you should still reach for the ideas

1:22:21.440 --> 1:22:28.800
 to understand the science yeah let me kind of ask do you think neural networks or functions

1:22:30.800 --> 1:22:37.840
 can be made to reason sort of what do you think we've been talking about intelligence but this

1:22:37.840 --> 1:22:45.200
 idea of reasoning there's a there's an element of sequentially disassembling interpreting

1:22:45.200 --> 1:22:54.240
 the the images so when you think of handwritten recognition we kind of think that there will

1:22:54.240 --> 1:23:02.320
 be a single there's an input and output there's not a recurrence yeah what do you think about

1:23:02.320 --> 1:23:07.360
 sort of the idea of recurrence of going back to memory and thinking through this sort of

1:23:07.360 --> 1:23:17.040
 sequentially mangling the different representations over and over until you arrive at a conclusion

1:23:19.840 --> 1:23:22.560
 or is ultimately all that can be wrapped up into a function

1:23:23.280 --> 1:23:31.120
 no you you're suggesting that let us use this type of algorithm when I starting thinking I

1:23:31.120 --> 1:23:40.800
 first of all starting to understand what I want can I write down what I want and

1:23:41.840 --> 1:23:48.960
 then I trying to formalize and when I do that I think I have to solve this problem

1:23:48.960 --> 1:24:03.680
 and till now I did not see a situation where you need recurrence

1:24:03.680 --> 1:24:12.640
 but do you observe human beings yeah do you try to it's the imitation question right it seems

1:24:12.640 --> 1:24:22.800
 that human beings reason this kind of sequentially sort of does that inspire in you a thought that

1:24:22.800 --> 1:24:34.000
 we need to add that into our intelligent systems you're saying okay I mean you've kind of answered

1:24:34.000 --> 1:24:40.240
 saying until now I haven't seen a need for it and so because of that you don't see a reason to think

1:24:40.240 --> 1:24:50.480
 about it you know most of things I don't understand in reasoning in human it is for me too complicated

1:24:52.640 --> 1:25:04.080
 for me the most difficult part is to ask questions to good questions how it works how

1:25:04.080 --> 1:25:13.840
 people asking questions I don't know this you said that machine learning is not only about

1:25:13.840 --> 1:25:22.160
 technical things speaking of questions but it's also about philosophy so what role does philosophy

1:25:22.160 --> 1:25:29.600
 play in machine learning we talked about Plato but generally thinking in this philosophical way

1:25:29.600 --> 1:25:34.880
 does it have how does philosophy and math fit together in your mind

1:25:36.480 --> 1:25:40.960
 first ideas and then their implementation it's like predicate like

1:25:44.000 --> 1:25:51.760
 say admissible set of functions it comes together everything because

1:25:51.760 --> 1:26:01.200
 the first iteration of theory was done 50 years ago it all that this is so everything there

1:26:02.080 --> 1:26:12.560
 if you have data you can and you in your set of function is not has a not have a not big capacity

1:26:13.440 --> 1:26:19.360
 so low VC dimension you can do that you can make structural risk minimization control capacity

1:26:19.360 --> 1:26:31.680
 but you was not able to make admissible set of function good no one suddenly realized that

1:26:32.560 --> 1:26:36.800
 we did not use another idea of convergence which we can

1:26:39.280 --> 1:26:45.920
 everything comes together but those are mathematical notions philosophy plays a role of simply

1:26:45.920 --> 1:26:54.720
 saying that we should be swimming in the space of ideas let's talk what is philosophy philosophy

1:26:54.720 --> 1:27:04.320
 means understanding of life so understanding of life say people like Plato they understand

1:27:04.320 --> 1:27:14.240
 on very high abstract level of life so and whatever I doing just implementation of my

1:27:14.240 --> 1:27:23.040
 understanding of life but every new step it is very difficult for example

1:27:26.000 --> 1:27:32.400
 to find this idea that we need big convergence

1:27:35.520 --> 1:27:38.160
 was not simple for me

1:27:38.160 --> 1:27:46.000
 so that required thinking about life a little bit hard to hard to trace but

1:27:47.040 --> 1:27:53.200
 there was some thought process you know I working guys thinking about the same problem for

1:27:53.920 --> 1:28:02.560
 50 years somehow and again and again and again I trying to be honest and that is a very important

1:28:02.560 --> 1:28:10.000
 not to be very enthusiastic yeah but concentrate on whatever we was not able to achieve for example

1:28:11.920 --> 1:28:19.440
 and understand why and now I understand that because I believe in mass I believe that

1:28:19.440 --> 1:28:31.600
 in Wigner's idea but now when I see that there are only two way of convergence and we're using both

1:28:32.880 --> 1:28:43.920
 that means that we must do as well as people doing but now exactly in philosophy and what we

1:28:43.920 --> 1:28:52.400
 know about predicate what we how we understand life can we describe as a predicate I thought about that

1:28:54.560 --> 1:29:06.960
 and that is more or less obvious level of symmetry but next I have a feeling it's something about

1:29:06.960 --> 1:29:15.440
 structures but I don't know how to formulate how to measure measure of structure and all this stuff

1:29:16.080 --> 1:29:24.960
 and the guy who will solve this challenge problem then when we were looking how he did it

1:29:26.880 --> 1:29:33.520
 probably just only symmetry is not enough but something like symmetry will be there

1:29:33.520 --> 1:29:38.960
 that's absolutely symmetry will be there and level of symmetry will be there

1:29:40.560 --> 1:29:48.240
 and level of symmetry anti symmetry diagonal vertical and I I even don't know how you can

1:29:48.240 --> 1:29:53.040
 use in different direction idea of symmetry it was very general but it will be there

1:29:53.040 --> 1:30:02.640
 I think that people very sensitive to idea of symmetry but there are several ideas like symmetry

1:30:04.720 --> 1:30:13.280
 as I would like to learn but you cannot learn just thinking about that you should do challenging

1:30:13.280 --> 1:30:20.960
 problems and then analyze them why why it was we were able to solve them and then we will see

1:30:20.960 --> 1:30:25.120
 it very simple things it's not easy to find

1:30:27.760 --> 1:30:35.600
 even with talking about this every time about your your I was surprised I I try to understand

1:30:36.160 --> 1:30:42.960
 is people describe in language strong convergence mechanism for learning

1:30:42.960 --> 1:30:51.840
 I did not see I don't know but we convergence this dark story and story like that when you

1:30:51.840 --> 1:30:59.520
 will explain to kid you will use weak convergence argument it looks like it does like it does that

1:31:00.880 --> 1:31:09.760
 but when you try to formalize you just ignoring this why why 50 years from start of machine

1:31:09.760 --> 1:31:15.520
 learning and that's the role of philosophy I think I think that maybe I don't know

1:31:18.160 --> 1:31:25.200
 maybe this is theory also we should blame for that because empirical risk minimization

1:31:26.000 --> 1:31:33.520
 and all this stuff and if you read now textbooks they just about bound about empirical risk

1:31:33.520 --> 1:31:43.360
 minimization they don't looking for another problem like admissible set but on the topic of life

1:31:44.960 --> 1:31:52.880
 perhaps we you could talk in russian for a little bit what's your favorite memory from childhood

1:31:52.880 --> 1:32:03.040
 what is your favorite memory from childhood music how about can you try to answer in russian music

1:32:04.720 --> 1:32:12.400
 it was very cool when such music classical music what is your favorite

1:32:12.400 --> 1:32:23.760
 you were different composers at first it was evaldea in general was surprised that it was possible and then

1:32:23.760 --> 1:32:34.400
 when I understood Bach I was absolutely shocked by the way, I think that there are predicates

1:32:34.400 --> 1:32:43.520
 like structures in Bach, but of course, because there is just a sense of structure here and I don't think

1:32:43.520 --> 1:32:54.960
 that different elements of life are strongly divided in the sense of predicates all the way to the structure

1:32:54.960 --> 1:33:03.120
 of the structure in human relations to the structure here is how to find these here is a high level of

1:33:03.120 --> 1:33:15.520
 predicates in Bach and in life now that we're talking about Bach let's switch back to English

1:33:15.520 --> 1:33:23.040
 because I like Beethoven and Chopin so Chopin it's another music story but Bach if we talk about

1:33:23.040 --> 1:33:32.080
 predicates Bach probably has the most sort of well defined predicates that underlie you know it is

1:33:32.080 --> 1:33:41.040
 very interesting to read what critics writing about Bach which words they're using they're trying to

1:33:41.040 --> 1:33:55.040
 describe predicates and then Chopin it is very different vocabulary very different predicates

1:33:55.040 --> 1:34:05.200
 and I think that if you will make a collection of that so maybe from this you can describe

1:34:05.200 --> 1:34:12.400
 predicate for digit recognition well from Bach and Chopin no no no not from Bach and Chopin

1:34:12.400 --> 1:34:18.240
 from the critic interpretation of the music yeah when they're trying to explain you music

1:34:18.240 --> 1:34:27.520
 what they use as they use they describe high level ideas of of plateaus ideas what behind

1:34:27.520 --> 1:34:35.920
 this music that's brilliant so art is not self explanatory in some sense so you have to try to

1:34:35.920 --> 1:34:45.040
 convert it into ideas it is ill post problems when when you go from ideas to to the representation

1:34:45.040 --> 1:34:52.160
 it is easy way but when you're trying to go back it is ill post problems but nevertheless

1:34:52.800 --> 1:35:00.880
 I believe that when you're looking from that even from art you will be able to find predicate for

1:35:00.880 --> 1:35:10.240
 digit recognition that's such a fascinating and powerful notion do you ponder your own mortality

1:35:10.240 --> 1:35:14.800
 do you think about it do you fear it do you draw insight from it

1:35:16.640 --> 1:35:22.320
 about mortality no yeah are you afraid of death

1:35:25.760 --> 1:35:33.920
 not too much not too much it is pete is it I will not be able to do something which I

1:35:33.920 --> 1:35:44.960
 I think I have a feeling to do that for example I will be very happy to work with

1:35:46.080 --> 1:35:53.840
 guys theoretician from music to write this collection of description what what how they

1:35:53.840 --> 1:36:02.000
 describe music how they use what predicate and from art as well then take what is in common

1:36:02.000 --> 1:36:09.680
 and try to understand predicate which is absolute for everything and then use that for visual

1:36:09.680 --> 1:36:15.120
 recognition and see if there is a connection yeah exactly oh there's still time we got time

1:36:18.480 --> 1:36:27.520
 you got time it it it it takes years and years and years yeah it's a long way well see you've got

1:36:27.520 --> 1:36:33.440
 the patient mathematic mathematicians mind I think it could be done very quickly and very

1:36:33.440 --> 1:36:38.960
 beautifully I think it's a really elegant idea yeah but also some of many yeah you know the the

1:36:38.960 --> 1:36:47.040
 most time it is not to make this collection to understand what is the common to think about

1:36:47.040 --> 1:36:53.840
 that once again and again and again and again but I think sometimes especially just when you

1:36:53.840 --> 1:37:00.880
 say this idea now even just putting together the collection and looking at the different

1:37:02.160 --> 1:37:09.200
 sets of data language trying to interpret music criticize music and images I think there will

1:37:09.200 --> 1:37:13.520
 be sparks of ideas that will come of course again and again you'll come up with better ideas but

1:37:13.520 --> 1:37:18.960
 even just that notion is a beautiful notion I even have some example

1:37:18.960 --> 1:37:22.720
 so I have a friend

1:37:25.120 --> 1:37:36.080
 who was a specialist in Russian poetry she is a professor of Russian poetry he did not write

1:37:38.240 --> 1:37:44.880
 poems but she knows a lot of stuff she makes

1:37:44.880 --> 1:37:53.200
 a book several books and one of them is a collection of Russian poetry

1:37:54.560 --> 1:38:02.640
 she have images of Russian poetry she collect all images of Russian poetry and I ask you to do

1:38:02.640 --> 1:38:15.520
 following you have nips digit recognition and we get 100 digits or maybe less than 100 I don't

1:38:15.520 --> 1:38:25.520
 remember maybe 50 digits and try from a poetical point of view describe every image you see using

1:38:25.520 --> 1:38:37.040
 only words of images of Russian poetry and she did it and then we tried to

1:38:40.960 --> 1:38:45.040
 I call it learning using privileged information I call it privileged information

1:38:45.760 --> 1:38:54.080
 you have on two languages one language is just image of digit in another language

1:38:54.080 --> 1:38:59.760
 poetic description of this image and this is privileged information

1:39:02.160 --> 1:39:06.800
 and there is an algorithm when you're working using privileged information you're doing well

1:39:06.800 --> 1:39:13.440
 better much better so so there's something there something there and there is a

1:39:13.440 --> 1:39:26.800
 in NEC she unfortunately died the collection of digits in poetic descriptions of these digits

1:39:29.040 --> 1:39:33.680
 yeah there's some something there in that poetic description but I think that

1:39:35.440 --> 1:39:42.400
 there is an abstract ideas on the plateau level of ideas yeah that they're there that could be

1:39:42.400 --> 1:39:49.360
 discovered and music seems to be a good entry point but as soon as we start this is this challenge

1:39:49.360 --> 1:39:55.920
 problem the challenge from I listen it immediately connected to to all this stuff especially with

1:39:55.920 --> 1:40:01.280
 your talk and this podcast and I'll do whatever I can to advertise it's such a clean beautiful

1:40:01.280 --> 1:40:09.040
 Einstein like formulation of the challenge before us right let me ask another absurd question

1:40:09.040 --> 1:40:15.280
 and we talked about mortality we talked about philosophy of life what do you think is the

1:40:15.280 --> 1:40:23.520
 meaning of life what's the predicate for mysterious existence here on earth

1:40:23.520 --> 1:40:41.760
 I don't know it's very interesting how we have in Russia I don't know you know the guy Strugatsky

1:40:41.760 --> 1:40:52.720
 they are writing pictures they're thinking about hewn what what's going on and they have idea

1:40:55.360 --> 1:41:05.440
 that there are the developing two type of people common people and very smart people they just

1:41:05.440 --> 1:41:14.320
 started and these two branches of people will go in different direction very soon so that's what

1:41:14.320 --> 1:41:25.920
 they're thinking about that so the purpose of life is to create two two paths two human societies

1:41:25.920 --> 1:41:33.120
 yes simple people and more complicated which do you like best the simple people are the complicated

1:41:33.120 --> 1:41:43.440
 ones I don't know that he's just his fantasy but you know every week we have a guy who is just

1:41:46.320 --> 1:41:55.200
 writer and also a theoretic of literature and he explained how he understand

1:41:55.200 --> 1:42:05.600
 literature and human relationship how he see life and I understood that I'm just small kids

1:42:06.720 --> 1:42:15.920
 comparing to him he is very smart guy in understanding life he knows this predicate he

1:42:15.920 --> 1:42:26.160
 knows big blocks of life I am used every time when I listen to him and he just talking about

1:42:26.160 --> 1:42:42.720
 literature and I think that I was surprised so the managers in big companies most of them are

1:42:42.720 --> 1:42:53.840
 guys who study English language and English literature so why because they understand life

1:42:54.720 --> 1:43:02.320
 they understand models and among them maybe many talented critics

1:43:02.320 --> 1:43:11.920
 did just analyzing this and this is big science like property this is blocks

1:43:13.200 --> 1:43:22.320
 that's very smart it amazes me that you are and continue to be humbled by the brilliance of

1:43:22.320 --> 1:43:30.880
 others I'm very modest about myself I see so smart guys around well let me be immodest for you

1:43:30.880 --> 1:43:36.800
 you're one of the greatest mathematicians statisticians of our time it's truly an honor

1:43:36.800 --> 1:43:47.680
 thank you for talking and let's talk it is not yeah I know my limits let's let's talk again when

1:43:47.680 --> 1:43:58.720
 your challenge is taken on and solved by grad student especially when maybe musical be involved

1:43:58.720 --> 1:44:04.240
 latimer thank you so much thank you very much thanks for listening to this conversation with

1:44:04.240 --> 1:44:11.280
 latimer of apnick and thank you to our presenting sponsor cash app download it use code lex podcast

1:44:11.280 --> 1:44:16.320
 you'll get ten dollars and ten dollars will go to first an organization that inspires and educates

1:44:16.320 --> 1:44:22.000
 young minds to become science and technology innovators of tomorrow if you enjoy this podcast

1:44:22.000 --> 1:44:26.640
 subscribe on youtube give us five stars an apple podcast support it on page share on

1:44:26.640 --> 1:44:33.360
 or simply connect with me on twitter at lex freedman and now let me leave you with some words

1:44:33.360 --> 1:44:39.920
 from latimer of apnick when solving a problem of interest do not solve a more general problem

1:44:39.920 --> 1:44:57.360
 as an intermediate step thank you for listening I hope to see you next time

