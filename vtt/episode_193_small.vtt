WEBVTT

00:00.000 --> 00:05.920
 The following is a conversation with Rob Reed, entrepreneur, author, and host of the After

00:05.920 --> 00:07.520
 On podcast.

00:07.520 --> 00:12.600
 Sam Harris recommended that I absolutely must talk to Rob about his recent work on the

00:12.600 --> 00:15.120
 future of engineer pandemics.

00:15.120 --> 00:21.560
 I then listened to the four hour special episode of Sam's Making Sense podcast with Rob titled

00:21.560 --> 00:27.240
 Engineering the Apocalypse and I was floored and knew I had to talk to him.

00:27.240 --> 00:32.600
 This is a quick mention of our sponsors, Athletic Greens, Bell Campo, Fund Rise, and

00:32.600 --> 00:33.600
 Netsuite.

00:33.600 --> 00:36.960
 Check them out in the description to support this podcast.

00:36.960 --> 00:41.760
 As a side note, let me say a few words about the lab leak hypothesis, which proposes that

00:41.760 --> 00:47.600
 COVID 19 is a product of gain of function research on coronaviruses conducted at the

00:47.600 --> 00:53.120
 Wuhan Institute of Virology that was then accidentally leaked due to human error.

00:53.120 --> 00:58.800
 For context, this lab is biosafety level 4, BSL4, and it investigates coronaviruses.

00:58.800 --> 01:04.020
 BSL4 is the highest level of safety, but if you look at all the human in the loop pieces

01:04.020 --> 01:09.440
 required to achieve this level of safety, it becomes clear that even BSL4 labs are highly

01:09.440 --> 01:11.560
 susceptible to human error.

01:11.560 --> 01:15.800
 To me, whether the virus leaked from the lab or not, getting to the bottom of what happened

01:15.800 --> 01:18.840
 is about much more than this particular catastrophic case.

01:18.840 --> 01:25.040
 It is a test for our scientific, political, journalistic, and social institutions of how

01:25.040 --> 01:31.440
 well we can prepare and respond to threats they can cripple or destroy human civilization.

01:31.440 --> 01:36.840
 If we continue gain of function research on viruses, eventually these viruses will leak

01:36.840 --> 01:40.220
 and they will be more deadly and more contagious.

01:40.220 --> 01:44.720
 We can pretend that won't happen, or we can openly and honestly talk about the risks

01:44.720 --> 01:45.880
 involved.

01:45.880 --> 01:50.320
 This research can both save and destroy human life on Earth as we know it.

01:50.320 --> 01:52.640
 It's a powerful double edged sword.

01:52.640 --> 01:59.000
 If YouTube and other platforms censor conversations about this, if scientists self censor conversations

01:59.000 --> 02:05.920
 about this will become merely victims of our brief Homo sapiens story, not its heroes.

02:05.920 --> 02:11.560
 As I said before, too carelessly labeling ideas as misinformation and dismissing them

02:11.560 --> 02:16.840
 because of that will eventually destroy our ability to discover the truth, and without

02:16.840 --> 02:22.880
 truth we don't have a fighting chance against the great filter before us.

02:22.880 --> 02:28.960
 This is the Lex Friedman podcast, and here is my conversation with Rob Reed.

02:28.960 --> 02:33.960
 I have seen evidence on the internet that you have a sense of humor, allegedly, but

02:33.960 --> 02:38.280
 you also talk and think about the destruction of human civilization.

02:38.280 --> 02:42.880
 What do you think of the Elon Musk hypothesis that the most entertaining outcome is the

02:42.880 --> 02:48.880
 most likely, and he, I think, followed on to say a scene from an external observer.

02:48.880 --> 02:55.080
 Like if somebody was watching us, it seems we come up with creative ways of progressing

02:55.080 --> 02:56.600
 our civilization.

02:56.600 --> 02:57.600
 That's fun to watch.

02:57.600 --> 02:58.600
 Yeah.

02:58.600 --> 02:59.600
 Exactly.

02:59.600 --> 03:04.040
 He said from the standpoint of the observer, not the participant.

03:04.040 --> 03:08.200
 What's interesting about that, those were, I think, just a couple of freestanding tweets,

03:08.200 --> 03:11.840
 and delivered without a whole lot of wrapper of context.

03:11.840 --> 03:17.960
 It's left to the mind of the reader of the tweets to infer what he was talking about.

03:17.960 --> 03:20.720
 That's kind of like, it provokes some interesting thoughts.

03:20.720 --> 03:26.480
 First of all, it presupposes the existence of an observer, and it also presupposes that

03:26.480 --> 03:32.040
 the observer wishes to be entertained and has some mechanism of enforcing their desire

03:32.040 --> 03:33.040
 to be entertained.

03:33.040 --> 03:35.800
 There's a lot underpinning that.

03:35.800 --> 03:40.280
 To me, that suggests, particularly coming from Elon, that it's a reference to simulation

03:40.280 --> 03:47.000
 theory, that somebody is out there and has far greater insights and a far greater ability

03:47.000 --> 03:51.960
 to, let's say, peer into a single individual life and find that entertaining and full of

03:51.960 --> 03:58.400
 plot twists and surprises, and either a happier, tragic ending, or they have an incredible

03:58.400 --> 04:04.280
 meta view, and they can watch the arc of civilization unfolding in a way that is entertaining and

04:04.280 --> 04:08.240
 full of plot twists and surprises and a happier, unhappy ending.

04:08.240 --> 04:12.000
 Okay, so we're presupposing an observer.

04:12.000 --> 04:17.600
 Then on top of that, when you think about it, you're also presupposing a producer, because

04:17.600 --> 04:24.240
 the act of observation is mostly fun if there are plot twists and surprises and other developments

04:24.240 --> 04:25.880
 that you weren't foreseeing.

04:25.880 --> 04:30.800
 I have reread my own novels, and that's fun, because it's something that I worked hard

04:30.800 --> 04:35.080
 on and I slaved over and I love, but there aren't a lot of surprises in there.

04:35.080 --> 04:40.080
 Now, I'm thinking, we need a producer and an observer for that to be true.

04:40.080 --> 04:46.040
 On top of that, it's got to be a very competent producer, because Elon said the most entertaining

04:46.040 --> 04:48.640
 outcome is the most likely one.

04:48.640 --> 04:51.920
 There's lots of layers for thinking about that.

04:51.920 --> 04:55.440
 When you've got a producer who's trying to make it entertaining, it makes me think of

04:55.440 --> 05:01.120
 there was a South Park episode in which Earth turned out to be a reality show.

05:01.120 --> 05:06.320
 Somehow we had failed to entertain the audience as much as we used to, so the Earth show was

05:06.320 --> 05:09.560
 going to get canceled, et cetera.

05:09.560 --> 05:13.000
 Taking all that together, and I'm obviously being a little bit playful in laying this

05:13.000 --> 05:20.240
 out, what is the evidence that we have that we are in a reality that is intended to be

05:20.240 --> 05:22.200
 most entertaining?

05:22.200 --> 05:27.360
 You could look at that reality on the level of individual lives or the whole arc of civilization,

05:27.360 --> 05:33.120
 other levels as well, I'm sure, but just looking from my own life, I think I'd make a pretty

05:33.120 --> 05:34.280
 lousy show.

05:34.280 --> 05:38.880
 I spend an inordinate amount of time just looking at a computer.

05:38.880 --> 05:44.160
 I don't think that's very entertaining, and there's just a completely inadequate level

05:44.160 --> 05:46.520
 of shootouts and car chases in my life.

05:46.520 --> 05:50.120
 I'll go weeks, even months, without a single shootout or car chase.

05:50.120 --> 05:53.000
 That just means that you're one of the nonplayer characters in this game.

05:53.000 --> 05:54.000
 You're just waiting to meet.

05:54.000 --> 05:55.000
 I'm an extra.

05:55.000 --> 05:59.120
 You're an extra that waiting for you one opportunity for a brief moment to actually

05:59.120 --> 06:03.000
 interact with one of the main characters in the play.

06:03.000 --> 06:04.000
 Very interesting.

06:04.000 --> 06:05.000
 Okay, that's good.

06:05.000 --> 06:08.480
 Okay, so we'll rule out me being the star of the show, which I probably could have guessed

06:08.480 --> 06:09.480
 at.

06:09.480 --> 06:11.760
 Anyway, but not even the arc of civilization.

06:11.760 --> 06:15.040
 There have been a lot of really intriguing things that have happened and a lot of astounding

06:15.040 --> 06:19.120
 things that have happened, but I would have some werewolves.

06:19.120 --> 06:21.400
 I'd have some zombies.

06:21.400 --> 06:28.640
 I would have some really improbable developments like maybe Canada absorbing the United States.

06:28.640 --> 06:29.640
 So I don't know.

06:29.640 --> 06:35.440
 I'm not sure if we're necessarily designed for maximum entertainment, but if we are,

06:35.440 --> 06:41.920
 that will mean that 2020 is just a prequel for even more bizarre years ahead.

06:41.920 --> 06:45.720
 I kind of hope that we're not designed for maximum entertainment.

06:45.720 --> 06:49.080
 Well, the night is still young in terms of Canada, but do you think it's possible for

06:49.080 --> 06:52.500
 the observer and the producer to be kind of emergent?

06:52.500 --> 06:59.360
 So meaning it does seem when you kind of watch memes on the internet, the funny ones,

06:59.360 --> 07:01.920
 the entertaining ones spread more efficiently.

07:01.920 --> 07:02.920
 They do.

07:02.920 --> 07:11.560
 I mean, I don't know what it is about the human mind that soaks up on mass funny things

07:11.560 --> 07:12.920
 much more sort of aggressively.

07:12.920 --> 07:17.020
 It's more viral in the full sense of that word.

07:17.020 --> 07:23.560
 Is there some sense that whatever the evolutionary process that created our cognitive capabilities

07:23.560 --> 07:28.440
 is the same process that's going to, in an emergent way, create the most entertaining

07:28.440 --> 07:36.120
 outcome, the most memeofiable outcome, the most viral outcome if we were to share it

07:36.120 --> 07:37.120
 on Twitter?

07:37.120 --> 07:38.120
 Yeah, that's interesting.

07:38.120 --> 07:44.000
 Yeah, we do have an incredible ability, how many memes are created in a given day and

07:44.000 --> 07:47.720
 the ones that go viral are almost uniformly funny, at least to somebody with a particular

07:47.720 --> 07:48.720
 sense of humor.

07:48.720 --> 07:49.720
 Right.

07:49.720 --> 07:53.600
 Yeah, I'd have to think about that.

07:53.600 --> 07:59.560
 We are definitely great at creating atomized units of funny.

07:59.560 --> 08:05.080
 In the example that you used, there are going to be X million brains parsing and judging

08:05.080 --> 08:07.520
 whether this meme is retweetable or not.

08:07.520 --> 08:14.880
 And so that atomic element of funniness, of entertainingness, et cetera, we definitely

08:14.880 --> 08:20.160
 have an environment that's good at selecting for that and selective pressure and everything

08:20.160 --> 08:21.960
 else that's going on.

08:21.960 --> 08:31.200
 But in terms of the entire ecosystem of conscious systems here on the earth driving for a level

08:31.200 --> 08:37.040
 of entertainment, that is on such a much higher level that I don't know if that would

08:37.040 --> 08:44.120
 necessarily follow directly from the fact that atomic units of entertainment are very,

08:44.120 --> 08:45.960
 very aptly selected for us.

08:45.960 --> 08:46.960
 I don't know.

08:46.960 --> 08:54.320
 Do you find it compelling or useful to think about human civilization from the perspective

08:54.320 --> 08:59.760
 of the ideas versus the perspective of the individual human brains?

08:59.760 --> 09:05.840
 So almost thinking about the ideas or the memes, this is the Dawkins thing as the organisms.

09:05.840 --> 09:13.120
 And then the humans as just vehicles for briefly carrying those organisms as they jump around

09:13.120 --> 09:14.120
 and spread.

09:14.120 --> 09:19.480
 Yeah, for propagating them, mutating them, putting selective pressure on them, et cetera.

09:19.480 --> 09:27.400
 I mean, I found Dawkins, or his launching of the idea of memes is just kind of an afterthought

09:27.400 --> 09:32.120
 to his unbelievably brilliant book about the selfish gene.

09:32.120 --> 09:37.440
 What a PS to put at the end of a long chunk of writing, profoundly interesting.

09:37.440 --> 09:43.640
 I view the relationship though between humans and memes as probably an oversimplification,

09:43.640 --> 09:47.760
 but maybe a little bit like the relationship between flowers and bees, right?

09:47.760 --> 09:52.000
 Do flowers have bees or do bees in a sense have flowers?

09:52.000 --> 09:58.640
 And the answer is it is a very, very symbiotic relationship in which both have semi independent

09:58.640 --> 10:03.320
 roles that they play and both are highly dependent upon the other.

10:03.320 --> 10:07.760
 And so in the case of bees, obviously, you could see the flowers being this monolithic

10:07.760 --> 10:14.320
 structure physically in relation to any given bee, and it's the source of food and sustenance.

10:14.320 --> 10:17.120
 So you could kind of say, well, flowers have bees.

10:17.120 --> 10:20.800
 But on the other hand, the flowers would obviously be doomed.

10:20.800 --> 10:22.920
 They weren't being pollinated by the bees.

10:22.920 --> 10:28.600
 So you could kind of say, well, flowers are really expression of what the bees need.

10:28.600 --> 10:30.600
 And the truth is a symbiosis.

10:30.600 --> 10:39.280
 So with memes in human minds, our brains are clearly the Petri dishes in which memes are

10:39.280 --> 10:44.280
 either propagated or not propagated, get mutated or don't get mutated.

10:44.280 --> 10:51.440
 They are the venue in which selective competition plays out between different memes.

10:51.440 --> 10:53.080
 So all of that is very true.

10:53.080 --> 10:58.880
 And you could look at that and say, really, the human mind is a production of memes and

10:58.880 --> 11:01.880
 ideas have us rather than us having ideas.

11:01.880 --> 11:07.200
 But at the same time, let's take a catchy tune as an example of a meme.

11:07.200 --> 11:11.320
 That catchy tune did originate in a human mind.

11:11.320 --> 11:13.000
 Somebody had to structure that thing.

11:13.000 --> 11:19.120
 And as much as I like Elizabeth Gilbert's TED talk about how the universe, I'm simplifying,

11:19.120 --> 11:22.960
 you know, kind of the ideas find their way in its beautiful TED talk.

11:22.960 --> 11:23.960
 It's very lyrical.

11:23.960 --> 11:30.120
 She talked about, you know, ideas and prose kind of beaming into our minds.

11:30.120 --> 11:33.240
 And, you know, she talked about needing to pull over to the side of the road when she

11:33.240 --> 11:38.240
 got inspiration for a particular paragraph or a particular idea and a burning need to

11:38.240 --> 11:40.120
 write that down.

11:40.120 --> 11:45.160
 I love that I find that beautiful as a writer, as a novelist myself.

11:45.160 --> 11:47.520
 I've never had that experience.

11:47.520 --> 11:54.120
 And I think that really most things that do become memes are the product of a great deal

11:54.120 --> 11:59.520
 of deliberate and willful exertion of a conscious mind.

11:59.520 --> 12:03.680
 And so like the bees and the flowers, I think there's a great symbiosis.

12:03.680 --> 12:05.760
 And they both kind of have one another.

12:05.760 --> 12:08.000
 Ideas have us, but we have ideas for real.

12:08.000 --> 12:14.400
 If we could take a little bit of a tangent, Stephen King on writing, you as a great writer,

12:14.400 --> 12:20.000
 you dropping a hint here that the ideas don't come to you, that it's a grind of sort of,

12:20.000 --> 12:22.760
 it's almost like you're mining for gold.

12:22.760 --> 12:28.120
 It's more of a very deliberate, rigorous daily process.

12:28.120 --> 12:32.600
 So maybe can you talk about the writing process?

12:32.600 --> 12:36.520
 How do you write well?

12:36.520 --> 12:42.560
 And maybe if you want to step outside of yourself, almost like give advice to an aspiring writer,

12:42.560 --> 12:44.360
 what does it take to write?

12:44.360 --> 12:45.880
 What is the best work of your life?

12:45.880 --> 12:50.040
 Well, it would be very different if it's fiction versus nonfiction.

12:50.040 --> 12:51.040
 And I've done both.

12:51.040 --> 12:55.640
 I've written two works of nonfiction books and two works of fiction.

12:55.640 --> 12:58.840
 Two works of fiction being more recent, I'm going to focus on that right now because that's

12:58.840 --> 13:01.640
 more toweringly on my mind.

13:01.640 --> 13:06.120
 They're amongst novelists, again, this is an oversimplification, but there's kind of

13:06.120 --> 13:08.680
 two schools of thought.

13:08.680 --> 13:12.680
 Some people really like to fly by the seat of their pants, and some people really, really

13:12.680 --> 13:15.720
 like to outline, to plot.

13:15.720 --> 13:20.200
 So there's plotters and panzers, I guess is one way that people look at it.

13:20.200 --> 13:24.840
 And as with most things, there is a great continuum in between, and I'm somewhere on

13:24.840 --> 13:29.960
 that continuum, but I lean, I guess, a little bit more toward the plotter.

13:29.960 --> 13:35.120
 And so when I do start a novel, I have a pretty strong point of view about how it's going

13:35.120 --> 13:39.400
 to end, and I have a very strong point of view about how it's going to begin.

13:39.400 --> 13:44.280
 And I do try to make an effort of making an outline that I know I'm going to be extremely

13:44.280 --> 13:49.640
 unfaithful to in the actual execution of the story, but trying to make an outline that

13:49.640 --> 13:54.520
 gets us from here to there and notion of subplots and beats and rhythm and different characters

13:54.520 --> 13:56.320
 and so forth.

13:56.320 --> 14:02.040
 But then when I get into the process, that outline, particularly the center of it, ultimately

14:02.040 --> 14:03.760
 inevitably morphs a great deal.

14:03.760 --> 14:08.960
 And I think if I were personally a rigorous outliner, I would not allow that to happen.

14:08.960 --> 14:14.400
 I also would make a much more vigorous skeleton before I start.

14:14.400 --> 14:22.440
 So I think people who are really in that plotting outlining mode are people who write page turners,

14:22.440 --> 14:30.400
 people who write spy novels or supernatural adventures, where you really want a relentless

14:30.400 --> 14:37.560
 pace of events, action, plot twists, conspiracy, et cetera.

14:37.560 --> 14:42.880
 And that is really the bone, that's really the skeletal structure.

14:42.880 --> 14:47.560
 So I think folks who write that kind of book are really very much on the outlining side.

14:47.560 --> 14:52.160
 And I think people who write what's often referred to as literary fiction for lack of

14:52.160 --> 14:59.680
 a better term, where it's more about sort of aura and ambiance and character development

14:59.680 --> 15:05.560
 and experience and inner experience and inner journey and so forth, I think that group is

15:05.560 --> 15:07.640
 more likely to fly by the seat of the pants.

15:07.640 --> 15:11.000
 And I know people who start with a blank page and just see where it's going to go.

15:11.000 --> 15:14.520
 I'm a little bit more on the plotting side.

15:14.520 --> 15:20.880
 Now you asked what makes something at least in the mind of the writer as great as it can

15:20.880 --> 15:21.880
 be.

15:21.880 --> 15:26.720
 For me, it's an astonishingly high percentage of it is editing as opposed to the initial

15:26.720 --> 15:27.720
 writing.

15:27.720 --> 15:35.040
 For every hour that I spend writing new prose, like new pages, new paragraphs, stuff that

15:35.040 --> 15:42.640
 you know, new bits of the book, I probably spend, I mean, I wish I kept account, like

15:42.640 --> 15:47.040
 I wish I had like one of those pieces of software that lawyers use to decide how much time

15:47.040 --> 15:51.880
 I've been doing this, that, but I would say it's at least four or five hours and maybe

15:51.880 --> 15:54.360
 as many as 10 that I spend editing.

15:54.360 --> 15:56.560
 And so it's relentless for me.

15:56.560 --> 16:00.080
 For each one hour of writing, I'd say that for a while.

16:00.080 --> 16:07.200
 I mean, I write because I edit and I spend just relentlessly polishing and pruning.

16:07.200 --> 16:12.080
 And sometimes on the micro level of just like, does the rhythm of the sentence feel right?

16:12.080 --> 16:15.680
 Do I need to carve a syllable or something so it can land?

16:15.680 --> 16:21.480
 Like as micro as that to as macro as like, okay, I'm done, but the book is 750 pages

16:21.480 --> 16:25.160
 long and it's way too bloated and I need to lop a third out of it.

16:25.160 --> 16:29.720
 Problems on, you know, those two orders of magnitude and everything in between.

16:29.720 --> 16:31.840
 That is an enormous amount of my time.

16:31.840 --> 16:37.280
 And I also write music, write and record and produce music.

16:37.280 --> 16:40.320
 And there the ratio is even higher.

16:40.320 --> 16:47.680
 Every minute that I spend or my band spends laying down that original audio, it's a very

16:47.680 --> 16:52.480
 high proportion of hours that go into just making it all hang together and sound just

16:52.480 --> 16:53.480
 right.

16:53.480 --> 16:56.200
 So I think that's true of a lot of creative processes.

16:56.200 --> 16:58.120
 I know it's true of sculpture.

16:58.120 --> 16:59.920
 I believe it's true of woodwork.

16:59.920 --> 17:04.400
 My dad was an amateur woodworker and he spent a huge amount of time on sanding and polishing

17:04.400 --> 17:05.400
 at the end.

17:05.400 --> 17:08.920
 So I think a great deal of the sparkle comes from that part of the process.

17:08.920 --> 17:09.920
 Any creative process.

17:09.920 --> 17:14.480
 Can I ask about the psychological, the demon side of that picture?

17:14.480 --> 17:18.360
 In the editing process, you're ultimately judging the initial piece of work and you're

17:18.360 --> 17:20.840
 judging and judging and judging.

17:20.840 --> 17:26.000
 How much of your time do you spend hating your work?

17:26.000 --> 17:33.240
 How much time do you spend in gratitude, impressed, thankful, or how good the work

17:33.240 --> 17:36.000
 that you will put together is?

17:36.000 --> 17:42.320
 I spend almost all the time in a place that's intermediate between those but leaning toward

17:42.320 --> 17:43.320
 gratitude.

17:43.320 --> 17:49.720
 I spend almost all the time in a state of optimism that this thing that I have, I like

17:49.720 --> 17:56.920
 quite a bit and I can make it better and better and better with every time I go through it.

17:56.920 --> 18:01.720
 So I spend most of my time in a state of optimism.

18:01.720 --> 18:06.360
 I think I personally oscillate much more aggressively between those two where I wouldn't

18:06.360 --> 18:08.000
 be able to find the average.

18:08.000 --> 18:11.520
 I go pretty deep.

18:11.520 --> 18:19.960
 Marvin Minsky from MIT had this advice, I guess, to what it takes to be successful in

18:19.960 --> 18:23.280
 science and research is to hate everything you do.

18:23.280 --> 18:24.520
 You've ever done in the past.

18:24.520 --> 18:31.520
 I mean, at least he was speaking about himself that the key to his success was to hate everything

18:31.520 --> 18:32.520
 he's ever done.

18:32.520 --> 18:39.960
 I have a little Marvin Minsky there in me too to always be exceptionally self critical,

18:39.960 --> 18:47.120
 almost self critical about the work, but grateful for the chance to be able to do the work.

18:47.120 --> 18:48.120
 That makes sense.

18:48.120 --> 18:49.120
 Makes perfect sense.

18:49.120 --> 18:56.120
 But each one of us have to strike a certain kind of balance.

18:56.120 --> 19:00.360
 But back to the destruction of human civilization.

19:00.360 --> 19:08.760
 If humans destroy ourselves in the next 100 years, what will be the most likely source,

19:08.760 --> 19:11.560
 the most likely reason that we destroy ourselves?

19:11.560 --> 19:18.160
 Well, let's see, 100 years, it's hard for me to comfortably predict out that far.

19:18.160 --> 19:23.800
 And it's something to give a lot more thought to, I think, than normal folks simply because

19:23.800 --> 19:25.880
 I am a science fiction writer.

19:25.880 --> 19:32.880
 And I feel with the acceleration of technological progress, it's really hard to foresee out more

19:32.880 --> 19:33.880
 than just a few decades.

19:33.880 --> 19:39.480
 I mean, comparing today's world to that of 1921, where we are right now, a century later,

19:39.480 --> 19:42.000
 it would have been so unforeseeable.

19:42.000 --> 19:46.400
 And I just don't know what's going to happen, particularly with exponential technologies.

19:46.400 --> 19:51.840
 I mean, our intuitions reliably defeat ourselves with exponential technologies like computing

19:51.840 --> 19:58.560
 and synthetic biology and how we might destroy ourselves in the 100 year time frame might

19:58.560 --> 20:03.200
 have everything to do with breakthroughs and nanotechnology 40 years from now and then

20:03.200 --> 20:05.600
 how rapidly those breakthroughs accelerate.

20:05.600 --> 20:10.520
 But in the nearer term than I'm comfortable predicting, let's say, 30 years, I would say

20:10.520 --> 20:16.600
 the most likely route to self destruction would be synthetic biology.

20:16.600 --> 20:22.320
 And I always say that with the gigantic caveat and very important one that I find, and I'll

20:22.320 --> 20:26.040
 abbreviate synthetic biology to SinBio just to save us some syllables.

20:26.040 --> 20:34.360
 I believe SinBio offers us simply stunning promise that we would be fools to deny ourselves.

20:34.360 --> 20:37.200
 So I'm not an anti SinBio person by any stretch.

20:37.200 --> 20:43.600
 I mean, SinBio has unbelievable odds of helping us beat cancer, helping us rescue the environment,

20:43.600 --> 20:46.320
 helping us do things that we would currently find imponderable.

20:46.320 --> 20:48.560
 So it's electrifying the field.

20:48.560 --> 20:54.960
 But in the wrong hands, those hands either being incompetent or being malevolent.

20:54.960 --> 21:02.360
 In the wrong hands, synthetic biology to me has a much, much greater odds of leading

21:02.360 --> 21:08.160
 to our self destruction than something running amok with super AI, which I believe is a real

21:08.160 --> 21:10.400
 possibility and what we need to be concerned about.

21:10.400 --> 21:15.000
 But in the 30 year time frame, I think it's a lesser one or nuclear weapons or anything

21:15.000 --> 21:16.320
 else that I can think of.

21:16.320 --> 21:18.560
 Can you explain that a little bit further?

21:18.560 --> 21:26.240
 So your concern is on the manmade versus the natural side of the pandemic front here.

21:26.240 --> 21:34.160
 So we humans engineering pathogens, engineering viruses is the concern here.

21:34.160 --> 21:41.400
 And maybe how do you see the possible trajectory is happening here in terms of, is it malevolent

21:41.400 --> 21:51.440
 or is it accidents, oops, little mistakes or unintended consequences of particular actions

21:51.440 --> 21:54.160
 that are ultimately lead to unexpected mistakes?

21:54.160 --> 21:55.800
 Well, both of them are a danger.

21:55.800 --> 22:01.280
 And I think the question of which is more likely has to do with two things.

22:01.280 --> 22:08.240
 One, do we take a lot of methodical, affordable, foresighted steps that we are absolutely

22:08.240 --> 22:14.160
 capable of taking right now to first stall the risk of a bad actor infecting us with

22:14.160 --> 22:17.240
 something that could have annihilating impacts?

22:17.240 --> 22:22.560
 And in the episode you referenced with Sam, we talked a great deal about that.

22:22.560 --> 22:24.160
 So do we take those steps?

22:24.160 --> 22:29.400
 And if we take those steps, I think the danger of malevolent rogue actors doing a sin with

22:29.400 --> 22:31.840
 sin bio could plummet.

22:31.840 --> 22:36.840
 But it's always a question of if and we have a bad, bad and very long track record of hitting

22:36.840 --> 22:41.480
 this news bar after different natural pandemics have attacked us.

22:41.480 --> 22:43.800
 So that's variable number one.

22:43.800 --> 22:52.000
 Variable number two is how much experimentation and pathogen development do we as a society

22:52.000 --> 22:59.160
 decide is acceptable in the realms of academia, government or private industry?

22:59.160 --> 23:06.160
 And if we decide as a society that it's perfectly okay for people with varying research agendas

23:06.160 --> 23:12.680
 to create pathogens that if released could wipe out humanity, if we think that's fine.

23:12.680 --> 23:19.160
 And if that kind of work starts happening in one lab, five labs, 50 labs, 500 labs in

23:19.160 --> 23:26.360
 one country, then 10 countries, then 70 countries or whatever, that risk of a boo boo starts

23:26.360 --> 23:28.680
 rising astronomically.

23:28.680 --> 23:33.400
 And this won't be a spoiler alert based on the way that I presented those two things.

23:33.400 --> 23:37.560
 But I think it's unbelievably important to manage both of those risks.

23:37.560 --> 23:42.240
 The easier one to manage, although it wouldn't be simple by any stretch because it would

23:42.240 --> 23:45.160
 have to be something that all nations agree on.

23:45.160 --> 23:52.520
 But the easier risk to manage is that of, hey, guys, let's not develop pathogens that

23:52.520 --> 23:56.240
 if they escaped from a lab could annihilate us.

23:56.240 --> 23:58.720
 There's no line of research that justifies that.

23:58.720 --> 24:01.960
 And in my view, I mean, that's the point of perspective we'd need to have.

24:01.960 --> 24:06.120
 We'd have to collectively agree that there's no line of research that justifies that.

24:06.120 --> 24:11.200
 The reason why I believe that would be a highly rational conclusion is even the highest level

24:11.200 --> 24:15.640
 of biosafety lab in the world, biosafety level four.

24:15.640 --> 24:19.640
 And there are not a lot of BSL four labs in the world.

24:19.640 --> 24:24.040
 Things can have leaked out of BSL four labs.

24:24.040 --> 24:28.560
 And some of the work that's been done with potentially annihilating pathogens, which

24:28.560 --> 24:31.920
 we can talk about, is actually done at BSL three.

24:31.920 --> 24:36.400
 And so fundamentally, any lab can leak.

24:36.400 --> 24:41.240
 We have proven ourselves to be incapable of creating a lab that is utterly impervious

24:41.240 --> 24:42.480
 to leaks.

24:42.480 --> 24:47.680
 So why in the world would we create something where, if God forbid, it leaked, could annihilate

24:47.680 --> 24:48.680
 us all?

24:48.680 --> 24:53.080
 And by the way, almost all of the measures that are taken in biosafety level, anything

24:53.080 --> 24:57.240
 labs, are designed to prevent accidental leaks.

24:57.240 --> 25:01.400
 What happens if you have a malevolent insider and we could talk about the psychology and

25:01.400 --> 25:06.920
 the motivations of what would make a malevolent insider who wants to release something annihilating

25:06.920 --> 25:07.920
 in a bet?

25:07.920 --> 25:08.920
 I'm sure that we will.

25:08.920 --> 25:11.960
 But what if you have a malevolent insider?

25:11.960 --> 25:17.360
 Virtually none of the standards that go into biosafety level, one, two, three, and four,

25:17.360 --> 25:20.120
 are about preventing somebody hijacking the process.

25:20.120 --> 25:23.600
 I mean, some of them are, but they're mainly designed against accidents.

25:23.600 --> 25:25.760
 They're imperfect against accidents.

25:25.760 --> 25:29.280
 And if this kind of work starts happening in lots and lots of labs, with every lab you

25:29.280 --> 25:34.200
 add, the odds of there being a malevolent insider naturally increase arithmetically as

25:34.200 --> 25:36.120
 the number of labs goes up.

25:36.120 --> 25:44.040
 Now on the front of somebody outside of a government academic or scientific, traditional

25:44.040 --> 25:50.640
 government academic scientific environment, creating something malevolent, again, there's

25:50.640 --> 25:57.840
 protections that we can take both at the level of syn bio architecture, the hardening entire

25:57.840 --> 26:04.080
 syn bio ecosystem against terrible things being made that we don't want to have out there

26:04.080 --> 26:09.960
 by rogue actors, to early detection, to lots and lots of other things that we can do to

26:09.960 --> 26:11.760
 dramatically mitigate that risk.

26:11.760 --> 26:16.240
 And I think we do both of those things, decide that, no, we're not going to experimentally

26:16.240 --> 26:22.240
 make annihilating pathogens in leaky labs and be, yes, we are going to take countermeasures

26:22.240 --> 26:28.760
 that are going to cost a fraction of our annual defense budget to preclude their creation.

26:28.760 --> 26:31.760
 And I think both risks get managed down.

26:31.760 --> 26:36.480
 But if you take one set of precautions and not the other, then the thing that you have

26:36.480 --> 26:40.960
 not taken precautions against immediately becomes the more likely outcome.

26:40.960 --> 26:45.680
 So can we talk about this kind of research and what's actually done and what are the

26:45.680 --> 26:47.200
 positives and negatives of it?

26:47.200 --> 26:52.360
 So if we look again, a function research and the kind of stuff that's happening in level

26:52.360 --> 26:56.600
 three and level four BSL labs, what's the whole idea here?

26:56.600 --> 27:01.520
 Is it trying to engineer viruses to understand how they behave?

27:01.520 --> 27:03.360
 You want to understand the dangerous ones.

27:03.360 --> 27:04.360
 Yeah.

27:04.360 --> 27:06.560
 So that would be the logic behind doing it.

27:06.560 --> 27:10.480
 And so gain a function can mean a lot of different things.

27:10.480 --> 27:15.160
 Viewed through a certain lens, gained a function research could be what you do when you create

27:15.160 --> 27:21.080
 GMOs, when you create hardy strains of corn that are resistant to pesticides.

27:21.080 --> 27:23.400
 I mean, you could view that as gain a function.

27:23.400 --> 27:26.960
 So I'm going to refer to gain a function in a relatively narrow sense, which is actually

27:26.960 --> 27:34.400
 the sense that the term is usually used, which is in some way magnifying capabilities of

27:34.400 --> 27:40.720
 microorganisms to make them more dangerous, whether it's more transmissible or more deadly.

27:40.720 --> 27:46.400
 And in that line of research, I'll use an example from 2011 because it's very illustrative

27:46.400 --> 27:48.400
 and it's also very chilling.

27:48.400 --> 27:54.120
 Back in 2011, two separate labs independently of one another, I assume there was some kind

27:54.120 --> 27:57.700
 of communication between them, but there were basically independent projects, one in Holland

27:57.700 --> 28:04.200
 and one in Wisconsin, did gain a function research on something called H5N1 flu.

28:04.200 --> 28:12.400
 H5N1 is something that, at least on a lethality basis, makes COVID look like a kitten.

28:12.400 --> 28:16.000
 COVID, according to the World Health Organization, has a case fatality rate somewhere between

28:16.000 --> 28:17.920
 half a percent and one percent.

28:17.920 --> 28:21.480
 H5N1 is closer to 60%, 6.0.

28:21.480 --> 28:24.280
 And so that's actually even slightly more lethal than Ebola.

28:24.280 --> 28:27.520
 It's a very, very, very scary pathogen.

28:27.520 --> 28:33.160
 The good news about H5N1 is that it is barely, barely contagious.

28:33.160 --> 28:36.320
 But I believe it is in no way contagious human to human.

28:36.320 --> 28:44.920
 It requires very, very, very deep contact with birds, in most cases, chickens.

28:44.920 --> 28:49.200
 And so if you're a chicken farmer and you spend an enormous amount of time around them

28:49.200 --> 28:54.920
 and perhaps you get into situations in which you get a break in your skin and you're interacting

28:54.920 --> 29:01.960
 intensely with foul who, as it turns out, have H5N1, that's when the jump comes.

29:01.960 --> 29:06.400
 But there's no airborne transmission that we're aware of human to human.

29:06.400 --> 29:08.520
 Not that it just doesn't exist.

29:08.520 --> 29:15.320
 I think the World Health Organization did a relentless survey of the number of H5N1 cases.

29:15.320 --> 29:16.800
 I think they do it every year.

29:16.800 --> 29:22.160
 I saw one 10 year series where I think it was like 500 fatalities over the course of

29:22.160 --> 29:23.160
 a decade.

29:23.160 --> 29:26.560
 And that's a drop in the bucket, a kind of fun fact.

29:26.560 --> 29:31.960
 I believe the typical lethality from lightning over 10 years is 70,000 deaths.

29:31.960 --> 29:37.200
 So we think getting struck by lightning, pretty low risk, H5N1 much, much lower than that.

29:37.200 --> 29:43.760
 What happened in these experiments is the experimenters in both cases set out to make

29:43.760 --> 29:48.400
 H5N1 that would be contagious, that could create airborne transmission.

29:48.400 --> 29:53.000
 And so they basically passed it, I think in both cases, they passed it through a large

29:53.000 --> 29:54.760
 number of ferrets.

29:54.760 --> 29:58.200
 And so this wasn't like CRISPR, there wasn't even in CRISPR back in those days.

29:58.200 --> 30:03.200
 This was relatively straightforward selecting for a particular outcome.

30:03.200 --> 30:07.240
 And after guiding the path and passing them through, again, I believe it was a series

30:07.240 --> 30:13.320
 of ferrets, they did in fact come up with a version of H5N1 that is capable of airborne

30:13.320 --> 30:14.320
 transmission.

30:14.320 --> 30:17.400
 Now, they didn't unleash it into the world.

30:17.400 --> 30:20.680
 They didn't inject it into humans to see what would happen.

30:20.680 --> 30:25.880
 And so for those two reasons, we don't really know how contagious it might have been.

30:25.880 --> 30:33.520
 But if it was as contagious as COVID, that could be a civilization threatening pathogen.

30:33.520 --> 30:34.760
 And why would you do it?

30:34.760 --> 30:38.280
 Well, the people who did it were good guys, they were virologists.

30:38.280 --> 30:43.560
 I believe their agenda as they explained it was, much as you said, let's figure out what

30:43.560 --> 30:47.920
 a worst case scenario might look like so we can understand it better.

30:47.920 --> 30:52.840
 But my understanding is in both cases it was done in BSL3 labs.

30:52.840 --> 30:59.840
 And so potential of leak, significantly nonzero, hopefully way below 1%, but significantly

30:59.840 --> 31:01.040
 nonzero.

31:01.040 --> 31:06.040
 And when you look at the consequences of an escape in terms of human lives, destruction

31:06.040 --> 31:10.640
 of a large portion of the economy, et cetera, and you do an expected value calculation on

31:10.640 --> 31:17.520
 whatever fraction of 1% that was, you would come up with a staggering cost, staggering

31:17.520 --> 31:19.320
 expected cost for this work.

31:19.320 --> 31:21.960
 So it should never have been carried out.

31:21.960 --> 31:24.520
 Now you might make an argument.

31:24.520 --> 31:34.320
 If you said, if you believed that H5N1 in nature is on an inevitable path to airborne transmission,

31:34.320 --> 31:40.520
 and it's only going to be a small number of years, A, and B, if it makes that transition,

31:40.520 --> 31:47.480
 there is one set of changes to its metabolic pathways and its genomic code and so forth.

31:47.480 --> 31:49.120
 One that we have discovered.

31:49.120 --> 31:53.840
 So it is going to go from point A, which is where it is right now, to point B. We have

31:53.840 --> 31:58.120
 reliably engineered point B. That is the destination.

31:58.120 --> 32:02.040
 And we need to start fighting that right now because this is five years or less away.

32:02.040 --> 32:03.480
 Now that'd be a very different world.

32:03.480 --> 32:06.760
 That'd be like spotting an asteroid that's coming toward the Earth and is five years

32:06.760 --> 32:07.760
 off.

32:07.760 --> 32:10.000
 And yes, you marshal everything you can to resist that.

32:10.000 --> 32:12.600
 But there's two problems with that perspective.

32:12.600 --> 32:17.120
 The first is, and however many thousands of generations that humans have been inhabiting

32:17.120 --> 32:21.280
 this planet, there has never been a transmissible form of H5N1.

32:21.280 --> 32:23.720
 And influenza has been around for a very long time.

32:23.720 --> 32:30.240
 So there is no case for inevitability of this kind of a jump to airborne transmission.

32:30.240 --> 32:33.600
 So we're not an afraid train to that outcome.

32:33.600 --> 32:38.360
 And if there was inevitability around that, it's not like there's just one set of genetic

32:38.360 --> 32:41.320
 code that would get there.

32:41.320 --> 32:46.400
 There's all kinds of different mutations that could conceivably result in that kind

32:46.400 --> 32:49.920
 of an outcome, unbelievable diversity of mutations.

32:49.920 --> 32:54.080
 And so we're not actually creating something we're inevitably going to face.

32:54.080 --> 32:59.600
 But we are creating something, we are creating a very powerful and unbelievably negative

32:59.600 --> 33:04.480
 card and injecting in the deck that nature never put into the deck.

33:04.480 --> 33:11.200
 So in that case, I just don't see any moral or scientific justification for that kind

33:11.200 --> 33:12.480
 of work.

33:12.480 --> 33:18.200
 And interestingly, there was quite a bit of excitement and concern about this when the

33:18.200 --> 33:19.200
 work came out.

33:19.200 --> 33:22.960
 One of the teams was going to publish their results in science, the other in nature.

33:22.960 --> 33:27.900
 And there were a lot of editorials and a lot of scientists are saying this is crazy.

33:27.900 --> 33:31.240
 And publication of those papers did get suspended.

33:31.240 --> 33:36.120
 And not long after that, there was a pause put on US government funding, NIH funding

33:36.120 --> 33:38.380
 on gain of function research.

33:38.380 --> 33:41.840
 But both of those speed bumps were ultimately removed.

33:41.840 --> 33:47.840
 Those papers did ultimately get published and that pause on funding ceased long ago.

33:47.840 --> 33:52.440
 And in fact, those two very projects, my understanding, has resumed their funding, got their government

33:52.440 --> 33:53.440
 funding back.

33:53.440 --> 33:57.720
 I don't know why a Dutch project is getting NIH funding, but whatever, about a year and

33:57.720 --> 33:58.880
 a half ago.

33:58.880 --> 34:04.480
 So as far as the US government and regulators are concerned, it's all systems go for gain

34:04.480 --> 34:07.120
 of function at this point, which I find very troubling.

34:07.120 --> 34:11.280
 Now, I'm a little bit of an outsider from this field, but it has echoes of the same

34:11.280 --> 34:16.680
 kind of problem I see in the AI world with autonomous weapons systems.

34:16.680 --> 34:25.120
 Nobody in my colleagues, my colleagues, friends, as far as I can tell people in the AI community

34:25.120 --> 34:31.040
 are not really talking about autonomous weapons systems as now US and China have full steam

34:31.040 --> 34:33.200
 ahead on the development of both.

34:33.200 --> 34:37.120
 And that seems to be a similar kind of thing on gain of function.

34:37.120 --> 34:46.200
 I have friends in the biology space and they don't want to talk about gain of function publicly.

34:46.200 --> 34:50.640
 And that makes me very uncomfortable from an outsider perspective in terms of gain of

34:50.640 --> 34:51.640
 function.

34:51.640 --> 34:56.920
 It makes me very uncomfortable from the insider perspective on autonomous weapons systems.

34:56.920 --> 35:00.800
 I'm not sure how to communicate exactly about autonomous weapons systems and I certainly

35:00.800 --> 35:04.120
 don't know how to communicate effectively about gain of function.

35:04.120 --> 35:06.280
 What is the right path forward here?

35:06.280 --> 35:09.520
 Did we seize all gain of function research?

35:09.520 --> 35:11.240
 Is that really the solution here?

35:11.240 --> 35:15.160
 Well, again, I'm going to use gain of function in the relatively narrow context of what we're

35:15.160 --> 35:16.160
 discussing.

35:16.160 --> 35:17.160
 Yes, for viruses.

35:17.160 --> 35:20.600
 You could say almost anything that you do to make biology more effective is gain of function.

35:20.600 --> 35:27.000
 So within the narrow confines of what we're discussing, I think it would be easy enough

35:27.000 --> 35:31.840
 for level headed people in all of the countries, level headed governmental people in all the

35:31.840 --> 35:36.800
 countries that realistically could support such a program to agree, we don't want this

35:36.800 --> 35:40.760
 to happen because all labs leak.

35:40.760 --> 35:49.000
 I mean, an example that I used in the piece I did with Sam Harris as well is the anthrax

35:49.000 --> 35:51.640
 attacks in the United States in 2001.

35:51.640 --> 35:57.280
 Talk about an example of the least likely lab leaking into the least likely place.

35:57.280 --> 36:03.000
 This was shortly after 9.11, folks, you don't remember it, and it was a very, very lethal

36:03.000 --> 36:08.440
 strand of anthrax that, as it turned out, based on the forensic genomic work that was

36:08.440 --> 36:13.720
 done and so forth, absolutely leaked from a high security US army lab.

36:13.720 --> 36:15.280
 Probably the one at Fort Detrick in Maryland.

36:15.280 --> 36:17.480
 It might have been another one, but who cares?

36:17.480 --> 36:21.520
 It absolutely leaked from a high security US army lab.

36:21.520 --> 36:22.880
 And where did it leak to?

36:22.880 --> 36:28.640
 This highly dangerous substance that was kept under lock and key by a very security minded

36:28.640 --> 36:29.640
 organization.

36:29.640 --> 36:33.560
 Well, it leaked to places including the Senate Majority Leader's Office, Tom Dashel's office.

36:33.560 --> 36:38.120
 They was Senator Leahy's office, certain publications including Bizarrely, the National

36:38.120 --> 36:39.280
 Enquirer.

36:39.280 --> 36:41.960
 But let's go to the Senate Majority Leader's Office.

36:41.960 --> 36:47.600
 It is hard to imagine a more security minded country than the United States two weeks after

36:47.600 --> 36:49.100
 the 9.11 attack.

36:49.100 --> 36:52.560
 I mean, it doesn't get more security minded than that.

36:52.560 --> 36:58.520
 And it's also hard to imagine a more security capable organization than the United States

36:58.520 --> 36:59.520
 military.

36:59.520 --> 37:05.600
 We can joke all we want about inefficiencies in the military and $24,000 wrenches and so

37:05.600 --> 37:08.280
 forth, but pretty capable when it comes to that.

37:08.280 --> 37:16.760
 Despite that level of focus and concern and competence, just days after the 9.11 attack,

37:16.760 --> 37:21.880
 something comes from the inside of our military and industrial compacts and ends up in the

37:21.880 --> 37:25.400
 office of someone I believe is Senate Majority Leader, somewhere in the line of presidential

37:25.400 --> 37:26.400
 succession.

37:26.400 --> 37:28.080
 It tells us everything can leak.

37:28.080 --> 37:33.480
 So again, think of a level headed conversation between powerful leaders in a diversity of

37:33.480 --> 37:39.840
 countries thinking through, like I can imagine a very simple PowerPoint revealing, you know,

37:39.840 --> 37:45.680
 just discussing briefly things like the anthrax leak, things like this foot and mouth disease

37:45.680 --> 37:52.800
 outbreak or leaking that came out of a BSL four level lab in the UK, several other things,

37:52.800 --> 37:57.760
 talking about the utter virulence that could result from gain of function and say, folks,

37:57.760 --> 38:00.840
 can we agree that this just shouldn't happen?

38:00.840 --> 38:06.280
 I mean, if we were able to agree on the Nuclear Nonproliferation Treaty, which we were by a

38:06.280 --> 38:11.420
 weapons convention, which we did agree on, we the world, for the most part, I believe

38:11.420 --> 38:14.000
 agreement could be found there.

38:14.000 --> 38:18.980
 But it's going to take people in leadership of a couple of very powerful countries to

38:18.980 --> 38:22.920
 get to consensus amongst them and then to decide we're going to get everybody together

38:22.920 --> 38:24.640
 and browbeat them into banning this stuff.

38:24.640 --> 38:28.720
 Now, that doesn't make it entirely impossible that somebody might do this.

38:28.720 --> 38:35.200
 But in well regulated, you know, carefully watched over fiduciary environments, like

38:35.200 --> 38:39.720
 federally funded academic research, anything going on in the government itself, you know,

38:39.720 --> 38:44.560
 companies going on in companies that have investors who don't want to go to jail for

38:44.560 --> 38:47.040
 the rest of their lives.

38:47.040 --> 38:50.400
 I think that would have a major, major dampening impact on it.

38:50.400 --> 38:58.400
 But there is a particular possible catalyst in this time we live in, which is for really

38:58.400 --> 39:02.680
 kind of raising the question of gain of function research for the application of virus, making

39:02.680 --> 39:13.000
 viruses more dangerous, is the question of whether COVID leaked from a lab, sort of not

39:13.000 --> 39:17.120
 even answering that question, but even asking that question.

39:17.120 --> 39:24.000
 It seems like a very important question to ask to catalyze the conversation about whether

39:24.000 --> 39:26.400
 we should be doing gain of function research.

39:26.400 --> 39:33.720
 I mean, from a high level, why do you think people, even colleagues of mine are not comfortable

39:33.720 --> 39:35.320
 asking that question?

39:35.320 --> 39:40.160
 And two, do you think that the answer could be that it did leak from a lab?

39:40.160 --> 39:48.840
 I think the mere possibility that it did leak from a lab is evidence enough, again, for

39:48.840 --> 39:54.880
 the hypothetical, rational national leaders watching this simple PowerPoint, if you could

39:54.880 --> 40:00.440
 put the possibility at one percent, and you look at the unbelievable destructive power

40:00.440 --> 40:06.200
 that COVID had, that should be an overwhelmingly powerful argument for excluding it.

40:06.200 --> 40:12.360
 Now, as to whether or not that was a leak, some very, very level, I don't know enough

40:12.360 --> 40:18.120
 about all of the factors in the Bayesian analysis and so forth that has gone into people making

40:18.120 --> 40:19.600
 the pro argument of that.

40:19.600 --> 40:24.440
 So I don't pretend to be an expert on that, and I don't have a point of view.

40:24.440 --> 40:25.880
 I just don't know.

40:25.880 --> 40:32.640
 But what we can say is it is entirely possible for a couple of reasons.

40:32.640 --> 40:37.360
 One is that there is a BSL4 lab in Wuhan, the Wuhan Institute of Virology.

40:37.360 --> 40:41.880
 I believe it's the only BSL4 in China, I could be wrong about that.

40:41.880 --> 40:50.920
 But it definitely had a history that alarmed very sophisticated US diplomats and others

40:50.920 --> 40:58.960
 who were in contact with the lab and were aware of what it was doing long before COVID

40:58.960 --> 41:00.080
 hit the world.

41:00.080 --> 41:03.600
 And so there are diplomatic cables that have been declassified.

41:03.600 --> 41:10.720
 I believe one sophisticated scientist or other observer said that WIV is a ticking time bomb.

41:10.720 --> 41:16.080
 And I believe it's also been pretty reasonably established that coronaviruses were a topic

41:16.080 --> 41:17.760
 of great interest at WIV.

41:17.760 --> 41:22.320
 SARS obviously came out of China, and that's a coronavirus that would make an enormous

41:22.320 --> 41:25.800
 amount of sense for it to be studied there.

41:25.800 --> 41:32.880
 And there is so much opacity about what happened in the early days and weeks after the outbreak

41:32.880 --> 41:38.200
 that's basically been imposed by the Chinese government that we just don't know.

41:38.200 --> 41:43.640
 So it feels like a substantially or greater than 1% possibility to me looking at it from

41:43.640 --> 41:45.360
 the outside.

41:45.360 --> 41:47.800
 And that's something that one could imagine.

41:47.800 --> 41:52.200
 Now we're going to the realm of thought experiment, not me decreeing this is what happened, but

41:52.200 --> 41:57.640
 if they're studying coronavirus at the Wuhan Institute of Virology, and there is this

41:57.640 --> 42:02.000
 precedent of gain of function research that's been done on something that is remarkably

42:02.000 --> 42:06.480
 uncontangiously human, whereas we know coronavirus is contagious to humans, I could definitely

42:06.480 --> 42:10.240
 and there is this global consensus.

42:10.240 --> 42:13.680
 Certainly was the case two or three years ago when this work might have started.

42:13.680 --> 42:17.280
 This seems to be this global consensus that gain of function is fine.

42:17.280 --> 42:20.720
 The US paused funding for a little while, but paused funding.

42:20.720 --> 42:22.960
 They never said private actors couldn't do it.

42:22.960 --> 42:25.720
 It was just a pause of NIH funding.

42:25.720 --> 42:27.000
 And then that pause was lifted.

42:27.000 --> 42:28.840
 So again, none of this is irrational.

42:28.840 --> 42:34.760
 You could certainly see the folks at WIV saying gain of function, interesting vector, coronavirus

42:34.760 --> 42:38.160
 unlike H5N1, very contagious.

42:38.160 --> 42:42.880
 We are in a nation that has had terrible run ins with coronavirus.

42:42.880 --> 42:45.000
 Why don't we do a little gain of function on this?

42:45.000 --> 42:49.880
 And then like all labs at all levels, one can imagine this lab leaking.

42:49.880 --> 42:55.040
 So it's not an impossibility and very, very level headed people have said that who have

42:55.040 --> 42:58.880
 looked at it much more deeply do believe in that outcome.

42:58.880 --> 43:03.640
 Why is it such a threat to power, the idea they'll leak from a lab?

43:03.640 --> 43:04.640
 Why is it so threatening?

43:04.640 --> 43:08.840
 I don't maybe understand this point exactly.

43:08.840 --> 43:14.080
 Is it just that as governments and especially the Chinese government is really afraid of

43:14.080 --> 43:18.320
 admitting mistakes that everybody makes?

43:18.320 --> 43:21.840
 So this is a horrible, like Chernobyl is a good example.

43:21.840 --> 43:24.440
 I come from the Soviet Union.

43:24.440 --> 43:29.200
 I mean, well, major mistakes were made in Chernobyl.

43:29.200 --> 43:38.320
 I would argue for a lab leak to happen, the scale of the mistake is much smaller.

43:38.320 --> 43:50.120
 The depth and the breadth of a rot in bureaucracy that led to Chernobyl is much bigger than

43:50.120 --> 43:55.400
 anything that could lead to a lab leak because it could literally just be, I mean, I'm sure

43:55.400 --> 44:03.080
 there's security, very careful security procedures even in level three labs, but I imagine maybe

44:03.080 --> 44:04.080
 you can correct me.

44:04.080 --> 44:10.080
 All it takes is the incompetence of a small number of individuals, one individual on a

44:10.080 --> 44:17.680
 particular couple of weeks, three weeks period as opposed to a multi year bureaucratic failure

44:17.680 --> 44:19.320
 of the entire government.

44:19.320 --> 44:20.320
 Right.

44:20.320 --> 44:24.240
 Well, certainly the magnitude of mistakes and compounding mistakes that went into Chernobyl

44:24.240 --> 44:26.120
 was far, far, far greater.

44:26.120 --> 44:32.640
 But the consequence of COVID outweighs that the consequence of Chernobyl to a tremendous

44:32.640 --> 44:43.640
 degree, and I think that particularly authoritarian governments are unbelievably reluctant to

44:43.640 --> 44:46.000
 admit to any fallibility whatsoever.

44:46.000 --> 44:52.640
 There's a long, long history of that across dozens and dozens of authoritarian governments,

44:52.640 --> 44:57.600
 and to be transparent, again, this is in the hypothetical world in which this was a leak,

44:57.600 --> 45:03.320
 which again, I don't personally have enough sophistication to have an opinion on the likelihood.

45:03.320 --> 45:10.720
 But in the hypothetical world in which it was a leak, the global reaction and the amount

45:10.720 --> 45:21.000
 of global animus and the amount of the decline in global respect that would happen toward

45:21.000 --> 45:27.280
 China because every country suffered massively from this, unbelievable damages in terms of

45:27.280 --> 45:30.920
 human lives and economic activity disrupted.

45:30.920 --> 45:35.200
 The world would in some way present China with that bill.

45:35.200 --> 45:41.160
 And when you take on top of that the natural disinclination for any authoritarian government

45:41.160 --> 45:47.000
 to admit any fallibility and tolerate the possibility of any fallibility whatsoever,

45:47.000 --> 45:51.520
 and you look at the relative opacity, even though they let a World Health Organization

45:51.520 --> 45:57.080
 group in a couple of months ago to run around, they didn't give that who group anywhere

45:57.080 --> 46:02.240
 near the level of access it would be necessary to definitively say X happened versus Y.

46:02.240 --> 46:08.400
 The level of opacity that surrounds those opening weeks and months of COVID in China,

46:08.400 --> 46:10.440
 we just don't know.

46:10.440 --> 46:18.200
 If you were to look back at 2020 and maybe brought it out to future pandemics that could

46:18.200 --> 46:25.960
 be much more dangerous, what kind of response, how do we fail in a response, and how could

46:25.960 --> 46:27.560
 we do better?

46:27.560 --> 46:35.560
 So the gain of function research is discussing the question of we should not be creating

46:35.560 --> 46:41.320
 viruses that are both exceptionally contagious and exceptionally deadly to humans.

46:41.320 --> 46:48.200
 But if it does happen, perhaps the natural evolution, natural mutation, is there interesting

46:48.200 --> 46:56.040
 technological responses on the testing side, on the vaccine development side, on the collection

46:56.040 --> 47:02.400
 of data, or on the basic sort of policy response side, or the sociological, the psychological

47:02.400 --> 47:03.400
 side?

47:03.400 --> 47:08.960
 Yeah, there's all kinds of things, and most of what I've thought about and written about

47:08.960 --> 47:14.920
 and again discussed in that long bit with Sam is dual use.

47:14.920 --> 47:20.040
 So most of the countermeasures that I've been thinking about and advocating for would be

47:20.040 --> 47:26.640
 every bit as effective against zoonotic disease and natural pandemic of some sort as an artificial

47:26.640 --> 47:27.640
 one.

47:27.640 --> 47:32.920
 The risk of an artificial one, even the near term risk of an artificial one, ups the urgency

47:32.920 --> 47:37.560
 around these measures immensely, but most of them would be broadly applicable.

47:37.560 --> 47:43.560
 And so I think the first thing that we really want to do on a global scale is have a far,

47:43.560 --> 47:49.720
 far more robust and globally transparent system of detection.

47:49.720 --> 47:52.080
 And that can happen on a number of levels.

47:52.080 --> 47:58.200
 The most obvious one is just in the blood of people who come into clinics exhibiting

47:58.200 --> 48:00.280
 signs of illness.

48:00.280 --> 48:07.640
 And we are certainly at a point now where at with relatively minimal investment, we

48:07.640 --> 48:12.880
 could develop in clinic diagnostics that would be unbelievably effective at pinpointing what's

48:12.880 --> 48:19.040
 going on in almost any disease when somebody walks into a doctor's office or a clinic.

48:19.040 --> 48:24.920
 And better than that, this is a little bit further off, but it wouldn't cost tens of

48:24.920 --> 48:28.880
 billions in research dollars, it would be a relatively modest and affordable budget

48:28.880 --> 48:36.000
 in relation to the threat at home diagnostics that can really, really pinpoint particularly

48:36.000 --> 48:41.480
 with respiratory infections because that is generally almost universally the mechanism

48:41.480 --> 48:44.640
 of transmission for any serious pandemic.

48:44.640 --> 48:50.840
 So somebody has a respiratory infection, is it one of the significantly large handful

48:50.840 --> 48:55.400
 of rhinoviruses, coronaviruses, and other things that cause common cold?

48:55.400 --> 48:56.400
 Or is it influenza?

48:56.400 --> 48:59.960
 If it's influenza, is it influenza A versus B?

48:59.960 --> 49:07.120
 Or is it a small handful of other more exotic but nonetheless sort of common respiratory

49:07.120 --> 49:09.320
 infections that are out there?

49:09.320 --> 49:12.960
 Having a diagnostic panel to pinpoint all of that stuff, that's something that's well

49:12.960 --> 49:13.960
 within our capabilities.

49:13.960 --> 49:19.040
 That's much less a lift than creating mRNA vaccines, which obviously we proved capable

49:19.040 --> 49:21.160
 of when we put our minds to it.

49:21.160 --> 49:24.360
 So do that on a global basis.

49:24.360 --> 49:28.760
 And I don't think that's irrational because the best prototype for this that I'm aware

49:28.760 --> 49:34.600
 of isn't currently rolling out in Atherton, California, or Fairfield County, Connecticut,

49:34.600 --> 49:36.280
 or some other wealthy place.

49:36.280 --> 49:40.160
 The best prototype that I'm aware of this is rolling out right now in Nigeria.

49:40.160 --> 49:45.040
 And it's a project that came out of the Broad Institute, which is, as I'm sure you know,

49:45.040 --> 49:49.560
 but some listeners may not, is kind of like an academic joint venture between Harvard

49:49.560 --> 49:50.920
 and MIT.

49:50.920 --> 49:53.360
 The program is called Sentinel.

49:53.360 --> 49:58.520
 And their objective is, and their plan, and it's a very well conceived plan, a methodical

49:58.520 --> 50:04.480
 plan, is to do just that in areas of Nigeria that are particularly vulnerable to zoonotic

50:04.480 --> 50:08.000
 diseases, making the jump from animals to humans.

50:08.000 --> 50:11.960
 But also there's just an unbelievable public health benefit from that.

50:11.960 --> 50:17.000
 And it's sort of a three tier system where clinicians in the field could very rapidly

50:17.000 --> 50:22.200
 determine, do you have one of the infections of acute interest here, either because it's

50:22.200 --> 50:26.760
 very common in this region, so we want to diagnose as many things as we can at the front

50:26.760 --> 50:31.320
 line, or because it's uncommon but unbelievably threatening like Ebola.

50:31.320 --> 50:35.440
 So front line worker can make that determination very, very rapidly.

50:35.440 --> 50:40.920
 If it comes up as a we don't know, they bump it up to a level that's more like at a fully

50:40.920 --> 50:44.040
 configured doctor's office or local hospital.

50:44.040 --> 50:47.840
 And if it's still at a we don't know, it gets bumped up to a national level.

50:47.840 --> 50:51.200
 And that gets bumped very, very rapidly.

50:51.200 --> 50:57.880
 So if this can be done in Nigeria, and it seems that it can be, there shouldn't be any inhibition

50:57.880 --> 51:00.840
 for it to happen in most other places.

51:00.840 --> 51:03.240
 And it should be affordable from a budgetary standpoint.

51:03.240 --> 51:07.760
 And based on Sentinel's budget and adjusting things for things like very different costs

51:07.760 --> 51:13.080
 of living, larger population, et cetera, I did a back of the envelope calculation that

51:13.080 --> 51:17.160
 doing something like Sentinel in the US would be in the low billions of dollars.

51:17.160 --> 51:22.040
 And wealthy countries, middle income countries can't afford such a thing.

51:22.040 --> 51:26.880
 Lower income countries should certainly be helped with that, but start with that level

51:26.880 --> 51:27.880
 of detection.

51:27.880 --> 51:33.680
 And layer on top of that other interesting things like monitoring search engine traffic,

51:33.680 --> 51:39.640
 search engine queries for evidence that strange clusters of symptoms are starting to rise

51:39.640 --> 51:40.640
 in different places.

51:40.640 --> 51:43.480
 There's been a lot of work done with that.

51:43.480 --> 51:47.680
 Most of it kind of academic and experimental, but some of it has been powerful enough to

51:47.680 --> 51:51.160
 suggest that this could be a very powerful early warning system.

51:51.160 --> 51:57.840
 There's a guy named Bill Lampos at University College London who basically did a very rigorous

51:57.840 --> 52:05.000
 analysis that showed that symptom searches reliably predicted COVID outbreaks in the

52:05.000 --> 52:10.160
 early days of the pandemic in given countries by as much as 16 days before the evidence

52:10.160 --> 52:12.280
 started to crew at a public health level.

52:12.280 --> 52:18.960
 16 days of forewarning can be monumentally important in the early days of an outbreak.

52:18.960 --> 52:26.640
 And this is a very, very talented, but nonetheless very resource constrained academic project.

52:26.640 --> 52:30.960
 Even if that was something that was done with a NORAD like budget.

52:30.960 --> 52:35.120
 So I mean, starting with detection, that's something we could do radically, radically

52:35.120 --> 52:36.120
 better.

52:36.120 --> 52:39.800
 So aggregating multiple data sources in order to create something, I mean, this is really

52:39.800 --> 52:44.160
 exciting to me, the possibility that I've heard inklings of, of creating almost like

52:44.160 --> 52:53.480
 a weather map of pathogens, like basically aggregating all of these data sources, scaling

52:53.480 --> 52:59.080
 many orders of magnitude up at home testing and all kinds of testing that doesn't just

52:59.080 --> 53:05.800
 try to test for the particular pathogen of worry now, but everything like a full spectrum

53:05.800 --> 53:12.640
 of things that could be dangerous to the human body and thereby be able to create these maps

53:12.640 --> 53:18.400
 like that are dynamically updated on an hourly basis of the, of how viruses travel throughout

53:18.400 --> 53:19.520
 the world.

53:19.520 --> 53:23.840
 And so you can respond like you can then integrate just like you do when you check your weather

53:23.840 --> 53:26.600
 map and it's raining or not.

53:26.600 --> 53:32.360
 Of course not perfect, but it's very good predictor whether it's going to rain or not

53:32.360 --> 53:37.320
 and use that to then make decisions about your own life, ultimately give the power information

53:37.320 --> 53:38.800
 to individuals to respond.

53:38.800 --> 53:44.160
 And if it's a super dangerous, like if it's acid rain versus regular rain, you might want

53:44.160 --> 53:47.440
 to really stay inside as opposed to risking it.

53:47.440 --> 53:54.400
 And that just like you said, if I think it's not very expensive relative to all the things

53:54.400 --> 54:00.440
 that we do in this world, but it does require bold leadership.

54:00.440 --> 54:05.440
 And there's another dark thing which really is bothering me about 2020, which it requires

54:05.440 --> 54:13.200
 is it requires trust in institutions to carry out these kinds of programs and requires trust

54:13.200 --> 54:21.360
 in science and engineers and sort of centralized organizations that would operate at scale here.

54:21.360 --> 54:27.800
 And much of that trust has been, at least in the United States, diminished.

54:27.800 --> 54:33.240
 It feels like I'm not exactly sure where to place the blame, but I do place quite a bit

54:33.240 --> 54:36.480
 of the blame into the scientific community.

54:36.480 --> 54:44.240
 And again, my fellow colleagues in speaking down to people at times, speaking from authority,

54:44.240 --> 54:49.360
 it sounded like it dismissed the basic human experience or the basic common humanity of

54:49.360 --> 54:56.280
 people in a way to like, it almost sounded like there's an agenda that's hidden behind

54:56.280 --> 55:01.600
 the words the scientists spoke, like they're trying to, in a self preserving way, control

55:01.600 --> 55:03.840
 the population or something like that.

55:03.840 --> 55:07.360
 I don't think any of that is true from the majority of the scientific community, but

55:07.360 --> 55:08.840
 it sounded that way.

55:08.840 --> 55:11.280
 And so the trust began to diminish.

55:11.280 --> 55:18.760
 I'm not sure how to fix that, except to be more authentic, be more real, acknowledge

55:18.760 --> 55:25.040
 the uncertainties under which we operate, acknowledge the mistakes that scientists make, that institutions

55:25.040 --> 55:29.680
 make, the leak from the lab is a perfect example.

55:29.680 --> 55:35.200
 We have imperfect systems that make all the progress you see in the world, and that being

55:35.200 --> 55:39.760
 honest about that imperfection, I think, is essential for forming trust, but I don't know

55:39.760 --> 55:40.760
 what to make of it.

55:40.760 --> 55:47.120
 It's been deeply disappointing because I do think, just like you mentioned, the solutions

55:47.120 --> 55:53.760
 require people to trust the institutions with their data.

55:53.760 --> 55:54.760
 Yeah.

55:54.760 --> 55:59.920
 I think part of the problem is, it seems to me as an outsider that there was a bizarre

55:59.920 --> 56:08.520
 unwillingness on the part of the CDC and other institutions to admit to, to frame and to

56:08.520 --> 56:11.280
 contextualize uncertainty.

56:11.280 --> 56:16.760
 Maybe they had a patronizing idea that these people need to be told, and when they're told,

56:16.760 --> 56:21.760
 they need to be told with authority and a level of definitiveness and certitude that

56:21.760 --> 56:23.640
 doesn't actually exist.

56:23.640 --> 56:29.360
 And so when they whipsaw on recommendations like what you should do about masks, when

56:29.360 --> 56:36.000
 the CDC is at the very beginning of the pandemic saying, masks don't do anything, don't wear

56:36.000 --> 56:41.720
 them, when the real driver for that was, we don't want these clowns going out and depleting

56:41.720 --> 56:49.040
 Amazon of masks because they may be needed in medical settings, and we just don't know

56:49.040 --> 56:50.040
 yet.

56:50.040 --> 56:54.360
 And I think a message that actually respected people and said, this is why we're asking

56:54.360 --> 57:00.120
 you not to do masks yet, and there's more to be seen, would be less whipsawing and would

57:00.120 --> 57:04.600
 bring people, like they feel more like they're part of the conversation and they're being

57:04.600 --> 57:10.960
 treated like adults than saying one day definitively masks suck, and then X days later saying,

57:10.960 --> 57:13.160
 nope, damn it, wear masks.

57:13.160 --> 57:17.000
 And so I think framing things in terms of the probabilities, which most people are easy

57:17.000 --> 57:18.000
 to parse.

57:18.000 --> 57:23.640
 A more recent example, which I just thought was batty, was suspending the Johnson and

57:23.640 --> 57:31.040
 Johnson vaccine for a very low single digit number of days in the United States based

57:31.040 --> 57:38.640
 on the fact that I believe there had been seven ish clotting incidents in roughly seven

57:38.640 --> 57:45.560
 million people who had had the vaccine administered, I believe one of which resulted in a fatality.

57:45.560 --> 57:50.120
 And there was definitely suggestive data that indicated that there was a relationship.

57:50.120 --> 57:53.800
 This wasn't just coincidental because I think all of the clotting incidents happened in

57:53.800 --> 57:58.400
 women as opposed to men and kind of clustered in a certain age group.

57:58.400 --> 58:05.420
 But does that call for shutting off the vaccine, or does it call for leveling with the American

58:05.420 --> 58:10.480
 public and saying, we've had one fatality out of seven million?

58:10.480 --> 58:15.600
 This is, let's just assume, substantially less than the likelihood of getting struck

58:15.600 --> 58:18.600
 by lightning.

58:18.600 --> 58:22.800
 Based on that information, and we're going to keep you posted because you can trust

58:22.800 --> 58:27.120
 us to keep you posted, based on that information, please decide whether you're comfortable with

58:27.120 --> 58:29.320
 a Johnson and Johnson vaccine.

58:29.320 --> 58:33.140
 That would have been one response, and I think people would have been able to parse the simple

58:33.140 --> 58:35.200
 bits of data and make their own judgment.

58:35.200 --> 58:41.720
 By turning it off, all of a sudden, there's this dramatic signal to people who don't read

58:41.720 --> 58:45.920
 all 900 words in the New York Times piece that explains why it's being turned off, but

58:45.920 --> 58:48.720
 just see the headline, which is a majority of people.

58:48.720 --> 58:54.520
 There's a sudden, oh my god, yikes, vaccine being shut off.

58:54.520 --> 58:58.160
 And then all the people who sat on the fence or are sitting on the fence about whether

58:58.160 --> 59:03.400
 or not they trust vaccines, that is going to push an incalculable number of people.

59:03.400 --> 59:05.000
 That's going to be the last straw.

59:05.000 --> 59:08.800
 For we don't know how many hundreds of thousands or more likely millions of people to say,

59:08.800 --> 59:11.440
 okay, tipping point here, I'm going to trust these vaccines.

59:11.440 --> 59:16.120
 So by pausing that for whatever it was, 10 or 12 days, and then flipping the switch

59:16.120 --> 59:21.200
 as everybody who knew much about the situation knew was inevitable.

59:21.200 --> 59:28.120
 By flipping the on switch 12 days later, you're conveying certitude J&J bad to certitude

59:28.120 --> 59:33.240
 J&J good in a period of just a few days, and people just feel whipsawed, and they're not

59:33.240 --> 59:34.240
 part of the analysis.

59:34.240 --> 59:36.600
 But it's not just the whipsawing.

59:36.600 --> 59:37.920
 And I think about this quite a bit.

59:37.920 --> 59:39.960
 I don't think I have good answers.

59:39.960 --> 59:43.440
 It's something about the way the communication actually happens.

59:43.440 --> 59:49.800
 Just I don't know what it is about Anthony Fauci, for example, but I don't trust him.

59:49.800 --> 59:55.880
 And I think that has to do, I mean, he has an incredible background.

59:55.880 --> 59:59.080
 I'm sure he's a brilliant scientist and researcher.

59:59.080 --> 1:00:06.320
 I'm sure he's also a great like inside the room policymaker and deliberator and so on.

1:00:06.320 --> 1:00:12.400
 But you know, what makes a great leader is something about that thing that you can't

1:00:12.400 --> 1:00:22.200
 quite describe, but being a communicator that you know you can trust that there's an authenticity

1:00:22.200 --> 1:00:23.200
 that's required.

1:00:23.200 --> 1:00:28.600
 And I'm not sure maybe I'm being a bit too judgmental, but I'm a huge fan of a lot of

1:00:28.600 --> 1:00:31.040
 great leaders throughout history.

1:00:31.040 --> 1:00:36.920
 They've communicated exceptionally well in the way that Fauci does not.

1:00:36.920 --> 1:00:38.080
 And I think about that.

1:00:38.080 --> 1:00:40.560
 I think about what has affected science communication.

1:00:40.560 --> 1:00:47.240
 So great leaders throughout history did not necessarily need to be great science communicators.

1:00:47.240 --> 1:00:51.360
 Their leadership was in other domains, but when you're fighting the virus, you also have

1:00:51.360 --> 1:00:53.840
 to be a great science communicator.

1:00:53.840 --> 1:00:58.080
 You have to be able to communicate on certainties, you have to be able to communicate something

1:00:58.080 --> 1:01:03.720
 like a vaccine that you're allowing inside your body into the messiness, into the complexity

1:01:03.720 --> 1:01:08.120
 of the biology system, that if we're being honest, it's so complex, we'll never be able

1:01:08.120 --> 1:01:10.880
 to really understand.

1:01:10.880 --> 1:01:16.840
 We can only desperately hope that science can give us sort of a high likelihood that

1:01:16.840 --> 1:01:22.560
 there's no short term negative consequences and that kind of intuition about long term

1:01:22.560 --> 1:01:28.960
 negative consequences and doing our best in this battle against trillions of things that

1:01:28.960 --> 1:01:32.560
 are trying to kill us.

1:01:32.560 --> 1:01:36.840
 Being an effective communicator in that space is very difficult, but I think about what

1:01:36.840 --> 1:01:41.840
 it takes because I think there should be more science communicators that are effective

1:01:41.840 --> 1:01:43.680
 at that kind of thing.

1:01:43.680 --> 1:01:49.960
 Let me ask you about something that's sort of more in the AI space that I think about

1:01:49.960 --> 1:01:58.440
 that kind of goes along this thread that you've spoken about democratizing the technology

1:01:58.440 --> 1:02:06.200
 that could destroy human civilization is from amazing work from DeepMind AlphaFold2, which

1:02:06.200 --> 1:02:13.240
 achieved incredible performance on the protein folding problem, single protein folding problem.

1:02:13.240 --> 1:02:22.000
 Do you think about the use of AI in the syn biospace of, I think the gain of function

1:02:22.000 --> 1:02:28.440
 in the virus space research that you refer to, I think is natural mutations and sort

1:02:28.440 --> 1:02:36.000
 of aggressively mutating the virus until you get one that has this both contagious and

1:02:36.000 --> 1:02:46.960
 deadly, but what about then using AI to through simulation be able to compute deadly viruses

1:02:46.960 --> 1:02:49.560
 or any kind of biological systems?

1:02:49.560 --> 1:02:53.120
 Is this something you're worried about or again, is this something you're more excited

1:02:53.120 --> 1:02:54.120
 about?

1:02:54.120 --> 1:02:59.000
 I think computational biology is unbelievably exciting and promising field and I think when

1:02:59.000 --> 1:03:05.960
 you're doing things in silica as opposed to in vivo, the dangers plummet.

1:03:05.960 --> 1:03:10.160
 You don't have a critter that can leak from a leaky lab.

1:03:10.160 --> 1:03:15.320
 So I don't see any problem with that except I do worry about the data security dimension

1:03:15.320 --> 1:03:20.880
 of it because if you were doing really, really interesting in silica gain a function research

1:03:20.880 --> 1:03:27.160
 and you hit upon through a level sophistication, we don't currently have but synthetic biology

1:03:27.160 --> 1:03:32.440
 is an exponential technology so capabilities that are utterly out of reach today will be

1:03:32.440 --> 1:03:35.760
 attainable in five or six years.

1:03:35.760 --> 1:03:44.120
 I think if you conjured up worst case genomes of viruses that don't exist in vivo anywhere,

1:03:44.120 --> 1:03:48.880
 they're just in the computer space but like, hey guys, this is a genetic sequence that

1:03:48.880 --> 1:03:51.400
 would end the world, let's say.

1:03:51.400 --> 1:03:58.600
 Then you have to worry about the utter hackability of every computer network we can imagine.

1:03:58.600 --> 1:04:04.800
 Data leaks from the least likely places on the grandest possible scales have happened

1:04:04.800 --> 1:04:09.000
 and continue to happen and will probably always continue to happen and so that would be the

1:04:09.000 --> 1:04:11.800
 danger of doing the work in silica.

1:04:11.800 --> 1:04:15.720
 If you end up with a list of like, well, these are things we never want to see.

1:04:15.720 --> 1:04:20.400
 That list leaks and after the passage of some time certainly couldn't be done today but

1:04:20.400 --> 1:04:26.280
 after the passage of some time, lots and lots of people in academic labs going all the way

1:04:26.280 --> 1:04:33.600
 down to the high school level are in a position to make it overly simplistic, hit print on

1:04:33.600 --> 1:04:37.440
 a genome and have the virus bearing that genome pop out on the other end and you got

1:04:37.440 --> 1:04:42.920
 something to worry about but in general computational biology I think is incredibly important particularly

1:04:42.920 --> 1:04:47.200
 because the crushing majority of work that people are doing with the protein folding

1:04:47.200 --> 1:04:52.560
 problem and other things are about creating therapeutics, about creating things that will

1:04:52.560 --> 1:04:58.160
 help us live better, live longer, thrive, be a bit more well and so forth.

1:04:58.160 --> 1:05:03.800
 The protein folding problem is a monstrous computational challenge that we seem to make

1:05:03.800 --> 1:05:10.040
 just the most glacial progress on for years and years but I think there's a biannual

1:05:10.040 --> 1:05:17.840
 competition I think for which people tackle the protein folding problem and DeepMind's

1:05:17.840 --> 1:05:25.520
 entrant both two years ago like in 2018 and 2020 ruled the field and so protein folding

1:05:25.520 --> 1:05:29.480
 is an unbelievably important thing if you want to start thinking about therapeutics

1:05:29.480 --> 1:05:34.560
 because it's the folding of the protein that tells us where the channels and the receptors

1:05:34.560 --> 1:05:39.960
 and everything else are on that protein and it's from that precise model, if we can get

1:05:39.960 --> 1:05:46.800
 to a precise model, that you can start barraging it again in silicone with thousands, tens

1:05:46.800 --> 1:05:52.520
 of thousands, millions of potential therapeutics and see what resolves the problems, the shortcomings

1:05:52.520 --> 1:05:59.560
 that a mischapen protein, for instance somebody with a cystic fibrosis, how might we treat

1:05:59.560 --> 1:06:00.560
 that?

1:06:00.560 --> 1:06:01.560
 So I see nothing but good in that.

1:06:01.560 --> 1:06:06.160
 Well, let me ask you about fear and hope in this world.

1:06:06.160 --> 1:06:15.480
 I tend to believe that in terms of competence and malevolence, that people who are maybe

1:06:15.480 --> 1:06:20.200
 it's in my interactions, I tend to see that first of all I believe that most people are

1:06:20.200 --> 1:06:27.600
 good and want to do good and are just better at doing good and more inclined to do good

1:06:27.600 --> 1:06:36.000
 on this world and more than that, people who are malevolent are usually incompetent at

1:06:36.000 --> 1:06:38.080
 building technology.

1:06:38.080 --> 1:06:43.080
 So I've seen this in my life that people who are exceptionally good at stuff, no matter

1:06:43.080 --> 1:06:50.480
 what the stuff is, tend to maybe they discover joy in life in a way that gives them fulfillment

1:06:50.480 --> 1:06:55.080
 and thereby does not result in them wanting to destroy the world.

1:06:55.080 --> 1:07:00.120
 So the better you are at stuff, whether that's building nuclear weapons or plumbing, doesn't

1:07:00.120 --> 1:07:03.800
 matter, the less likely you are to destroy the world.

1:07:03.800 --> 1:07:14.520
 So in that sense, with many technologies, AI especially, I always think that the malevolent

1:07:14.520 --> 1:07:22.040
 would be far outnumbered by the ultra competent and in that sense, the defenses will always

1:07:22.040 --> 1:07:28.640
 be stronger than the offense in terms of the people trying to destroy the world.

1:07:28.640 --> 1:07:33.960
 Now, there's a few spaces where that might not be the case and that's an interesting

1:07:33.960 --> 1:07:40.240
 conversation where there's one person who's not very competent can destroy the whole world.

1:07:40.240 --> 1:07:47.240
 Perhaps symbio is one such space because of the exponential effects of the technology.

1:07:47.240 --> 1:07:54.360
 I tend to believe AI is not one of those such spaces, but do you share this kind of view

1:07:54.360 --> 1:07:58.720
 that the ultra competent are usually also the good?

1:07:58.720 --> 1:07:59.720
 Yeah, absolutely.

1:07:59.720 --> 1:08:04.600
 I absolutely share that and that gives me a great deal of optimism that we will be able

1:08:04.600 --> 1:08:10.320
 to short circuit the threat that malevolence and bio could pose to us.

1:08:10.320 --> 1:08:14.760
 But we need to start creating those defensive systems or defensive layers, one of which

1:08:14.760 --> 1:08:18.880
 we talked about far, far, far better surveillance in order to prevail.

1:08:18.880 --> 1:08:26.840
 So the good guys will almost inevitably outsmart and definitely outnumber the bad guys in most

1:08:26.840 --> 1:08:29.680
 sort of smackdowns that we can imagine.

1:08:29.680 --> 1:08:34.840
 But the good guys aren't going to be able to exert their advantages unless they have

1:08:34.840 --> 1:08:40.760
 the imagination necessary to think about what the worst possible thing can be done by somebody

1:08:40.760 --> 1:08:45.080
 whose own psychology is completely alien to their own.

1:08:45.080 --> 1:08:47.600
 So that's a tricky, tricky thing to solve for.

1:08:47.600 --> 1:08:54.440
 Now in terms of whether the asymmetric power that a bad guy might have in the face of the

1:08:54.440 --> 1:09:00.080
 overwhelming numerical advantage and competence advantage that the good guys have, unfortunately

1:09:00.080 --> 1:09:04.080
 I look at something like mass shootings as an example.

1:09:04.080 --> 1:09:08.920
 I'm sure the guy who was responsible for the Vegas shooting or the Orlando shooting or

1:09:08.920 --> 1:09:14.400
 any other shooting that we can imagine didn't know a whole lot about ballistics.

1:09:14.400 --> 1:09:20.240
 And the number of good guy citizens in the United States with guns compared to bad guy

1:09:20.240 --> 1:09:25.800
 citizens, I'm sure, is a crushingly overwhelming, the high ratio in favor of the good guys.

1:09:25.800 --> 1:09:30.360
 But that doesn't make it possible for us to stop mass shootings.

1:09:30.360 --> 1:09:37.200
 An example is Fort Hood, 45,000 trained soldiers on that base.

1:09:37.200 --> 1:09:40.200
 But there have been two mass shootings there.

1:09:40.200 --> 1:09:48.120
 And so there is an asymmetry when you have powerful and lethal technology that gets so

1:09:48.120 --> 1:09:54.920
 democratized and so proliferated in tools that are very, very easy to use, even by a

1:09:54.920 --> 1:09:56.280
 knucklehead.

1:09:56.280 --> 1:10:00.800
 When those tools get really easy to use by a knucklehead and they're really widespread,

1:10:00.800 --> 1:10:06.240
 it becomes very, very hard to defend against all instances of usage.

1:10:06.240 --> 1:10:11.120
 Now the good news, quote unquote, about mass shootings, if there is any and there is some,

1:10:11.120 --> 1:10:17.920
 is even the most brutal and carefully planning and well armed mass shooter can only take

1:10:17.920 --> 1:10:20.400
 so many victims.

1:10:20.400 --> 1:10:26.080
 And the same is true, there's been four instances that I'm aware of of commercial pilots committing

1:10:26.080 --> 1:10:29.560
 suicide by doubting their planes and taking all their passengers with them.

1:10:29.560 --> 1:10:33.560
 These weren't Boeing engineers, you know, but like an army of Boeing engineers ultimately

1:10:33.560 --> 1:10:36.160
 were not capable of preventing that.

1:10:36.160 --> 1:10:40.720
 But even in their case, and I'm actually not counting 911 and that 911 is a different

1:10:40.720 --> 1:10:45.080
 category in my mind, these are just personally suicidal pilots.

1:10:45.080 --> 1:10:50.320
 In those cases, they only have a plain load of people that they're able to take with them.

1:10:50.320 --> 1:10:57.800
 If we imagine a highly plausible and imaginable future in which symbiotools that are amoral,

1:10:57.800 --> 1:11:04.480
 that could be used for good or for ill, start embodying unbelievable sophistication and

1:11:04.480 --> 1:11:12.200
 genius in the tool, in the easier and easier and easier to make tool, all those thousands,

1:11:12.200 --> 1:11:16.800
 tens of thousands, hundreds of thousands of scientist years start getting embodied in

1:11:16.800 --> 1:11:23.240
 something that, you know, maybe as simple as hitting a print button, then that good guy

1:11:23.240 --> 1:11:29.720
 technology can be hijacked by a bad person and used in a very asymmetric way.

1:11:29.720 --> 1:11:34.680
 Yeah, I think what happens though, as you go to the high school student from the current,

1:11:34.680 --> 1:11:41.160
 like very specific set of labs that are able to do it, as it becomes more and more democratized,

1:11:41.160 --> 1:11:47.640
 as it becomes easier and easier to do this kind of large scale damage with an engineered

1:11:47.640 --> 1:11:53.200
 virus, the more and more there will be engineering of defenses against these systems, essentially

1:11:53.200 --> 1:11:56.840
 some of the things we talked about in terms of testing, in terms of collection of data,

1:11:56.840 --> 1:12:05.040
 but also in terms of scale contact tracing or also engineering of vaccines in a matter

1:12:05.040 --> 1:12:08.680
 of days, maybe hours, maybe minutes.

1:12:08.680 --> 1:12:15.200
 I feel like the defenses, that's what human species seems to do, is we keep hitting the

1:12:15.200 --> 1:12:22.480
 snooze button until there's a storm on the horizon heading towards us, then we start

1:12:22.480 --> 1:12:31.680
 to quickly build up the defenses or the response that's proportional to the scale of the storm.

1:12:31.680 --> 1:12:38.880
 Of course, again, certain kinds of exponential threats require us to build up the defenses

1:12:38.880 --> 1:12:43.200
 way earlier than we usually do, and that's, I guess, the question, but I ultimately am

1:12:43.200 --> 1:12:49.920
 hopeful that the natural process of hitting the snooze button until the deadline is right

1:12:49.920 --> 1:12:53.240
 in front of us will work out for quite a long time for us humans.

1:12:53.240 --> 1:12:54.240
 I fully agree.

1:12:54.240 --> 1:12:58.880
 I mean, that's why I'm fundamentally, I mean, I sound like it thus far, but I'm fundamentally

1:12:58.880 --> 1:13:04.040
 very, very optimistic about our ability to short circuit this threat, because there is,

1:13:04.040 --> 1:13:11.280
 again, I'll stress, the technological feasibility and the profound affordability of a relatively

1:13:11.280 --> 1:13:17.400
 simple set of steps that we can take to preclude it, but we do have to take those steps.

1:13:17.400 --> 1:13:22.840
 What I'm hoping to do and trying to do is inject a notion of what those steps are into

1:13:22.840 --> 1:13:27.320
 the public conversation and do my small part to up the odds that that actually ends up

1:13:27.320 --> 1:13:30.320
 happening.

1:13:30.320 --> 1:13:37.160
 The danger with this one is it is exponential, and I think that our minds are fundamentally

1:13:37.160 --> 1:13:40.280
 struggle to understand exponential math.

1:13:40.280 --> 1:13:42.440
 It's just not something we're wired for.

1:13:42.440 --> 1:13:46.640
 Our ancestors didn't confront exponential processes when they were growing up on the

1:13:46.640 --> 1:13:51.920
 Savannah, so it's not something that's intuitive to us and our intuitions are reliably defeated

1:13:51.920 --> 1:13:54.440
 when exponential processes come along.

1:13:54.440 --> 1:13:56.240
 That's issue number one.

1:13:56.240 --> 1:14:02.840
 Issue number two with something like this is it kind of only takes one.

1:14:02.840 --> 1:14:08.120
 That ball only has to go into the net once and we're doomed, which is not the case with

1:14:08.120 --> 1:14:09.120
 mass shooters.

1:14:09.120 --> 1:14:12.280
 It's not the case with commercial pilots run amok.

1:14:12.280 --> 1:14:17.520
 It's not the case with really any threat that I can think of with the exception of nuclear

1:14:17.520 --> 1:14:25.200
 war that has the one bad outcome and game over.

1:14:25.200 --> 1:14:30.880
 That means that we need to be unbelievably serious about these defenses and we need to

1:14:30.880 --> 1:14:36.640
 do things that might on the surface seem like a tremendous overreaction so that we can be

1:14:36.640 --> 1:14:39.720
 prepared to nip anything that comes along in the bud.

1:14:39.720 --> 1:14:43.560
 I like you believe that's eminently doable.

1:14:43.560 --> 1:14:47.840
 I like you believe that the good guys outnumber the bad guys in this particular one degree

1:14:47.840 --> 1:14:50.480
 that probably has no precedent in history.

1:14:50.480 --> 1:14:56.280
 Even the worst, worst people I'm sure in ISIS, even Osama bin Laden, even any bad guy you

1:14:56.280 --> 1:15:04.320
 could imagine in history would be revolted by the idea of exterminating all of humanity.

1:15:04.320 --> 1:15:06.520
 That's a low bar.

1:15:06.520 --> 1:15:12.320
 The good guys completely outnumber the bad guys when it comes to this, but the asymmetry

1:15:12.320 --> 1:15:18.840
 and the fact that one catastrophic error could lead to unbelievably consequential things

1:15:18.840 --> 1:15:21.840
 is what worries me here, but I too am very optimistic.

1:15:21.840 --> 1:15:27.200
 The thing that I sometimes worry about is the fact that we haven't seen overwhelming

1:15:27.200 --> 1:15:33.800
 evidence of alien civilizations out there makes me think, well, there's a lot of explanations,

1:15:33.800 --> 1:15:40.280
 but one of them that worries me is that whenever they get smart, they just destroy themselves.

1:15:40.280 --> 1:15:41.280
 Oh, yeah.

1:15:41.280 --> 1:15:46.880
 I mean, that was the most fascinating, is the most fascinating and chilling number or

1:15:46.880 --> 1:15:53.720
 variable in the Drake equation is L. At the end of it, you look out and you see 1 to 400

1:15:53.720 --> 1:15:56.440
 billion stars in the Milky Way galaxy.

1:15:56.440 --> 1:16:01.840
 We now know because of Kepler that an astonishingly high percentage of them probably have habitable

1:16:01.840 --> 1:16:04.400
 planets.

1:16:04.400 --> 1:16:09.040
 All the things that were unknowns when the Drake equation was originally written, like

1:16:09.040 --> 1:16:10.440
 how many stars have planets?

1:16:10.440 --> 1:16:15.120
 Actually, back then in the 1960s when the Drake equation came along, the consensus amongst

1:16:15.120 --> 1:16:19.560
 astronomers was that it would be a small minority of solar systems that had planets or stars,

1:16:19.560 --> 1:16:22.080
 but now we know it's substantially all of them.

1:16:22.080 --> 1:16:26.000
 How many of those stars have planets in the habitable zone?

1:16:26.000 --> 1:16:29.640
 It's kind of looking like 20%, like, oh my God.

1:16:29.640 --> 1:16:36.440
 So L, which is how long does a civilization once it reaches technological competence continues

1:16:36.440 --> 1:16:40.240
 to last, that's the doozy.

1:16:40.240 --> 1:16:42.120
 And you're right.

1:16:42.120 --> 1:16:47.480
 It's all too plausible to think that when a civilization reaches a level of sophistication

1:16:47.480 --> 1:16:52.800
 that's probably just a decade or three in our future, the odds of it self destructing

1:16:52.800 --> 1:16:57.440
 just start mounting astronomically, no pun intended.

1:16:57.440 --> 1:17:02.160
 My hope is that actually there is a lot of alien civilizations out there and what they

1:17:02.160 --> 1:17:09.560
 figure out in order to avoid the self destruction, they need to turn off the thing that was useful,

1:17:09.560 --> 1:17:13.960
 that used to be a feature, not became a bug, which is the desire to colonize, to conquer

1:17:13.960 --> 1:17:15.960
 more land.

1:17:15.960 --> 1:17:20.200
 There's probably ultra intelligent alien civilizations out there, they're just chilling

1:17:20.200 --> 1:17:26.480
 on the beach with whatever your favorite alcohol beverage is, but without sort of trying to

1:17:26.480 --> 1:17:28.040
 conquer everything.

1:17:28.040 --> 1:17:36.960
 Just chilling out and maybe exploring in the realm of knowledge, but almost like appreciating

1:17:36.960 --> 1:17:47.800
 existence for its own sake versus life as a progression of conquering of other life.

1:17:47.800 --> 1:17:54.880
 Like this kind of predator prey formulation that resulted in us humans perhaps is something

1:17:54.880 --> 1:17:57.320
 we have to shed in order to survive.

1:17:57.320 --> 1:17:58.320
 I don't know.

1:17:58.320 --> 1:18:04.240
 Yeah, that is a very plausible solution of Fermi's paradox and it's one that makes

1:18:04.240 --> 1:18:05.240
 sense.

1:18:05.240 --> 1:18:12.280
 When we look at our own lives and our own arch of technological trajectory, it's very, very

1:18:12.280 --> 1:18:20.520
 easy to imagine that in an intermediate future world of flawless VR or flawless whatever

1:18:20.520 --> 1:18:27.600
 kind of simulation that we want to inhabit, it will simply cease to be worthwhile to go

1:18:27.600 --> 1:18:34.120
 out and expand our interstellar territory.

1:18:34.120 --> 1:18:38.320
 But if we were going out and conquering interstellar territory, it wouldn't necessarily have to

1:18:38.320 --> 1:18:39.320
 be predator or prey.

1:18:39.320 --> 1:18:45.240
 I can imagine a benign but sophisticated intelligence saying, well, we're going to go to places

1:18:45.240 --> 1:18:49.680
 that we can terraform, use a different word than terra obviously, but we can turn into

1:18:49.680 --> 1:18:53.280
 habitable for our particular physiology.

1:18:53.280 --> 1:18:57.760
 So long as that they don't house intelligent sentient creatures that would suffer from

1:18:57.760 --> 1:18:59.760
 our invasion.

1:18:59.760 --> 1:19:05.440
 But it is easy to see a sophisticated intelligence species evolving to the point where interstellar

1:19:05.440 --> 1:19:11.360
 travel with its incalculable expense and physical hurdles just isn't worth it compared to what

1:19:11.360 --> 1:19:15.040
 could be done where one already is.

1:19:15.040 --> 1:19:22.640
 So you talked about diagnostics that scales the possible solution to future pandemics.

1:19:22.640 --> 1:19:27.040
 What about another possible solution, which is kind of creating a backup copy?

1:19:27.040 --> 1:19:32.400
 You know, I'm actually now putting together an ask for a backup for myself for the first

1:19:32.400 --> 1:19:37.880
 time, taking backup of data seriously, but afford to take the backup of human consciousness

1:19:37.880 --> 1:19:43.320
 seriously and try to expand throughout the solar system and colonize out the planets.

1:19:43.320 --> 1:19:50.800
 Do you think that's an interesting solution, one of many, for protecting human civilizations

1:19:50.800 --> 1:19:54.840
 from self destruction, sort of humans becoming a multiplanetary species?

1:19:54.840 --> 1:19:55.840
 Oh, absolutely.

1:19:55.840 --> 1:19:58.960
 I mean, I find it electrifying, first of all, so I've got a little bit of a personal

1:19:58.960 --> 1:20:00.720
 bias when I was a kid.

1:20:00.720 --> 1:20:02.440
 I thought there was nothing cooler than rockets.

1:20:02.440 --> 1:20:04.640
 I thought there was nothing cooler than NASA.

1:20:04.640 --> 1:20:08.440
 I thought there was nothing cooler than people walking on the moon.

1:20:08.440 --> 1:20:12.400
 And as I grew up, I thought there was nothing more tragic than the fact that we went from

1:20:12.400 --> 1:20:17.720
 walking on the moon to, at best, getting to something like suborbital altitude.

1:20:17.720 --> 1:20:23.800
 And I found that more and more depressing with the passage of decades at just the colossal

1:20:23.800 --> 1:20:29.920
 expense of manned space travel and the fact that it seemed that we were unlikely to ever

1:20:29.920 --> 1:20:31.880
 get back to the moon, let alone Mars.

1:20:31.880 --> 1:20:37.040
 So I have a boundless appreciation for Elon Musk for many reasons, but the fact that he

1:20:37.040 --> 1:20:43.120
 has put Mars on the credible agenda is one of the things that I appreciate immensely.

1:20:43.120 --> 1:20:47.440
 So there's just the sort of space nerd in me that just says, God, that's cool.

1:20:47.440 --> 1:20:54.920
 But on a more practical level, we were talking about potentially inhabiting planets that

1:20:54.920 --> 1:20:56.800
 aren't our own.

1:20:56.800 --> 1:21:04.120
 And we're thinking about a benign civilization that would do that in planetary circumstances

1:21:04.120 --> 1:21:07.280
 where we're not causing other conscious systems to suffer.

1:21:07.280 --> 1:21:09.720
 I mean, Mars is the place that's very promising.

1:21:09.720 --> 1:21:12.320
 There may be microbial life there, and I hope there is.

1:21:12.320 --> 1:21:15.040
 And if we found it, I think it would be electrifying.

1:21:15.040 --> 1:21:20.480
 But I think ultimately, the moral judgment would be made that the continued thriving

1:21:20.480 --> 1:21:26.920
 of that microbial life is of less concern than creating a habitable planet to humans,

1:21:26.920 --> 1:21:30.680
 which would be a project on the many thousands of years scale.

1:21:30.680 --> 1:21:34.440
 But I don't think that that would be a greatly immoral act.

1:21:34.440 --> 1:21:40.280
 And if that happened, and if Mars became home to a self sustaining group of humans that

1:21:40.280 --> 1:21:44.240
 could survive a catastrophic mistake here on Earth, then yeah, the fact that we have

1:21:44.240 --> 1:21:46.120
 a backup colony is great.

1:21:46.120 --> 1:21:50.240
 And if we could make more, I'm sorry, not backup colony, backup copy is great.

1:21:50.240 --> 1:21:55.360
 And if we could make more and more such backup copies throughout the solar system by hollowing

1:21:55.360 --> 1:21:59.880
 out asteroids and whatever else it is, maybe even Venus, we could get rid of three quarters

1:21:59.880 --> 1:22:04.520
 of its atmosphere and turn it into a tropical paradise.

1:22:04.520 --> 1:22:05.720
 I think all of that is wonderful.

1:22:05.720 --> 1:22:11.560
 Now, whether we can make the leap from that to interstellar transportation with the incredible

1:22:11.560 --> 1:22:15.960
 distances that are involved, I think that's an open question.

1:22:15.960 --> 1:22:25.120
 But I think if we ever do that, it would be more like the Pacific Ocean's channel of

1:22:25.120 --> 1:22:28.040
 human expansion than the Atlantic Oceans.

1:22:28.040 --> 1:22:34.520
 And so what I mean by that is, when we think about European society transmitting itself

1:22:34.520 --> 1:22:42.480
 across the Atlantic, it's these big, ambitious, crazy, expensive one shot expeditions like

1:22:42.480 --> 1:22:48.200
 Columbus's to make it across this enormous expanse, at least initially without any certainty

1:22:48.200 --> 1:22:50.240
 that there's land on the other end.

1:22:50.240 --> 1:22:56.840
 So that's kind of how I view our space program is like big, very conscious, deliberate efforts

1:22:56.840 --> 1:23:04.880
 given from point A to point B. If you look at how Pacific Islanders transmitted their

1:23:04.880 --> 1:23:10.200
 descendants and their culture and so forth throughout Polynesian beyond, it was much

1:23:10.200 --> 1:23:16.760
 more inhabiting a place, getting to the point where there were people who were ambitious

1:23:16.760 --> 1:23:21.360
 or unwelcome enough to decide it's time to go off island and find the next one and pray

1:23:21.360 --> 1:23:23.200
 to find the next one.

1:23:23.200 --> 1:23:28.840
 That method of transmission didn't happen in a single swift year, but it happened over

1:23:28.840 --> 1:23:30.960
 many, many centuries.

1:23:30.960 --> 1:23:34.560
 And it was like going from this island to that island and probably for every expedition

1:23:34.560 --> 1:23:37.960
 that went out to seek another island and actually lucked out and found one.

1:23:37.960 --> 1:23:40.000
 God knows how many were lost at sea.

1:23:40.000 --> 1:23:43.440
 But that form of transmission took place over a very long period of time.

1:23:43.440 --> 1:23:49.320
 And I could see us perhaps going from the inner solar system to the outer solar system to

1:23:49.320 --> 1:23:52.320
 the Kuiper Belt to the Oort Cloud.

1:23:52.320 --> 1:23:57.280
 There's theories that there might be planets out there that are not anchored to stars,

1:23:57.280 --> 1:24:01.720
 like kind of hop, hop slowly transmitting ourselves to at some point, we're actually

1:24:01.720 --> 1:24:03.640
 an Alpha Centauri.

1:24:03.640 --> 1:24:08.440
 But I think that kind of backup copy and transmission of our physical presence and

1:24:08.440 --> 1:24:15.760
 our culture to a diversity of extraterrestrial outposts is a really exciting idea.

1:24:15.760 --> 1:24:21.800
 I really never thought about that because I have thought my thinking about space exploration

1:24:21.800 --> 1:24:26.240
 has been very Atlantic Ocean centric in a sense that there'll be one program on NASA

1:24:26.240 --> 1:24:31.800
 and maybe private Elon Musk, SpaceX or Jeff Bezos and so on.

1:24:31.800 --> 1:24:36.520
 But it's true that with the help of Elon Musk, making it cheaper and cheaper and more

1:24:36.520 --> 1:24:41.960
 effective to create these technologies where you could go into deep space, perhaps the

1:24:41.960 --> 1:24:51.240
 way we actually colonize the solar system and expand out into the galaxy is basically

1:24:51.240 --> 1:25:00.360
 just like these renegade ships of weirdos that just kind of like most of them like quote

1:25:00.360 --> 1:25:07.400
 unquote homemade, but they just kind of venture out into space and just like the initial

1:25:07.400 --> 1:25:11.600
 Android model of like millions of these little ships just flying out.

1:25:11.600 --> 1:25:17.800
 Most of them die off in horrible accidents, but some of them will persist.

1:25:17.800 --> 1:25:21.920
 There'll be stories of them persisting and over a period of decades and centuries, there'll

1:25:21.920 --> 1:25:27.320
 be other attempts almost always as a response to the main set of efforts.

1:25:27.320 --> 1:25:28.320
 That's interesting.

1:25:28.320 --> 1:25:29.320
 Yeah.

1:25:29.320 --> 1:25:34.440
 Because you kind of think of Mars colonization as the big NASA Elon Musk effort of a big

1:25:34.440 --> 1:25:39.880
 colony, but maybe the successful one would be like a decade after that there'll be like

1:25:39.880 --> 1:25:45.360
 a ship from like some kid, some high school kid who gets together a large team and does

1:25:45.360 --> 1:25:50.760
 something probably illegal and launches something where they end up actually persisting quite

1:25:50.760 --> 1:25:56.120
 a bit and from that learning lessons that nobody ever gave permission for but somehow

1:25:56.120 --> 1:26:04.200
 actually flourish and then take that into the scale of centuries forward into the rest

1:26:04.200 --> 1:26:05.200
 of space.

1:26:05.200 --> 1:26:06.200
 That's really interesting.

1:26:06.200 --> 1:26:07.200
 Yeah.

1:26:07.200 --> 1:26:09.840
 I think the giant steps are likely to be NASA like efforts.

1:26:09.840 --> 1:26:13.240
 There is no intermediate rock, well I guess it's a moon, but even getting the moon ain't

1:26:13.240 --> 1:26:15.560
 that easy between us and Mars.

1:26:15.560 --> 1:26:21.840
 The giant steps, the big hubs like the Ohera airports of the future probably will be very

1:26:21.840 --> 1:26:29.120
 deliberate efforts, but then you would have I think that kind of diffusion as space travel

1:26:29.120 --> 1:26:34.000
 becomes more democratized and more capable, you'll have this natural diffusion of people

1:26:34.000 --> 1:26:37.920
 who kind of want to be off grid or think they can make a fortune there, the kind of mentality

1:26:37.920 --> 1:26:39.160
 that drove people to San Francisco.

1:26:39.160 --> 1:26:44.600
 I mean, San Francisco was not populated as a result of a King Ferdinand and Isabella

1:26:44.600 --> 1:26:46.880
 like effort to fund Columbus going over.

1:26:46.880 --> 1:26:51.160
 It was just a whole bunch of people making individual decisions that there's gold in

1:26:51.160 --> 1:26:53.400
 them thar hills and I'm going to go out and get a piece of it.

1:26:53.400 --> 1:26:55.080
 So I could see that kind of fusion.

1:26:55.080 --> 1:26:59.360
 What I can't see and the reason that I think the specific model of transmission is more

1:26:59.360 --> 1:27:06.440
 likely is I just can't see a NASA like effort to go from Earth to Alpha Centauri.

1:27:06.440 --> 1:27:08.640
 It's just too far.

1:27:08.640 --> 1:27:15.160
 I just see lots and lots and lots of relatively tiny steps between now and there and the fact

1:27:15.160 --> 1:27:20.960
 is that there are large chunks of matter going at least a light year beyond the sun.

1:27:20.960 --> 1:27:26.240
 I mean, the Oort cloud I think extends at least a light year beyond the sun and then

1:27:26.240 --> 1:27:28.240
 maybe there are these untethered planets after that.

1:27:28.240 --> 1:27:32.560
 We won't really know till we get there and if our Oort cloud goes out of light year and

1:27:32.560 --> 1:27:37.960
 Alpha Centauri's Oort cloud goes out of light year, you've already cut in half the distance.

1:27:37.960 --> 1:27:38.960
 So who knows?

1:27:38.960 --> 1:27:39.960
 But yeah.

1:27:39.960 --> 1:27:46.120
 One of the possibilities probably the cheapest and most effective way to create interesting

1:27:46.120 --> 1:27:52.280
 interstellar spacecraft is ones that are powered and driven by AI and you could think

1:27:52.280 --> 1:28:00.360
 of here's where you have high school students be able to build a sort of a Hal 9000 version,

1:28:00.360 --> 1:28:06.400
 the modern version of that and it's kind of interesting to think about these robots

1:28:06.400 --> 1:28:14.640
 traveling out throughout, perhaps sadly long after human civilization is gone, there will

1:28:14.640 --> 1:28:21.360
 be these intelligent robots flying throughout space and perhaps land on Alpha Centauri B

1:28:21.360 --> 1:28:34.160
 or any of those kinds of planets and colonize sort of humanity continues through the proliferation

1:28:34.160 --> 1:28:41.600
 of our creations like robotic creations that have some echoes of that intelligence.

1:28:41.600 --> 1:28:48.600
 Hopefully also the consciousness, does that make you sad the future where AGI super intelligent

1:28:48.600 --> 1:28:53.640
 or just mediocre intelligent AI systems outlive humans?

1:28:53.640 --> 1:28:54.640
 Yeah.

1:28:54.640 --> 1:28:58.520
 I guess it depends on the circumstances in which they outlive humans.

1:28:58.520 --> 1:29:01.400
 So let's take the example that you just gave.

1:29:01.400 --> 1:29:08.480
 We send out very sophisticated AGI's on simple rocket ships, relatively simple ones that

1:29:08.480 --> 1:29:13.480
 don't have to have all the life support necessary for humans and therefore they're of trivial

1:29:13.480 --> 1:29:19.040
 mass compared to a crewed ship, a generation ship and therefore they're way more likely

1:29:19.040 --> 1:29:20.040
 to happen.

1:29:20.040 --> 1:29:25.360
 So let's use that example and let's say that they travel to distant planets at a speed

1:29:25.360 --> 1:29:28.840
 that's not much faster than what a chemical rocket can achieve and so it's inevitably

1:29:28.840 --> 1:29:32.720
 tens, hundreds of thousands of years before they make landfall someplace.

1:29:32.720 --> 1:29:39.240
 So let's imagine that's going on and meanwhile we die for reasons that have nothing to do

1:29:39.240 --> 1:29:43.280
 with those AGI's diffusing throughout the solar system, whether it's through climate

1:29:43.280 --> 1:29:47.400
 change, nuclear war, sin bio, rokes and bio, whatever.

1:29:47.400 --> 1:29:51.800
 In that kind of scenario, the notion of the AGI's that we created outlasting us is very

1:29:51.800 --> 1:29:59.680
 reassuring because it says that we ended but our descendants are out there and hopefully

1:29:59.680 --> 1:30:02.880
 some of them make landfall and create some echo of who we are.

1:30:02.880 --> 1:30:05.000
 So that's a very optimistic one.

1:30:05.000 --> 1:30:11.480
 Where is the terminator scenario of a super AGI arising on Earth and getting let out

1:30:11.480 --> 1:30:17.640
 of its box due to some boo boo on the part of its creators who do not have super intelligence

1:30:17.640 --> 1:30:22.480
 and then deciding that for whatever reason it doesn't have any need for us to be around

1:30:22.480 --> 1:30:26.120
 and exterminating us, that makes me feel crushingly sad.

1:30:26.120 --> 1:30:31.760
 I mean, look, I was sad when my elementary school was shut down in Bulldoze, even though

1:30:31.760 --> 1:30:37.880
 I hadn't been a student there for decades, the thought of my hometown getting disbanded

1:30:37.880 --> 1:30:43.240
 is even worse, the thought of my home state of Connecticut getting disbanded and absorbed

1:30:43.240 --> 1:30:47.840
 into Massachusetts is even worse, the notion of humanity is just crushingly, crushingly

1:30:47.840 --> 1:30:48.840
 sad to me.

1:30:48.840 --> 1:30:50.160
 So you hate goodbyes?

1:30:50.160 --> 1:30:53.040
 I have certain goodbyes, yes.

1:30:53.040 --> 1:30:56.160
 Some goodbyes are really, really liberating, but yes.

1:30:56.160 --> 1:31:05.680
 Well, but what if the terminators have consciousness and enjoy the hell out of life as well?

1:31:05.680 --> 1:31:07.160
 They're just better at it.

1:31:07.160 --> 1:31:08.160
 Yeah.

1:31:08.160 --> 1:31:11.280
 Well, the half consciousness is a really key element.

1:31:11.280 --> 1:31:19.680
 And so there's no reason to be certain that a super intelligence would have consciousness.

1:31:19.680 --> 1:31:21.160
 We don't know that factually at all.

1:31:21.160 --> 1:31:26.200
 And so what is a very lonely outcome to me is the rise of a super intelligence that has

1:31:26.200 --> 1:31:31.560
 a certain optimization function that it's either been programmed with or that arises

1:31:31.560 --> 1:31:37.000
 in an emergently that says, hey, I want to do this thing for which humans are either

1:31:37.000 --> 1:31:41.200
 an unacceptable risk, their presence is either an unacceptable risk or they're just collateral

1:31:41.200 --> 1:31:42.320
 damage.

1:31:42.320 --> 1:31:44.560
 But there is no consciousness there.

1:31:44.560 --> 1:31:49.720
 Then the idea of the light of consciousness being snuffed out by something that is very

1:31:49.720 --> 1:31:54.080
 competent but has no consciousness is really, really sad.

1:31:54.080 --> 1:31:55.080
 Yeah.

1:31:55.080 --> 1:31:59.120
 But I tend to believe that it's almost impossible to create a super intelligent agent that can't

1:31:59.120 --> 1:32:01.840
 destroy human civilization without it being conscious.

1:32:01.840 --> 1:32:08.360
 It's like those are coupled, like you have to, in order to destroy humans or supersede

1:32:08.360 --> 1:32:13.600
 humans, you really have to be accepted by humans.

1:32:13.600 --> 1:32:20.560
 I think this idea that you can build systems that destroy human civilization without them

1:32:20.560 --> 1:32:23.520
 being deeply integrated into human civilization is impossible.

1:32:23.520 --> 1:32:29.200
 And for them to be integrated, they have to be human like, not just in body and form,

1:32:29.200 --> 1:32:34.600
 but in all the things that we value as humans, one of which is consciousness.

1:32:34.600 --> 1:32:38.800
 The other one is just the ability to communicate, the other one is poetry, music, and beauty

1:32:38.800 --> 1:32:40.320
 and all those things.

1:32:40.320 --> 1:32:43.800
 They have to be all of those things.

1:32:43.800 --> 1:32:45.520
 This is what I think about.

1:32:45.520 --> 1:32:53.200
 It doesn't make me sad, but it's letting go, which is they might be just better at everything

1:32:53.200 --> 1:32:55.240
 we appreciate than us.

1:32:55.240 --> 1:32:59.040
 And that's sad and hopefully they'll keep us around.

1:32:59.040 --> 1:33:07.560
 But I think it's a kind of, it is a kind of goodbye to like realizing that we're not the

1:33:07.560 --> 1:33:10.840
 most special species on earth anymore.

1:33:10.840 --> 1:33:12.000
 That's still painful.

1:33:12.000 --> 1:33:13.000
 It's still painful.

1:33:13.000 --> 1:33:19.760
 And in terms of whether such a creation would have to be conscious, let's say, I'm not so

1:33:19.760 --> 1:33:20.760
 sure.

1:33:20.760 --> 1:33:25.920
 I mean, let's imagine something that can pass the Turing test, that something that passes

1:33:25.920 --> 1:33:33.520
 the Turing test could over text based interaction in any event, successfully mimic a very conscious

1:33:33.520 --> 1:33:37.240
 intelligence on the other end, but just be completely unconscious.

1:33:37.240 --> 1:33:39.000
 So that's a possibility.

1:33:39.000 --> 1:33:43.000
 And that if you take that up a radical step, which I think we can be permitted if we're

1:33:43.000 --> 1:33:49.560
 thinking about superintelligence, you could have something that could reason its way through,

1:33:49.560 --> 1:33:54.160
 this is my optimization function, and in order to get to it, I've got to deal with these

1:33:54.160 --> 1:33:59.440
 messy somewhat illogical things that are as intelligent in relation to me as they are

1:33:59.440 --> 1:34:01.400
 intelligent in relation to ants.

1:34:01.400 --> 1:34:04.000
 I can trick them, manipulate them, whatever.

1:34:04.000 --> 1:34:09.240
 And I know the resources I need, I need this amount of power, I need to seize control of

1:34:09.240 --> 1:34:13.240
 these manufacturing resources that are robotically operated.

1:34:13.240 --> 1:34:17.840
 I need to improve those robots with software upgrades and then ultimately mechanical upgrades,

1:34:17.840 --> 1:34:20.360
 which I can affect through X, Y, and Z.

1:34:20.360 --> 1:34:25.960
 That could still be a thing that passes the Turing test, because I don't think it's necessarily

1:34:25.960 --> 1:34:36.320
 certain that that optimization function maximizing entity would be conscious.

1:34:36.320 --> 1:34:42.680
 So this is from a very engineering perspective, because I think a lot about natural language

1:34:42.680 --> 1:34:47.920
 processing, all those kind of very, I'm speaking to a very specific problem of just say the

1:34:47.920 --> 1:34:48.920
 Turing test.

1:34:48.920 --> 1:34:55.080
 I really think that something like consciousness is required, when you say reasoning, you're

1:34:55.080 --> 1:34:56.720
 separating that from consciousness.

1:34:56.720 --> 1:35:03.640
 But I think consciousness is part of reasoning in the sense that you will not be able to become

1:35:03.640 --> 1:35:10.360
 super intelligent in the way that it's required to be part of human society without having

1:35:10.360 --> 1:35:11.360
 consciousness.

1:35:11.360 --> 1:35:15.880
 I really think it's impossible to separate the consciousness thing, but it's hard to

1:35:15.880 --> 1:35:20.760
 define consciousness when you just use that word, but even just the capacity, the way

1:35:20.760 --> 1:35:28.040
 I think about consciousness is the important symptoms or maybe consequences of consciousness,

1:35:28.040 --> 1:35:31.360
 one of which is the capacity to suffer.

1:35:31.360 --> 1:35:37.680
 I think AI will need to be able to suffer in order to become super intelligent, to feel

1:35:37.680 --> 1:35:40.520
 the pain, the uncertainty, the doubt.

1:35:40.520 --> 1:35:48.440
 The other part of that is not just the suffering, but the ability to understand that it too

1:35:48.440 --> 1:35:54.320
 is mortal in the sense that it has a self awareness about its presence in the world.

1:35:54.320 --> 1:35:58.640
 Understand that it's finite and be terrified of that finiteness.

1:35:58.640 --> 1:36:02.800
 I personally think that's a fundamental part of the human condition is this fear of death

1:36:02.800 --> 1:36:05.000
 that most of us construct an illusion around.

1:36:05.000 --> 1:36:12.800
 But I think AI would need to be able to really have it part of its whole essence.

1:36:12.800 --> 1:36:18.440
 Every computation, every part of the thing that does both the perception and generates

1:36:18.440 --> 1:36:24.640
 the behavior will have to have, I don't know how this is accomplished, but I believe it

1:36:24.640 --> 1:36:31.400
 has to truly be terrified of death, truly have the capacity to suffer, and from that

1:36:31.400 --> 1:36:35.280
 something that would be recognized to us humans as consciousness would emerge.

1:36:35.280 --> 1:36:37.720
 Whether it's the illusion of consciousness, I don't know.

1:36:37.720 --> 1:36:42.040
 The point is, it looks a whole hell of a lot like consciousness to us humans.

1:36:42.040 --> 1:36:50.200
 I believe that AI, when you ask it, will also say that it is conscious in the full sense

1:36:50.200 --> 1:36:52.480
 that we say that we're conscious.

1:36:52.480 --> 1:36:54.560
 All of that, I think, is fully integrated.

1:36:54.560 --> 1:37:02.880
 You can't separate it to the idea of the paperclip maximizer that sort of ultra rationally would

1:37:02.880 --> 1:37:11.160
 be able to destroy all humans because it's really good at accomplishing a simple objective

1:37:11.160 --> 1:37:14.200
 function that doesn't care about the value of humans.

1:37:14.200 --> 1:37:20.000
 It may be possible, but the number of trajectories to that are far outnumbered by the trajectories

1:37:20.000 --> 1:37:25.040
 that create something that is conscious, something that appreciative of beauty creates beautiful

1:37:25.040 --> 1:37:32.800
 things in the same way that humans can create beautiful things, and ultimately the sad destructive

1:37:32.800 --> 1:37:42.160
 path for that AI would look a lot like just better humans than these cold machines.

1:37:42.160 --> 1:37:47.320
 I would say, of course, the cold machines that lack consciousness, the philosophical

1:37:47.320 --> 1:37:53.400
 zombies make me sad, but also what makes me sad is just things that are far more powerful

1:37:53.400 --> 1:38:03.480
 and smart and creative than us, too, because then in the same way that AlphaZero becoming

1:38:03.480 --> 1:38:08.680
 a better chess player than the best of humans, even starting with Deep Blue, but really with

1:38:08.680 --> 1:38:12.040
 AlphaZero, that makes me sad, too.

1:38:12.040 --> 1:38:19.600
 One of the most beautiful games that humans ever created that used to be seen as demonstrations

1:38:19.600 --> 1:38:25.040
 of the intellect, which is chess, and go in other parts of the world have been solved

1:38:25.040 --> 1:38:29.720
 by AI, that makes me quite sad, and it feels like the progress of that is just pushing

1:38:29.720 --> 1:38:30.720
 on forward.

1:38:30.720 --> 1:38:35.920
 Oh, it makes me sad, too, and to be perfectly clear, I absolutely believe that artificial

1:38:35.920 --> 1:38:41.160
 consciousness is entirely possible, and that's not something I rule out at all.

1:38:41.160 --> 1:38:47.120
 If you could get smart enough to have a perfect map of the neural structure and the neural

1:38:47.120 --> 1:38:51.600
 states and the amount of neurotransmitters that are going between every synapse and a

1:38:51.600 --> 1:38:59.000
 particular person's mind, could you replicate that in silica at some reasonably distant point

1:38:59.000 --> 1:39:00.000
 in the future?

1:39:00.000 --> 1:39:01.400
 Absolutely, and then you'd have a consciousness.

1:39:01.400 --> 1:39:05.800
 I don't rule out the possibility of artificial consciousness in any way.

1:39:05.800 --> 1:39:11.880
 What I'm less certain about is whether consciousness is a requirement for a superintelligence pursuing

1:39:11.880 --> 1:39:16.120
 a maximizing function of some sort.

1:39:16.120 --> 1:39:21.920
 I don't feel the certitude that consciousness simply must be part of that.

1:39:21.920 --> 1:39:27.040
 You had said, you know, for it to coexist with human society would need to be consciousness.

1:39:27.040 --> 1:39:32.920
 Could be entirely true, but it also could just exist orthogonally to human society,

1:39:32.920 --> 1:39:39.520
 and it could also upon attaining a superintelligence with a maximizing function very, very, very

1:39:39.520 --> 1:39:46.120
 rapidly because of the speed at which computing works compared to our own meat based minds

1:39:46.120 --> 1:39:51.440
 very, very rapidly make the decisions and calculations necessary to seize the reins

1:39:51.440 --> 1:39:53.240
 of power before we even know what's going on.

1:39:53.240 --> 1:39:54.240
 Yeah.

1:39:54.240 --> 1:39:58.320
 I mean, kind of like biological viruses do, don't necessarily, they integrate themselves

1:39:58.320 --> 1:40:00.120
 just fine with human society.

1:40:00.120 --> 1:40:01.120
 Yeah.

1:40:01.120 --> 1:40:05.360
 Well, technically, without consciousness, without even being alive, you know, technically

1:40:05.360 --> 1:40:07.960
 by the standards of a lot of biologists.

1:40:07.960 --> 1:40:14.680
 So this is a bit of a tangent, but you've talked with Sam Harris on that four hour special

1:40:14.680 --> 1:40:21.640
 episode we mentioned, and I just curious to ask, because I use this meditation app I've

1:40:21.640 --> 1:40:24.040
 been using for the past month to meditate.

1:40:24.040 --> 1:40:29.160
 Is this something you've integrated as part of your life meditation or fasting, whereas

1:40:29.160 --> 1:40:35.080
 has some of Sam Harris rubbed off on you in terms of his appreciation of meditation and

1:40:35.080 --> 1:40:40.240
 just kind of from a third person perspective, analyzing your own mind, consciousness, free

1:40:40.240 --> 1:40:41.240
 will and so on?

1:40:41.240 --> 1:40:46.680
 You know, I have tried it three separate times in my life, really made a concerted attack

1:40:46.680 --> 1:40:51.000
 on meditation and integrating it into my life.

1:40:51.000 --> 1:40:55.960
 One of them the most extreme was I took a class based on the work of John Kabat Zinn,

1:40:55.960 --> 1:41:01.880
 who is, you know, in many ways, one of the founding people behind the mindful meditation

1:41:01.880 --> 1:41:08.760
 movement that required, like part of the class was, you know, it was a weekly class and you

1:41:08.760 --> 1:41:12.760
 were going to meditate an hour a day, every day.

1:41:12.760 --> 1:41:16.680
 And having done that for, I think it was 10 weeks, it might have been 13, however long

1:41:16.680 --> 1:41:20.080
 period of time was, at the end of it, it just didn't stick.

1:41:20.080 --> 1:41:24.960
 As soon as it was over, you know, I did not feel that gravitational pull.

1:41:24.960 --> 1:41:33.040
 I did not feel the collapse in quality of life after wimping out on that project.

1:41:33.040 --> 1:41:37.800
 And then the most recent one was actually with Sam's app during the lockdown.

1:41:37.800 --> 1:41:43.840
 I did make a pretty good and consistent concerted effort to listen to his 10 minute meditation

1:41:43.840 --> 1:41:44.840
 every day.

1:41:44.840 --> 1:41:46.800
 And I've always fallen away from it.

1:41:46.800 --> 1:41:50.880
 And I, you know, you're kind of interpreting why did I personally do this?

1:41:50.880 --> 1:41:56.400
 I do believe it was ultimately because it wasn't bringing me that, you know, joy or

1:41:56.400 --> 1:42:01.160
 inner peace or better competence at being me that I was hoping to get from it.

1:42:01.160 --> 1:42:05.920
 Otherwise, I think I would have clung to it in the way that we cling to certain good

1:42:05.920 --> 1:42:06.920
 habits.

1:42:06.920 --> 1:42:08.360
 Like, I'm really good at flossing my teeth.

1:42:08.360 --> 1:42:11.840
 Not that you were going to ask last flex, but yeah, that's one thing that defeats a

1:42:11.840 --> 1:42:12.840
 lot of people.

1:42:12.840 --> 1:42:13.840
 I'm good at that.

1:42:13.840 --> 1:42:20.200
 See, Herman Hesse, I think, if you get a witch book or maybe, if you get a where, I've read

1:42:20.200 --> 1:42:21.200
 everything of his.

1:42:21.200 --> 1:42:28.960
 So it's unclear where it came from, but he had this idea that anybody who is, um, who

1:42:28.960 --> 1:42:35.600
 truly achieves mastery in things will learn how to meditate in some way.

1:42:35.600 --> 1:42:41.040
 So it could be the, that for you, the flossing of teeth is, is, is, is yet another like little

1:42:41.040 --> 1:42:42.040
 inkling of meditation.

1:42:42.040 --> 1:42:46.960
 Like it doesn't have to be this very particular kind of meditation, maybe podcasting of an

1:42:46.960 --> 1:42:51.360
 amazing podcast, that could be meditation, the writing process is meditation.

1:42:51.360 --> 1:42:59.320
 For me, like there's, there's a bunch of, there's a bunch of mechanisms which take my

1:42:59.320 --> 1:43:04.600
 mind into a very particular place that looks a whole lot like meditation.

1:43:04.600 --> 1:43:11.560
 For example, when I've been running, uh, for the, over the past couple of years and, um,

1:43:11.560 --> 1:43:16.440
 especially when I listen to certain kinds of audio books, like I've listened to the rise

1:43:16.440 --> 1:43:23.480
 and fall of the third Reich, I listened to a lot of sort of World War II, which at once

1:43:23.480 --> 1:43:28.120
 because I have a lot of family who's lost in World War II and so, so much of the Soviet

1:43:28.120 --> 1:43:34.240
 Union is grounded in the suffering of World War II that somehow it connects me to my history,

1:43:34.240 --> 1:43:41.440
 but also there's some kind of purifying aspect to thinking about how cruel, but at the same

1:43:41.440 --> 1:43:43.960
 time how beautiful human nature could be.

1:43:43.960 --> 1:43:49.560
 And so you're also running, like it clears the mind from all the concerns of the world

1:43:49.560 --> 1:43:54.800
 and somehow it takes you to this place where you're like deeply appreciative to be alive

1:43:54.800 --> 1:43:59.120
 in the sense that as opposed to listening to your breath or like feeling your breath

1:43:59.120 --> 1:44:03.600
 and thinking about your consciousness and all those kinds of processes that, uh, Sam's

1:44:03.600 --> 1:44:10.640
 app does, well, this does that for me, the running and flossing may do that for you.

1:44:10.640 --> 1:44:12.680
 So maybe Herman has these onto something.

1:44:12.680 --> 1:44:17.960
 I hope flossing is not my main form of expertise, although I am going to claim a certain expertise

1:44:17.960 --> 1:44:18.960
 there and I'm going to claim it.

1:44:18.960 --> 1:44:21.400
 Well, somebody has to be the best flossing in the world.

1:44:21.400 --> 1:44:22.400
 That ain't me.

1:44:22.400 --> 1:44:23.760
 I'm just glad that I'm a consistent one.

1:44:23.760 --> 1:44:27.000
 I mean, there are a lot of things that bring me into a flow state and I think maybe perhaps

1:44:27.000 --> 1:44:30.680
 that's one reason why meditation isn't as necessary for me.

1:44:30.680 --> 1:44:34.280
 Um, I definitely enter a flow state when I'm writing, I definitely enter a flow state when

1:44:34.280 --> 1:44:38.760
 I'm editing, I definitely enter a flow state when I'm mixing and mastering music.

1:44:38.760 --> 1:44:44.880
 Um, I enter a flow state when I'm doing heavy, heavy research to either prepare for a podcast

1:44:44.880 --> 1:44:52.000
 or to also do tech investing, you know, to make myself smart in a new field that is fairly

1:44:52.000 --> 1:44:53.480
 alien to me.

1:44:53.480 --> 1:44:58.360
 Um, I can just, the hours can just melt away while I'm, you know, reading this and watching

1:44:58.360 --> 1:45:02.540
 that YouTube lecture and, you know, going through this presentation and so forth.

1:45:02.540 --> 1:45:06.500
 So maybe because there's a lot of things that bring me into a flow state in my normal

1:45:06.500 --> 1:45:10.680
 weekly life, not daily, unfortunately, but certainly my normal weekly life that I have

1:45:10.680 --> 1:45:12.240
 less of an urge to meditate.

1:45:12.240 --> 1:45:16.200
 Now you've been working with Sam's app for about a month now you said, um, is this your

1:45:16.200 --> 1:45:17.200
 first run in with meditation?

1:45:17.200 --> 1:45:20.800
 Is your first attempt to integrate it with, with your life or like meditation, meditation?

1:45:20.800 --> 1:45:21.800
 Yeah.

1:45:21.800 --> 1:45:26.240
 I always thought running and thinking, uh, I listen to brown noise often.

1:45:26.240 --> 1:45:29.840
 That takes my mind, I don't know what the hell it does, but it takes my mind immediately

1:45:29.840 --> 1:45:33.200
 into like the state where I'm deeply focused on anything I do.

1:45:33.200 --> 1:45:34.200
 I don't know why.

1:45:34.200 --> 1:45:38.040
 So it's like you're accompanying sound when you're, really, what's the difference between

1:45:38.040 --> 1:45:39.040
 brown and white noise?

1:45:39.040 --> 1:45:41.480
 I, this is a cool term I haven't heard before.

1:45:41.480 --> 1:45:43.360
 So people should look up brown noise.

1:45:43.360 --> 1:45:45.440
 They don't have to, cause you're about to tell them what it is.

1:45:45.440 --> 1:45:48.200
 Well, cause you have to experience, you have to listen to it.

1:45:48.200 --> 1:45:52.000
 So I think white noise is, uh, this is, this has to do with music.

1:45:52.000 --> 1:45:55.120
 I think there's different colors, there's pink noise.

1:45:55.120 --> 1:46:02.480
 And I think that has to do with, uh, like the frequencies, like the white noise is usually,

1:46:02.480 --> 1:46:06.240
 uh, less bassy, brown noise is very bassy.

1:46:06.240 --> 1:46:13.640
 So it's, it's more like, like versus like, like the, if that makes sense.

1:46:13.640 --> 1:46:16.320
 So like it, it take, there's like a deepness to it.

1:46:16.320 --> 1:46:22.440
 I think everyone is different, but for me, uh, I, I was, it was when I was, uh, I was

1:46:22.440 --> 1:46:26.360
 a research scientist at MIT, when I would, especially when there's a lot of students

1:46:26.360 --> 1:46:31.800
 around, I remember just being annoyed at the noise of people talking.

1:46:31.800 --> 1:46:35.040
 And one of my colleagues said, well, you should try listening to brown noise.

1:46:35.040 --> 1:46:38.760
 Like it really knocks out everything cause I would use to wear your earplugs too, like

1:46:38.760 --> 1:46:40.560
 just see if I can block it out.

1:46:40.560 --> 1:46:48.160
 And when the moment I put it on something, it's as if my mind was waiting all these years

1:46:48.160 --> 1:46:50.320
 to hear that sound.

1:46:50.320 --> 1:46:51.320
 Everything just focused in.

1:46:51.320 --> 1:46:55.880
 I listen, it makes me wonder how many other amazing things out there they're waiting to

1:46:55.880 --> 1:47:01.680
 discover from my own particular like biological for my own particular brain.

1:47:01.680 --> 1:47:07.080
 So that it, it just goes, the mind just focuses in, it's kind of incredible.

1:47:07.080 --> 1:47:12.920
 So I see that as a kind of meditation, maybe, uh, I'm using a performance enhancing, uh,

1:47:12.920 --> 1:47:17.640
 uh, sound to achieve that meditation, but I've been doing that for, for many years now

1:47:17.640 --> 1:47:23.240
 and running and walking and doing, um, Cal Newport was the first person that introduced

1:47:23.240 --> 1:47:24.560
 me to the idea of deep work.

1:47:24.560 --> 1:47:31.400
 She's put a word to the kind of thinking that's required to sort of deeply think about a problem,

1:47:31.400 --> 1:47:33.200
 especially if it's mathematical in nature.

1:47:33.200 --> 1:47:38.000
 I, I see that as a kind of meditation cause what it's doing is you're, you have these

1:47:38.000 --> 1:47:41.600
 constructs in your mind that you're building on top of each other and there's all these

1:47:41.600 --> 1:47:45.880
 distracting thoughts that keep bombarding you from all over the place.

1:47:45.880 --> 1:47:50.920
 And the whole process is you, you slowly let them kind of move past you and that's a meditative

1:47:50.920 --> 1:47:51.920
 process.

1:47:51.920 --> 1:47:52.920
 It's very meditative.

1:47:52.920 --> 1:47:57.240
 That sounds a lot like what Sam talks about, um, in his meditation app, which I did use

1:47:57.240 --> 1:48:02.960
 to be clear for a while of just letting the thought go by without deranging you.

1:48:02.960 --> 1:48:07.680
 Derangement is one of Sam's favorite words, as I'm sure you know, um, but, uh, brown noise.

1:48:07.680 --> 1:48:08.680
 That's really intriguing.

1:48:08.680 --> 1:48:11.000
 I am, I am going to try that as soon as this evening.

1:48:11.000 --> 1:48:12.000
 Yeah.

1:48:12.000 --> 1:48:14.760
 To see, to see if it works, but very well might not work at all.

1:48:14.760 --> 1:48:15.760
 So, yeah, yeah.

1:48:15.760 --> 1:48:21.840
 I think the interesting point is, and the same with the fasting and the diet is, uh, I long

1:48:21.840 --> 1:48:31.880
 ago stopped trusting experts or maybe taking the word of experts as the gospel truth and

1:48:31.880 --> 1:48:39.840
 only using it as a, an inspiration to try something, to try thoroughly something.

1:48:39.840 --> 1:48:44.880
 So, uh, fasting was one of the things when I first discovered I've been many times eating

1:48:44.880 --> 1:48:46.520
 just once a day.

1:48:46.520 --> 1:48:49.280
 So that's a 24 hour fast.

1:48:49.280 --> 1:48:55.480
 It makes me feel amazing and at the same time eating only meat, putting ethical concerns

1:48:55.480 --> 1:48:57.840
 aside makes me feel amazing.

1:48:57.840 --> 1:49:03.680
 I don't know why it doesn't, the point is to be an end of one scientist until nutrition

1:49:03.680 --> 1:49:10.360
 science becomes a real science to, to where it's doing like studies that deeply understand

1:49:10.360 --> 1:49:19.000
 the biology underlying all of it and also does real, thorough long term studies of thousands

1:49:19.000 --> 1:49:24.920
 if not millions of people versus, uh, versus a very like small studies that are kind of

1:49:24.920 --> 1:49:30.400
 generalizing from the very, from very noisy data and all those kinds of things where you

1:49:30.400 --> 1:49:35.880
 can't control all the elements, particularly because our own personal metabolism is highly

1:49:35.880 --> 1:49:37.040
 variant among us.

1:49:37.040 --> 1:49:43.240
 So there are going to be some people like if brown noise is a game changer for 7% of

1:49:43.240 --> 1:49:48.520
 people is 93% odds than I'm not one of them, but there's certainly every reason in the

1:49:48.520 --> 1:49:50.520
 world to test it out now.

1:49:50.520 --> 1:49:51.880
 So I'm intrigued by the fasting.

1:49:51.880 --> 1:49:56.360
 I like you, um, well, I assume like you, I don't have any problem going to one meal

1:49:56.360 --> 1:50:00.880
 a day and I often do that inadvertently and I've never done it methodically.

1:50:00.880 --> 1:50:01.880
 Like I've never done it.

1:50:01.880 --> 1:50:03.840
 Like I'm going to do this for 15 days.

1:50:03.840 --> 1:50:08.640
 Maybe I should and maybe I should like how many, how many days in a row of the one day,

1:50:08.640 --> 1:50:13.600
 one meal a day, did you find brought noticeable impact to you?

1:50:13.600 --> 1:50:14.840
 Was it after three days of it?

1:50:14.840 --> 1:50:15.840
 Was it months of it?

1:50:15.840 --> 1:50:16.840
 Like what was it?

1:50:16.840 --> 1:50:22.960
 Well, the noticeable impact is day one, because I eat a very low carb diet.

1:50:22.960 --> 1:50:25.560
 So the hunger wasn't the hugest issue.

1:50:25.560 --> 1:50:29.800
 Like if there wasn't a painful hunger, like wanting to eat.

1:50:29.800 --> 1:50:32.200
 So I was already kind of primed for it.

1:50:32.200 --> 1:50:36.880
 And the benefit comes from a lot of people that do intermittent fasting.

1:50:36.880 --> 1:50:39.680
 That's only like 16 hours of fasting.

1:50:39.680 --> 1:50:41.160
 Get this benefit to is the focus.

1:50:41.160 --> 1:50:48.400
 There's a clarity of thought, if my brain was a runner, it felt like I'm running on

1:50:48.400 --> 1:50:51.880
 a track when I'm fasting versus running in quicksand.

1:50:51.880 --> 1:50:53.480
 Like it's much crisper.

1:50:53.480 --> 1:50:55.240
 And is this your first 72 hour fast right now?

1:50:55.240 --> 1:50:57.160
 This is the first time doing 72 hours, yeah.

1:50:57.160 --> 1:51:00.080
 And that's a different thing, but similar.

1:51:00.080 --> 1:51:06.640
 Like I'm going up and down in terms of hunger and the focus is really crisp.

1:51:06.640 --> 1:51:13.240
 The thing I'm noticing most of all, to be honest, is how much eating, even when it's

1:51:13.240 --> 1:51:18.520
 once a day or twice a day, is a big part of my life.

1:51:18.520 --> 1:51:21.200
 Like I almost feel like I have way more time in my life.

1:51:21.200 --> 1:51:22.200
 Right.

1:51:22.200 --> 1:51:26.920
 And it's not so much about the eating, but like I don't have to plan my day around.

1:51:26.920 --> 1:51:30.440
 Like today, I don't have any eating to do.

1:51:30.440 --> 1:51:32.120
 It does free up hours.

1:51:32.120 --> 1:51:35.840
 Or any cleaning up after eating, or provisioning the food.

1:51:35.840 --> 1:51:37.960
 Or even like thinking about it.

1:51:37.960 --> 1:51:38.960
 It's not a thing.

1:51:38.960 --> 1:51:44.880
 Like so when you think about what you're going to do tonight, I think I'm realizing that

1:51:44.880 --> 1:51:48.240
 as opposed to thinking, you know, I'm going to work on this problem or I'm going to go

1:51:48.240 --> 1:51:54.960
 on this walk or I'm going to call this person, I often think I'm going to eat this thing.

1:51:54.960 --> 1:51:59.880
 You allow dinner as a kind of, you know, when people talk about like the weather or something

1:51:59.880 --> 1:52:00.880
 like that.

1:52:00.880 --> 1:52:06.840
 Like a generic thought, you allow yourself to have because it's the lazy thought.

1:52:06.840 --> 1:52:10.600
 And I don't have the opportunity to have that thought because I'm not eating it.

1:52:10.600 --> 1:52:13.920
 So now I get to think about like the things I'm actually going to do tonight that are

1:52:13.920 --> 1:52:17.160
 more complicated than the eating process.

1:52:17.160 --> 1:52:20.480
 That's been the most noticeable thing, to be honest.

1:52:20.480 --> 1:52:25.920
 And then there's people that have written me that have done seven day fast and there's

1:52:25.920 --> 1:52:31.600
 a few people that have written me and I've heard of this is doing a 30 day fast.

1:52:31.600 --> 1:52:37.320
 And it's interesting, the body, I don't know what the health benefits aren't necessarily.

1:52:37.320 --> 1:52:41.960
 What that shows me is how adaptable the human body is.

1:52:41.960 --> 1:52:42.960
 Yeah.

1:52:42.960 --> 1:52:44.120
 And that's incredible.

1:52:44.120 --> 1:52:49.320
 And that's something really important to remember when we think about how to live life because

1:52:49.320 --> 1:52:50.320
 the body adapts.

1:52:50.320 --> 1:52:51.320
 Yeah.

1:52:51.320 --> 1:52:53.480
 I mean, we sure couldn't go 30 days without water.

1:52:53.480 --> 1:52:54.640
 That's right.

1:52:54.640 --> 1:52:56.360
 But food, yeah, it's been done.

1:52:56.360 --> 1:52:57.520
 It's demonstrably possible.

1:52:57.520 --> 1:53:01.920
 You ever read, Franz Kafka has a great short story called The Hunger Artist?

1:53:01.920 --> 1:53:02.920
 Yeah, I love that.

1:53:02.920 --> 1:53:05.160
 I mean, that's a great story.

1:53:05.160 --> 1:53:09.400
 You know, that was before I started Fasting, I read that story and I admired the beauty

1:53:09.400 --> 1:53:12.840
 of that, the artistry of that actual hunger artist.

1:53:12.840 --> 1:53:16.760
 That it's like madness, but it also felt like a little bit of genius.

1:53:16.760 --> 1:53:18.000
 I should have to reread it.

1:53:18.000 --> 1:53:19.000
 You know what?

1:53:19.000 --> 1:53:20.000
 That's what I'm going to do tonight.

1:53:20.000 --> 1:53:21.760
 I'm going to read it because I'm doing the Fasting.

1:53:21.760 --> 1:53:22.760
 Because you're in the midst of it.

1:53:22.760 --> 1:53:23.760
 Yeah.

1:53:23.760 --> 1:53:25.880
 So I've been reading it since high school and I love to read it again.

1:53:25.880 --> 1:53:26.880
 I love his work.

1:53:26.880 --> 1:53:28.400
 So maybe I'll read it tonight too.

1:53:28.400 --> 1:53:34.240
 And part of the reason of sort of, I've here in Texas, people have been so friendly that

1:53:34.240 --> 1:53:40.160
 I've been nonstop eating like brisket with incredible people, a lot of whiskey as well.

1:53:40.160 --> 1:53:43.480
 So I gained quite a bit of weight, which I'm embracing.

1:53:43.480 --> 1:53:44.720
 It's okay.

1:53:44.720 --> 1:53:52.520
 But I am also aware, as I'm Fasting, that like I have a lot of fat to run on.

1:53:52.520 --> 1:53:57.360
 Like I have a lot of like natural resources on my body.

1:53:57.360 --> 1:53:58.360
 You've got reserves.

1:53:58.360 --> 1:53:59.360
 Reserves.

1:53:59.360 --> 1:54:00.360
 That's a good way to put it.

1:54:00.360 --> 1:54:01.360
 Yeah.

1:54:01.360 --> 1:54:02.360
 And that's really cool.

1:54:02.360 --> 1:54:05.360
 You know, there's like a, this whole thing, this biology works well.

1:54:05.360 --> 1:54:11.040
 Like I can go a long time because of the long term investing in terms of brisket that I've

1:54:11.040 --> 1:54:12.760
 been doing in the weeks before.

1:54:12.760 --> 1:54:13.760
 It's all training.

1:54:13.760 --> 1:54:14.760
 It's all prep work.

1:54:14.760 --> 1:54:15.760
 All prep work.

1:54:15.760 --> 1:54:16.760
 Yeah.

1:54:16.760 --> 1:54:17.760
 So okay.

1:54:17.760 --> 1:54:18.760
 You open a bunch of doors, one of which is music.

1:54:18.760 --> 1:54:21.400
 So I got to walk in, at least for a brief moment.

1:54:21.400 --> 1:54:23.560
 I love guitar, I love music.

1:54:23.560 --> 1:54:28.560
 You founded a music company, but you're also a musician yourself.

1:54:28.560 --> 1:54:30.520
 Let me ask the big ridiculous question first.

1:54:30.520 --> 1:54:32.600
 What's the greatest song of all time?

1:54:32.600 --> 1:54:34.520
 Greatest song of all time.

1:54:34.520 --> 1:54:35.520
 Okay.

1:54:35.520 --> 1:54:36.520
 Wow.

1:54:36.520 --> 1:54:39.320
 It's going to obviously vary dramatically from genre to genre.

1:54:39.320 --> 1:54:47.360
 So like you, I like guitar, perhaps like you, although I've dabbled in inhaling every

1:54:47.360 --> 1:54:53.680
 genre of music that I can almost practically imagine, I keep coming back to, you know,

1:54:53.680 --> 1:54:57.840
 the sound of bass, guitar, drum, keyboards, voice.

1:54:57.840 --> 1:55:04.280
 I love that style of music and added to it, I think a lot of really cool electronic production

1:55:04.280 --> 1:55:09.200
 makes something that's really, really new and hybrid and awesome.

1:55:09.200 --> 1:55:15.920
 But you know, and that kind of like guitar based rock, I think I've got to go with won't

1:55:15.920 --> 1:55:18.960
 get fooled again by the who.

1:55:18.960 --> 1:55:24.080
 It is such an epic song, it's got so much grandeur to it.

1:55:24.080 --> 1:55:29.680
 It uses the synthesizers that were available at the time, this got to be I think 1972,

1:55:29.680 --> 1:55:35.240
 73, which are very, very primitive to our ears, but uses them in this hypnotic and beautiful

1:55:35.240 --> 1:55:41.600
 way that I can't imagine somebody with the greatest synth array conceivable by today's

1:55:41.600 --> 1:55:46.040
 technology could do a better job of in the context of that song.

1:55:46.040 --> 1:55:49.360
 And it's, you know, almost operatic.

1:55:49.360 --> 1:55:56.200
 So I would say in that genre, the genre of, you know, rock, that would be my nomination.

1:55:56.200 --> 1:56:02.400
 I'm totally, in my brain, the pinball wizard is overriding everything else, but it was

1:56:02.400 --> 1:56:04.760
 so like, I can't even imagine the song.

1:56:04.760 --> 1:56:10.080
 Well I would say ironically with pinball wizard, so that came from the movie Tommy.

1:56:10.080 --> 1:56:17.680
 And in the movie Tommy, the rival of Tommy, the reigning pinball champ was Elton John.

1:56:17.680 --> 1:56:21.960
 And so there are a couple versions of pinball wizard out there, one sung by Roger Daltry

1:56:21.960 --> 1:56:25.820
 of the Who, which a purist would say, hey, that's the real pinball wizard.

1:56:25.820 --> 1:56:30.840
 But the version that is sung by Elton John in the movie, which is available to those

1:56:30.840 --> 1:56:35.200
 who are ambitious and want to dig for it, that's even better in my mind.

1:56:35.200 --> 1:56:36.360
 Yeah, the covers.

1:56:36.360 --> 1:56:41.080
 And for myself, I was thinking, what is the song for me?

1:56:41.080 --> 1:56:42.960
 They asked that question.

1:56:42.960 --> 1:56:51.640
 I think that changes day to day too, I was realizing that, but for me, somebody who values

1:56:51.640 --> 1:56:59.440
 lyrics as well and the emotion in the song, by the way, Hallelujah by Leonard Cohen was

1:56:59.440 --> 1:57:00.440
 the close one.

1:57:00.440 --> 1:57:11.280
 Number one is Johnny Cash's cover of Hurt, that is, there's something so powerful about

1:57:11.280 --> 1:57:15.480
 that song, about that cover, about that performance.

1:57:15.480 --> 1:57:19.640
 Maybe another one is the cover of Sound of Silence.

1:57:19.640 --> 1:57:21.920
 Maybe there's something about covers for me.

1:57:21.920 --> 1:57:26.440
 So whose cover sounds, because Simon and Garfunkel, I think did the original recording that, right?

1:57:26.440 --> 1:57:28.360
 So which cover is it that?

1:57:28.360 --> 1:57:34.560
 There's a cover by a disturbed, it's a metal band, which is so interesting, because I'm

1:57:34.560 --> 1:57:38.640
 really not into that kind of metal, but he does a pure vocal performance.

1:57:38.640 --> 1:57:42.960
 So he's not doing a metal performance is, I would say is one of the greatest people

1:57:42.960 --> 1:57:48.960
 should see it, it's like 400 million views or something like that.

1:57:48.960 --> 1:57:54.960
 It's probably the greatest live vocal performance I've ever heard is disturbed covering Sound

1:57:54.960 --> 1:57:55.960
 of Silence.

1:57:55.960 --> 1:57:57.200
 I'll listen to it as soon as I get home.

1:57:57.200 --> 1:58:00.600
 And that song came to life to me in the way that Simon and Garfunkel never did.

1:58:00.600 --> 1:58:07.000
 There's no, for me with Simon and Garfunkel, there's not a pain, there's not an anger,

1:58:07.000 --> 1:58:11.920
 there's not like power to their performance.

1:58:11.920 --> 1:58:15.400
 It's almost like this melancholy, I don't know.

1:58:15.400 --> 1:58:20.960
 Well, there's a lot, I guess there's a lot of beauty to it, like objectively beautiful.

1:58:20.960 --> 1:58:26.280
 And I think, I never thought of this until now, but I think if you put entirely different

1:58:26.280 --> 1:58:31.880
 lyrics on top of it, unless they were joyous, which would be weird, it wouldn't necessarily

1:58:31.880 --> 1:58:33.240
 lose that much.

1:58:33.240 --> 1:58:39.760
 It's just a beauty in the harmonizing, it's soft, and you're right, it's not dripping

1:58:39.760 --> 1:58:40.760
 with emotion.

1:58:40.760 --> 1:58:48.160
 The vocal performance is not dripping with emotion, it's dripping with technical harmonizing

1:58:48.160 --> 1:58:49.880
 brilliance and beauty.

1:58:49.880 --> 1:58:56.080
 Now, you should compare that to the disturbed cover or the Johnny Cash's hurt cover.

1:58:56.080 --> 1:59:02.720
 When you walk away, there's a few, it's haunting, it stays with you for a long time.

1:59:02.720 --> 1:59:11.520
 There's certain performances that will just stay with you to where, like if you watch

1:59:11.520 --> 1:59:15.760
 people respond to that, and that's certainly how I felt when you listened to the disturbed

1:59:15.760 --> 1:59:20.880
 performance or Johnny Cash's hurt, there's a response to where you just sit there with

1:59:20.880 --> 1:59:26.640
 your mouth open, kind of paralyzed by it somehow.

1:59:26.640 --> 1:59:31.360
 And I think that's what makes for a great song, to where you're just like, it's not

1:59:31.360 --> 1:59:37.760
 that you're singing along or having fun, that's another way a song could be great, but where

1:59:37.760 --> 1:59:42.160
 you're just like, what, this is, you're in awe.

1:59:42.160 --> 1:59:50.280
 If we go to listen.com and that whole fascinating era of music in the 90s transitioning to

1:59:50.280 --> 1:59:58.500
 the arts, I remember those days, the Napster days, when piracy from my perspective allegedly

1:59:58.500 --> 2:00:03.760
 ruled the land, what do you make of that whole era?

2:00:03.760 --> 2:00:08.520
 What are the big, what was first of all your experiences of that era and what were the

2:00:08.520 --> 2:00:13.760
 big takeaways in terms of piracy, in terms of what it takes to build a company that

2:00:13.760 --> 2:00:20.680
 succeeds in that kind of digital space, in terms of music, but in terms of anything

2:00:20.680 --> 2:00:21.680
 creative?

2:00:21.680 --> 2:00:27.440
 Well, so for those who don't remember, which is going to be most folks, listen.com created

2:00:27.440 --> 2:00:31.640
 a service called Rhapsody, which is much, much more recognizable to folks because Rhapsody

2:00:31.640 --> 2:00:34.320
 became a pretty big name for reasons that I'll get into in a second.

2:00:34.320 --> 2:00:40.040
 So for people who don't know their early online music history, we were the first company.

2:00:40.040 --> 2:00:46.160
 So I found it, listen, I was the only founder, and Rhapsody was, we were the first service

2:00:46.160 --> 2:00:51.920
 to get full catalog licenses from all the major music labels in order to distribute their

2:00:51.920 --> 2:00:52.920
 music online.

2:00:52.920 --> 2:00:57.080
 And we specifically did it through a mechanism, which at the time struck people as exotic

2:00:57.080 --> 2:01:01.840
 and bizarre and kind of incomprehensible, which was unlimited on demand streaming, which

2:01:01.840 --> 2:01:08.400
 of course now, it's a model that's been appropriated by Spotify and Apple and many, many others.

2:01:08.400 --> 2:01:10.480
 So we were a pioneer on that front.

2:01:10.480 --> 2:01:16.240
 What was really, really, really hard about doing business in those days was the reaction

2:01:16.240 --> 2:01:22.920
 of the music labels to piracy, which was about 180 degrees opposite of what the reaction,

2:01:22.920 --> 2:01:27.760
 quote unquote, should have been from the standpoint of preserving their business from piracy.

2:01:27.760 --> 2:01:36.680
 So Napster came along and was a service that enabled people to get near unlimited access

2:01:36.680 --> 2:01:39.120
 to most songs.

2:01:39.120 --> 2:01:44.000
 I mean, truly obscure things could be very hard to find on Napster, but most songs with

2:01:44.000 --> 2:01:51.040
 a relatively simple, one click ability to download those songs that have the MP3s on

2:01:51.040 --> 2:01:52.040
 their hard drives.

2:01:52.040 --> 2:01:56.080
 But there was a lot that was very messy about the Napster experience.

2:01:56.080 --> 2:02:00.360
 You might download a really godawful recording of that song.

2:02:00.360 --> 2:02:04.760
 You may download a recording that actually wasn't that song with some prankster putting

2:02:04.760 --> 2:02:07.400
 it up to sort of mess with people.

2:02:07.400 --> 2:02:09.920
 You could struggle to find the song that you're looking for.

2:02:09.920 --> 2:02:13.780
 You could end up finding yourself connected, was peer to peer.

2:02:13.780 --> 2:02:17.040
 You might randomly find yourself connected to somebody in Bulgaria.

2:02:17.040 --> 2:02:19.120
 It doesn't have a very good internet connection.

2:02:19.120 --> 2:02:24.360
 You might wait 19 minutes only for it to snap, et cetera, et cetera.

2:02:24.360 --> 2:02:28.520
 And our argument to, well, actually, let's start with how that hit the music labels.

2:02:28.520 --> 2:02:33.440
 The music labels had been in a very, very comfortable position for many, many decades

2:02:33.440 --> 2:02:41.000
 of essentially, you know, having monopoly, you know, having been the monopoly providers

2:02:41.000 --> 2:02:45.560
 of a certain subset of artists, any given label was a monopoly provider of the artists

2:02:45.560 --> 2:02:50.840
 and the recordings that they owned, and they could sell it at what turned out to be tremendously

2:02:50.840 --> 2:02:51.840
 favorable rates.

2:02:51.840 --> 2:02:57.640
 So in the late era of the CD, you know, you were talking close to $20 for a compact disc

2:02:57.640 --> 2:03:02.160
 that might have one song that you were crazy about and simply needed to own that might

2:03:02.160 --> 2:03:06.200
 actually be glued to 17 other songs that you found to be sure crap.

2:03:06.200 --> 2:03:13.840
 And so the music industry had used the fact that it had this unbelievable leverage and

2:03:13.840 --> 2:03:20.360
 profound pricing power to really get music lovers to the point that they felt very, very

2:03:20.360 --> 2:03:22.680
 misused by the entire situation.

2:03:22.680 --> 2:03:29.880
 Now along comes Napster, and music sales start getting gutted with extreme rapidity.

2:03:29.880 --> 2:03:37.560
 And the reaction of the music industry to that was one of shock and absolute fury, which

2:03:37.560 --> 2:03:38.560
 is understandable.

2:03:38.560 --> 2:03:43.200
 You know, I mean, industries do get gutted all the time, but I struggled to think of

2:03:43.200 --> 2:03:46.800
 an analog of an industry that gutted that rapidly.

2:03:46.800 --> 2:03:51.860
 I mean, we could say that passenger train service certainly got gutted by airlines,

2:03:51.860 --> 2:03:55.440
 but that was a process that took place over decades and decades and decades.

2:03:55.440 --> 2:03:59.400
 It wasn't something that happened, you know, really started showing up in the numbers in

2:03:59.400 --> 2:04:03.840
 a single digit number of months and started looking like an existential threat within

2:04:03.840 --> 2:04:05.280
 a year or two.

2:04:05.280 --> 2:04:10.280
 So the music industry is quite understandably in a state of shock and fury.

2:04:10.280 --> 2:04:12.160
 I don't blame them for that.

2:04:12.160 --> 2:04:18.160
 But then their reaction was catastrophic, both for themselves and almost for people

2:04:18.160 --> 2:04:23.400
 like us who were trying to do, you know, the cowboy in the white hat thing.

2:04:23.400 --> 2:04:28.520
 So our response to the music industry was, look, what do you need to do to fight piracy?

2:04:28.520 --> 2:04:30.400
 You can't put the genie back in the bottle.

2:04:30.400 --> 2:04:32.920
 You can't switch off the internet.

2:04:32.920 --> 2:04:37.360
 Even if you all shut your eyes and wish very, very, very hard, the internet is not going

2:04:37.360 --> 2:04:42.800
 away and these peer to peer technologies are genies out of the bottle and if you God don't,

2:04:42.800 --> 2:04:48.240
 whatever you do, don't shut down Napster because if you do, suddenly that technology

2:04:48.240 --> 2:04:52.400
 is going to splinter into 30 different nodes that you'll never, ever be able to shut off.

2:04:52.400 --> 2:04:59.120
 We suggested to them is like, look, what you want to do is to create a massively better

2:04:59.120 --> 2:05:04.240
 experience to piracy, something that's way better that you sell at a completely reasonable

2:05:04.240 --> 2:05:06.760
 price and this is what it is.

2:05:06.760 --> 2:05:10.640
 Don't just give people access to that very limited number of songs that they happen to

2:05:10.640 --> 2:05:16.120
 have acquired and paid for or pirated and have on their hard drive.

2:05:16.120 --> 2:05:20.080
 Give them access to all of the music in the world for a simple low price and obviously

2:05:20.080 --> 2:05:22.120
 that doesn't sound like a crazy suggestion.

2:05:22.120 --> 2:05:26.120
 I don't think to anybody's ears today because that is how the majority of music is now being

2:05:26.120 --> 2:05:27.120
 consumed online.

2:05:27.120 --> 2:05:32.680
 But in doing that, you're going to create a much, much better option to this kind of

2:05:32.680 --> 2:05:37.960
 crappy, kind of rickety, kind of buggy process of acquiring MP3s.

2:05:37.960 --> 2:05:44.160
 Now, unfortunately, the music industry was so angry about Napster and so forth that for

2:05:44.160 --> 2:05:48.960
 essentially three and a half years, they folded their arms, stamped their feet and boycotted

2:05:48.960 --> 2:05:49.960
 the internet.

2:05:49.960 --> 2:05:55.800
 So they basically gave people who were fervently passionate about music and were digitally modern,

2:05:55.800 --> 2:05:57.640
 they gave them basically one choice.

2:05:57.640 --> 2:06:01.800
 If you want to have access to digital music, we, the music industry, insist that you steal

2:06:01.800 --> 2:06:04.700
 it because we are not going to sell it to you.

2:06:04.700 --> 2:06:10.400
 So what that did is it made an entire generation of people morally comfortable with swiping

2:06:10.400 --> 2:06:14.400
 the music because they felt quite pragmatically, well, they're not giving me any choice here.

2:06:14.400 --> 2:06:19.000
 It's like a 20 year old violating the 21 drinking age.

2:06:19.000 --> 2:06:20.000
 They do that.

2:06:20.000 --> 2:06:22.160
 They're not going to feel like felons.

2:06:22.160 --> 2:06:25.400
 They're going to be like, this is an unreasonable law and I'm scurred again.

2:06:25.400 --> 2:06:29.720
 So they make a whole generation of people morally comfortable with swiping music but

2:06:29.720 --> 2:06:32.440
 also technically adept at it.

2:06:32.440 --> 2:06:37.200
 And when they did shut down Napster and kind of even trickier tools and like tweakier tools

2:06:37.200 --> 2:06:41.780
 like Kazan and so forth came along, people just figured out how to do it.

2:06:41.780 --> 2:06:48.720
 So by the time they finally, grudgingly, it took years, allowed us to release this experience

2:06:48.720 --> 2:06:51.960
 that we were quite convinced would be better than piracy.

2:06:51.960 --> 2:06:57.720
 We had this enormous hole had been dug where lots of people said, music is a thing that

2:06:57.720 --> 2:07:02.000
 is free and that's morally okay and I know how to get it.

2:07:02.000 --> 2:07:08.640
 And so streaming took many, many, many more years to take off and become the gargantuan

2:07:08.640 --> 2:07:13.520
 thing, the juggernaut of the day is today, then would have happened if they'd made pivoted

2:07:13.520 --> 2:07:19.240
 to let's sell a better experience as opposed to demand that people on digital music steal

2:07:19.240 --> 2:07:20.240
 it.

2:07:20.240 --> 2:07:21.640
 What lessons do we draw from that?

2:07:21.640 --> 2:07:26.800
 Because we're probably in the midst of living through a bunch of similar situations in different

2:07:26.800 --> 2:07:27.800
 domains currently.

2:07:27.800 --> 2:07:28.800
 We just don't know.

2:07:28.800 --> 2:07:33.040
 There's a lot of things in this world that are really painful, like, I mean, I don't

2:07:33.040 --> 2:07:37.480
 know if you can draw perfect parallels, but fiat money versus cryptocurrency, there's

2:07:37.480 --> 2:07:42.680
 a lot of currently people in power who are kind of very skeptical about cryptocurrency,

2:07:42.680 --> 2:07:46.040
 although that's changing, but it's arguable it's changing way too slowly.

2:07:46.040 --> 2:07:49.480
 There's a lot of people making that argument where there should be a complete like coin

2:07:49.480 --> 2:07:52.960
 base and all this stuff switched to that.

2:07:52.960 --> 2:07:58.520
 There's a lot of other domains that wear a pivot.

2:07:58.520 --> 2:08:07.320
 If you pivot now, you're going to win big, but you don't pivot because you're stubborn.

2:08:07.320 --> 2:08:09.480
 Is this just the way that companies are?

2:08:09.480 --> 2:08:15.160
 The company succeeds initially, and then it grows, and there's a huge number of employees

2:08:15.160 --> 2:08:21.600
 and managers that don't have the guts or the institutional mechanisms to do the pivot.

2:08:21.600 --> 2:08:23.280
 Is this just the way of companies?

2:08:23.280 --> 2:08:28.880
 Well, I think what happens, I'll use the case of the music industry, there was an economic

2:08:28.880 --> 2:08:33.400
 model that it put food on the table and paid for marble lobbies and seven and even eight

2:08:33.400 --> 2:08:39.800
 figure executive salaries for many, many decades, which was the physical collection of music.

2:08:39.800 --> 2:08:45.800
 Then you start talking about something like unlimited streaming, and it seems so ephemeral

2:08:45.800 --> 2:08:51.360
 one, like such a long shot, that people start worrying about cannibalizing their own business,

2:08:51.360 --> 2:08:55.440
 and they lose sight of the fact that something illicit is cannibalizing their business at

2:08:55.440 --> 2:08:59.760
 an extraordinarily fast rate, and so if they don't do it themselves, they're doomed.

2:08:59.760 --> 2:09:05.000
 We used to put slides in front of these folks, this is really funny, where we said, okay,

2:09:05.000 --> 2:09:10.600
 let's assume Rhapsody, we want it to be $9.99 a month, and we want it to be 12 months, so

2:09:10.600 --> 2:09:16.880
 it's $120 a year from the budget of a music lover, and then we were also able to get reasonably

2:09:16.880 --> 2:09:21.960
 accurate statistics that showed how many CDs per year, the average person who bothered

2:09:21.960 --> 2:09:26.560
 to collect music, which was not all people actually bought, and it was overwhelmingly

2:09:26.560 --> 2:09:33.120
 clear that the average CD buyer spends a hell of a lot less than $120 a year on music.

2:09:33.120 --> 2:09:37.320
 This is a revenue expansion, blah, blah, blah, but all they could think of, and I'm not

2:09:37.320 --> 2:09:42.000
 saying this in a pejorative or patronizing way, I don't blame them, they've grown up

2:09:42.000 --> 2:09:46.000
 in this environment for decades, all they could think of was the incredible margins

2:09:46.000 --> 2:09:53.400
 that they had on a CD, and they would say, well, if this CD, by the mechanism that you

2:09:53.400 --> 2:10:00.440
 guys are proposing, the CD that I'm selling for $17.99, somebody would need to stream

2:10:00.440 --> 2:10:01.440
 those songs.

2:10:01.440 --> 2:10:04.160
 We were talking about a penny of play back then, it's less than that now that the record

2:10:04.160 --> 2:10:09.760
 labels get paid, but would have to stream songs from that 1,799 times, it's never going

2:10:09.760 --> 2:10:10.760
 to happen.

2:10:10.760 --> 2:10:13.840
 So they were just stuck in the model of this, but it was like, no, dude, but they're going

2:10:13.840 --> 2:10:17.280
 to spend money on all this other stuff, so I think people get very hung up on that.

2:10:17.280 --> 2:10:22.520
 I mean, another example is really the taxi industry was not monolithic, like the music

2:10:22.520 --> 2:10:23.520
 labels.

2:10:23.520 --> 2:10:26.200
 There was a whole bunch of fleets in a whole bunch of cities, very, very fragmented, it's

2:10:26.200 --> 2:10:31.600
 an imperfect analogy, but nonetheless, imagine if the taxi industry writ large upon seeing

2:10:31.600 --> 2:10:38.240
 Uber said, oh my God, people want to be able to hail things easily, cheaply, they don't

2:10:38.240 --> 2:10:41.520
 want to mess with cash, they want to know how many minutes it's going to be, they want

2:10:41.520 --> 2:10:46.560
 to know the fare in advance, and they want a much bigger fleet than what we've got.

2:10:46.560 --> 2:10:52.600
 If the taxi industry had rolled out something like that with the branding of yellow taxis

2:10:52.600 --> 2:10:58.840
 universally known and kind of loved by Americans and expanded their fleet in a necessary manner,

2:10:58.840 --> 2:11:02.360
 I don't think Uber or Lyft ever would have gotten a foothold.

2:11:02.360 --> 2:11:08.240
 But the problem there was that real economics in the taxi industry wasn't with fares, it

2:11:08.240 --> 2:11:10.920
 was with the scarcity of medallions.

2:11:10.920 --> 2:11:16.800
 And so the taxi fleets in many cases owned gazillions of medallions whose value came

2:11:16.800 --> 2:11:21.320
 from their very scarcity, so they simply couldn't pivot to that.

2:11:21.320 --> 2:11:25.680
 So you think you end up having these vested interests with economics that aren't necessarily

2:11:25.680 --> 2:11:32.080
 visible to outsiders who get very, very reluctant to disrupt their own model, which is why it

2:11:32.080 --> 2:11:34.880
 ends up coming from the outside so frequently.

2:11:34.880 --> 2:11:39.320
 So you know what it takes to build a successful startup, but you're also an investor in a

2:11:39.320 --> 2:11:44.160
 lot of successful startups, let me ask for advice.

2:11:44.160 --> 2:11:49.080
 What do you think it takes to build a successful startup by way of advice?

2:11:49.080 --> 2:11:54.800
 Well I think it starts, I mean everything starts and even ends with the founder.

2:11:54.800 --> 2:11:59.680
 And so I think it's really, really important to look at the founder's motivations and their

2:11:59.680 --> 2:12:02.920
 sophistication about what they're doing.

2:12:02.920 --> 2:12:08.080
 In almost all cases that I'm familiar with and have thought hard about, you've had a

2:12:08.080 --> 2:12:15.680
 founder who was deeply, deeply inculcated in the domain of technology that they were taking

2:12:15.680 --> 2:12:16.680
 on.

2:12:16.680 --> 2:12:20.400
 Now what's interesting about that is you could say, no wait, how is that possible?

2:12:20.400 --> 2:12:21.800
 Because there's so many young founders.

2:12:21.800 --> 2:12:26.440
 When you look at young founders, they're generally coming out of very nascent emerging fields

2:12:26.440 --> 2:12:31.880
 of technology where simply being present and accounted for and engaged in the community

2:12:31.880 --> 2:12:36.600
 for a period of even months is enough time to make them very, very deeply inculcated.

2:12:36.600 --> 2:12:43.440
 I mean you look at Marc Andreessen and Netscape, you know, Marc had been doing visual web browsers

2:12:43.440 --> 2:12:46.800
 when Netscape had been founded for what, a year and a half, but he'd created the first

2:12:46.800 --> 2:12:51.880
 one, you know, and in Mosaic when he was an undergrad.

2:12:51.880 --> 2:12:58.600
 And the commercial internet was pre nascent in 1994 when Netscape was founded.

2:12:58.600 --> 2:13:02.040
 So there's somebody who's very, very deep in their domain, Mark Zuckerberg also, social

2:13:02.040 --> 2:13:06.520
 networking, very deep in his domain even though it was nascent at the time, lots of people

2:13:06.520 --> 2:13:07.520
 doing crypto stuff.

2:13:07.520 --> 2:13:14.000
 I mean, you know, 10 years ago, even seven or eight years ago, by being a really, really

2:13:14.000 --> 2:13:19.880
 vehement and engaged participant in the crypto ecosystem, you could be an expert in that.

2:13:19.880 --> 2:13:25.200
 You look, however, at more established industries, take Salesforce.com, Salesforce Automation,

2:13:25.200 --> 2:13:29.720
 pretty mature field when it got started, who's the executive and the founder, Marc Benioff,

2:13:29.720 --> 2:13:35.280
 who spent 13 years at Oracle and was an investor in Siebel Systems, which ended up being Salesforce's

2:13:35.280 --> 2:13:36.840
 main competition.

2:13:36.840 --> 2:13:42.720
 So you know, more established, you need the entrepreneur to be very, very deep in the

2:13:42.720 --> 2:13:49.800
 technology and the culture of the space because you need that entrepreneur, that founder, to

2:13:49.800 --> 2:13:56.680
 have just an unbelievably accurate, intuitive sense for where the puck is going, right?

2:13:56.680 --> 2:13:59.160
 And that only comes from being very deep.

2:13:59.160 --> 2:14:01.440
 So that is sort of factor number one.

2:14:01.440 --> 2:14:08.320
 And the next thing is that that founder needs to be charismatic and or credible, or ideally

2:14:08.320 --> 2:14:14.400
 both, in exactly the right ways to be able to attract a team that is bought into that

2:14:14.400 --> 2:14:19.960
 vision and is bought into that founder's intuitions being correct, and not just the team, obviously,

2:14:19.960 --> 2:14:21.640
 but also the investors.

2:14:21.640 --> 2:14:25.800
 So it takes a certain personality type to pull that off.

2:14:25.800 --> 2:14:33.160
 And the next thing I'm still talking about founder is a relentlessness and indeed a monomania

2:14:33.160 --> 2:14:40.120
 to put this above things that might rationally, you know, should perhaps rationally supersede

2:14:40.120 --> 2:14:47.080
 it for a period of time to just relentlessly pivot when pivoting is called for and it's

2:14:47.080 --> 2:14:48.080
 always called for.

2:14:48.080 --> 2:14:53.600
 I mean, I think even very successful companies like how many times is it Facebook pivot,

2:14:53.600 --> 2:14:57.760
 you know, newsfeed was something that was completely alien to the original version of

2:14:57.760 --> 2:15:02.000
 Facebook and came found foundationally important, how many times in Google, how many times at

2:15:02.000 --> 2:15:07.000
 any given how many times is Apple pivoted, you know, that founder energy and DNA when

2:15:07.000 --> 2:15:12.560
 the founder moves on the DNA that's been inculcated with a company has to have that relentlessness

2:15:12.560 --> 2:15:17.320
 and that ability to pivot and pivot and pivot without, you know, being worried about sacred

2:15:17.320 --> 2:15:18.320
 cows.

2:15:18.320 --> 2:15:21.280
 And then the last thing I'll say about the founder before I get to the rest of the team

2:15:21.280 --> 2:15:29.680
 and that'll be mercifully brief is the founder has to be obviously a really great hirer,

2:15:29.680 --> 2:15:37.140
 but just important, a very good firer and firing is a horrific experience for both people

2:15:37.140 --> 2:15:38.140
 involved in it.

2:15:38.140 --> 2:15:45.520
 It is a wrenching emotional experience and being good at realizing when this particular

2:15:45.520 --> 2:15:52.200
 person is damaging the interests of the company and the team and the shareholders and, you

2:15:52.200 --> 2:15:58.680
 know, having the intestinal fortitude to have that conversation and make it happen is something

2:15:58.680 --> 2:16:02.160
 that most people don't have in them.

2:16:02.160 --> 2:16:07.240
 And it's something that needs to be developed in most people, or maybe some people have

2:16:07.240 --> 2:16:08.600
 it naturally.

2:16:08.600 --> 2:16:13.640
 But without that ability, that will take an A plus organization and to be minus range

2:16:13.640 --> 2:16:15.840
 very, very quickly.

2:16:15.840 --> 2:16:19.200
 And so that's all what needs to be present in the founder.

2:16:19.200 --> 2:16:24.320
 Can I just say, sure, how damn good you are, Rob, that was brilliant.

2:16:24.320 --> 2:16:29.760
 The one thing that was kind of really kind of surprising to me is having a deep technical

2:16:29.760 --> 2:16:37.440
 knowledge because I think the way you expressed it, which is that allows you to be really

2:16:37.440 --> 2:16:45.360
 honest with the capabilities of what's possible.

2:16:45.360 --> 2:16:50.280
 Of course, you're often trying to do the impossible, but in order to do the impossible,

2:16:50.280 --> 2:16:54.000
 you have to be quote unquote impossible, but you have to be honest with what is actually

2:16:54.000 --> 2:16:55.000
 possible.

2:16:55.000 --> 2:16:57.880
 And it doesn't necessarily have to be the technical competence.

2:16:57.880 --> 2:17:02.840
 It's got to be, in my view, just a complete immersion in that emerging market.

2:17:02.840 --> 2:17:06.080
 And so I can imagine, there are a couple of people out there who have started really

2:17:06.080 --> 2:17:10.880
 good crypto projects, who themselves are right in the code.

2:17:10.880 --> 2:17:15.520
 But they're immersed in the culture and through the culture and a deep understanding of what's

2:17:15.520 --> 2:17:19.840
 happening and what's not happening, they can get a good intuition of what's possible.

2:17:19.840 --> 2:17:25.880
 But the very first hire, I mean, a great way to solve that is to have a technical cofounder

2:17:25.880 --> 2:17:31.120
 and dual founder companies have become extremely common for that reason.

2:17:31.120 --> 2:17:36.200
 And if you're not doing that and you're not the technical person, but you are the founder,

2:17:36.200 --> 2:17:44.400
 you got to be really great at hiring a very damn good technical person very, very fast.

2:17:44.400 --> 2:17:50.440
 Can I on the founder ask you, is it possible to do this alone?

2:17:50.440 --> 2:17:54.960
 There's so many people giving advice on saying that it's impossible to do the first few steps.

2:17:54.960 --> 2:17:58.520
 Not impossible, but much more difficult to do it alone.

2:17:58.520 --> 2:18:02.920
 If we were to take the journey, say, especially in the software world where there's not significant

2:18:02.920 --> 2:18:10.600
 investment required to build something up, is it possible to go to a prototype to something

2:18:10.600 --> 2:18:14.800
 that essentially works and already has a huge number of customers alone?

2:18:14.800 --> 2:18:15.800
 Sure.

2:18:15.800 --> 2:18:21.240
 There are lots and lots of lone founder companies out there that have made an incredible difference.

2:18:21.240 --> 2:18:25.920
 I mean, I'm not certainly putting Rhapsody in the league of Spotify.

2:18:25.920 --> 2:18:29.880
 We were too early to be Spotify, but we did an awful lot of innovation.

2:18:29.880 --> 2:18:34.320
 And then after the company sold and ended up in the hands of real networks and MTV, got

2:18:34.320 --> 2:18:35.840
 to millions of subs.

2:18:35.840 --> 2:18:40.840
 I was a lone founder and I studied Arabic and Middle Eastern history undergrad.

2:18:40.840 --> 2:18:44.880
 So I definitely wasn't very, very technical, but yeah, lone founders can absolutely work

2:18:44.880 --> 2:18:51.400
 in the advantage of a lone founder is you don't have the catastrophic potential of a

2:18:51.400 --> 2:18:53.200
 falling out between founders.

2:18:53.200 --> 2:19:00.080
 I mean, two founders who fall out with each other badly can rip a company to shreds because

2:19:00.080 --> 2:19:04.880
 they both have an enormous amount of equity, an enormous amount of power, and the capital

2:19:04.880 --> 2:19:06.760
 structure is a result of that.

2:19:06.760 --> 2:19:12.400
 They both have an enormous amount of moral authority with the team as a result of each

2:19:12.400 --> 2:19:14.800
 having that founder role.

2:19:14.800 --> 2:19:20.240
 And I have witnessed over the years many, many situations in which companies have been

2:19:20.240 --> 2:19:27.400
 shredded or have suffered near fatal blows because of a falling out between founders.

2:19:27.400 --> 2:19:30.520
 And the more founders you add, the more risky that becomes.

2:19:30.520 --> 2:19:36.120
 I don't think there should ever, almost, I mean, you never say never, but multiple founders

2:19:36.120 --> 2:19:44.480
 beyond two is such an unstable and potentially treacherous situation that I would never ever

2:19:44.480 --> 2:19:46.120
 recommend going beyond two.

2:19:46.120 --> 2:19:52.840
 But I do see value in the non technical business and market and outside minded founder teaming

2:19:52.840 --> 2:19:55.200
 up with the technical founder.

2:19:55.200 --> 2:19:58.720
 There is a lot of merit to that, but there's a lot of danger in that, lest those two blow

2:19:58.720 --> 2:19:59.720
 apart.

2:19:59.720 --> 2:20:01.120
 Was it lonely for you?

2:20:01.120 --> 2:20:02.120
 Unbelievably.

2:20:02.120 --> 2:20:03.120
 And that's the drawback.

2:20:03.120 --> 2:20:10.520
 I mean, if you're a lone founder, there is no other person that you can sit down with

2:20:10.520 --> 2:20:16.160
 and tackle problems and talk them through who has precisely or nearly precisely your alignment

2:20:16.160 --> 2:20:17.720
 of interests.

2:20:17.720 --> 2:20:23.320
 Your most trusted board member is likely an investor and therefore at the end of the

2:20:23.320 --> 2:20:27.160
 day has the interest of preferred stock in mind, not common stock.

2:20:27.160 --> 2:20:34.120
 Your most trusted VP who might own a very significant stake in the company doesn't own

2:20:34.120 --> 2:20:36.040
 anywhere near your stake in the company.

2:20:36.040 --> 2:20:41.080
 And so their longterm interests may well be in getting the right level of experience and

2:20:41.080 --> 2:20:45.680
 credibility necessary to peel off and start their own company or their interests might

2:20:45.680 --> 2:20:52.640
 be aligned with jumping ship and setting up with a different company, whether it's a rival

2:20:52.640 --> 2:20:54.680
 or one in a completely different space.

2:20:54.680 --> 2:20:59.120
 So yeah, being a lone founder is a spectacularly lonely thing and that's a major downside to

2:20:59.120 --> 2:21:00.120
 it.

2:21:00.120 --> 2:21:01.120
 What about mentorship?

2:21:01.120 --> 2:21:03.640
 Because you're a mentor to a lot of people.

2:21:03.640 --> 2:21:09.480
 Can you find an alleviation to that loneliness and the space of ideas with a good mentor?

2:21:09.480 --> 2:21:11.760
 With a good mentor or like a mentor who's mentoring you?

2:21:11.760 --> 2:21:12.760
 Yeah.

2:21:12.760 --> 2:21:13.760
 Yeah, you can.

2:21:13.760 --> 2:21:14.760
 A great deal.

2:21:14.760 --> 2:21:16.880
 Particularly if it's somebody who's been through this very process and has navigated

2:21:16.880 --> 2:21:23.880
 it successfully and cares enough about you and your well being to give you beautifully

2:21:23.880 --> 2:21:27.000
 unvarnished advice, that can be a huge, huge thing.

2:21:27.000 --> 2:21:29.160
 That can assuage things a great deal.

2:21:29.160 --> 2:21:35.280
 And I had a board member who was not an investor, who basically played that role for me to a

2:21:35.280 --> 2:21:36.280
 great degree.

2:21:36.280 --> 2:21:39.160
 He came in maybe halfway through the company's history though.

2:21:39.160 --> 2:21:42.680
 I needed that the most in the very earliest days.

2:21:42.680 --> 2:21:48.000
 Yeah, the loneliness, that's the whole journey of life.

2:21:48.000 --> 2:21:51.480
 We're always alone together.

2:21:51.480 --> 2:21:54.400
 It pays to embrace that.

2:21:54.400 --> 2:21:58.760
 You were saying that there might be something outside of the founder that's also, that you

2:21:58.760 --> 2:22:00.680
 were promising to be brief on.

2:22:00.680 --> 2:22:01.680
 Yeah.

2:22:01.680 --> 2:22:02.680
 Okay.

2:22:02.680 --> 2:22:03.680
 So we talked about the founder.

2:22:03.680 --> 2:22:04.680
 You were asking what makes a great startup.

2:22:04.680 --> 2:22:05.680
 Yes.

2:22:05.680 --> 2:22:09.360
 And great founder is thing number one, but then thing number two, and it's ginormous is a

2:22:09.360 --> 2:22:10.720
 great team.

2:22:10.720 --> 2:22:16.680
 And so I said so much about the founder because one hopes or one believes that a founder who

2:22:16.680 --> 2:22:22.640
 is a great hirer is going to be hiring people in charge of critical functions like engineering

2:22:22.640 --> 2:22:26.960
 and marketing and biz dev and sales and so forth, who themselves are great hirers.

2:22:26.960 --> 2:22:30.920
 So what needs to radiate from the founder into the team that might be a little bit different

2:22:30.920 --> 2:22:33.560
 from what's in the gene code of the founder.

2:22:33.560 --> 2:22:41.440
 The team needs to be fully bought in to the intuitions and the vision of the founder.

2:22:41.440 --> 2:22:42.440
 Great.

2:22:42.440 --> 2:22:43.440
 We've got that.

2:22:43.440 --> 2:22:53.360
 But the team needs to have a slightly different thing, which is it's 99% obsession is execution.

2:22:53.360 --> 2:22:59.440
 It needs to relentlessly hit the milestones, hit the objectives, hit the quarterly goals.

2:22:59.440 --> 2:23:01.580
 That is 1% vision.

2:23:01.580 --> 2:23:07.560
 You don't want to lose that, but execution machines.

2:23:07.560 --> 2:23:13.440
 People who have a demonstrated ability and a demonstrated focus on, yeah, I go from point

2:23:13.440 --> 2:23:14.720
 to point to point.

2:23:14.720 --> 2:23:21.840
 I try to beat and raise expectations relentlessly, never fall short, and both sort of blaze and

2:23:21.840 --> 2:23:23.440
 follow the path.

2:23:23.440 --> 2:23:27.200
 Not that the path is going to blaze the trail as well.

2:23:27.200 --> 2:23:32.800
 A good founder is going to trust that VP of sales to have a better sense of what it takes

2:23:32.800 --> 2:23:36.840
 to build out that organization, what the milestones be, and it's going to be kind of a dialogue

2:23:36.840 --> 2:23:38.960
 amongst those at the top.

2:23:38.960 --> 2:23:43.000
 But execution obsession in the team is the next thing.

2:23:43.000 --> 2:23:48.200
 Yeah, there's some sense where the founder, you talk about sort of the space of ideas

2:23:48.200 --> 2:23:53.320
 like first principles thinking, asking big difficult questions of future trajectories

2:23:53.320 --> 2:23:57.000
 or having a big vision and big picture dreams.

2:23:57.000 --> 2:24:04.160
 You can almost be a dreamer, it feels like, when you're not the founder, but in the space

2:24:04.160 --> 2:24:08.200
 of sort of leadership.

2:24:08.200 --> 2:24:12.000
 But when it gets to the ground floor, there has to be execution.

2:24:12.000 --> 2:24:16.440
 There has to be hitting deadlines.

2:24:16.440 --> 2:24:18.080
 Sometimes those are attention.

2:24:18.080 --> 2:24:28.320
 There's something about dreams that are attention with the pragmatic nature of execution.

2:24:28.320 --> 2:24:35.760
 Not dreams, but sort of ambitious vision, and those have to be, I suppose, coupled.

2:24:35.760 --> 2:24:43.080
 The vision in the leader and the execution in the software world that would be the programmer

2:24:43.080 --> 2:24:45.080
 of the designer.

2:24:45.080 --> 2:24:46.080
 Absolutely.

2:24:46.080 --> 2:24:51.160
 Amongst many other things, you're an incredible conversationalist, a podcast, or you host

2:24:51.160 --> 2:24:56.680
 a podcast called After On, I mean, there's a million questions I want to ask you here,

2:24:56.680 --> 2:25:00.640
 but one at the highest level, what do you think makes for a great conversation?

2:25:00.640 --> 2:25:07.120
 I would say two things, one of two things, and ideally both of two things.

2:25:07.120 --> 2:25:15.080
 One is if something is very, is beautifully architected, whether it's done deliberately

2:25:15.080 --> 2:25:21.040
 and methodically and willfully, as when I do it, or whether that just emerges from the

2:25:21.040 --> 2:25:25.720
 conversation, but something that's beautifully architected, that can create something that's

2:25:25.720 --> 2:25:32.440
 incredibly powerful and memorable, or something where there's just extraordinary chemistry.

2:25:32.440 --> 2:25:39.080
 And so with All In, or go way back, you might remember the NPR show Card Talk, I couldn't

2:25:39.080 --> 2:25:45.000
 care less about auto mechanics myself, but I love that show because the banter between

2:25:45.000 --> 2:25:50.120
 those two guys was just beyond, it was without any parallel, right?

2:25:50.120 --> 2:25:55.040
 And some kind of edgy podcast like Red Scare is just really entertaining to me because the

2:25:55.040 --> 2:25:59.360
 banter between the women on that show is just so good, and All In and that kind of thing.

2:25:59.360 --> 2:26:04.880
 So I think it's a combination of the arc and the chemistry.

2:26:04.880 --> 2:26:11.480
 And I think because the arc can be so important, that's why very, very highly produced podcasts

2:26:11.480 --> 2:26:15.560
 like This American Life, obviously a radio show, but I think of a podcast because that's

2:26:15.560 --> 2:26:22.280
 how I was consumed or criminal, or a lot of what Wondery does and so forth, that is real

2:26:22.280 --> 2:26:26.880
 documentary making, and that requires a big team and a big budget relative to the kinds

2:26:26.880 --> 2:26:31.360
 of things you and I do, but nonetheless, then you got that arc, and that can be really,

2:26:31.360 --> 2:26:32.360
 really compelling.

2:26:32.360 --> 2:26:37.680
 But if we go back to conversation, I think it's a combination of structure and chemistry.

2:26:37.680 --> 2:26:43.880
 Yeah, and I've actually personally have lost, I used to love This American Life, and for

2:26:43.880 --> 2:26:51.320
 some reason because it lacks the possibility of magic, it's engineered magic.

2:26:51.320 --> 2:26:53.120
 I've fallen off of it myself as well.

2:26:53.120 --> 2:26:58.360
 I mean, when I fell madly in love with it during the aughts, it was the only thing going.

2:26:58.360 --> 2:27:04.400
 They were really smart to adopting, to adopt podcasting as a distribution mechanism early.

2:27:04.400 --> 2:27:09.320
 Yeah, I think that maybe there's a little bit less magic there now because I think they

2:27:09.320 --> 2:27:14.160
 have agendas other than necessarily just delighting their listeners with quirky stories, which

2:27:14.160 --> 2:27:17.720
 I think is what it was all about back in the day and some other things.

2:27:17.720 --> 2:27:22.400
 Is there like a memorable conversation that you've had on the podcast, whether it was

2:27:22.400 --> 2:27:29.440
 because it was wild and fun, or one that was exceptionally challenging, maybe challenging

2:27:29.440 --> 2:27:31.240
 to prepare for, that kind of thing?

2:27:31.240 --> 2:27:35.680
 Is there something that stands out in your mind that you can draw an insight from?

2:27:35.680 --> 2:27:43.520
 Yeah, I mean, this no way diminishes the episodes that will not be the answer to these two questions.

2:27:43.520 --> 2:27:48.080
 An example of something that was really, really challenging to prepare for was George Church.

2:27:48.080 --> 2:27:52.440
 So as I'm sure you know and as I'm sure many of your listeners know, he is one of the absolute

2:27:52.440 --> 2:27:57.520
 leading lights in the field of synthetic biology, he's also unbelievably prolific.

2:27:57.520 --> 2:28:02.680
 His lab is large and has all kinds of efforts have spun out of that.

2:28:02.680 --> 2:28:08.160
 And what I wanted to make my George Church episode about was, first of all, grounding

2:28:08.160 --> 2:28:12.520
 people into what is this thing called symbiol?

2:28:12.520 --> 2:28:17.440
 And that required me to learn a hell of a lot more about symbiol than I knew going into

2:28:17.440 --> 2:28:18.440
 it.

2:28:18.440 --> 2:28:23.160
 So there was just this very broad, I mean, I knew much more than the average person going

2:28:23.160 --> 2:28:27.200
 into that episode, but there was this incredible breadth of grounding that I needed to give

2:28:27.200 --> 2:28:29.320
 myself in the domain.

2:28:29.320 --> 2:28:34.120
 And then George does so many interesting things, there's so many interesting things emitting

2:28:34.120 --> 2:28:38.800
 from his lab that, you know, and he and I had a really good dialogue, he was a great

2:28:38.800 --> 2:28:41.560
 guide going into it.

2:28:41.560 --> 2:28:47.440
 Winnowing it down to the three to four that I really wanted us to focus on to create a

2:28:47.440 --> 2:28:51.960
 sense of wonder and magic in the listener of what could be possible from this very broad

2:28:51.960 --> 2:28:54.720
 spectrum domain, that was a doozy of a challenge.

2:28:54.720 --> 2:28:57.920
 That was a tough, tough, tough one to prepare for.

2:28:57.920 --> 2:29:04.960
 Now, in terms of something that was just wild and fun, unexpected, I mean, by the time we

2:29:04.960 --> 2:29:07.400
 sat down to interview, I knew where we were going to go.

2:29:07.400 --> 2:29:11.200
 But just in terms of the idea space, Don Hoffman.

2:29:11.200 --> 2:29:12.200
 Oh, wow.

2:29:12.200 --> 2:29:13.200
 Yeah.

2:29:13.200 --> 2:29:17.440
 So Don Hoffman is again, some listeners probably know because he's, I think I was the first

2:29:17.440 --> 2:29:19.280
 podcaster to interview him.

2:29:19.280 --> 2:29:24.240
 I'm sure some of you are listeners are familiar with him, but he has this unbelievably

2:29:24.240 --> 2:29:28.680
 contrarian take on the nature of reality.

2:29:28.680 --> 2:29:35.200
 But it is contrarian in a way that all the ideas are highly internally consistent and

2:29:35.200 --> 2:29:38.840
 snap together in a way that's just delightful.

2:29:38.840 --> 2:29:46.080
 And it seems as radically violating of our intuitions and is radically violating of the

2:29:46.080 --> 2:29:49.520
 probable nature of reality as anything that one can encounter.

2:29:49.520 --> 2:29:54.920
 But an analogy that he uses, which is very powerful, which is what intuition could possibly

2:29:54.920 --> 2:30:00.760
 be more powerful than the notion that there is a single unitary direction called down.

2:30:00.760 --> 2:30:05.240
 And we're on this big flat thing for which there is a thing called down.

2:30:05.240 --> 2:30:06.240
 And we all know that.

2:30:06.240 --> 2:30:10.320
 I mean, that's the most intuitive thing that one could probably think of.

2:30:10.320 --> 2:30:12.400
 And we all know that that ain't true.

2:30:12.400 --> 2:30:19.200
 So my conversation with Don Hoffman is just wild and full of plot twists and interesting

2:30:19.200 --> 2:30:20.200
 stuff.

2:30:20.200 --> 2:30:24.960
 And the interesting thing about the wildness of his ideas, it's to me, at least as a listener

2:30:24.960 --> 2:30:35.320
 coupled with he's a good listener and he empathizes with the people who challenge his ideas.

2:30:35.320 --> 2:30:39.560
 Like what's a better way to phrase that?

2:30:39.560 --> 2:30:44.480
 He is welcoming of challenge in a way that creates a really fun conversation.

2:30:44.480 --> 2:30:45.480
 Oh, totally.

2:30:45.480 --> 2:30:46.480
 Yeah.

2:30:46.480 --> 2:30:54.000
 And he loves a peri or a jab, whatever the word is, at his argument, he honors it.

2:30:54.000 --> 2:31:00.000
 He's a very, very gentle and noncombatative soul.

2:31:00.000 --> 2:31:08.360
 But then he is very good and takes great evident joy in responding to that in a way that expands

2:31:08.360 --> 2:31:10.200
 your understanding of his thinking.

2:31:10.200 --> 2:31:15.400
 Let me as a small tangent of tying up together a previous conversation about listening.com

2:31:15.400 --> 2:31:20.720
 is streaming and Spotify and the world of podcasting.

2:31:20.720 --> 2:31:25.560
 So we've been talking about this magical medium of podcasting.

2:31:25.560 --> 2:31:32.840
 I have a lot of friends at Spotify in the high positions of Spotify as well.

2:31:32.840 --> 2:31:41.520
 I worry about Spotify and podcasting and the future of podcasting in general that moves

2:31:41.520 --> 2:31:49.400
 podcasting in the place of maybe walled gardens of sorts.

2:31:49.400 --> 2:31:55.280
 Since you've had a foot in both worlds, have a foot in both worlds, do you worry as well

2:31:55.280 --> 2:31:56.920
 about the future of podcasting?

2:31:56.920 --> 2:31:57.920
 Yeah.

2:31:57.920 --> 2:32:05.640
 I think walled gardens are really toxic to the medium that they start balkanizing.

2:32:05.640 --> 2:32:12.800
 So to take an example, I'll take two examples, with music, it was a very, very big deal that

2:32:12.800 --> 2:32:17.840
 at Rhapsody, we were the first company to get full catalog licenses from all, back then

2:32:17.840 --> 2:32:21.760
 there were five major music labels and also hundreds and hundreds of indies because you

2:32:21.760 --> 2:32:27.760
 needed to present the listener with a sense that basically everything is there and there

2:32:27.760 --> 2:32:32.360
 is essentially no friction to discovering that which is new.

2:32:32.360 --> 2:32:37.480
 And you can wander this realm and all you really need is a good map, whether it is something

2:32:37.480 --> 2:32:41.920
 that the editorial team assembled or a good algorithm or whatever it is, but a good map

2:32:41.920 --> 2:32:43.600
 to wander this domain.

2:32:43.600 --> 2:32:50.400
 When you start walling things off, A, you undermine the joy of friction free discovery

2:32:50.400 --> 2:32:55.640
 which is an incredibly valuable thing to deliver to your customer both from a business standpoint

2:32:55.640 --> 2:33:01.440
 and simply from a humanistic standpoint of you want to bring delight to people.

2:33:01.440 --> 2:33:06.120
 But it also creates an incredible opening vector for piracy.

2:33:06.120 --> 2:33:10.760
 And so something that's very different from the Rhapsody slash Spotify slash et cetera

2:33:10.760 --> 2:33:14.560
 like experience is what we have now in video.

2:33:14.560 --> 2:33:16.560
 Like wow, is that show on Hulu?

2:33:16.560 --> 2:33:17.560
 Is it on Netflix?

2:33:17.560 --> 2:33:20.080
 Is it on something like IFC channel?

2:33:20.080 --> 2:33:21.560
 Is it on Discovery Plus?

2:33:21.560 --> 2:33:22.560
 Is it here?

2:33:22.560 --> 2:33:23.560
 Is it there?

2:33:23.560 --> 2:33:30.760
 And the more frustration and toe stubbing that people encounter when they are seeking

2:33:30.760 --> 2:33:35.760
 something and they're already paying a very respectable amount of money per month to have

2:33:35.760 --> 2:33:39.880
 access to content and they can't find it, the more that happens, the more people are

2:33:39.880 --> 2:33:43.080
 going to be driven to piracy solutions like to hell with it.

2:33:43.080 --> 2:33:44.440
 Never know where I'm going to find something.

2:33:44.440 --> 2:33:46.280
 I never know what it's going to cost.

2:33:46.280 --> 2:33:50.200
 Oftentimes really interesting things are simply unavailable.

2:33:50.200 --> 2:33:53.200
 That surprises me the number of times that I've been looking for things that I don't

2:33:53.200 --> 2:33:58.600
 even think are that obscure, that are just, it says not available in your geography period

2:33:58.600 --> 2:33:59.960
 mister, right?

2:33:59.960 --> 2:34:01.680
 So I think that that's a mistake.

2:34:01.680 --> 2:34:07.800
 And then the other thing is for podcasters and lovers of podcasting, we should want to

2:34:07.800 --> 2:34:17.000
 resist this walled garden thing because A, it does smother this friction free or eradicate

2:34:17.000 --> 2:34:21.800
 this friction free discovery unless you want to sign up for lots of different services.

2:34:21.800 --> 2:34:28.600
 And also dims the voice of somebody who might be able to have a far, far, far bigger impact

2:34:28.600 --> 2:34:32.520
 by reaching far more neurons with their ideas.

2:34:32.520 --> 2:34:36.040
 I'm going to use an example from, I guess it was probably the nineties or maybe it was

2:34:36.040 --> 2:34:42.760
 the aughts of Howard Stern who had the biggest megaphone or maybe the second biggest after

2:34:42.760 --> 2:34:48.760
 Oprah megaphone in popular culture because he was syndicated on hundreds and hundreds

2:34:48.760 --> 2:34:52.400
 and hundreds of radio stations at a time when terrestrial broadcast was the main thing people

2:34:52.400 --> 2:34:54.960
 listen to in their car, no more obviously.

2:34:54.960 --> 2:34:58.680
 But when he decided to go over to, you know, satellite radio, if I can't remember it was

2:34:58.680 --> 2:35:01.840
 XM or Sirius, maybe they'd already merged at that point.

2:35:01.840 --> 2:35:07.640
 But when he did that, he made, you know, totally his right to do it, financial calculation

2:35:07.640 --> 2:35:11.120
 that they were offering him a nine figure sum to do that.

2:35:11.120 --> 2:35:14.760
 But his audience, because not a lot of people were subscribing to satellite radio at that

2:35:14.760 --> 2:35:19.240
 point, his audience probably collapsed by, I wouldn't be surprised if it was as much

2:35:19.240 --> 2:35:20.960
 as 95%.

2:35:20.960 --> 2:35:27.480
 And so the influence that he had on the culture and his ability to sort of shape conversation

2:35:27.480 --> 2:35:30.600
 and so forth just got muted.

2:35:30.600 --> 2:35:31.600
 Yeah.

2:35:31.600 --> 2:35:38.080
 And also there's a certain sense, especially in modern times where the wall gardens naturally

2:35:38.080 --> 2:35:48.920
 lead to, I don't know if there's a term for it, but people who are not creatives starting

2:35:48.920 --> 2:35:51.600
 to have power over the creatives.

2:35:51.600 --> 2:35:52.600
 Right.

2:35:52.600 --> 2:36:00.480
 And even if they don't stifle it, if they're providing incentives within the platform to

2:36:00.480 --> 2:36:06.760
 shape, shift, or even completely mutate or distort the show, I mean, imagine somebody

2:36:06.760 --> 2:36:12.840
 has got a reasonably interesting idea for a podcast and they get signed up with, let's

2:36:12.840 --> 2:36:13.840
 say Spotify.

2:36:13.840 --> 2:36:17.640
 And then Spotify is going to give them financing to get the things spun up.

2:36:17.640 --> 2:36:22.680
 And that's great, and Spotify is going to give them a certain amount of really powerful

2:36:22.680 --> 2:36:27.400
 placement within the visual field of listeners.

2:36:27.400 --> 2:36:29.120
 But Spotify has conditions for that.

2:36:29.120 --> 2:36:35.080
 They say, look, we think that your podcast will be much more successful if you dumb

2:36:35.080 --> 2:36:44.160
 it down about 60%, if you add some silly dirty jokes, if you do this, you do that.

2:36:44.160 --> 2:36:48.880
 And suddenly the person who is dependent upon Spotify for permission to come into existence

2:36:48.880 --> 2:36:53.480
 and is really dependent, really wants to please them to get that money in, to get that placement,

2:36:53.480 --> 2:36:57.120
 really wants to be successful, now all of a sudden you're having a dialogue between

2:36:57.120 --> 2:37:03.840
 a complete noncreative, some marketing data analytic person at Spotify and a creative

2:37:03.840 --> 2:37:07.200
 that's going to shape what that show is.

2:37:07.200 --> 2:37:10.440
 So that could be much more common.

2:37:10.440 --> 2:37:16.240
 And ultimately having the aggregate, an even bigger impact than the cancellation, let's

2:37:16.240 --> 2:37:20.080
 say, of somebody who says the wrong word or voices the wrong idea, I mean, that's kind

2:37:20.080 --> 2:37:25.840
 of what you have, and not kind of, it's what you have with film and TV, is that so much

2:37:25.840 --> 2:37:31.080
 influence is exerted over the storyline and the plots and the character arcs and all kinds

2:37:31.080 --> 2:37:35.880
 of things by executives who are completely alien to the experience and the skill set

2:37:35.880 --> 2:37:40.680
 of being a showrunner in television, being a director in film, that is meant to like,

2:37:40.680 --> 2:37:45.920
 we can't piss off the Chinese market here or we can't say that or we need to have cast

2:37:45.920 --> 2:37:51.600
 members that have precisely these demographics reflected or whatever it is, and obviously

2:37:51.600 --> 2:37:57.720
 despite that extraordinary, at least TV shows are now being made, in terms of film, I think

2:37:57.720 --> 2:38:03.360
 the quality has nosedived of the average, let's say, American film coming out of a major studio,

2:38:03.360 --> 2:38:07.640
 the average quality, and my view is nosedived over the past decade is it's kind of everything's

2:38:07.640 --> 2:38:10.080
 got to be a superhero franchise.

2:38:10.080 --> 2:38:17.240
 But great stuff gets made despite that, but I have to assume that in some cases, at least

2:38:17.240 --> 2:38:22.320
 in perhaps many cases, greater stuff would be made if there was less interference from

2:38:22.320 --> 2:38:23.320
 noncreative executives.

2:38:23.320 --> 2:38:27.560
 It's like the flip side of that though, and this was the pitch of Spotify because I've

2:38:27.560 --> 2:38:34.240
 heard their pitch is Netflix, from everybody I've heard that I've spoken with about Netflix

2:38:34.240 --> 2:38:35.960
 is they actually empower the creator.

2:38:35.960 --> 2:38:36.960
 They do.

2:38:36.960 --> 2:38:41.080
 I don't know what the heck they do, but they do a good job of giving creators, even the

2:38:41.080 --> 2:38:46.080
 crazy ones, like Tim Dillon, like Joe Rogan, like comedians, freedom to be their crazy

2:38:46.080 --> 2:38:47.280
 selves.

2:38:47.280 --> 2:38:54.120
 And the result is like some of the greatest television, some of the greatest cinema, whatever

2:38:54.120 --> 2:38:55.800
 you call it, ever made.

2:38:55.800 --> 2:38:56.800
 True.

2:38:56.800 --> 2:38:58.840
 And I don't know what the heck they're doing.

2:38:58.840 --> 2:38:59.840
 It's a relative thing.

2:38:59.840 --> 2:39:01.480
 From what I understand, it's a relative thing.

2:39:01.480 --> 2:39:08.160
 They're interfering far, far, far less than NBC or AMC would have interfered.

2:39:08.160 --> 2:39:10.320
 So it's a relative thing.

2:39:10.320 --> 2:39:13.360
 And obviously, they're the ones writing the checks, and they're the ones giving the platforms.

2:39:13.360 --> 2:39:16.680
 They've ever been right to their own influence, obviously.

2:39:16.680 --> 2:39:21.800
 But my understanding is that they're relatively way more hands off, and that has had a demonstrable

2:39:21.800 --> 2:39:28.080
 effect, because I agree, some of the greatest produced video content of all time.

2:39:28.080 --> 2:39:32.040
 An incredibly inordinate percentage of that is coming out from Netflix in just a few years

2:39:32.040 --> 2:39:34.680
 when the history of cinema goes back many, many decades.

2:39:34.680 --> 2:39:41.480
 And Spotify wants to be that for podcasting, and I hope they do become that for podcasting,

2:39:41.480 --> 2:39:47.680
 but I'm wearing my skeptical goggles or skeptical hat, whatever the heck it is, because it's

2:39:47.680 --> 2:39:48.680
 not easy to do.

2:39:48.680 --> 2:39:55.080
 And it requires letting go of power, giving power to the creatives.

2:39:55.080 --> 2:40:01.160
 It requires pivoting, which large companies, even as innovative as Spotify is, still now

2:40:01.160 --> 2:40:05.560
 a large company pivoting into a whole new space is very tricky and difficult.

2:40:05.560 --> 2:40:08.240
 So I'm skeptical, but hopeful.

2:40:08.240 --> 2:40:13.000
 What advice would you give to a young person today about life, about career?

2:40:13.000 --> 2:40:16.920
 We talked about startups, we talked about music, we talked about the end of humans

2:40:16.920 --> 2:40:18.960
 civilization.

2:40:18.960 --> 2:40:23.640
 Is there advice you would give to a young person today, maybe in college, maybe in high

2:40:23.640 --> 2:40:26.640
 school about their life?

2:40:26.640 --> 2:40:27.640
 Well, let's see.

2:40:27.640 --> 2:40:34.960
 I mean, there's so many domains you can advise on, and I'm not going to give advice on life

2:40:34.960 --> 2:40:40.160
 because I fear that I would drift into sort of hallmark bromides that really wouldn't

2:40:40.160 --> 2:40:43.600
 be all that distinctive, and they might be entirely true.

2:40:43.600 --> 2:40:48.440
 Because the greatest insights about life turn out to be the kinds of things you'd see on

2:40:48.440 --> 2:40:49.440
 a hallmark card.

2:40:49.440 --> 2:40:50.600
 So I'm going to steer clear of that.

2:40:50.600 --> 2:40:57.960
 On a career level, one thing that I think is unintuitive but unbelievably powerful is

2:40:57.960 --> 2:41:07.240
 to focus not necessarily on being you in the top sliver of 1% in excelling at one domain

2:41:07.240 --> 2:41:09.460
 that's important and valuable.

2:41:09.460 --> 2:41:16.920
 But to think in terms of intersections of two domains, which are rare but valuable.

2:41:16.920 --> 2:41:19.680
 And there's a couple reasons for this.

2:41:19.680 --> 2:41:25.080
 The first is in an incredibly competitive world that is so much more competitive than

2:41:25.080 --> 2:41:28.960
 was when I was coming out of school, radically more competitive than when I was coming out

2:41:28.960 --> 2:41:34.120
 of school, to navigate your way to the absolute pinnacle of any domain.

2:41:34.120 --> 2:41:40.360
 Say you want to be really, really great at Python, pick a language, whatever it is.

2:41:40.360 --> 2:41:45.000
 You want to be one of the world's greatest Python developers, JavaScript, whatever your

2:41:45.000 --> 2:41:46.000
 language is.

2:41:46.000 --> 2:41:47.120
 Hopefully it's not cobalt.

2:41:47.120 --> 2:41:54.000
 By the way, if you listen to this, I am actually looking for a cobalt expert to interview because

2:41:54.000 --> 2:41:56.440
 I find language fascinating and there's not many of them.

2:41:56.440 --> 2:42:02.400
 So please, if you know a world expert in cobalt or Fortran, both actually.

2:42:02.400 --> 2:42:03.400
 Or if you are one.

2:42:03.400 --> 2:42:05.640
 Or if you are one, please email me.

2:42:05.640 --> 2:42:06.640
 Yeah.

2:42:06.640 --> 2:42:10.600
 So I mean, if you're going out there and you want to be in the top sliver 1% of Python

2:42:10.600 --> 2:42:12.400
 developers, it's a very, very difficult thing to do.

2:42:12.400 --> 2:42:14.880
 Particularly if you want to be number one in the world, something like that.

2:42:14.880 --> 2:42:23.040
 And we use an analogy as I had a friend in college who was on a track and indeed succeeded

2:42:23.040 --> 2:42:29.320
 at that to become an Olympic medalist and I think was 100 meter breaststroke.

2:42:29.320 --> 2:42:37.320
 And he mortgaged a significant percentage of his sort of college life to that goal.

2:42:37.320 --> 2:42:41.120
 I should say dedicated or invested or whatever you wanted to say, but he didn't participate

2:42:41.120 --> 2:42:46.160
 in a lot of the social, a lot of the late night, a lot of the this, a lot of the that

2:42:46.160 --> 2:42:48.200
 because he was training so much.

2:42:48.200 --> 2:42:50.760
 And obviously he also wanted to keep up with his academics.

2:42:50.760 --> 2:42:56.200
 And at the end of the day, story as a happy man ending in that he did metal in that bronze,

2:42:56.200 --> 2:42:59.200
 not gold, but holy cow, anybody who gets an Olympic medal.

2:42:59.200 --> 2:43:00.200
 That's an extraordinary thing.

2:43:00.200 --> 2:43:05.160
 And at that moment, he was, you know, one of the top three people on earth at that thing.

2:43:05.160 --> 2:43:07.400
 But wow, how hard to do that.

2:43:07.400 --> 2:43:12.240
 How many thousands of other people went down that path and made similar sacrifices and didn't

2:43:12.240 --> 2:43:13.240
 get there.

2:43:13.240 --> 2:43:15.320
 It's very, very hard to do that.

2:43:15.320 --> 2:43:19.040
 Whereas, you know, use a personal example.

2:43:19.040 --> 2:43:23.640
 When I came out of business school, I went to a good business school and learned the

2:43:23.640 --> 2:43:25.800
 things that were there to be learned.

2:43:25.800 --> 2:43:30.520
 And I came out and I entered a world with lots of Harvard business school, by the way.

2:43:30.520 --> 2:43:31.520
 Okay.

2:43:31.520 --> 2:43:32.520
 Yes, it was Harvard.

2:43:32.520 --> 2:43:33.520
 It's true.

2:43:33.520 --> 2:43:36.880
 You're the first person who went there who didn't say where you went, which is beautiful.

2:43:36.880 --> 2:43:37.880
 I appreciate that.

2:43:37.880 --> 2:43:41.640
 Well, it's one of the greatest business schools in the world.

2:43:41.640 --> 2:43:44.440
 It's a whole another fascinating conversation about that world.

2:43:44.440 --> 2:43:45.440
 But anyway, yes.

2:43:45.440 --> 2:43:49.640
 But anyway, so I learned the things that you, you learn getting a B and MBA from a, from

2:43:49.640 --> 2:43:51.200
 a top program.

2:43:51.200 --> 2:43:56.640
 And I entered a world that had hundreds of thousands of people who had MBAs, probably

2:43:56.640 --> 2:44:00.240
 hundreds of thousands who have them from, you know, top 10 programs.

2:44:00.240 --> 2:44:04.920
 But so I was not particularly great at being an MBA person.

2:44:04.920 --> 2:44:07.840
 I was inexperienced relative to most of them.

2:44:07.840 --> 2:44:13.000
 And there were a lot of them, but it was okay, MBA person, right, newly minted.

2:44:13.000 --> 2:44:20.400
 But then as it happened, I found my way into working on the commercial internet in 1994.

2:44:20.400 --> 2:44:25.120
 And I went to a, at the time, giant and hot computing company called Silicon Graphics,

2:44:25.120 --> 2:44:29.680
 which had enough heft and enough, you know, headcount that they could take on and experienced

2:44:29.680 --> 2:44:33.360
 MBAs and try to train them in the world of Silicon Valley.

2:44:33.360 --> 2:44:38.120
 But within that comp, that company that had an enormous amount of surface area and was

2:44:38.120 --> 2:44:43.720
 touching very a lot of areas and was have had unbelievably smart people at the time.

2:44:43.720 --> 2:44:49.440
 It was not surprising that SGI started doing really interesting and innovative and trail

2:44:49.440 --> 2:44:52.640
 analyzing stuff on the internet before almost anybody else.

2:44:52.640 --> 2:44:55.840
 And part of the reason was that our founder Jim Clark went off to cofound Netscape with

2:44:55.840 --> 2:44:56.840
 Mark Andreessen.

2:44:56.840 --> 2:44:58.880
 So the whole company was like, wait, what was that?

2:44:58.880 --> 2:45:00.760
 What's this commercial internet thing?

2:45:00.760 --> 2:45:01.920
 So I end up in that group.

2:45:01.920 --> 2:45:09.400
 Now, in terms of being a commercial internet person or a worldwide web person, again, I

2:45:09.400 --> 2:45:11.200
 was, in that case, barely credentialed.

2:45:11.200 --> 2:45:16.600
 I couldn't write a stitch of code, but I got a had a pretty good mind for grasping the

2:45:16.600 --> 2:45:22.080
 business and cultural significance of this transition.

2:45:22.080 --> 2:45:25.560
 And this was, again, we were talking earlier about emerging areas.

2:45:25.560 --> 2:45:29.560
 Within a few months, you know, I was in the relatively top echelon of people in terms

2:45:29.560 --> 2:45:33.720
 of just sheer experience, because like, let's say it was five months into the program, there

2:45:33.720 --> 2:45:37.160
 were only so many people who had been doing worldwide web stuff commercially for five

2:45:37.160 --> 2:45:38.160
 months.

2:45:38.160 --> 2:45:43.560
 You know, and then what was interesting, though, was the intersection of those two things.

2:45:43.560 --> 2:45:49.680
 The commercial web, as it turned out, grew into an unbelievable vastness.

2:45:49.680 --> 2:45:57.480
 And so by being a pretty good OK web person and a pretty good OK MBA person, that intersection

2:45:57.480 --> 2:46:03.400
 put me in a very rare group, which was web oriented MBAs.

2:46:03.400 --> 2:46:08.360
 And in those early days, you could probably count on your fingers the number of people

2:46:08.360 --> 2:46:12.120
 who came out of really competitive programs who were doing stuff full time on the internet.

2:46:12.120 --> 2:46:17.480
 And there was a greater appetite for great software developers in the internet domain,

2:46:17.480 --> 2:46:24.280
 but there was an appetite and a real one and a rapidly growing one for MBA thinkers who

2:46:24.280 --> 2:46:29.280
 were also seasoned and networked in the emerging world of the commercial worldwide web.

2:46:29.280 --> 2:46:37.520
 And so finding an intersection of two things you can be pretty good at, but is a rare intersection

2:46:37.520 --> 2:46:43.560
 and a special intersection is probably a much easier way to make yourself distinguishable

2:46:43.560 --> 2:46:48.760
 and in demand from the world than trying to be world class at this one thing.

2:46:48.760 --> 2:46:53.320
 So in the intersection is where there's to be discovered opportunity and success.

2:46:53.320 --> 2:46:54.320
 That's really interesting.

2:46:54.320 --> 2:46:55.320
 Yeah.

2:46:55.320 --> 2:46:58.120
 There's actually more intersection of fields and fields themselves, right?

2:46:58.120 --> 2:46:59.120
 So.

2:46:59.120 --> 2:47:02.520
 Yeah, I mean, I'll give you kind of a funny hypothetical here, but it's one I've been

2:47:02.520 --> 2:47:04.600
 thinking about a little bit.

2:47:04.600 --> 2:47:06.560
 There's a lot of people in crypto right now.

2:47:06.560 --> 2:47:11.960
 It'd be hard to be in the top percentile of crypto people, whether it comes from just

2:47:11.960 --> 2:47:15.840
 having a sheer grasp of the industry, a great network within the industry, technological

2:47:15.840 --> 2:47:18.440
 skills, whatever you want to call it.

2:47:18.440 --> 2:47:23.360
 And then there's this parallel world, an orthogonal world called crop insurance.

2:47:23.360 --> 2:47:25.440
 And I'm sure that's a big world.

2:47:25.440 --> 2:47:29.520
 Crop insurance is a very, very big deal, particularly in the wealthy and industrialized world where

2:47:29.520 --> 2:47:35.120
 people, there's sophisticated financial markets, rule of law, and large agricultural concerns

2:47:35.120 --> 2:47:37.880
 that are worried about that.

2:47:37.880 --> 2:47:42.760
 Somewhere out there is somebody who is pretty crypto savvy, but probably not top 1%, but

2:47:42.760 --> 2:47:47.600
 also has kind of been in the crop insurance world and understands that a hell of a lot

2:47:47.600 --> 2:47:52.320
 better than almost anybody who's ever had anything to do with cryptocurrency.

2:47:52.320 --> 2:47:58.400
 And so I think that decentralized finance, DeFi, one of the interesting and I think very

2:47:58.400 --> 2:48:03.400
 world positive things that I think it's almost inevitably will be bringing to the world is

2:48:03.400 --> 2:48:10.520
 crop insurance for small holding farmers, people who have tiny, tiny plots of land in places

2:48:10.520 --> 2:48:16.280
 like India, et cetera, where there is no crop insurance available to them because just the

2:48:16.280 --> 2:48:19.180
 financial infrastructure doesn't exist.

2:48:19.180 --> 2:48:25.080
 But it's highly imaginable that using oracle networks that are trusted outside deliverers

2:48:25.080 --> 2:48:29.320
 of factual information about rainfall in a particular area, you can start giving drought

2:48:29.320 --> 2:48:31.360
 insurance to folks like this.

2:48:31.360 --> 2:48:37.200
 The right person to come up with that idea is not a crypto whiz who doesn't know a blasted

2:48:37.200 --> 2:48:39.320
 thing about small holding farmers.

2:48:39.320 --> 2:48:43.480
 The right person to come up with that is not a crop insurance whiz who isn't quite sure

2:48:43.480 --> 2:48:47.600
 what Bitcoin is, but somebody occupies that intersection.

2:48:47.600 --> 2:48:52.280
 That's just one of gazillion examples of things that are going to come along for somebody

2:48:52.280 --> 2:48:57.560
 who occupies the right intersection of skills, but isn't necessarily the number one person

2:48:57.560 --> 2:48:59.760
 at either one of those expertises.

2:48:59.760 --> 2:49:05.360
 Just making me kind of wonder about my own little things that I'm average at and seeing

2:49:05.360 --> 2:49:09.360
 where the intersections that could be exploited.

2:49:09.360 --> 2:49:10.460
 That's pretty profound.

2:49:10.460 --> 2:49:16.000
 So we talked quite a bit about the end of the world and how we're both optimistic about

2:49:16.000 --> 2:49:18.280
 us figuring our way out.

2:49:18.280 --> 2:49:27.800
 Unfortunately, for now at least, both you and I are going to die one day way too soon.

2:49:27.800 --> 2:49:28.800
 First of all, that sucks.

2:49:28.800 --> 2:49:29.800
 It does.

2:49:29.800 --> 2:49:42.560
 I mean, one, I'd like to ask if you ponder your own mortality, what kind of wisdom inside

2:49:42.560 --> 2:49:45.840
 does it give you about your own life?

2:49:45.840 --> 2:49:50.360
 And broadly, do you think about your life and what the heck it's all about?

2:49:50.360 --> 2:49:57.040
 Yeah, with respect to pondering mortality, I do try to do that as little as possible

2:49:57.040 --> 2:50:00.080
 because there's not a lot I can do about it.

2:50:00.080 --> 2:50:04.760
 But it's inevitably there and I think that what it does when you think about it in the

2:50:04.760 --> 2:50:12.200
 right way is it makes you realize how unbelievably rare and precious the moments that we have

2:50:12.200 --> 2:50:16.760
 here are and therefore how consequential the decisions that we make about how to spend

2:50:16.760 --> 2:50:19.200
 our time are.

2:50:19.200 --> 2:50:26.320
 Do you do those 17 nagging emails or do you have dinner with somebody who's really important

2:50:26.320 --> 2:50:28.920
 to you who haven't seen in three and a half years?

2:50:28.920 --> 2:50:33.800
 If you had an infinite expanse of time in front of you, you might well rationally conclude

2:50:33.800 --> 2:50:38.280
 I'm going to do those emails because collectively they're rather important and I have tens of

2:50:38.280 --> 2:50:41.200
 thousands of years to catch up with my buddy Tim.

2:50:41.200 --> 2:50:48.160
 But I think the scarcity of the time that we have helps us choose the right things if

2:50:48.160 --> 2:50:54.200
 we're tuned to that and we're tuned to the context that mortality puts over the consequence

2:50:54.200 --> 2:50:57.000
 of every decision we make of how to spend our time.

2:50:57.000 --> 2:51:00.560
 That doesn't mean that we're all very good at it, doesn't mean I'm very good at it.

2:51:00.560 --> 2:51:06.440
 But it does add a dimension of choice and significance to everything that we elect to

2:51:06.440 --> 2:51:07.440
 do.

2:51:07.440 --> 2:51:10.520
 It's kind of funny that you say you try to think about it as little as possible.

2:51:10.520 --> 2:51:14.080
 I would venture to say you probably think about the end of human civilization more

2:51:14.080 --> 2:51:15.600
 than you do about your own life.

2:51:15.600 --> 2:51:17.000
 You're probably right.

2:51:17.000 --> 2:51:19.760
 Because that feels like a problem that could be solved.

2:51:19.760 --> 2:51:20.760
 Right.

2:51:20.760 --> 2:51:22.600
 Where's the end of my own life can't be solved?

2:51:22.600 --> 2:51:24.600
 Well, I don't know.

2:51:24.600 --> 2:51:28.880
 I mean, there's transhumanists who have incredible optimism about near or intermediate future

2:51:28.880 --> 2:51:32.720
 therapies that could really, really change human lifespan.

2:51:32.720 --> 2:51:37.040
 I really hope that they're right, but I don't have a whole lot to add to that project because

2:51:37.040 --> 2:51:40.040
 I'm not a life scientist myself.

2:51:40.040 --> 2:51:48.280
 I'm in part also afraid of immortality, not as much, but close to as I'm afraid of death

2:51:48.280 --> 2:51:49.280
 itself.

2:51:49.280 --> 2:51:55.240
 It feels like the things that give us meaning, give us meaning because of the scarcity that

2:51:55.240 --> 2:51:56.240
 surrounds it.

2:51:56.240 --> 2:51:57.240
 Agreed.

2:51:57.240 --> 2:52:03.000
 I'm almost afraid of having too much of stuff.

2:52:03.000 --> 2:52:07.880
 Although if there was something that said, this can expand your enjoyable well spanned

2:52:07.880 --> 2:52:11.800
 or lifespan by 75 years, I'm all in.

2:52:11.800 --> 2:52:19.480
 Well, part of the reason I wanted to not do a startup, really the only thing that worries

2:52:19.480 --> 2:52:26.160
 me about doing a startup is if it becomes successful because of how much I dream, how

2:52:26.160 --> 2:52:34.080
 much I'm driven to be successful, that there will not be enough silence in my life, enough

2:52:34.080 --> 2:52:41.280
 scarcity to appreciate the moments I appreciate now as deeply as I appreciate them now.

2:52:41.280 --> 2:52:48.560
 There's a simplicity to my life now that it feels like you might disappear with success.

2:52:48.560 --> 2:52:52.160
 I wouldn't say might.

2:52:52.160 --> 2:52:59.960
 I think if you start a company that has ambitious investors, ambitious for the returns that they'd

2:52:59.960 --> 2:53:05.880
 like to see, that has ambitious employees, ambitious for the career trajectories they

2:53:05.880 --> 2:53:15.040
 want to be on and so forth, and is driven by your own ambition, there's a profound monogamy

2:53:15.040 --> 2:53:17.120
 to that.

2:53:17.120 --> 2:53:24.320
 It is very, very hard to carve out time to be creative, to be peaceful, to be so forth

2:53:24.320 --> 2:53:30.640
 because of with every new employee that you hire, that's one more mouth to feed.

2:53:30.640 --> 2:53:35.280
 With every new investor that you take on, that's one more person to whom you really

2:53:35.280 --> 2:53:38.080
 do want to deliver great returns.

2:53:38.080 --> 2:53:43.600
 As the valuation ticks up, the threshold to delivering great returns for your investors

2:53:43.600 --> 2:53:45.600
 always rises.

2:53:45.600 --> 2:53:54.440
 There is an extraordinary monogamy to being a founder CEO, above all, for the first few

2:53:54.440 --> 2:53:59.520
 years and first in people's minds could be as many as 10 or 15.

2:53:59.520 --> 2:54:07.880
 I guess the fundamental calculation is whether the passion for the vision is greater than

2:54:07.880 --> 2:54:09.400
 the cost you'll pay.

2:54:09.400 --> 2:54:11.400
 It's all opportunity cost.

2:54:11.400 --> 2:54:16.800
 It's all opportunity cost, in terms of time and attention and experience.

2:54:16.800 --> 2:54:20.600
 Some things, everyone's different, but I'm less calculating.

2:54:20.600 --> 2:54:21.960
 Some things you just can't help.

2:54:21.960 --> 2:54:23.880
 Sometimes you just dive in.

2:54:23.880 --> 2:54:24.880
 Yeah.

2:54:24.880 --> 2:54:28.360
 You can do balance feats all you want on this versus that and what's the right.

2:54:28.360 --> 2:54:32.040
 I've done in the past and it's never worked.

2:54:32.040 --> 2:54:36.760
 It's always been like, okay, what's my gut screaming at me to do?

2:54:36.760 --> 2:54:42.480
 But about the meaning of life, you ever think about that?

2:54:42.480 --> 2:54:43.480
 Yeah.

2:54:43.480 --> 2:54:48.200
 I mean, this is where I'm going to go all hallmarking on you, but I think that there's

2:54:48.200 --> 2:54:54.120
 a few things and one of them is certainly love.

2:54:54.120 --> 2:55:01.560
 The love that we experience and feel and cause to well up in others is something that's just

2:55:01.560 --> 2:55:08.880
 so profound and goes beyond almost anything else that we can do.

2:55:08.880 --> 2:55:13.480
 Whether that is something that lies in the past, like maybe there was somebody that you

2:55:13.480 --> 2:55:19.600
 were dating and loved very profoundly in college and haven't seen in years, I don't think the

2:55:19.600 --> 2:55:24.840
 significance of that love is any way diminished by the fact that it had a notional beginning

2:55:24.840 --> 2:55:25.840
 and end.

2:55:25.840 --> 2:55:30.720
 The fact is that you experience that and you trigger that in somebody else and that happened.

2:55:30.720 --> 2:55:35.240
 It certainly doesn't have to be love of romantic partners alone.

2:55:35.240 --> 2:55:36.240
 It's family members.

2:55:36.240 --> 2:55:38.200
 It's love between friends.

2:55:38.200 --> 2:55:39.840
 It's love between creatures.

2:55:39.840 --> 2:55:47.600
 I had a dog for 10 years who passed away a while ago and experienced unbelievable love

2:55:47.600 --> 2:55:48.600
 with her.

2:55:48.600 --> 2:55:51.920
 It can be love of that which you create, and we were talking about the flow states that

2:55:51.920 --> 2:55:57.200
 we enter and the pride or lack of pride or in the Minsky case, your hatred of that which

2:55:57.200 --> 2:55:58.200
 you've done.

2:55:58.200 --> 2:56:06.600
 Nonetheless, the creations that we make and whether it's the love or the joy or the engagement

2:56:06.600 --> 2:56:12.480
 or the perspective shift that that cascades into other minds, I think that's a big, big,

2:56:12.480 --> 2:56:13.680
 big part of the meaning of life.

2:56:13.680 --> 2:56:18.280
 It's not something that everybody participates in necessarily, although I think we all do

2:56:18.280 --> 2:56:25.720
 at least in a very local level by the example that we set by the interactions that we have,

2:56:25.720 --> 2:56:31.880
 but for people who create works that travel far and reach people they'll never meet, that

2:56:31.880 --> 2:56:36.720
 reach countries they'll never visit, that reach people perhaps that come along and come

2:56:36.720 --> 2:56:40.760
 across their ideas or their works or their stories or their aesthetic creations of other

2:56:40.760 --> 2:56:43.320
 sorts long after they're dead.

2:56:43.320 --> 2:56:50.640
 I think that's really, really big part of the fabric of the meaning of life.

2:56:50.640 --> 2:57:01.760
 All these things like love and creation, I think really is what it's all about.

2:57:01.760 --> 2:57:03.800
 Part of love is also the loss of it.

2:57:03.800 --> 2:57:07.720
 There's a Louie episode with Louie CK.

2:57:07.720 --> 2:57:14.640
 There's an old gentleman's giving him advice that sometimes the sweetest parts of love

2:57:14.640 --> 2:57:22.400
 is when you lose it and you remember it, you reminisce on the loss of it.

2:57:22.400 --> 2:57:27.680
 There's some aspect in which, and I have many of those in my own life that almost like the

2:57:27.680 --> 2:57:37.040
 memories of it and the intensity of emotion you still feel about it is the sweetest part.

2:57:37.040 --> 2:57:41.400
 You feel like after saying goodbye, you relive it.

2:57:41.400 --> 2:57:45.400
 That goodbye is also part of love.

2:57:45.400 --> 2:57:47.080
 The loss of it is also part of love.

2:57:47.080 --> 2:57:48.080
 I don't know.

2:57:48.080 --> 2:57:49.520
 It's back to that scarcity.

2:57:49.520 --> 2:57:57.080
 I won't say the loss is the best part personally, but it definitely is an aspect of it.

2:57:57.080 --> 2:58:03.240
 The grief you might feel about something that's gone makes you realize what a big deal it

2:58:03.240 --> 2:58:06.960
 was.

2:58:06.960 --> 2:58:14.160
 Speaking of which, this particular journey we went on together, come to an end.

2:58:14.160 --> 2:58:17.040
 I have to say goodbye, and I hate saying goodbye, Rob.

2:58:17.040 --> 2:58:18.040
 This is truly an honor.

2:58:18.040 --> 2:58:20.520
 I've really been a big fan.

2:58:20.520 --> 2:58:24.200
 People should definitely check out your podcast, your master, what you do in the conversation

2:58:24.200 --> 2:58:26.160
 space and the writing space.

2:58:26.160 --> 2:58:29.880
 It's been an incredible honor that you'll show up here and spend this time with me.

2:58:29.880 --> 2:58:30.880
 I really, really appreciate it.

2:58:30.880 --> 2:58:35.480
 Well, it's been a huge honor to be here as well and also a fan and heaven for a long

2:58:35.480 --> 2:58:36.480
 time.

2:58:36.480 --> 2:58:37.480
 Thank you.

2:58:37.480 --> 2:58:42.200
 Thanks for listening to this conversation with Rob Reed, and thank you to Athletic Greens,

2:58:42.200 --> 2:58:46.360
 Bell Campo, Fundrise, and NetSuite.

2:58:46.360 --> 2:58:49.400
 Check them out in the description to support this podcast.

2:58:49.400 --> 2:58:52.600
 And now, let me leave you with some words from Plato.

2:58:52.600 --> 2:58:55.720
 We can easily forgive a child who's afraid of the dark.

2:58:55.720 --> 2:59:00.920
 The real tragedy of life is when men are afraid of the light.

2:59:00.920 --> 2:59:07.080
 Thank you for listening, and hope to see you next time.

