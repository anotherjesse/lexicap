WEBVTT

00:00.000 --> 00:03.360
 The following is a conversation with Norman Neymarck,

00:03.360 --> 00:07.800
 a historian at Stanford specializing in genocide, war,

00:07.800 --> 00:09.400
 and empire.

00:09.400 --> 00:11.600
 This is the Lex Friedman podcast.

00:11.600 --> 00:13.880
 To support it, please check out our sponsors

00:13.880 --> 00:15.040
 in the description.

00:15.040 --> 00:18.960
 And now, here's my conversation with Norman Neymarck.

00:20.160 --> 00:22.480
 Did Stalin believe that communism is good,

00:22.480 --> 00:25.400
 not just for him, but for the people of the Soviet Union

00:25.400 --> 00:26.960
 and the people of the world?

00:26.960 --> 00:31.720
 Oh, absolutely. I mean, Stalin believed that socialism

00:31.720 --> 00:36.840
 was the be all and end all of human existence.

00:36.840 --> 00:38.480
 I mean, he was a true Leninist.

00:38.480 --> 00:43.200
 And in Lenin's tradition, this was what he believed.

00:43.200 --> 00:46.880
 I mean, that set of beliefs didn't exclude other kinds

00:46.880 --> 00:49.880
 of things he believed or thought or did.

00:49.880 --> 00:53.920
 But no, the way he defined socialism,

00:53.920 --> 00:56.040
 the way he thought about socialism,

00:56.040 --> 00:57.720
 he absolutely thought it was the interests

00:57.720 --> 00:59.800
 of the Soviet Union and of the world.

00:59.800 --> 01:01.720
 And in fact, that the world was one day

01:01.720 --> 01:03.320
 going to go socialist.

01:03.320 --> 01:05.840
 In other words, I think he believed in that.

01:05.840 --> 01:08.200
 And eventually in the international revolution.

01:09.240 --> 01:13.840
 So given the genocide in the 1930s that you described,

01:13.840 --> 01:17.400
 was Stalin evil, delusional, or incompetent?

01:20.040 --> 01:22.480
 Evil, delusional, or incompetent.

01:22.480 --> 01:25.720
 Well, evil is one of those words,

01:25.720 --> 01:30.720
 which has a lot of kind of religious and moral connotations.

01:30.720 --> 01:33.320
 And in that sense, yes, I think he was an evil man.

01:33.320 --> 01:38.320
 I mean, he eliminated people absolutely unnecessarily.

01:38.720 --> 01:42.120
 He tortured people, had people tortured.

01:43.040 --> 01:48.040
 He was completely indifferent to the suffering of others.

01:48.400 --> 01:53.400
 He couldn't have cared a wit that millions were suffering.

01:53.400 --> 01:57.320
 And so, yes, I consider him an evil man.

01:57.320 --> 02:00.680
 I mean, historians don't like to use the word evil.

02:00.680 --> 02:04.040
 Use the word evil, it's a word for moral philosophers,

02:04.040 --> 02:09.040
 but I think it certainly fits who he is.

02:10.160 --> 02:12.640
 I think he was delusional.

02:12.640 --> 02:16.640
 And there is a wonderful historian in Princeton,

02:16.640 --> 02:19.240
 a political scientist actually named Robert Tucker,

02:19.240 --> 02:23.360
 who said he suffered from a parent of a child

02:23.360 --> 02:26.480
 paranoid delusional system.

02:26.480 --> 02:30.360
 And I always remember that of Tucker's writing

02:30.360 --> 02:35.280
 because what Tucker meant is that he was not just paranoid,

02:35.280 --> 02:39.960
 meaning, I'm paranoid, I'm worried you're out to get me, right?

02:39.960 --> 02:44.960
 But that he constructed whole plots of people,

02:47.480 --> 02:51.360
 whole systems of people who were out to get him.

02:51.360 --> 02:53.520
 So in other words, his delusions

02:53.520 --> 02:56.560
 were that there were all of these groups of people out there

02:58.040 --> 03:00.680
 who were out to diminish his power

03:00.680 --> 03:04.440
 and remove him from his position

03:04.440 --> 03:07.400
 and undermine the Soviet Union in his view.

03:07.400 --> 03:12.400
 So yes, I think he did suffer from delusions.

03:12.840 --> 03:16.880
 And this had a huge effect because whole groups then

03:16.880 --> 03:20.960
 were destroyed by his activities,

03:20.960 --> 03:25.960
 which he would construct based on these delusions.

03:26.160 --> 03:27.400
 He was not incompetent.

03:27.400 --> 03:29.360
 He was an extremely competent man.

03:29.360 --> 03:32.720
 I mean, I think most of the research that's got on,

03:32.720 --> 03:36.880
 especially since the Stalin archive was opened

03:36.880 --> 03:38.840
 at the beginning of the century.

03:38.840 --> 03:40.520
 And I think almost every historian

03:40.520 --> 03:42.840
 who goes in that archive comes away from it

03:42.840 --> 03:47.840
 with the feeling of a man who is enormously hardworking,

03:47.840 --> 03:51.920
 intelligent, with an acute sense of politics,

03:51.920 --> 03:56.920
 a really excellent sense of political rhetoric,

03:58.120 --> 04:02.200
 a fantastic editor, in a kind of agitational sense.

04:02.200 --> 04:04.520
 I mean, he's a real agitator, right?

04:04.520 --> 04:09.320
 And of a really hard worker.

04:09.320 --> 04:11.920
 I mean, somebody who works from morning till night,

04:11.920 --> 04:14.760
 a micromanager in some ways.

04:14.760 --> 04:17.880
 So his competence, I think was really extreme.

04:17.880 --> 04:20.760
 Now there were times when that fell down,

04:20.760 --> 04:23.560
 times in the 30s, times in the 20s,

04:23.560 --> 04:26.240
 times during the war where he made mistakes.

04:26.240 --> 04:28.960
 It's not as if he didn't make any mistakes.

04:28.960 --> 04:31.520
 But I think, you look at his stuff,

04:31.520 --> 04:34.160
 you look at his archives, you look what he did.

04:34.160 --> 04:36.760
 I mean, this is an enormously competent man

04:36.760 --> 04:41.360
 who in many, many different areas of enterprise,

04:41.360 --> 04:43.600
 because he had this notion

04:43.600 --> 04:46.640
 that he should know everything and did know everything.

04:46.640 --> 04:50.640
 I remember one archive in the Elads called,

04:50.640 --> 04:52.360
 you know, a kind of folder that I looked at

04:52.360 --> 04:56.280
 where he actually went through the wines

04:56.280 --> 04:59.480
 that were produced in his native Georgia

04:59.480 --> 05:03.360
 and wrote down how much they should make

05:03.360 --> 05:05.080
 of each of these wines, you know,

05:05.080 --> 05:10.080
 how many barrels they should produce of these wines,

05:10.080 --> 05:12.200
 which grapes were better than the other grapes,

05:12.200 --> 05:14.320
 sort of correcting, in other words,

05:14.320 --> 05:16.680
 what people were putting down there.

05:16.680 --> 05:20.840
 So he was, you know, his competence ranged very wide

05:20.840 --> 05:23.440
 or at least he thought his competence ranged very wide.

05:23.440 --> 05:25.720
 I mean, both things, I think, are the case.

05:25.720 --> 05:27.840
 If we look at this paranoid delusional system,

05:27.840 --> 05:29.880
 Stalin was in power for 30 years.

05:31.280 --> 05:34.960
 He is, many argue, one of the most powerful men in history.

05:36.640 --> 05:38.600
 In his case, absolute power corrupt him

05:38.600 --> 05:40.920
 or did it reveal the true nature of the man?

05:40.920 --> 05:43.480
 And maybe just in your sense,

05:43.480 --> 05:45.560
 as we kind of build around this genocide

05:45.560 --> 05:50.320
 of the early 1930s, this paranoid delusional system,

05:50.320 --> 05:52.760
 did it get built up over time?

05:52.760 --> 05:54.600
 Was it always there?

05:54.600 --> 05:59.600
 It's kind of a question of did the genocide,

06:00.280 --> 06:03.240
 was that always inevitable, essentially, in this man

06:03.240 --> 06:05.920
 or did power create that?

06:05.920 --> 06:08.480
 I mean, it's a great question and I don't think you can,

06:08.480 --> 06:11.080
 I don't think you can say that it was always

06:12.240 --> 06:14.480
 kind of inherent in the man.

06:14.480 --> 06:18.720
 I mean, the man without his position and without his power,

06:18.720 --> 06:21.040
 you know, wouldn't have been able to accomplish

06:21.040 --> 06:25.040
 what he eventually did in the way of murdering people,

06:25.040 --> 06:26.560
 you know, and murdering groups of people,

06:26.560 --> 06:28.840
 which is what genocide is.

06:28.840 --> 06:32.720
 So, you know, I don't, it wasn't sort of in him.

06:32.720 --> 06:34.160
 I mean, there were, and again, you know,

06:34.160 --> 06:37.000
 the new research has shown that, you know,

06:37.000 --> 06:39.560
 he had his childhood was, you know,

06:39.560 --> 06:42.280
 not a particularly nasty one.

06:42.280 --> 06:45.760
 And people used to say, you know, the father beat him up

06:45.760 --> 06:47.520
 and it turns out actually it wasn't the father,

06:47.520 --> 06:49.360
 it was the mother once in a while.

06:49.360 --> 06:53.440
 But basically, you know, he was not an unusual young

06:53.440 --> 06:56.960
 Georgian kid or student even.

06:56.960 --> 07:01.080
 And, you know, it was the growth of the Soviet system

07:01.080 --> 07:04.720
 and him within the Soviet system.

07:04.720 --> 07:07.800
 I mean, his own development within the Soviet system,

07:07.800 --> 07:12.800
 I think that led, you know, to the kind of mass killing

07:13.040 --> 07:15.400
 that occurred in the 1930s.

07:16.360 --> 07:19.720
 You know, he essentially achieved complete power

07:19.720 --> 07:22.480
 by the early 1930s.

07:22.480 --> 07:26.520
 And then as he rolled with it, as you would say,

07:26.520 --> 07:30.000
 you know, or people would say, you know,

07:30.000 --> 07:32.440
 it increasingly became murderous.

07:32.440 --> 07:35.560
 And there was no, you know,

07:35.560 --> 07:37.600
 there were no checks and balances, obviously,

07:37.600 --> 07:39.600
 on that murderous system.

07:39.600 --> 07:42.840
 And not only that, you know, people supported it

07:42.840 --> 07:44.640
 in the NKVD and elsewhere.

07:44.640 --> 07:46.560
 And he learned how to manipulate people.

07:46.560 --> 07:49.360
 I mean, he was a superb, you know,

07:49.360 --> 07:54.360
 political manipulator of those people around him.

07:54.360 --> 07:59.360
 And, you know, we have, we've got new transcripts,

07:59.360 --> 08:01.720
 we've got new transcripts, for example,

08:01.720 --> 08:05.840
 of, you know, a police bureau meetings in the early 1930s.

08:05.840 --> 08:07.000
 And you read those things.

08:07.000 --> 08:12.000
 And, you know, he uses humor and he uses sarcasm,

08:12.000 --> 08:16.880
 especially he uses verbal ways to undermine people,

08:16.880 --> 08:20.760
 you know, to control their behavior and what they do.

08:20.760 --> 08:25.440
 And he's a really, you know, he's a real,

08:25.440 --> 08:27.360
 I guess, manipulator is the right word.

08:27.360 --> 08:32.360
 And he does it, he does it with, you know, a kind of skill.

08:33.320 --> 08:36.080
 Now, on the one hand is admirable.

08:36.080 --> 08:39.920
 And on the other hand, of course, is terrible

08:39.920 --> 08:43.160
 because it ends up, you know, creating the system

08:44.160 --> 08:46.480
 of terror that he creates.

08:48.120 --> 08:50.680
 I mean, I guess just to linger on it,

08:50.680 --> 08:53.240
 I just wonder how much of it is a slippery slope

08:53.240 --> 08:57.480
 in the early 20s, 1920s,

08:57.480 --> 08:59.440
 did he think he was going to be murdering

08:59.440 --> 09:04.440
 even a single person but thousands and millions?

09:06.080 --> 09:07.360
 I just wonder,

09:10.760 --> 09:14.080
 maybe the murder of a single human being,

09:14.080 --> 09:17.760
 just to get them, you know, because you're paranoid

09:17.760 --> 09:19.920
 about them potentially threatening your power,

09:19.920 --> 09:22.240
 does that murder and open a door?

09:22.240 --> 09:23.960
 And once you open the door,

09:23.960 --> 09:25.960
 you become a different human being.

09:25.960 --> 09:29.040
 A deeper question here is the Solzhenitsyn,

09:29.040 --> 09:32.120
 you know, the line between good and evil runs in every man.

09:32.120 --> 09:35.760
 Are all of us, once we commit one murder in the situation,

09:35.760 --> 09:38.040
 does that open a door for all of us?

09:38.040 --> 09:41.760
 And I guess even the further deeper question is,

09:41.760 --> 09:45.400
 how easy it is for human nature to go

09:45.400 --> 09:49.040
 under the slippery slope that ends in genocide?

09:49.040 --> 09:52.360
 There are a lot of questions in those questions.

09:52.360 --> 09:55.880
 And, you know, the slippery slope question,

09:55.880 --> 09:59.120
 I would answer, I suppose by saying,

10:00.160 --> 10:04.080
 you know, Stalin wasn't the most likely successor of Lenin,

10:04.080 --> 10:06.000
 there were plenty of others.

10:06.000 --> 10:09.600
 There were a lot of political contingencies

10:09.600 --> 10:12.640
 that emerged in the 1920s

10:12.640 --> 10:16.600
 that made it possible for Stalin to seize power.

10:16.600 --> 10:19.800
 I don't think of him as, you know,

10:19.800 --> 10:22.800
 if you would just know him in 1925,

10:22.800 --> 10:25.880
 I don't think anybody would say much less himself

10:25.880 --> 10:28.760
 that this was a future mass murderer.

10:28.760 --> 10:30.960
 I mean, Trotsky mistrusted him

10:30.960 --> 10:35.960
 and thought he was, you know, a mindless bureaucrat.

10:36.320 --> 10:39.480
 You know, others were less mistrustful of him,

10:39.480 --> 10:41.720
 but, you know, he managed to gain power

10:41.720 --> 10:43.560
 in the way he did through this bureaucratic

10:43.560 --> 10:47.920
 and political maneuvering that was very successful.

10:49.000 --> 10:51.960
 You know, the slippery slope, as it were,

10:51.960 --> 10:55.560
 doesn't really begin until the 1930s, in my view.

10:55.560 --> 10:58.840
 In other words, once he gains complete power

10:58.840 --> 11:01.320
 in control of the Politburo,

11:01.320 --> 11:05.840
 once the programs that he institutes

11:05.840 --> 11:10.080
 of the five year plan and collectivization go through,

11:10.080 --> 11:14.000
 once he reverses himself and is able to reverse himself

11:14.000 --> 11:17.120
 or reverse the Soviet path, you know,

11:17.120 --> 11:20.520
 to give various nationalities their, you know,

11:20.520 --> 11:22.920
 their ability to develop their own cultures

11:22.920 --> 11:26.600
 and sort of internal politics,

11:26.600 --> 11:28.960
 once he reverses all that, you know,

11:28.960 --> 11:32.160
 you have the Ukrainian famine in 32, 33,

11:32.160 --> 11:34.400
 you have the murder of Kirov,

11:34.400 --> 11:38.040
 who was one of the leading figures, you know,

11:38.040 --> 11:41.120
 in the political system, you have the suicide of his wife,

11:41.120 --> 11:45.520
 you have all these things come together in 32, 33,

11:45.520 --> 11:50.520
 that then, you know, make it more likely,

11:50.640 --> 11:53.440
 in other words, that bad things are gonna happen.

11:54.440 --> 11:57.800
 And people start seeing that, too, around him.

11:57.800 --> 12:00.920
 They start seeing that it's not a slippery slope,

12:00.920 --> 12:05.920
 it's a dangerous, it's a dangerous situation

12:05.920 --> 12:09.840
 which is emerging and some people really understand that.

12:09.840 --> 12:12.960
 So I don't, I really do see a differentiation

12:12.960 --> 12:14.440
 then between the 20s.

12:14.440 --> 12:17.160
 I mean, it's true that Stalin during the Civil War,

12:17.160 --> 12:19.840
 there's a lot of, you know, good research on that,

12:21.040 --> 12:24.920
 you know, shows that he already had some of these characteristics

12:24.920 --> 12:29.400
 of being, as it were, murderous and being, you know,

12:29.400 --> 12:33.760
 being dictatorial and pushing people around

12:33.760 --> 12:36.480
 and that sort of thing, that was all there.

12:36.480 --> 12:40.640
 But I don't really see that as kind of the necessary stage

12:40.640 --> 12:43.360
 for the next thing that came, which was the 30s,

12:43.360 --> 12:46.920
 which was really terror of the worst sort, you know,

12:46.920 --> 12:49.160
 where everybody's afraid for their lives

12:49.160 --> 12:51.440
 and most people are afraid for their lives

12:51.440 --> 12:54.240
 and their family's lives and where torture

12:54.240 --> 12:57.320
 and that sort of thing becomes a common part, you know,

12:57.320 --> 13:00.160
 of what people had to face.

13:00.160 --> 13:02.960
 So it's a different world.

13:02.960 --> 13:04.720
 And, you know, people will argue,

13:04.720 --> 13:10.120
 they'll argue this kind of Lenin, Stalin continuity debate,

13:10.120 --> 13:12.720
 you know, that's been going on since I was an undergraduate,

13:12.720 --> 13:14.680
 you know, that argument, you know,

13:14.680 --> 13:19.000
 was Stalin the natural sort of next step from Lenin

13:19.000 --> 13:21.080
 or was he something completely different?

13:22.920 --> 13:24.280
 Many people will argue, you know,

13:24.280 --> 13:27.640
 because of Marxism, Leninism, because of the ideology

13:27.640 --> 13:30.720
 that, you know, it was the next natural,

13:30.720 --> 13:32.560
 it was a kind of natural next step.

13:32.560 --> 13:34.200
 I don't think so, you know,

13:34.200 --> 13:37.080
 and I would tend to lean the other way, not absolutely.

13:37.080 --> 13:39.960
 I mean, I won't make an absolute argument

13:39.960 --> 13:43.360
 that what Stalin became had nothing to do with Lenin

13:43.360 --> 13:44.880
 and nothing to do with Marxism.

13:44.880 --> 13:47.240
 Leninism had a lot to do with it.

13:47.240 --> 13:51.400
 But, you know, he takes it one major step further.

13:51.400 --> 13:53.640
 And again, that's why I don't like the slippery slope,

13:53.640 --> 13:57.120
 you know, metaphor, because that means it's kind of slow and easy.

13:57.120 --> 13:58.720
 It's a leap.

13:58.720 --> 14:01.160
 And we call, you know, I mean, historians talk

14:01.160 --> 14:05.240
 about the Stalin Revolution, you know, in 28 and 29,

14:05.240 --> 14:08.760
 you know, that he, in some senses,

14:08.760 --> 14:11.440
 creates a whole new system, you know,

14:11.440 --> 14:14.160
 through the five year plan collectivization

14:14.160 --> 14:16.560
 and seizing political power the way he does.

14:17.680 --> 14:19.320
 Can you talk about the 1930s?

14:19.320 --> 14:21.520
 Can you describe what happened in Haldemur,

14:21.520 --> 14:25.080
 the Soviet terror famine in Ukraine in the 32 and 33?

14:25.080 --> 14:25.920
 Yes.

14:25.920 --> 14:27.080
 That killed millions of Ukrainians.

14:27.080 --> 14:27.920
 Right.

14:27.920 --> 14:29.560
 It's a long story, you know,

14:29.560 --> 14:33.960
 but let me try to be as succinct as I can be.

14:33.960 --> 14:40.040
 I mean, the Haldemur, the terror famine of 32, 33,

14:40.040 --> 14:45.960
 comes out of, in part, an all union famine

14:45.960 --> 14:49.680
 that is the result of collectivization.

14:49.680 --> 14:52.960
 You know, collectivization was a catastrophe.

14:52.960 --> 14:55.880
 You know, the more or less of the so called Kulaks,

14:55.880 --> 14:57.840
 the more or less richer farmers,

14:57.840 --> 15:00.080
 I mean, they weren't really rich, right?

15:00.080 --> 15:03.040
 Anybody with a tin roof and a cow was considered a Kulak,

15:03.040 --> 15:04.960
 you know, and other people who had nothing

15:04.960 --> 15:06.280
 were also considered Kulaks

15:06.280 --> 15:09.040
 if they opposed collectivization.

15:09.040 --> 15:12.240
 So these Kulaks, we're talking millions of them, right?

15:12.240 --> 15:16.360
 And Ukraine, it's worth recalling and I'm sure you know this,

15:16.360 --> 15:19.200
 was a, you know, heavily agricultural area

15:19.200 --> 15:22.400
 and Ukrainian peasants, you know,

15:22.400 --> 15:26.960
 were on in the countryside and resisted collectivization

15:26.960 --> 15:32.920
 more than even Russian peasants resisted collectivization,

15:32.920 --> 15:35.280
 suffered during this collectivization program

15:35.280 --> 15:38.400
 and they, you know, burned sometimes their own houses,

15:38.400 --> 15:43.280
 they killed their own animals, they were shot, you know,

15:43.280 --> 15:46.040
 sometimes on the spot,

15:46.040 --> 15:49.840
 tens of thousands and others were sent into exile.

15:49.840 --> 15:53.320
 So there was a conflagration in the countryside

15:53.320 --> 15:56.040
 and the result of that conflagration in Ukraine

15:56.040 --> 15:57.920
 was terrible famine.

15:57.920 --> 16:00.840
 And again, there was famine all over the Soviet Union,

16:00.840 --> 16:05.160
 but it was especially bad in Ukraine in part

16:05.160 --> 16:07.720
 because Ukrainian peasants resisted.

16:07.720 --> 16:12.200
 Now, in 3233, a couple of things happened.

16:12.200 --> 16:16.120
 I mean, I've argued this in my writing and, you know,

16:16.120 --> 16:19.240
 I've also worked on this, I continue to work on it,

16:19.240 --> 16:23.120
 by the way, with a museum in Kiev

16:23.120 --> 16:25.320
 that's going to be about the Holodomor.

16:25.320 --> 16:27.320
 They're building the museum now

16:27.320 --> 16:31.880
 and it's going to be a very impressive set of exhibits

16:31.880 --> 16:34.120
 and talk with historians all the time about it.

16:34.120 --> 16:37.240
 So what happens in 3233 at a couple of things?

16:37.240 --> 16:45.000
 First of all, the Stalin develops an even stronger,

16:45.000 --> 16:46.040
 I say even stronger,

16:46.040 --> 16:49.080
 because they already had an antipathy for the Ukrainians,

16:49.080 --> 16:52.920
 an even stronger antipathy for the Ukrainians in general.

16:52.920 --> 16:55.800
 First of all, they resist collectivization.

16:55.800 --> 17:00.360
 Second of all, he's not getting all the grain he wants out of them

17:00.360 --> 17:01.880
 and which he needs.

17:01.880 --> 17:06.920
 And so he sends in, then, people to expropriate the grain

17:06.920 --> 17:09.320
 and take the grain away from the peasants.

17:09.320 --> 17:12.680
 These teams of people, you know, some policemen,

17:12.680 --> 17:16.440
 some urban thugs, some party people,

17:16.440 --> 17:19.240
 some poor peasants, you know, take part too,

17:19.240 --> 17:23.880
 go into the villages and forcibly seize grain

17:23.880 --> 17:28.360
 and animals from the Ukrainian peasantry.

17:28.360 --> 17:29.800
 They're seizing it all over.

17:29.800 --> 17:30.840
 I mean, let's remember again,

17:30.840 --> 17:34.520
 this is all over the Soviet Union in 32, especially.

17:36.520 --> 17:42.360
 Then, you know, in December of 1932, January of 33,

17:42.360 --> 17:47.560
 February of 33, Stalin has convinced the Ukrainian peasantry

17:47.560 --> 17:51.240
 needs to be shown whose boss,

17:52.840 --> 17:54.600
 that they're not turning over their grain,

17:55.480 --> 17:57.720
 that they're resisting the expropriators,

17:57.720 --> 18:00.520
 that they're hiding the grain, which they do sometimes, right?

18:01.400 --> 18:05.480
 That they're basically not loyal to the Soviet Union,

18:05.480 --> 18:08.120
 that they're acting like traitors, that they're ready,

18:08.680 --> 18:11.240
 and he says this, you know, I think it's Kaganovich,

18:11.240 --> 18:14.040
 he says it too, you know, they're ready to kind of pull out

18:14.040 --> 18:15.720
 of the Soviet Union and join Poland.

18:15.720 --> 18:19.480
 I mean, he thinks Poland is, you know, out to get Ukraine,

18:20.280 --> 18:23.880
 and so he's gonna then essentially break the back of these peasantry

18:23.880 --> 18:28.280
 and the way he breaks their back is by going through

18:28.280 --> 18:30.360
 another expropriation program,

18:30.360 --> 18:33.240
 which is not done in the rest of the Soviet Union.

18:33.240 --> 18:37.080
 So he's taking away everything they have, everything they have.

18:38.120 --> 18:42.680
 Their new laws introduced where they will actually punish people,

18:42.680 --> 18:47.400
 including kids, with death if they steal any grain,

18:47.400 --> 18:50.520
 you know, if they take anything from the, you know, from the fields.

18:51.080 --> 18:55.720
 So, you know, you can shoot anybody, you know, who is looking for food.

18:55.720 --> 18:58.600
 And then he introduces measures in Ukraine,

18:58.600 --> 19:02.120
 which are not introduced into the rest of the Soviet Union.

19:02.120 --> 19:05.800
 For example, Ukrainian peasantry are not allowed

19:05.800 --> 19:07.640
 to leave their villages anymore.

19:08.760 --> 19:11.000
 They can't go to the city to try to find some things.

19:11.000 --> 19:13.880
 I mean, we've got pictures of, you know, Ukrainian peasants

19:14.440 --> 19:19.400
 dying on the sidewalks and Kharkiv and Kyiv and places like that,

19:19.400 --> 19:21.880
 who've managed to get out of the village and get to the cities.

19:21.880 --> 19:23.080
 But now they can't leave.

19:23.880 --> 19:29.480
 They can't leave Ukraine to go to Belarus, or Belarus today,

19:29.480 --> 19:32.040
 or to Russia, you know, to get any food.

19:32.680 --> 19:36.680
 There's no, he won't allow any relief to Ukraine.

19:36.680 --> 19:39.480
 Number of people offer relief, including the Poles,

19:39.480 --> 19:41.320
 but also the Vatican offers relief.

19:41.960 --> 19:44.360
 He won't allow any relief to Ukraine.

19:44.360 --> 19:46.600
 He won't admit that there's a famine in Ukraine.

19:47.160 --> 19:52.520
 And instead, what happens is that Ukraine turns into,

19:52.520 --> 19:56.680
 the Ukrainian countryside turns into what my now

19:58.200 --> 20:00.520
 past colleague who died several years ago,

20:00.520 --> 20:03.640
 Robert Conquest called a vast belson.

20:04.360 --> 20:07.720
 And by that, you know, the images of bodies just lying everywhere,

20:07.720 --> 20:14.920
 you know, people dead and dying, you know, of hunger, which is,

20:15.960 --> 20:19.240
 by the way, I mean, as you know, I've spent a lot of time

20:19.880 --> 20:20.680
 studying genocide.

20:20.680 --> 20:23.320
 I don't think there's anything worse than dying of hunger

20:23.320 --> 20:24.360
 from what I have read.

20:24.360 --> 20:26.840
 I mean, you see terrible ways that people die, right?

20:27.400 --> 20:31.560
 But dying of hunger is just such a horrible, horrible thing.

20:31.560 --> 20:36.120
 And so, for example, we know there were many cases of

20:36.120 --> 20:39.080
 cannibalism in the countryside because there wasn't anything to eat.

20:39.080 --> 20:42.120
 People were eating their own kids, right?

20:42.120 --> 20:43.400
 And Stalin knew about this.

20:43.400 --> 20:46.680
 And again, you know, we started with this question a little bit earlier.

20:48.360 --> 20:54.200
 There's not a sign of remorse, not a sign of pity, right?

20:54.200 --> 21:01.480
 Not a sign of any kind of human emotion that normal people would have.

21:01.480 --> 21:07.400
 What about the opposite of joy for teaching them a lesson?

21:08.120 --> 21:09.400
 I don't think there's joy.

21:09.400 --> 21:14.840
 I'm not sure Stalin really understood what joy was, you know.

21:16.120 --> 21:21.720
 I think he felt it was necessary to get those SOBs, right?

21:21.720 --> 21:22.920
 That they deserved it.

21:23.480 --> 21:24.760
 He says that several times.

21:24.760 --> 21:26.520
 This is their own fault, right?

21:26.520 --> 21:27.560
 This is their own fault.

21:27.560 --> 21:33.560
 And as their own fault, you know, they get what they deserve.

21:35.000 --> 21:35.880
 Basically.

21:35.880 --> 21:37.240
 How much was the calculation?

21:37.240 --> 21:39.560
 How much was the reason versus emotion?

21:41.400 --> 21:44.440
 In terms of, you said he was competent.

21:45.560 --> 21:50.840
 Was there a long term strategy or was this strategy based on emotion and anger?

21:51.480 --> 21:55.400
 No, I think actually the right answer is a little of both.

21:55.400 --> 21:58.200
 I mean, usually the right answer in history is something like that.

21:58.200 --> 21:58.200
 A little.

21:58.200 --> 22:03.320
 No, you can't, you can't, it wasn't just, I mean, first of all, you know,

22:03.320 --> 22:10.120
 the Soviets had it in for Ukraine and Ukrainian nationalism, which they really didn't like.

22:11.080 --> 22:13.480
 And by the way, Russians still don't like it, right?

22:14.680 --> 22:17.080
 So they had it in for Ukrainian nationalism.

22:17.080 --> 22:19.880
 They feared Ukrainian nationalism.

22:19.880 --> 22:45.880
 As I said, you know, Stalin, Stalin writes, you know, we'll, we'll lose Ukraine, you know, if these guys win, you know, so there's a kind of long term determination, as I said, you know, to kind of break the back of Ukrainian national identity and Ukrainian nationalism as any kind of separatist force whatsoever.

22:45.880 --> 22:49.880
 And so there's that rational calculation at the same time.

22:49.880 --> 23:11.880
 I think Stalin is annoyed and peeved and angry on one level with the Ukrainians for resisting collectivization and for being difficult and for not, you know, not conforming, you know, to the way he thinks peasants should act in this situation.

23:11.880 --> 23:21.880
 So you have both things. He's also very angry at the Ukrainian party and eventually purges it for not being able to control Ukraine and not be able to control the situation.

23:23.880 --> 23:35.880
 You know, Ukraine is in theory the bread basket, right? Of Europe. Well, well, how come the bread basket isn't turning over to me all this grain so I can sell it abroad and, and, you know, build new factories and support the workers in the cities.

23:35.880 --> 23:49.880
 So there's a kind of a nuance, you know, when things fail, and this is absolutely typical of Stalin, when things fail, he blames it on other people and usually groups of people, right? Not individuals, but groups again.

23:49.880 --> 23:53.880
 So a little bit of both, I think is the right answer.

23:53.880 --> 24:09.880
 This blame, it feels like there's a playbook that dictators follow. I just wonder if it comes naturally or just kind of evolves. It's, you know, blaming others and then telling these narratives and then creating the other and then somehow at least a hatred and genocide.

24:09.880 --> 24:19.880
 It feels like, like there's too many commonalities for it not to be a naturally emergent strategy that works for dictatorships.

24:19.880 --> 24:34.880
 I mean, that's a good, it's a very good point. And I think it's one, you know, that, you know, has its merits. In other words, I think you're right that there's certain kinds of strategies by dictators that, you know, are common to them.

24:34.880 --> 24:51.880
 A lot of them do killing, not all of them, of that sort that Stalin did. I've written about Mao and Paul Pot and, you know, and Hitler and, you know, there is a sort of, as you say, a kind of playbook for political dictatorship.

24:51.880 --> 25:05.880
 It's also for, you know, a kind of communist totalitarian way of functioning, you know, and that that way of functioning was described already by Hannah Arendt early on when she wrote the Origins of Totalitarianism.

25:05.880 --> 25:20.880
 And she more or less writes the playbook and Stalin does follow it. The real question and it seems to me is to what extent, you know, and how deep does this go and how often does it go in that direction.

25:20.880 --> 25:29.880
 I mean, you can, you can argue, for example, I mean, Fidel Castro was not a nice man, right? He was a dictator. He was a terrible dictator.

25:29.880 --> 25:46.880
 But he did not engage in mass murder. Ho Chi Minh was a dictator, a communist dictator who grew up, you know, in the communist movement, went to Moscow, you know, spent time in Moscow in the 30s and went to find, found the, the Vietnamese Communist Party.

25:46.880 --> 25:54.880
 You know, he was a horrible dictator. I'm sure he was responsible for a lot of death and destruction, but he wasn't a mass murderer.

25:54.880 --> 26:08.880
 And so you get those, you know, I mean, I would even argue others, others will disagree that Lenin wasn't a mass murderer, you know, that he didn't, he didn't kill the same way, you know, that Stalin killed or people after him.

26:08.880 --> 26:22.880
 They're communist dictators too, after all, Khrushchev, well, was a communist dictator, but he stopped this killing. And, you know, he's still responsible for a gulag and people sending us sent off into a gulag and imprisonment and torture and that sort of thing.

26:22.880 --> 26:37.880
 But it's not at all the same thing. So there are some, you know, like Stalin, like Mao, like Paul Pot, you know, who commit these horrible, horrible atrocities, extensively engaging in my view.

26:37.880 --> 26:53.880
 In genocide. And there's some who don't. And, you know, what's, what's the difference? Well, you know, the difference is partly in personality, partly in historical circumstance, you know, partly in, you know, who is it that controls the reins of power?

26:53.880 --> 27:08.880
 How much do you connect the ideas of communism or Marxism or socialism to how the more to Stalin's rule? So how natural is he kind of alluded to? Does it lead to genocide?

27:08.880 --> 27:24.880
 That's also, I mean, in some ways, I've just addressed that question by saying it doesn't always lead to genocide. You know, in the case, again, you know, Cuba is not pretty. But it didn't have, there was no genocide in Cuba.

27:24.880 --> 27:39.880
 And same thing in North Vietnam. You know, even North Korea, as awful as it is, as terrible dictatorship, right? And people's rights are totally destroyed, right? They have no freedom whatsoever.

27:39.880 --> 27:49.880
 You know, is not as far as we know, genocidal. Who knows whether it could be or whether if they took over South Korea, you know, mass murder wouldn't take place and that kind of thing.

27:49.880 --> 28:04.880
 But my point is, is that the ideology doesn't necessarily dictate genocide. In other words, it's an ideology, I think, that makes genocide sometimes too easily possible.

28:04.880 --> 28:16.880
 Given, you know, the way it thinks through history as being, you know, you're on the right side of history and some people are on the wrong side of history, and you have to destroy those people who are on the wrong side of history.

28:16.880 --> 28:30.880
 I mean, there is something in, you know, Marxism, Leninism, which, which, you know, has that kind of language and that kind of thinking. But I don't think it's necessarily that way.

28:30.880 --> 28:53.880
 There's a wonderful historian at Berkeley named Martin Malia, who has written, you know, wrote a number of books on this subject, and he was very, very, he was very, he was convinced that the, you know, that the ideology itself, you know, played a crucial role in the murderousness of the Soviet regime.

28:53.880 --> 29:04.880
 I'm not completely convinced, you know, when I say not completely convinced, I think there are, you could argue it different ways, equally, you know, with equally valid arguments.

29:04.880 --> 29:18.880
 I mean, there's something about the ideology of communism that allows you to decrease the value of human life, almost like this philosophy, if it's okay to crack a few eggs to make an omelet.

29:18.880 --> 29:19.880
 Right.

29:19.880 --> 29:30.880
 And maybe that, if you can reason like that, then it's easier to take the leap of for the good of the country, for the good of the people, for the good of the world, it's okay to kill a few people.

29:30.880 --> 29:36.880
 And then that's where I, I, I wonder about the slippery slope.

29:36.880 --> 29:43.880
 Yeah, no, no, again, you know, I don't think it's a slippery slope. I think it's, I think it's dangerous.

29:43.880 --> 29:51.880
 No, there's, I think it's dangerous, but I don't, I don't consider, you know, I don't like Marxism, but there's many better than the next guy.

29:51.880 --> 30:11.880
 And I've lived in plenty of those systems to know how they can beat people down and how they can, you know, destroy human aspirations and human interaction between people, but they're not necessarily murderous systems.

30:11.880 --> 30:21.880
 They are systems that contain people's autonomy, that force people to, into work and labor and lifestyles that they don't want to live.

30:21.880 --> 30:40.880
 I spent a lot of time, you know, with, with East Germans and Poles, you know, who lived in and even, and even in the Soviet Union, you know, when the post Stalin period, where people lived lives, they didn't want to live, you know, and, and had, didn't have the freedom to choose.

30:40.880 --> 30:46.880
 And that was terrifying in and of itself, but these were not murderous systems.

30:46.880 --> 30:51.880
 And they, and they, and they, and they, you know, ascribe to Marxism.

30:51.880 --> 31:02.880
 So I suppose it's important to draw the line between mass murder and genocide and mass murder versus just mass violation of human rights.

31:02.880 --> 31:03.880
 Right.

31:03.880 --> 31:04.880
 Right.

31:04.880 --> 31:17.880
 And the leap to mass murder, you're saying maybe easier in some ideologies than others, but it's not clear that somehow one ideology definitely leads to mass murder and not exact.

31:17.880 --> 31:23.880
 I wonder how many factors, what factors, how much of it is a single charismatic leader?

31:23.880 --> 31:37.880
 How much of it is the conflagration of multiple historical events? How much of it is just dumb, the opposite of luck?

31:37.880 --> 31:48.880
 Do you have a sense where if you look at a moment in history, predict, looking at the factors, whether something bad is going to happen here?

31:48.880 --> 31:59.880
 When you look at Iraq, when Saddam Hussein first took power, well, you could, or you can, you know, go even farther back in history, would you be able to predict?

31:59.880 --> 32:06.880
 So you said, you already kind of answered that was Stalin saying there's no way you could have predicted that in the early 20s.

32:06.880 --> 32:08.880
 Is that always the case? You basically can't predict.

32:08.880 --> 32:10.880
 It's pretty much always the case.

32:10.880 --> 32:22.880
 In other words, I mean, history is a wonderful, you know, discipline and way of looking at life in the world in retrospect, meaning it happened. It happened.

32:22.880 --> 32:33.880
 And we know it happened. And it's too easy to say sometimes it happened because it had to happen that way. It almost never has to happen that way.

32:33.880 --> 32:57.880
 And, you know, things. So I very much am of the school that emphasizes, you know, contingency and choice and difference and different paths and not, you know, not necessarily a path that has to be, it has to be followed.

32:57.880 --> 33:05.880
 And, you know, sometimes you can, you can, you can warn about things. I mean, you can think while something's going to happen.

33:05.880 --> 33:18.880
 And usually, usually the way it works. Let me just give you one example. I mean, I'm thinking about an example right now, which was the war in Yugoslavia, you know, which came in the 1990s and eventually ventured in genocide in Bosnia.

33:18.880 --> 33:30.880
 And, and, and I, you know, I remember very clearly, you know, the 1970s and 1980s in Yugoslavia and people would say, you know, there's trouble here and, you know, something could go wrong.

33:30.880 --> 33:42.880
 But no one in their wildest imagination thought that there would be outright war between them at all. Then the outright war happened, genocide happened, and afterwards people would say, I saw it coming.

33:42.880 --> 33:50.880
 You know, so you get a lot of that, especially with pundits and journalists and that's, I saw it coming. I knew it was happening.

33:50.880 --> 33:57.880
 You know, well, I mean, what happens in the human mind, and it happens in your mind too, is, you know, you go through a lot of alternatives.

33:57.880 --> 34:09.880
 I mean, think about January 6th, you know, in this country and all the different alternatives which people had in their mind or before January 6th, you know, after the, after the lost election.

34:09.880 --> 34:15.880
 You know, things could have gone in lots of different ways, and there were all kinds of people choosing different ways it could have gone.

34:15.880 --> 34:19.880
 But nobody really knew how it was going to turn out.

34:19.880 --> 34:28.880
 Wasn't it smart people really understood that there'd be this kakamemi uprising on January 6th, you know, that almost, you know, caused this enormous grief.

34:28.880 --> 34:36.880
 So all of these kinds of things in history, you know, are deeply contingent. They depend on, you know, factors that we cannot predict.

34:36.880 --> 34:40.880
 And, you know, and it's the joy of history that it's open.

34:40.880 --> 34:45.880
 You know, you think about how people are now, I mean, let me give you one more example and then I'll shut up.

34:45.880 --> 34:50.880
 But, you know, there's the environmental example. You know, we're all threatened, right?

34:50.880 --> 34:53.880
 We know it's coming. We know there's trouble, right?

34:53.880 --> 34:57.880
 We know there's going to be a catastrophe at some point.

34:57.880 --> 35:00.880
 But when? What's the catastrophe?

35:00.880 --> 35:02.880
 Yeah, what's the nature of the catastrophe? Everyone says the catastrophe.

35:02.880 --> 35:06.880
 Is it going to be wars because resource constraints are going to be hunger?

35:06.880 --> 35:12.880
 Is it going to be like mass migration of different kinds that leads to some kind of conflict and immigration?

35:12.880 --> 35:15.880
 And maybe it won't be that big of a deal.

35:15.880 --> 35:21.880
 And a total other catastrophic event will completely challenge the entirety of the human civilization.

35:21.880 --> 35:24.880
 That's my point. That's my point. That's my point.

35:24.880 --> 35:28.880
 You know, we really don't know. I mean, there's a lot we do know.

35:28.880 --> 35:33.880
 I mean, the warming business and all this kind of stuff, you know, scientifically there.

35:33.880 --> 35:38.880
 But how it's going to play out. And everybody's saying, you know, different things.

35:38.880 --> 35:43.880
 And then you get somewhere in 50 years or 60 years, which I won't see.

35:43.880 --> 35:48.880
 And people say, aha, I told you it was going to be X or it was going to be Y or it was going to be Z.

35:48.880 --> 35:53.880
 So I just don't think in history you can...

35:53.880 --> 35:58.880
 Well, you can't predict. You simply cannot predict what's going to happen.

35:58.880 --> 36:02.880
 It's kind of when you just look at Hitler in the 30s for me.

36:02.880 --> 36:08.880
 Oftentimes when I kind of read different accounts, it is so often, certainly in the press,

36:08.880 --> 36:14.880
 but in general, me just reading about Hitler, I get the sense like this is a clown.

36:14.880 --> 36:17.880
 There's no way this person will gain power.

36:17.880 --> 36:19.880
 Which one? Hitler or Stalin?

36:19.880 --> 36:23.880
 Hitler. No, no, no. With Stalin, you don't get a sense he's a clown.

36:23.880 --> 36:27.880
 He's a really good executive. You don't think he would lead to mass murder,

36:27.880 --> 36:32.880
 but you think he's going to build a giant bureaucracy at least.

36:32.880 --> 36:38.880
 With Hitler, it's like a failed artist who keeps screaming about stuff.

36:38.880 --> 36:44.880
 There's no way he's going to... I mean, you certainly don't think about the atrocities,

36:44.880 --> 36:48.880
 but there's no way he's going to gain power, especially against communism.

36:48.880 --> 36:53.880
 There's so many other competing forces that could have easily beat him.

36:53.880 --> 36:59.880
 But then you realize event after event where this clown keeps dancing,

36:59.880 --> 37:04.880
 and all of a sudden he gains more and more power, and just certain moments in time,

37:04.880 --> 37:12.880
 he makes strategic decisions in terms of cooperating or gaining power over the military,

37:12.880 --> 37:17.880
 all those kinds of things that eventually give him the power.

37:17.880 --> 37:25.880
 This clown is one of the most impactful in the negative sense human beings in history.

37:25.880 --> 37:30.880
 And even the Jews who are there and are being screamed at and discriminated against,

37:30.880 --> 37:36.880
 and there's a series of measures taken against them incrementally during the course of the 1930s.

37:36.880 --> 37:40.880
 Very few who leave. I mean, some pick up and go and say,

37:40.880 --> 37:47.880
 I'm getting the hell out of here, and some Zionists try to leave too and go to the United States and stuff,

37:47.880 --> 37:55.880
 but go to Israel and Palestine at the time, or to Britain or France.

37:55.880 --> 38:01.880
 But in general, even the Jews who should have been very sensitive to what was going on

38:01.880 --> 38:08.880
 didn't really understand the extent of the danger, and it's really hard for people to do that.

38:08.880 --> 38:11.880
 It's almost impossible, in fact, I think.

38:11.880 --> 38:17.880
 So most of the time in that exact situation, nothing would have happened,

38:17.880 --> 38:21.880
 or there'd be some drama and so on, and there'd be some bureaucrat.

38:21.880 --> 38:25.880
 But every once in a while in human history, there's a kind of turn,

38:25.880 --> 38:32.880
 and maybe something catalyzes something else, and it accelerates, it accelerates, it escalates, it escalates,

38:32.880 --> 38:37.880
 and then war breaks out, and revolutions break out.

38:37.880 --> 38:39.880
 Right.

38:39.880 --> 38:44.880
 Can we go to the big question of genocide? What is genocide?

38:44.880 --> 38:47.880
 What are the defining characteristics of genocide?

38:47.880 --> 38:52.880
 Dealing with genocide is a difficult thing when it comes to the definition.

38:52.880 --> 39:08.880
 There is a definition, the December 1948 UN Convention on the Prevention and Punishment of Genocide,

39:08.880 --> 39:21.880
 and it emphasizes the intentional destruction of an ethnic, national, racial, or religious group.

39:21.880 --> 39:26.880
 Those are the four groups, again, comma as such.

39:26.880 --> 39:31.880
 And what that means, basically, is destroying the group as a group.

39:31.880 --> 39:38.880
 In other words, there's a kind of beauty in human diversity and different groups of people,

39:38.880 --> 39:48.880
 you know, Estonians, you know, a tribe of Native Americans, South African tribes, you know, the Rohingya in Myanmar.

39:48.880 --> 39:54.880
 There's a kind of beauty humanity recognizes in the distinctiveness of those groups.

39:54.880 --> 40:00.880
 You know, this was a notion that emerges really with Romanticism after the French Revolution

40:00.880 --> 40:04.880
 in the beginning of the 19th century, with Herder mostly.

40:04.880 --> 40:13.880
 And this beauty of these groups then, you know, is what is under attack in genocide.

40:13.880 --> 40:19.880
 And it's with intent, you know, the idea is that it's intentional destruction.

40:19.880 --> 40:26.880
 So this is a kind of, you know, analogy to first degree, second degree, and third degree murder, right?

40:26.880 --> 40:33.880
 First degree murder, you know, you're out to kill this person and you plan it and you go out and you do it, right?

40:33.880 --> 40:35.880
 That's intent, right?

40:35.880 --> 40:37.880
 Manslaughter is not intent.

40:37.880 --> 40:40.880
 You end up doing the same thing, but it's different.

40:40.880 --> 40:47.880
 So, you know, the major person behind the definition is a man named Raphael Lemkin.

40:47.880 --> 40:55.880
 I don't know if you heard his name or not, but he was a Polish Jewish jurist who came, you know, from Poland,

40:55.880 --> 41:05.880
 came to the United States during the war and had been a kind of crusader for recognizing genocide.

41:05.880 --> 41:14.880
 It's a word that he created, by the way, and he coined the term in 1943 and then published it in 1944 for the first time.

41:14.880 --> 41:17.880
 Geno, meaning people inside, meaning killing, right?

41:17.880 --> 41:24.880
 And so Lemkin then had this term and he pushed hard to have it recognized and it was in the UN Convention.

41:24.880 --> 41:26.880
 So that's the rough definition.

41:26.880 --> 41:33.880
 The problem with the definition, the problems with the definition are several.

41:33.880 --> 41:41.880
 You know, one of them is, is it just these four groups, you know, racial, religious, ethnic, or national?

41:41.880 --> 41:43.880
 See, this comes right out of the war.

41:43.880 --> 41:52.880
 And what's in people's minds in 1948 are Jews, Poles, Russians, Yugoslavia sometimes, who were killed by the Nazis.

41:52.880 --> 41:53.880
 That's what's in their mind.

41:53.880 --> 42:00.880
 But there are other groups, too, if you think about it, you know, who are killed, social groups or political groups.

42:00.880 --> 42:09.880
 And that was not allowed in the convention, meaning for a lot of different reasons, the Soviets were primary among them.

42:09.880 --> 42:15.880
 They didn't want other kinds of groups, let's say Kulaks, for example, to be considered.

42:15.880 --> 42:20.880
 That's a social group or peasants, which is a social group.

42:20.880 --> 42:22.880
 So, or a political group.

42:22.880 --> 42:29.880
 I mean, let's take a group, you know, communist killed groups of people.

42:29.880 --> 42:34.880
 But noncommunists also killed groups of people in Indonesia in 1965, 66.

42:34.880 --> 42:39.880
 They killed, you know, exactly, but roughly 600,000 Indonesian communists.

42:39.880 --> 42:41.880
 Well, is that genocide or not?

42:41.880 --> 42:47.880
 You know, and my point of view, it is genocide, although it's Indonesians killing Indonesians.

42:47.880 --> 42:50.880
 And we have the same problem with the Cambodian genocide.

42:50.880 --> 42:57.880
 I mean, we talk about a Cambodian genocide, but most of the people killed in the Cambodian genocide were other Cambodians.

42:57.880 --> 43:03.880
 They give it the name, they're ready to recognize this genocide because they also killed some other peoples,

43:03.880 --> 43:13.880
 meaning the Vietnamese, Aham people who are, you know, Muslim, Muslim, smaller Muslim people in the area, and a few others.

43:13.880 --> 43:22.880
 So the question then becomes, well, does it have to be a different nationality or ethnic group or religious group for it to be genocide?

43:22.880 --> 43:23.880
 And my answer is no.

43:23.880 --> 43:25.880
 You know, you need to expand the definition.

43:25.880 --> 43:27.880
 It's a little bit like with our constitution.

43:27.880 --> 43:28.880
 You know, we got a constitution.

43:28.880 --> 43:31.880
 I mean, but we don't live in the end of the 18th century, right?

43:31.880 --> 43:32.880
 We live in the 21st century.

43:32.880 --> 43:37.880
 And so you have to update the constitution over the centuries.

43:37.880 --> 43:41.880
 And similarly, the genocide convention needs updating too.

43:41.880 --> 43:44.880
 So that's how I work with the definition.

43:44.880 --> 43:46.880
 So this is this invention.

43:46.880 --> 43:48.880
 Was it an invention?

43:48.880 --> 43:54.880
 This beautiful idea, romantic idea that there's groups of people and the group is united by some unique characters.

43:54.880 --> 44:02.880
 That was an invention in human history, this idea, not the CSS, individuals.

44:02.880 --> 44:04.880
 Yes, in some senses it was.

44:04.880 --> 44:09.880
 I mean, it's not, you know, there are things that are always constructed at one fashion or another.

44:09.880 --> 44:14.880
 And then in the construction, you know, more or less represents the reality.

44:14.880 --> 44:23.880
 And what the reality is always much more complicated than the construction or the invention of a term or a concept or a way of thinking about,

44:23.880 --> 44:25.880
 a nation, right?

44:25.880 --> 44:39.880
 And this way of thinking of nations, you know, as, again, you know, groups of religious, linguistic, not political necessarily,

44:39.880 --> 44:44.880
 but cultural entities is something that was essentially invented.

44:44.880 --> 44:45.880
 Yes.

44:45.880 --> 44:52.880
 Yes, I mean, you know, if you look at Germans in the 17th century, you know, Italians in the 17th century, right?

44:52.880 --> 45:01.880
 They were only there after, you know, the invention of the nation, which comes, again, mostly as out of the French Revolution,

45:01.880 --> 45:08.880
 in the Romantic Movement, a man named Johann Gottfried von Herder, right?

45:08.880 --> 45:17.880
 Who was really the first one who sort of went around, collected people's languages and collected their sayings and their dances and their folk ways and stuff and said,

45:17.880 --> 45:26.880
 isn't this cool, you know, that they're Estonians and that they're Latvians and that they're these other, these interesting different peoples who don't even know,

45:26.880 --> 45:30.880
 necessarily, that they're different peoples, right?

45:30.880 --> 45:32.880
 That comes a little bit later, right?

45:32.880 --> 45:41.880
 Once the concept is invented, then people start to say, hey, we're nations too, you know, and the Germans decide they're a nation and they unify.

45:41.880 --> 45:51.880
 And the Italians discover they're a nation and they unify instead of being, you know, to Florentines and Romans and, you know, Sicilians.

45:51.880 --> 45:55.880
 But then beyond nations, there are political affiliations, all those kinds of things.

45:55.880 --> 46:03.880
 It's fascinating that, you know, you start, you look at the early Homo sapiens and then there's obviously tribes, right?

46:03.880 --> 46:15.880
 And then that's very concrete, that's a geographic location and it's a small group of people and you have warring tribes probably connected to just limited resources.

46:15.880 --> 46:26.880
 But it's fascinating to think that that is then taken to the space of ideas to where you can create a group at first to appreciate its beauty.

46:26.880 --> 46:35.880
 You create a group based on language, based on maybe even political, philosophical ideas, religious ideas, all those kinds of things.

46:35.880 --> 46:43.880
 And then that naturally then leads to getting angry groups and making them the other and then hatred.

46:43.880 --> 46:49.880
 Right. That comes more towards the end of the 19th century, you know, with the influence of Darwin.

46:49.880 --> 47:02.880
 I mean, you can't blame Darwin for it, but Neo Darwin, Darwinians, you know, who start to talk about, you know, the competition between nations, the natural competition, the weak ones fall away, the strong ones get ahead.

47:02.880 --> 47:13.880
 You know, you get this sort of combination also with, you know, modern antisemitism and with racial thinking, you know, the racial thinking at the end of the 19th century is very powerful.

47:13.880 --> 47:25.880
 So now, you know, at the end of the 19th century versus the beginning, you know, the middle of the 19th century, you know, you can be a German and be a Jew and there's no contradiction.

47:25.880 --> 47:31.880
 Yeah. As long as you speak the language and you, you know, you dress and think and act and share the culture.

47:31.880 --> 47:36.880
 By the end of the 19th century, people saying, no, no, you know, they're not Germans.

47:36.880 --> 47:40.880
 They're Jews. They're different. They have different blood. They have different, they don't say genes yet.

47:40.880 --> 47:51.880
 You know, that's sort of a sense of people and that's when, you know, there's this sense of superiority too and inferiority, you know, that they're inferior to us.

47:51.880 --> 47:59.880
 Yeah. You know, and, and that we're the strong ones and we have to, you know, and Hitler, by the way, just adopts this hook line and sinker.

47:59.880 --> 48:08.880
 I mean, there are a whole series of thinkers at the end of the 19th and beginning of 20th century who he cites in Mein Kampf, you know, which is written in the early 1920s.

48:08.880 --> 48:14.880
 That, you know, basically pervades this racial thinking.

48:14.880 --> 48:18.880
 So nationalism changes. So nationalism in and of itself is not bad.

48:18.880 --> 48:31.880
 I mean, it's not bad, you know, to share culture and language and, and, you know, folk ways and, and sense of common belonging and nothing bad about it inherently.

48:31.880 --> 48:41.880
 But then what happens is it becomes, you know, frequently is used and becomes especially on fascism becomes dangerous.

48:41.880 --> 48:48.880
 And it's especially dangerous when the two conflicting groups share geographic location.

48:48.880 --> 48:49.880
 That's right.

48:49.880 --> 48:58.880
 So like with Jews, you know, I come, you know, I'm a Russian Jew and it's always interesting.

48:58.880 --> 49:07.880
 I take pride in, you know, I love the tradition of the Soviet Union of Russia.

49:07.880 --> 49:08.880
 I love America.

49:08.880 --> 49:10.880
 So I love these countries.

49:10.880 --> 49:15.880
 They have a beautiful tradition in literature and science and art and all those kinds of things.

49:15.880 --> 49:23.880
 But it's funny that people, not often, but sometimes correct me that I'm not Russian.

49:23.880 --> 49:26.880
 I'm a Jew.

49:26.880 --> 49:29.880
 It's a, it's a nice reminder.

49:29.880 --> 49:30.880
 Yes.

49:30.880 --> 49:36.880
 That that is always there, that desire to create these groups.

49:36.880 --> 49:45.880
 And then when they're living in the same place for that division between groups that hate between groups can explode.

49:45.880 --> 49:49.880
 And I just, I wonder why is that there?

49:49.880 --> 49:55.880
 Why does, why does the human heart tend so easily towards this kind of hate?

49:55.880 --> 50:01.880
 You know, that's a big question in and of itself.

50:01.880 --> 50:04.880
 You know, the human heart is full of everything, right?

50:04.880 --> 50:05.880
 It's full of hate.

50:05.880 --> 50:06.880
 It's full of love.

50:06.880 --> 50:07.880
 It's full of indifference.

50:07.880 --> 50:09.880
 It's full of apathy.

50:09.880 --> 50:10.880
 It's full of energy.

50:10.880 --> 50:22.880
 So, I mean, hate is something, you know, that, I mean, I think, and, you know, along with

50:22.880 --> 50:27.880
 hate, you know, the ability to really hurt and injure people is something that was within all of us.

50:27.880 --> 50:29.880
 You know, it's within all of us.

50:29.880 --> 50:36.880
 And it's just something that's part of who we are and part of our society.

50:36.880 --> 50:43.880
 So, you know, we're shaped by our society and our society can do with us often what it wishes.

50:43.880 --> 50:51.880
 You know, that's why it's so much nicer to live in a more or less beneficent society like that of a democracy in the west.

50:51.880 --> 50:54.880
 Than to live in the Soviet Union, right?

50:54.880 --> 51:08.880
 I mean, because, you know, you have more or less the freedom to do what you wish and not to be forced into situations in which you would have to then do nasty to other people.

51:08.880 --> 51:20.880
 You know, some societies, as we talked about, you know, or more have proclivities towards, you know, asking of its people to do things they don't want to do.

51:20.880 --> 51:23.880
 And, and forcing them to do so.

51:23.880 --> 51:30.880
 So, you know, freedom is a wonderful thing to be able to choose not to do evil is a great thing.

51:30.880 --> 51:44.880
 You know, whereas in some societies, you know, you feel in some ways for not so much for the NKVD bosses, but for the guys on the ground, you know, in the 1930s or not so much for the Nazi bosses,

51:44.880 --> 51:55.880
 but for the guys, you know, in the police battalion that were told, go shoot those Jews, you know, and you do it.

51:55.880 --> 52:09.880
 Not necessarily because they force you to do it, but because your social, you know, your social situation, you know, encourages you to and you don't have the courage not to.

52:09.880 --> 52:15.880
 Yeah, I was just, as I often do, rereading Victor Frankl's man search for meaning.

52:15.880 --> 52:21.880
 And he said something, I just, I often pull out sort of lines.

52:21.880 --> 52:27.880
 The mere knowledge that a man was either a camp guard or a prisoner tells us almost nothing.

52:27.880 --> 52:35.880
 Human kindness can be found in all groups, even those which as a whole, it would be easy to condemn.

52:35.880 --> 52:49.880
 So that's speaking to you feel for those people at the lowest level implementing the orders of those above.

52:49.880 --> 52:50.880
 Right.

52:50.880 --> 52:58.880
 And also you worry yourself, what will happen if you were given those same orders, you know, I mean, what would you do?

52:58.880 --> 53:06.880
 What kind of reaction would you have in the similar situation? And, you know, you don't know.

53:06.880 --> 53:16.880
 I could see myself in World War II fighting for almost any country that I was born in.

53:16.880 --> 53:18.880
 There's a love of community.

53:18.880 --> 53:22.880
 There's a love of country that's just, at least to me, comes naturally.

53:22.880 --> 53:26.880
 Just love of community and countries, one such community.

53:26.880 --> 53:33.880
 And I could see fighting for that country, especially when you're sold a story that you're fighting evil.

53:33.880 --> 53:37.880
 And I'm sure every single country was sold that story effectively.

53:37.880 --> 53:52.880
 And then when you're in the military and you have a gun in your hand or you're in the police force and you're ordered, go to this place and commit violence.

53:52.880 --> 53:54.880
 It's hard to know what you would do.

53:54.880 --> 54:02.880
 It's a mix of fear. It's a mix of, maybe you convince yourself, you know, what can one person really do?

54:02.880 --> 54:05.880
 And over time, it's, again, that slippery slope.

54:05.880 --> 54:12.880
 Because you could see all the people who protest, who revolt, they're ineffective.

54:12.880 --> 54:20.880
 So like, if you actually want to practically help somehow, you're going to convince yourself that you can't, one person can't possibly help.

54:20.880 --> 54:21.880
 Right.

54:21.880 --> 54:25.880
 And then you have a family, so you want to make, you know, you want to protect your family.

54:25.880 --> 54:32.880
 You tell all of these stories and over time, you naturally convince yourself to dehumanize the other.

54:32.880 --> 54:41.880
 Yeah, I think about this a lot, mostly because I worry that I would be a good German.

54:41.880 --> 54:44.880
 Yeah. No, no, that's right. That's right.

54:44.880 --> 54:50.880
 And one of my tasks as a teacher, right, are students.

54:50.880 --> 54:54.880
 And I have, you know, classes on genocide. I have one now.

54:54.880 --> 54:58.880
 And another one, by the way, on Stalin.

54:58.880 --> 55:10.880
 But the one on genocide, you know, one of my tasks is to try to get the students to understand this is not about weird people who live far away in time and in place.

55:10.880 --> 55:14.880
 But it's about them, you know, and that, you know, that's a hard lesson.

55:14.880 --> 55:19.880
 But it's an important one, you know, that this isn't all of us, you know, it's in all of us.

55:19.880 --> 55:29.880
 And there's nothing, you know, and you just try to gird yourself up, you know, to try to figure out ways that maybe you won't be complicit.

55:29.880 --> 55:35.880
 And that you learn how to stand by your principles, but it's very hard. It's extremely difficult.

55:35.880 --> 55:39.880
 And you can't, the other interesting thing about it is not predictable.

55:39.880 --> 55:48.880
 Now, they've done a lot of studies of Poles, for example, who during the war saved Jews, you know, well, who are the Poles who saved Jews versus those who turned them in?

55:48.880 --> 55:55.880
 It's completely unpredictable. You know, sometimes it's the worst antisemites who protect them because they don't believe they should be killed.

55:55.880 --> 56:00.880
 Right? And sometimes, you know, it's not predictable.

56:00.880 --> 56:17.880
 It's not as if the humanists among us, you know, are the ones who, you know, can consistently show up, you know, and experience danger, in other words, and are ready to take on danger to defend, you know, your fellow human beings.

56:17.880 --> 56:24.880
 Not necessarily. I mean, sometimes simple people do it and sometimes they do it for really simple reasons.

56:24.880 --> 56:32.880
 And sometimes people you would expect to do it don't, you know, and you've got that mix and it's just not predictable.

56:32.880 --> 56:43.880
 One thing I've learned in this age of social media is it feels like the people with integrity and the ones who would do the right thing are the quiet ones.

56:43.880 --> 56:52.880
 In terms of humanists, in terms of activists, there's so many points to be gained of declaring that you would do the right thing.

56:52.880 --> 57:05.880
 It's the simple quiet folks because I've seen quite, on a small, obviously much smaller scale, just shows of integrity and character.

57:05.880 --> 57:16.880
 When there were sacrifices to be made and it was done quietly, now this sort of the small heroes, those are, you're right there, it's surprising, but they're often quiet.

57:16.880 --> 57:22.880
 That's why I'm distrustful of people who kind of proclaim that they would do the right thing.

57:22.880 --> 57:25.880
 And there are different kinds of integrity too.

57:25.880 --> 57:38.880
 I edited a memoir of a Polish, you know, underground fighter, member of the underground who was in Majdanek in the concentration camp at Majdanek.

57:38.880 --> 57:42.880
 You know, and it was just an interesting mix of different kinds of integrity.

57:42.880 --> 57:53.880
 You know, on the one hand, you know, he really bothered him deeply when Jews were killed or sent to the camp or that sort of thing.

57:53.880 --> 58:02.880
 On the other hand, he was something of an antisemite, you know, and he would, you know, sometimes if Jews were his friends, he would help them.

58:02.880 --> 58:17.880
 And if they weren't, sometimes he was really mean to them, you know, and you could, in their various levels, you know, a concentration camp is, you know, a terrible social experiment in some ways, right?

58:17.880 --> 58:26.880
 And you learn a lot from how people behave, and what you see is that, you know, people behave sometimes extraordinarily well in some situations and extraordinarily poorly in others,

58:26.880 --> 58:32.880
 and that it's mixed and you can't predict it, and it's hard to find consistency.

58:32.880 --> 58:33.880
 I mean, that's the other thing.

58:33.880 --> 58:40.880
 It's, you know, I think we claim too much consistency for the people we study and the people we think about in the past.

58:40.880 --> 58:44.880
 They're not consistent anymore than we are consistent, right?

58:44.880 --> 58:47.880
 Well, let me ask you about human nature here on both sides.

58:47.880 --> 58:53.880
 So first, what have you learned about human nature from studying genocide?

58:53.880 --> 58:55.880
 Why do humans commit genocide?

58:55.880 --> 59:00.880
 What lessons, first of all, why is a difficult question?

59:00.880 --> 59:06.880
 But what insights do you have into humans that genocide is something that happens in the world?

59:06.880 --> 59:09.880
 That's a really big and difficult question, right?

59:09.880 --> 59:15.880
 And it has to be parsed, I think, into different kinds of questions.

59:15.880 --> 59:18.880
 You know, why does genocide happen?

59:18.880 --> 59:28.880
 You know, which the answer there is frequently political, meaning, you know, why Hitler ended up killing the Jews.

59:28.880 --> 59:35.880
 Well, it had a lot to do with the political history of Germany and wartime history of Germany, right?

59:35.880 --> 59:40.880
 In the 30s, and, you know, it's traceable to then.

59:40.880 --> 59:54.880
 Like you mentioned it yourself, you can't imagine Hitler in the mid 20s turning into anything of the kind of dictator he ended up being in the kind of murderer, mass murderer he ended up being.

59:54.880 --> 1:00:00.880
 So, and the same thing goes, by the way, for Stalin and Soviet Union and Pol Pot.

1:00:00.880 --> 1:00:13.880
 I mean, these are all essentially political movements where the polity state is seized, you know, by ideological or, you know, party, single party movement,

1:00:13.880 --> 1:00:17.880
 and then is moved in directions where where mass killing takes place.

1:00:17.880 --> 1:00:21.880
 And the other question, you know, separate that question out.

1:00:21.880 --> 1:00:32.880
 The other question is why do ordinary people participate? Because the fact of the matter is just ordering genocide is not enough.

1:00:32.880 --> 1:00:35.880
 Just saying, you know, go get them is not enough.

1:00:35.880 --> 1:00:45.880
 There have to be people who will cooperate and who will do their jobs, you know, both at the kind of mezzo level, the middle level of a bureaucracy, but also at the everyday level.

1:00:45.880 --> 1:01:02.880
 You know, people who have to pull the triggers and that kind of thing and, you know, force people into the gas chamber and grab people, you know, and Kiev in September 1941 at Babinyar and push them, you know, towards the ravine, where the machine gunners are going to shoot them down.

1:01:02.880 --> 1:01:05.880
 You know, and those are all different questions.

1:01:05.880 --> 1:01:22.880
 The question of, you know, the especially the lower level people who actually do the killing is a question which I think we've been talking about, which is that within all of us, you know, is the capability of being murderers and mass murderers.

1:01:22.880 --> 1:01:24.880
 I mean, to participate in mass murder.

1:01:24.880 --> 1:01:32.880
 I won't call them laws of social psychology, but that the character of social psychology, you know, we will do it in most cases.

1:01:32.880 --> 1:01:40.880
 I mean, one of the shocking things that I learned just a few years ago, studying the Holocaust is that you could pull out.

1:01:40.880 --> 1:01:47.880
 In other words, if they order a police battalion to go shoot Jews, you didn't have to do it.

1:01:47.880 --> 1:01:48.880
 You could pull out.

1:01:48.880 --> 1:01:50.880
 They weren't going to, they never killed anybody.

1:01:50.880 --> 1:01:52.880
 They never, they never executed anybody.

1:01:52.880 --> 1:01:56.880
 They never even punished people for saying, no, I'm not going to do that.

1:01:56.880 --> 1:01:58.880
 So people are doing it voluntarily.

1:01:58.880 --> 1:02:00.880
 They may not want to do it.

1:02:00.880 --> 1:02:08.880
 You know, they give them booze to try to, you know, numb the pain of murder because they know there's, there is pain.

1:02:08.880 --> 1:02:13.880
 I mean, people experience pain when they murder people, but they don't pull out.

1:02:13.880 --> 1:02:20.880
 And so it's the character of who we are in society, in groups, and we're very, very influenced.

1:02:20.880 --> 1:02:29.880
 I mean, we're highly influenced by the groups in which we operate and, you know, who we talk to and who our friends are within that group.

1:02:29.880 --> 1:02:31.880
 And who is the head of the group?

1:02:31.880 --> 1:02:37.880
 And I mean, you see this even, I mean, you see it in any group, you know, whether it's in the academy, right?

1:02:37.880 --> 1:02:48.880
 That, that, that Stanford, or whether it's, you know, in a labor union, or whether it's in a church group in, in Tennessee or wherever, you know, people pay attention to each other.

1:02:48.880 --> 1:02:54.880
 And they, and they are unwilling frequently to say, no, this is wrong.

1:02:54.880 --> 1:02:57.880
 Even though all of you think it's right, it's wrong.

1:02:57.880 --> 1:03:07.880
 I mean, they just don't do that usually, especially in societies that are authoritarian or totalitarian, right?

1:03:07.880 --> 1:03:10.880
 Because it's, it's harder because there's a backup to it, right?

1:03:10.880 --> 1:03:13.880
 There's the NKVD there, or there's the Gestapo there, and there are other people there.

1:03:13.880 --> 1:03:26.880
 So you just, you know, they may not be forcing you to do it, but, but your social being plus this danger in the, in the distance, you know, you do it.

1:03:26.880 --> 1:03:44.880
 But then if you go up the hierarchy, at the very top, there's a dictator, presumably, you know, you go to like middle management, bureaucracy, the higher you get up there, the more power you have to change the direction of the Titanic.

1:03:44.880 --> 1:03:46.880
 Right, right, right.

1:03:46.880 --> 1:03:48.880
 But nobody seems to do it.

1:03:48.880 --> 1:03:49.880
 Right.

1:03:49.880 --> 1:03:51.880
 Or what happens, and it does happen.

1:03:51.880 --> 1:04:00.880
 It happens in the German army, I mean, it happens in the case of the Armenian genocide, where we know they're governors who said, no, I'm not, I'm not going to kill Armenians.

1:04:00.880 --> 1:04:01.880
 What kind of businesses is this?

1:04:01.880 --> 1:04:03.880
 They're just removed.

1:04:03.880 --> 1:04:04.880
 They're removed.

1:04:04.880 --> 1:04:06.880
 And you find a replacement very easily.

1:04:06.880 --> 1:04:09.880
 So, you know, you do see people who stand up.

1:04:09.880 --> 1:04:12.880
 And again, it's not really predictable who it will be.

1:04:12.880 --> 1:04:13.880
 I would maintain.

1:04:13.880 --> 1:04:18.880
 I mean, I haven't done the study of the Armenian governors who said no.

1:04:18.880 --> 1:04:22.880
 I mean, the Turkish governors who said no to the Armenian genocide.

1:04:22.880 --> 1:04:30.880
 But, you know, there are people who do step aside every once in a while in the middle level.

1:04:30.880 --> 1:04:37.880
 And again, they're German generals who say, wait a minute, what is this business in Poland when they start to kill Jews or in Belarus?

1:04:37.880 --> 1:04:39.880
 And, you know, they're just pushed aside.

1:04:39.880 --> 1:04:43.880
 You know, if they don't do their job, they're pushed aside, or they end up doing it.

1:04:43.880 --> 1:04:46.880
 And they usually do end up doing it.

1:04:46.880 --> 1:04:49.880
 What about on the victim side?

1:04:49.880 --> 1:04:52.880
 I mentioned man search for meaning.

1:04:52.880 --> 1:04:59.880
 What can we learn about human nature, the human mind from the victims of genocide?

1:04:59.880 --> 1:05:06.880
 So, Victor Frankl talked about the ability to discover meaning and beauty, even in suffering.

1:05:06.880 --> 1:05:15.880
 Is there something to be said about, you know, in your studying of genocide that you've learned about human nature?

1:05:15.880 --> 1:05:23.880
 Well, again, I don't, I have to say, I come out of the study of genocide with a very pessimistic view of human nature.

1:05:23.880 --> 1:05:25.880
 A very pessimistic view.

1:05:25.880 --> 1:05:26.880
 Even on the victim side.

1:05:26.880 --> 1:05:28.880
 Even on the victim side.

1:05:28.880 --> 1:05:33.880
 I mean, the victims will eat their children, right?

1:05:33.880 --> 1:05:35.880
 Ukrainian case, they have no choice.

1:05:35.880 --> 1:05:38.880
 You know, the victims will rob each other.

1:05:38.880 --> 1:05:43.880
 The victims will form hierarchies within victimhood.

1:05:43.880 --> 1:05:46.880
 So you see, let me give you an example.

1:05:46.880 --> 1:05:50.880
 Again, I told you I was working on Maidanik.

1:05:50.880 --> 1:06:05.880
 And there's, in Maidanik, at a certain point in 42, a group of Slovak Jews were arrested and sent to Maidanik.

1:06:05.880 --> 1:06:14.880
 Those Slovak Jews were a group, somehow they, I mean, they stuck together, they were very competent, they were, you know, many of them were businessmen.

1:06:14.880 --> 1:06:19.880
 They knew each other and for a variety of different reasons within the camp.

1:06:19.880 --> 1:06:26.880
 And again, this shows you the diversity of the camps and also, you know, these images of black and white in the camps are not very useful.

1:06:26.880 --> 1:06:28.880
 They ruled the camp.

1:06:28.880 --> 1:06:34.880
 I mean, they basically had all the important jobs in the camp, including jobs like beating other Jews.

1:06:34.880 --> 1:06:42.880
 And persecuting other Jews and persecuting other peoples, which they did.

1:06:42.880 --> 1:06:52.880
 And this Polish guy, who I mentioned to you, who wrote this memoir, hated them because of what they were doing to the Poles, right?

1:06:52.880 --> 1:07:00.880
 And he, you know, he's incensed because aren't these supposed to be the unto mentioned, he says.

1:07:00.880 --> 1:07:05.880
 And look what they're doing, they're treating us, you know, like dirt.

1:07:05.880 --> 1:07:08.880
 And they do, they treat them like dirt.

1:07:08.880 --> 1:07:24.880
 So, you know, in this kind of work on Maidanik, there's certainly parts of it that, you know, we're inspiring, you know, people helping each other, people trying to feed each other, people giving warmth to each other.

1:07:24.880 --> 1:07:38.880
 You know, there's some very heroic Polish women who end up having a radio show called Radio Maidanik, which they put on every night in the women's camp, which is, you know, to raise people's spirits.

1:07:38.880 --> 1:07:50.880
 And they, you know, sing songs and do all this kind of stuff, you know, to try to keep themselves from, you know, the horrors that they're experiencing around them.

1:07:50.880 --> 1:07:59.880
 And so you do see that and you do see, you know, human beings acting in support of each other.

1:07:59.880 --> 1:08:09.880
 But, you know, I mean, Primo Levi is one of my favorite writers about the Holocaust and about the camps.

1:08:09.880 --> 1:08:19.880
 And, you know, I don't think Primo Levi saw anything, you know, I mean, he had pals, you know, who he helped and who helped him.

1:08:19.880 --> 1:08:29.880
 I mean, but he describes this kind of, you know, terrible inhuman environment which no one can escape, really, no one can escape.

1:08:29.880 --> 1:08:40.880
 He ends up committing suicide too, I think, because of his sense of, we don't know exactly why, but probably because of his sense of what happened in the camp.

1:08:40.880 --> 1:08:43.880
 I mean, later he goes back to Italy, becomes a writer in that sort of thing.

1:08:43.880 --> 1:09:01.880
 So I don't, I don't, especially in the concentration camps, it's really hard to find places like Vicofranco where you can say, you know, I am moved in a positive way, you know, by what happened.

1:09:01.880 --> 1:09:03.880
 There were cases, there's no question.

1:09:03.880 --> 1:09:14.880
 People hung together, they tried to help each other, but, you know, they were totally, totally caught in this web of genocide.

1:09:14.880 --> 1:09:32.880
 See, so there are stories, but the thing is, I have this sense, maybe it's a hope, that within most, if not every human heart, there's a kind of, like, flame of compassion and kindness and love that waits.

1:09:32.880 --> 1:09:40.880
 That longs to connect with others, that ultimately unmasks, overpowers everything else.

1:09:40.880 --> 1:09:52.880
 If you just look at the story of human history, the resistance to violence and mass murder and genocide feels like a force that's there.

1:09:52.880 --> 1:10:03.880
 And it feels like a force that's more powerful than whatever the dark momentum that leads to genocide is.

1:10:03.880 --> 1:10:06.880
 It feels like that, that's more powerful.

1:10:06.880 --> 1:10:07.880
 It's just quiet.

1:10:07.880 --> 1:10:15.880
 It's hard to tell the story of that little flame that burns within all of our hearts, that longing to connect to other human beings.

1:10:15.880 --> 1:10:23.880
 And we, there's something also about human nature and us as storytellers that we, we're not very good at telling the stories of that little flame.

1:10:23.880 --> 1:10:26.880
 We're much better at telling the stories of atrocities.

1:10:26.880 --> 1:10:30.880
 No, you know, I think maybe I fundamentally disagree with you.

1:10:30.880 --> 1:10:35.880
 I think maybe I fundamentally, I don't disagree that there is that flame.

1:10:35.880 --> 1:10:38.880
 I just think it's just too easily doused.

1:10:38.880 --> 1:10:42.880
 And I think it's too easily goes out in a lot of people.

1:10:42.880 --> 1:10:53.880
 And I mean, I, like I say, I come away from this work, a pessimist, you know, there is this work by a Harvard psychologist.

1:10:53.880 --> 1:10:54.880
 Now I'm forgetting it.

1:10:54.880 --> 1:10:55.880
 Steven Pinker.

1:10:55.880 --> 1:10:56.880
 Yes.

1:10:56.880 --> 1:10:57.880
 Yes.

1:10:57.880 --> 1:11:06.880
 Steven Pinker that shows over time, you know, and, you know, initially I was quite skeptical of the work, but in the end I thought he was quite convincing.

1:11:06.880 --> 1:11:12.880
 That over time, the incidents of homicide, you know, goes down.

1:11:12.880 --> 1:11:14.880
 The incidents of rape goes down.

1:11:14.880 --> 1:11:21.880
 The incidents of genocide, except for the big blip, you know, in the middle of the 20th century goes down.

1:11:21.880 --> 1:11:29.880
 Not markedly, but it goes down generally that, you know, more that norms, international norms are changing how we think about this and stuff like that.

1:11:29.880 --> 1:11:36.880
 I thought he was pretty convincing about that, but think about, think about, you know, we're, we're modern people.

1:11:36.880 --> 1:11:41.880
 I mean, we, we've advanced so fast in so many different areas.

1:11:41.880 --> 1:11:46.880
 I mean, we should have eliminated this a long time ago, a long time ago.

1:11:46.880 --> 1:12:03.880
 You know, how is it that, you know, we're still facing this business of genocide in Myanmar and Xinjiang and in, you know, Tigray in Ethiopia, you know, the potentials of genocide there and all over the world.

1:12:03.880 --> 1:12:09.880
 You know, we still, we still have this thing that we cannot handle, that we can't deal with.

1:12:09.880 --> 1:12:17.880
 And, you know, again, you know, electric cars and planes that fly from here to, you know, Beijing.

1:12:17.880 --> 1:12:26.880
 Think about the differences between 250 years ago or 300 years ago and today, but the differences in genocide are not all that great.

1:12:26.880 --> 1:12:28.880
 I mean, the incidents has gone down.

1:12:28.880 --> 1:12:35.880
 I think Pinker has demonstrated, I mean, there are problems with his methodology, but on the whole, I'm with him on that book.

1:12:35.880 --> 1:12:38.880
 I thought in the end it was, it was quite well done.

1:12:38.880 --> 1:12:48.880
 So, you know, I do not, I have to say I'm not, I'm not an optimist about what this human flame can do.

1:12:48.880 --> 1:12:59.880
 And, you know, I once, I once, someone once said to me, when I posed a similar kind of question to a seminar, a friend of mine at Berkeley once said, remember original sin, Norman.

1:12:59.880 --> 1:13:06.880
 Well, I don't, you know, that's very Catholic and I don't, I don't really think in terms of original sin.

1:13:06.880 --> 1:13:10.880
 But in some ways, you know, her point is we carry this with us.

1:13:10.880 --> 1:13:21.880
 You know, we carry with us a really potentially nasty mean streak that can do harm to other people.

1:13:21.880 --> 1:13:23.880
 Well, we carry the capacity to love too.

1:13:23.880 --> 1:13:24.880
 Yes, we do.

1:13:24.880 --> 1:13:27.880
 And so as we do, that's part of the deal.

1:13:27.880 --> 1:13:35.880
 You have a bias in that you have studied some of the darker aspects of human nature and human history.

1:13:35.880 --> 1:13:45.880
 So it is difficult from the trenches, from the muck to see a possible sort of way out through love.

1:13:45.880 --> 1:13:49.880
 But it's not obvious that that's not the case.

1:13:49.880 --> 1:13:53.880
 You mentioned electric cars and rockets and airplanes.

1:13:53.880 --> 1:14:07.880
 To me, the more powerful thing is Wikipedia, the internet, only 50% of the world currently has access to the internet, but that's growing in information and knowledge and wisdom, especially among women in the world.

1:14:07.880 --> 1:14:13.880
 As that grows, I think it becomes a lot more difficult if love wins.

1:14:13.880 --> 1:14:22.880
 It becomes a lot more difficult for somebody like Hitler to take power for genocide to occur because people think and the masses, I think the people have power.

1:14:22.880 --> 1:14:28.880
 When they're able to think, when they can see the full kind of...

1:14:28.880 --> 1:14:43.880
 First of all, when they can study your work, they can know about the fact that genocide happens, how it occurs, how the promises of great charismatic leaders lead to great destructive mass genocide.

1:14:43.880 --> 1:14:53.880
 And just even studying the fact that the Holocaust happened for a large number of people is a powerful preventer of future genocide.

1:14:53.880 --> 1:15:08.880
 One of the lessons of history is just knowing that this can happen, learning how it happens, that normal human beings, leaders that give big promises can also become evil and destructive.

1:15:08.880 --> 1:15:13.880
 Knowing that that can happen is a powerful preventer of that.

1:15:13.880 --> 1:15:28.880
 And then you kind of wake up from this haze of believing everything you hear and you learn to just, in your small local way, to put more love out there in the world.

1:15:28.880 --> 1:15:39.880
 I believe it's not to push back. It's not so obvious to me that in the end, I think in the end love wins.

1:15:39.880 --> 1:15:50.880
 That's my intuition. I have money on it. I have a sense that this genocide thing is more and more going to be an artifact of the past.

1:15:50.880 --> 1:15:59.880
 Well, I certainly hope you're right. I mean, I certainly hope you're right. And, you know, it could be you are, we don't know.

1:15:59.880 --> 1:16:04.880
 But the evidence is different. The evidence is different.

1:16:04.880 --> 1:16:16.880
 And, you know, the capacity of human beings to do evil to other human beings is repeatedly demonstrated.

1:16:16.880 --> 1:16:27.880
 You know, whether it's in massacres in Mexico or, you know, ISIS and the ZD Kurds or, you know, you can just go on and on Syria.

1:16:27.880 --> 1:16:40.880
 I mean, look what I mean, Syria used to be a country, you know, and now it's a, you know, it's been a mass grave and people then have left in the millions, you know, for other places.

1:16:40.880 --> 1:16:52.880
 And, you know, I'm not saying, you know, I'm not saying, I mean, the Turks have done nice things for the Syrians and the Germans welcomed in a million or so and actually reasonably absorb them.

1:16:52.880 --> 1:16:59.880
 I mean, it's all, it's not, I'm not saying bad things only happen in the world. They're good and bad things that happen. You're absolutely right.

1:16:59.880 --> 1:17:10.880
 And, but I don't think we're on the path to eliminating these bad things, really bad things from happening. I just don't think we are.

1:17:10.880 --> 1:17:16.880
 And I don't think there's any, I don't think the facts demonstrated. I'm, I hope, I hope you're right.

1:17:16.880 --> 1:17:21.880
 But, but I think otherwise, otherwise it's just an article of faith.

1:17:21.880 --> 1:17:31.880
 Well, you know, which is perfectly fine. It's better to have that article of faith than to have a article of faith which says, you know, things should get bad or things like that.

1:17:31.880 --> 1:17:39.880
 Well, it's not, it's not just fine. It's the only way if you want to build a better future. So optimism is a prerequisite for engineering about a future.

1:17:39.880 --> 1:17:54.880
 So like, okay, so a historian has to see clearly into the past and engineer has to, has to imagine a future that's different from the past, that's better than the past.

1:17:54.880 --> 1:17:58.880
 Because without that, they're not going to be able to build a better future.

1:17:58.880 --> 1:18:11.880
 So there's a kind of saying like you have to consider the facts. Well, at every single moment in history, if you allow yourself to be too grounded by the facts of the past, you're not going to create the future.

1:18:11.880 --> 1:18:18.880
 So that's kind of the tension that we're living with. To have a chance, we have to imagine that the better future is possible.

1:18:18.880 --> 1:18:22.880
 But one of the ways to do that is to study history.

1:18:22.880 --> 1:18:30.880
 Which engineers don't do enough of, which is a real problem, you know, it's a real problem.

1:18:30.880 --> 1:18:35.880
 Well, basically a lot of disciplines in science and so on don't do enough of.

1:18:35.880 --> 1:18:46.880
 Can you tell the story of China from 1958 to 1962, what was called the Great Leap Forward, orchestrated by Chairman Mao Zedong,

1:18:46.880 --> 1:18:53.880
 that led to the deaths of tons of millions of people making it arguably the largest famine in human history?

1:18:53.880 --> 1:19:01.880
 Yes. I mean, it was, you know, a terrible set of events that led to the death.

1:19:01.880 --> 1:19:15.880
 You know, people will dispute the numbers, 15 million, 17 million, 14 million, 20 million people died in the Great Leap.

1:19:15.880 --> 1:19:16.880
 30, 40, 50 million.

1:19:16.880 --> 1:19:19.880
 And some people will go that high too. That's right. That's right.

1:19:19.880 --> 1:19:32.880
 Essentially, Mao and the Communist Party leadership, but it was, you know, it was mostly Mao's doing, decided he wanted, you know, to move the country into communism.

1:19:32.880 --> 1:19:37.880
 And part of the idea of that, you know, was rivalry with the Soviet Union.

1:19:37.880 --> 1:19:47.880
 You know, Mao was a good Stalinist or at least felt like Stalin was the right kind of communist leader to have and he didn't like Khrushchev at all.

1:19:47.880 --> 1:19:56.880
 And he didn't like what he thought were Khrushchev's reforms and also Khrushchev's pretensions to moving the Soviet Union into communism.

1:19:56.880 --> 1:20:01.880
 So Khrushchev, you know, started talking about giving more power to the party, less power to the state.

1:20:01.880 --> 1:20:06.880
 And if you have more power to the party versus the state, then you're moving into communism quicker.

1:20:06.880 --> 1:20:16.880
 So what Mao decided to do was to engage in this vast program of, you know, building what were called people's communes.

1:20:16.880 --> 1:20:24.880
 And these communes, you know, were enormous conglomerations of essentially collective farms.

1:20:24.880 --> 1:20:34.880
 You know, and what would happen on those communes is there would be, you know, there would be places for people to eat and there would be places for the kids to be raised.

1:20:34.880 --> 1:20:39.880
 And, you know, essentially kind of separate homes and they would be schooled.

1:20:39.880 --> 1:20:51.880
 Everybody would turn over their metal, which was one of the actually turned out to be terribly negative phenomenon, their metal pots and pans to be melted to then make steel.

1:20:51.880 --> 1:21:00.880
 Every of these big communes would all have little steel plants and they would build steel and the whole countryside would be transformed.

1:21:00.880 --> 1:21:09.880
 Well, like many of these sort of, I mean, a true megalomaniac project, you know, like some of Stalin's projects too.

1:21:09.880 --> 1:21:14.880
 And this particular project then, you know, the people had no choice.

1:21:14.880 --> 1:21:17.880
 They were forced, you know, to do this.

1:21:17.880 --> 1:21:24.880
 It was incredibly dysfunctional for Chinese agriculture.

1:21:24.880 --> 1:21:35.880
 And ended up, you know, creating, as you mentioned, a terrible famine that everybody understood was a famine as a result of this.

1:21:35.880 --> 1:21:42.880
 I mean, there were some, there were also some problems of nature at the same time and some flooding and bad weather and that sort of thing.

1:21:42.880 --> 1:21:45.880
 But it was really a manmade famine.

1:21:45.880 --> 1:21:53.880
 And now a set at one point, you know, who cares, you know, if, you know, millions die, it just doesn't matter.

1:21:53.880 --> 1:21:54.880
 We've got millions more left.

1:21:54.880 --> 1:22:05.880
 I mean, he would periodically say things like this that show that like Stalin, he had, you know, total indifference, you know, to the fact that people were dying in large numbers.

1:22:05.880 --> 1:22:15.880
 It led again to cannibalism and to terrible wastage all over the country and millions of people died.

1:22:15.880 --> 1:22:17.880
 And there was just no stopping it.

1:22:17.880 --> 1:22:27.880
 You know, there were people in the party who began to kind of edge towards telling my oh, this wasn't a great idea, you know, and that he should back off, but he couldn't back off.

1:22:27.880 --> 1:22:37.880
 And the result was, you know, catastrophe in the countryside and all these people dying and then they, you know, compounding the problem was the political elite,

1:22:37.880 --> 1:22:48.880
 which then, you know, if peasants would object or if certain people would say no, they beat the hell out of them, you know, they would beat people, you know, who didn't do what they wanted them to do.

1:22:48.880 --> 1:22:58.880
 So it was, it was really, really a horrific set of events on the Chinese, the Chinese countryside.

1:22:58.880 --> 1:23:01.880
 I mean, you know, and people, people wrote about it.

1:23:01.880 --> 1:23:03.880
 I mean, we learned about it.

1:23:03.880 --> 1:23:08.880
 There were people who were keeping track of what was going on and eventually wrote books about it.

1:23:08.880 --> 1:23:13.880
 So, you know, so we have, I mean, we have pretty good documentation, not so much on the numbers.

1:23:13.880 --> 1:23:18.880
 Numbers is, numbers are always a difficult problem, you know, I'm facing this problem.

1:23:18.880 --> 1:23:27.880
 By the way, this is a little, little bit separate with the Halodomor, where, you know, Ukrainians are now claiming 11.5 million people died in Halodomor.

1:23:27.880 --> 1:23:32.880
 And, you know, most people assume it's somewhere in the neighborhood of 4 million, 4.5 million, maybe.

1:23:32.880 --> 1:23:41.880
 So you have wildly different numbers that come out and we have different kinds of numbers, as you mentioned too, with the Great Leap Forward.

1:23:41.880 --> 1:23:47.880
 So it was a huge catastrophe for China and now only backed off when he had to.

1:23:47.880 --> 1:24:01.880
 And then, you know, revived a little bit with the, you know, Red Guard's movement later on when, when, you know, he was, he was upset that the bureaucracy was resisting him a little bit when it came to the Great Leap.

1:24:01.880 --> 1:24:05.880
 But he had, he had to back off with such a, such a terrible catastrophe.

1:24:05.880 --> 1:24:23.880
 So one of the things about numbers is that you usually talk about deaths, but with, with the famine, with starvation, the thing I often think about that's impossible to put into numbers is the number of people and the degree to which they were suffering.

1:24:23.880 --> 1:24:28.880
 You know, the number of days spent in suffering.

1:24:28.880 --> 1:24:29.880
 Oh yeah.

1:24:29.880 --> 1:24:38.880
 And so, I mean, death is, death is just one of the consequences of suffering.

1:24:38.880 --> 1:24:51.880
 To me, it feels like one, two, three years or months and then years of, of not having anything to eat is, is worse.

1:24:51.880 --> 1:24:54.880
 And it's sort of those, those aren't put into numbers often.

1:24:54.880 --> 1:24:55.880
 That's right.

1:24:55.880 --> 1:25:12.880
 And the effect on people long term, you know, in terms of their mental health, in terms of their physical health, their ability to work, all those kinds of things, you know, I mean, Ukrainians are working on, the people working on this subject now, you know, the long term effect of, of the hunger famine on them.

1:25:12.880 --> 1:25:19.880
 And I'm sure there's a similar kind of long term effect on Chinese peasantry of what happened, you know, the, I mean, you're destroying.

1:25:19.880 --> 1:25:20.880
 Multi generational.

1:25:20.880 --> 1:25:21.880
 Yes, multi generational.

1:25:21.880 --> 1:25:22.880
 That's right.

1:25:22.880 --> 1:25:23.880
 Wow.

1:25:23.880 --> 1:25:26.880
 And, you know, it's a, it's a really, you're absolutely right.

1:25:26.880 --> 1:25:28.880
 This is a terrible, terrible way to die.

1:25:28.880 --> 1:25:31.880
 And, and it lasts a long time.

1:25:31.880 --> 1:25:33.880
 And sometimes you don't die, you survive.

1:25:33.880 --> 1:25:39.880
 But, you know, in, in the kind of shape where you can't, you can't do anything.

1:25:39.880 --> 1:25:41.880
 I mean, you can't, you can't function.

1:25:41.880 --> 1:25:43.880
 Now your brain's been injured.

1:25:43.880 --> 1:25:48.880
 You know, I know it's a really, these, these famines are really horrible.

1:25:48.880 --> 1:25:49.880
 You're right.

1:25:49.880 --> 1:25:52.880
 So when you talk about genocide, it's often talking about murder.

1:25:52.880 --> 1:25:54.880
 How do you place North Korea in this discussion?

1:25:54.880 --> 1:25:56.880
 We kind of mentioned it.

1:25:56.880 --> 1:25:58.880
 So in the, what is it?

1:25:58.880 --> 1:26:07.880
 The arduous March of the 1990s, where it was mass starvation.

1:26:07.880 --> 1:26:12.880
 Many people describe mass starvation going on now in North Korea.

1:26:12.880 --> 1:26:20.880
 When you think about genocide, when you think about atrocities going on in the world today, where do you place North Korea?

1:26:20.880 --> 1:26:33.880
 So take a step back when the, there were all these courts that were set up for, for Bosnia and for Wanda and, and, and for other genocides in the 1990s.

1:26:33.880 --> 1:26:38.880
 And then the decision was made by the international community.

1:26:38.880 --> 1:26:49.880
 UN basically to set up the international criminal court, which would then try genocide in the more modern period and the more contemporary period.

1:26:49.880 --> 1:27:10.880
 And the ICC lists three crimes basically, you know, the, the genocide crimes against humanity and war crimes and, and subsumed to crimes against humanity are a lot of the kinds of things you're talking about with North Korea.

1:27:10.880 --> 1:27:20.880
 I mean, it's, it's torture, it's artificial, sometimes artificial famine or famine, you know, that is not, not necessary, right?

1:27:20.880 --> 1:27:22.880
 Not necessary to have it.

1:27:22.880 --> 1:27:27.880
 And other, there are other kinds of, you know, mass rape and stuff like that.

1:27:27.880 --> 1:27:32.880
 There are other kinds of things that fit into the crimes against humanity.

1:27:32.880 --> 1:27:38.880
 And that's sort of where I think about North Korea as committing crimes against humanity, not genocide.

1:27:38.880 --> 1:27:48.880
 And again, remember, genocide is, is meant to be, I mean, some people, there's a disagreement among scholars and jurists about this.

1:27:48.880 --> 1:27:56.880
 Some people think of genocide as the crime of crimes, the worst of the three that I just mentioned, but some think of them as co equal.

1:27:56.880 --> 1:28:05.880
 And the ICC, the international criminal court is dealing with them more or less as co equal, even though we tend to think of genocide as the worst.

1:28:05.880 --> 1:28:10.880
 So, I mean, what I'm trying to say is that, you know, I don't want to, I don't want to split hairs.

1:28:10.880 --> 1:28:19.880
 I think it's sort of morally and ethically unseemly, you know, the split hairs about what is genocide and what is a crime against humanity.

1:28:19.880 --> 1:28:22.880
 You know, this is for lawyers, not for historians.

1:28:22.880 --> 1:28:23.880
 Terminology wise.

1:28:23.880 --> 1:28:27.880
 Yeah, yeah, you know, that you don't want to get into that.

1:28:27.880 --> 1:28:38.880
 Because it, I mean, it happened with Darfur a little bit where the Bush administration had had declared that Darfur was a genocide and the UN said no, no.

1:28:38.880 --> 1:28:42.880
 It's, you know, it wasn't genocide, it was a crime against humanity.

1:28:42.880 --> 1:28:46.880
 And then, you know, that confused things versus clarified them.

1:28:46.880 --> 1:28:48.880
 I mean, we damn well knew what was happening.

1:28:48.880 --> 1:28:51.880
 People were being killed or being attacked.

1:28:51.880 --> 1:29:07.880
 And, and so, you know, on the one hand, I think the whole concept and the way of thinking about history using genocide as an important part of human history is, is crucial.

1:29:07.880 --> 1:29:15.880
 On the other hand, I don't, I don't like to, you know, get, get involved in the hair splitting of what's genocide and what's not.

1:29:15.880 --> 1:29:27.880
 So that, you know, North Korea, I tend to think of, like I said, as, as committing crimes against humanity and, and, you know, forcibly incarcerating people, torturing them, that kind of thing.

1:29:27.880 --> 1:29:35.880
 You know, routinely incarcerating, depriving them of certain kinds of human rights can be considered a crime against humanity.

1:29:35.880 --> 1:29:40.880
 But I don't think of it as the same way I think about genocide, which is an attack on a group of people.

1:29:40.880 --> 1:29:42.880
 Let me just leave it at that.

1:29:42.880 --> 1:29:47.880
 What in this, if we think about, if it's okay, can we loosely use the term genocide here?

1:29:47.880 --> 1:29:49.880
 Just let's not play games with terminology.

1:29:49.880 --> 1:29:50.880
 Right.

1:29:50.880 --> 1:29:54.880
 Just bad crimes against humanity.

1:29:54.880 --> 1:29:56.880
 Right.

1:29:56.880 --> 1:30:08.880
 Of particular interest are the ones that are going on today still, because it raises the question to us, what do people outside of this, what role do they have to play?

1:30:08.880 --> 1:30:20.880
 So what role does the United States, or what role do I, as a human being, who has food today, who has shelter, who has a comfortable life?

1:30:20.880 --> 1:30:32.880
 What role do I have when I think about North Korea, when I think about Syria, what I think about maybe the Uighur population in, in China?

1:30:32.880 --> 1:30:43.880
 Well, I mean, the role is the same role I have, which is to teach and to learn and to get the message out that this is happening.

1:30:43.880 --> 1:30:56.880
 Because the more people who understand it, the more likely it is that the United States government will try to do something about it, you know, in, within the context of who we are and where we live, right?

1:30:56.880 --> 1:31:01.880
 And so, you know, I write books, you do shows, you know?

1:31:01.880 --> 1:31:03.880
 Or maybe you write books too.

1:31:03.880 --> 1:31:04.880
 I don't know.

1:31:04.880 --> 1:31:07.880
 No, I do not write books, but I tweet.

1:31:07.880 --> 1:31:08.880
 You tweet.

1:31:08.880 --> 1:31:09.880
 Okay.

1:31:09.880 --> 1:31:10.880
 Ineliquently.

1:31:10.880 --> 1:31:12.880
 But that's not the, I guess that's not the point.

1:31:12.880 --> 1:31:13.880
 Yes.

1:31:13.880 --> 1:31:14.880
 So certainly this is true.

1:31:14.880 --> 1:31:24.880
 And in terms of a voice, in terms of words, in terms of books, you are in, I would say, a rare example of somebody that has powerful reach with words.

1:31:24.880 --> 1:31:27.880
 But I was also referring to actions.

1:31:27.880 --> 1:31:31.880
 The United States government, what are the options here?

1:31:31.880 --> 1:31:34.880
 So war has costs.

1:31:34.880 --> 1:31:43.880
 And war seems to be, as you have described, sort of potentially increased the atrocity, not decrease it.

1:31:43.880 --> 1:31:55.880
 If there's anything that challenges my hope for the future is the fact that sometimes we're not powerless to help, but very close to powerless to help.

1:31:55.880 --> 1:32:04.880
 Because trying to help can often lead to, in the near term, more negative effects than positive effects.

1:32:04.880 --> 1:32:05.880
 That's exactly right.

1:32:05.880 --> 1:32:17.880
 I mean, you know, the unintended consequences of what we do can frequently be as bad, if not worse than, you know, trying to relieve the difficulties that people are having.

1:32:17.880 --> 1:32:20.880
 So I think, you know, you're caught a little bit.

1:32:20.880 --> 1:32:22.880
 But it's also true.

1:32:22.880 --> 1:32:24.880
 I think that we can be more forceful.

1:32:24.880 --> 1:32:28.880
 I think we can be more forceful without necessarily war.

1:32:28.880 --> 1:32:34.880
 You know, there is this idea of the so called responsibility to protect.

1:32:34.880 --> 1:32:42.880
 And this was an idea that came up, you know, after Kosovo, which was what, 1999.

1:32:42.880 --> 1:32:50.880
 And when, you know, the Serbs looked like they were going to engage in a genocidal program in Kosovo.

1:32:50.880 --> 1:32:59.880
 You know, it was basically a program of ethnic cleansing, but it could have gone bad and gotten worse, not just driving people out, but beginning to kill them.

1:32:59.880 --> 1:33:08.880
 And the United States and Britain and others intervened, you know, and Russians were there too, as you probably recall.

1:33:08.880 --> 1:33:19.880
 And I think correctly, people have analyzed this as a case in which genocide was prevented or stopped.

1:33:19.880 --> 1:33:21.880
 In other words, the Serbs were stopped in their tracks.

1:33:21.880 --> 1:33:23.880
 I mean, some bad things did happen.

1:33:23.880 --> 1:33:26.880
 We bombed Belgrade and the Chinese embassy and things like that.

1:33:26.880 --> 1:33:30.880
 But, you know, it was stopped.

1:33:30.880 --> 1:33:36.880
 And following upon that, then there was a kind of international consensus that we needed to do something.

1:33:36.880 --> 1:33:42.880
 I mean, because of Rwanda, Bosnia, and the positive example of Kosovo, right?

1:33:42.880 --> 1:33:45.880
 That genocide did not happen in Kosovo.

1:33:45.880 --> 1:33:51.880
 I think that argument, you know, has been substantiated anyway.

1:33:51.880 --> 1:34:05.880
 And this notion of the, or this, you know, doctrine or whatever of the responsibility to protect them was adopted by the UN in 2005 unanimously.

1:34:05.880 --> 1:34:13.880
 And what it says is there's a hierarchy of measures that should be, well, let me take a step back.

1:34:13.880 --> 1:34:26.880
 It starts with the principle that sovereignty of a country is not, you don't earn it just by being there and being your own country.

1:34:26.880 --> 1:34:29.880
 You have to earn it by protecting your people.

1:34:29.880 --> 1:34:36.880
 So every, this was all agreed with all the nations of the UN agreed, you know, Chinese and then Russians too.

1:34:36.880 --> 1:34:45.880
 That, you know, sovereignty is there because you protect your people against various depredations, right?

1:34:45.880 --> 1:34:51.880
 Including genocide, crimes against humanity, you know, forced imprisonment, torture and that sort of thing.

1:34:51.880 --> 1:35:02.880
 If you violate that justification for your sovereignty, that you're protecting your people, that you're not protecting them,

1:35:02.880 --> 1:35:09.880
 the international community has the obligation to do something about it, all right?

1:35:09.880 --> 1:35:16.880
 Now, then they have a kind of hierarchy of things you can do, you know, starting with, I mean, I'm not quoting exactly,

1:35:16.880 --> 1:35:22.880
 but, you know, starting with kind of push and pull, you know, trying to convince people, don't do that, you know, to Myanmar,

1:35:22.880 --> 1:35:27.880
 don't do that to the Rohingya people, right?

1:35:27.880 --> 1:35:33.880
 And then it goes down the list, you know, and you get to a little sanction, to threatening sanctions and then sanctions,

1:35:33.880 --> 1:35:38.880
 you know, like we have against Russia, but you go down the list, right?

1:35:38.880 --> 1:35:46.880
 You go down the list and eventually you get to military intervention at the bottom, which they say is the last thing,

1:35:46.880 --> 1:35:49.880
 you know, and you really don't want to do that.

1:35:49.880 --> 1:35:57.880
 And not only do you not want to do it, but it hit just as you said, just as you pointed out, it can have unintended consequences, right?

1:35:57.880 --> 1:36:08.880
 And we'll do everything we can short, you know, of military intervention, but, you know, if necessary, that can be undertaken as well.

1:36:08.880 --> 1:36:15.880
 And so the responsibility to protect, I think, is, you know, it was not implementable.

1:36:15.880 --> 1:36:19.880
 One of the things it says in this last category, right?

1:36:19.880 --> 1:36:28.880
 The military intervention is that the intervention cannot create more damage than it relieves, right?

1:36:28.880 --> 1:36:38.880
 And so for Syria, we came to the conclusion, you know, that, I mean, the international community in some ways said this in so many words,

1:36:38.880 --> 1:36:42.880
 even though the Russians were there, obviously, we ended up being there and that sort of thing.

1:36:42.880 --> 1:36:47.880
 But the international community basically said, you know, there's no way you can intervene in Syria.

1:36:47.880 --> 1:36:53.880
 You know, there's just no way without causing more damage, you know, than you would relieve.

1:36:53.880 --> 1:37:01.880
 So, you know, in some senses, that's what the international community is saying about, you know, Xinjiang and the Uyghurs, too.

1:37:01.880 --> 1:37:11.880
 You know, I mean, you can't even imagine what hell would break loose if there was some kind of military trouble, you know, to threaten the Chinese with.

1:37:11.880 --> 1:37:22.880
 But you can go down that list with, you know, the military leadership of Myanmar and you can go down that list with the Chinese Communist Party.

1:37:22.880 --> 1:37:32.880
 And you can go down the list, you know, with others who are threatening, you know, with Ethiopia and what it's doing in Tigray.

1:37:32.880 --> 1:37:36.880
 And, you know, you can go down that list and start pushing.

1:37:36.880 --> 1:37:49.880
 I think what happened, there was more of a willingness in the 90s and, you know, right at the turn of the century, you know, to do these kinds of things.

1:37:49.880 --> 1:37:57.880
 And then, you know, when Trump got elected and, you know, he basically said, you know, America first and out of the world, we're not going to do any of this kind of stuff.

1:37:57.880 --> 1:38:05.880
 And now Biden has the problem of trying to rebuild consensus on how you deal with these kinds of things.

1:38:05.880 --> 1:38:11.880
 I think it's not impossible. I mean, here I tend to be maybe more of an optimist than you.

1:38:11.880 --> 1:38:34.880
 You know, I think it's not impossible that the international community can, you know, muster some internal fortitude and push harder, short of war, you know, to get the Chinese and to get the, again, Myanmar and to get others to kind of back off of violations of people's rights.

1:38:34.880 --> 1:38:37.880
 The way they are routinely doing it.

1:38:37.880 --> 1:38:41.880
 So that's in the space of geopolitics. This is the space of politicians and UN and so on.

1:38:41.880 --> 1:38:42.880
 Yes, yes.

1:38:42.880 --> 1:39:02.880
 The interesting thing about China, and this is a difficult topic, but there's so many financial interests that not many voices with power and with money speak up, speak out against China.

1:39:02.880 --> 1:39:13.880
 Because it's a very interesting effect because it costs a lot for an individual to speak up because you're going to suffer.

1:39:13.880 --> 1:39:24.880
 I mean, China just cuts off the market. Like if you have a product, if you have a company and you say something negative, China just says, okay, well, then they knock you out of the market.

1:39:24.880 --> 1:39:32.880
 And so any person that speaks up, they get shut down immediately financially. It's a huge cost, sometimes millions or billions of dollars.

1:39:32.880 --> 1:39:40.880
 And so what happens is everybody of consequences, sort of financially, everybody with a giant platform is extremely hesitant to speak out.

1:39:40.880 --> 1:39:48.880
 It's a very, it's a different kind of hesitation. It's financial nature. I don't know if that was always the case.

1:39:48.880 --> 1:39:55.880
 It seems like in history, people were quiet because of fear, because of threat of violence.

1:39:55.880 --> 1:40:03.880
 Here, there's almost like a self interested preservation of financial wealth.

1:40:03.880 --> 1:40:17.880
 And I don't know what to do that. I mean, I don't know if you can say something there, like the genocide going on because people are financially self interested.

1:40:17.880 --> 1:40:38.880
 Yeah, no, I think, I mean, I think the analysis is correct. And it's not only, but it's not only corporations, but it's, you know, it's the American government that represents the American people that also feels compelled not to challenge the Chinese on human rights issues.

1:40:38.880 --> 1:40:48.880
 But the interesting thing is it's not just, you know, I know a lot of people from China and first of all, amazing human beings and a lot of brilliant people in China.

1:40:48.880 --> 1:40:57.880
 They also don't want to speak out and not because they're sort of quote unquote like silenced, but more because they're going to also lose financially.

1:40:57.880 --> 1:41:12.880
 They have a lot of businesses in China. They, you know, they're running. In fact, the Chinese government and the country has a very interesting structure because it has a lot of elements that enable capitalism within a certain framework.

1:41:12.880 --> 1:41:28.880
 So you have a lot of very successful companies, and they operate successfully. And then the leaders of those companies, many of whom have either been on this podcast, I want to be on this podcast, they really don't want to say anything negative about the government.

1:41:28.880 --> 1:41:48.880
 And the nature of the fear I sense is not the kind of fear you would have in Nazi Germany. It's a very kind of, it's a mellow, like why would I speak out when it has a negative effect on my company, on my family, in terms of financially, strictly financially.

1:41:48.880 --> 1:42:07.880
 And that's, that's difficult. That's a different problem to solve. That feels solvable, because it feels like it's a money problem. If you can control the flow of money, where the government has less power to control the flow of money, it feels like that's

1:42:07.880 --> 1:42:21.880
 solvable. And that's where capitalism is good. That's where the free market is good. So it's like, that's where a lot of people in the cryptocurrency space, I don't know if you follow them, they kind of say, okay, take the monetary system, the power to control money away from governments,

1:42:21.880 --> 1:42:41.880
 make it a distributed, like allow technology to help you with that. That's a hopeful message there. In fact, a lot of people argue that kind of Bitcoin, these cryptocurrencies can help deal with some of these authoritarian regimes that lead to violations of basic human rights.

1:42:41.880 --> 1:42:52.880
 If you can control, if you can give the power to control the money to the people, you can take that away from governments. That's another source of hope, where technology might be able to do something good.

1:42:52.880 --> 1:42:59.880
 That's something different about the 21st century than the 20th is there's technology in the hands of billions of people.

1:42:59.880 --> 1:43:13.880
 And I have to say, I think you're naive when it comes to technology. I mean, I'm not someone who understands technology, so it's wrong of me to argue with you because I don't really spend much time with it.

1:43:13.880 --> 1:43:28.880
 I don't really like it very much. And I'm not, I'm neither a fan nor a connoisseur. So I just don't really know. But what human history has shown, basically, and that's a big statement.

1:43:28.880 --> 1:43:39.880
 I don't want to pretend I can tell you what human history has shown. But technology, atom bomb, I mean, that's a perfect example of technology.

1:43:39.880 --> 1:43:47.880
 What happens when you discover new things? It's a perfect example of what's going on with Facebook now. It's an absolutely perfect example.

1:43:47.880 --> 1:43:59.880
 And I once went to a lecture by Eric Schmidt about the future and about all the things that were going to happen and all these wonderful things like you wouldn't have to translate yourself anything.

1:43:59.880 --> 1:44:06.880
 You wouldn't have to read a book. You wouldn't have to drive a car. You don't have to do this. You don't have to do that. What kind of life is that?

1:44:06.880 --> 1:44:19.880
 So, you know, my view of technology is it's, it's subsumed, you know, to the political, social and moral needs of our day and should be subsumed to that day.

1:44:19.880 --> 1:44:27.880
 It's not going to solve anything by itself. It's going to be you and me that solve things if they're solved or our political system that solve things.

1:44:27.880 --> 1:44:38.880
 Technology is neutral on one level. It is simply a human, I mean, they're talking now about how artificial intelligence, you know, is going to do this and is going to do that.

1:44:38.880 --> 1:44:47.880
 I'm not so sure there's anything necessarily positive or negative about it, except it does obviously make work easier and things like that.

1:44:47.880 --> 1:45:10.880
 I mean, I, you know, I like email and I like, you know, word processing and that sort of all that stuff is great. But, but actually solving human relations in and of itself or international relations or, or conflict among human beings.

1:45:10.880 --> 1:45:18.880
 I mean, I see technology as, you know, causing as many problems as it solves and maybe even more, you know, the kind.

1:45:18.880 --> 1:45:19.880
 Maybe, maybe.

1:45:19.880 --> 1:45:20.880
 Maybe, yeah.

1:45:20.880 --> 1:45:35.880
 The question is, so like you said, technology is neutral. I agree with this. Technology is a toolkit, is a tool set that enables humans to have wider reach and more power, the printing press.

1:45:35.880 --> 1:45:44.880
 The, the rare reason I can read your books is, I would argue, so first of all, the printing press and then the, the internet.

1:45:44.880 --> 1:45:58.880
 Wikipedia, I think, has immeasurable effect on humanity. Technology is a double edged sword. It allows bad people to do bad things and good people to do good things.

1:45:58.880 --> 1:45:59.880
 Exactly.

1:45:59.880 --> 1:46:00.880
 It ultimately boils down to.

1:46:00.880 --> 1:46:01.880
 Right, the people.

1:46:01.880 --> 1:46:11.880
 The people and whether you believe the capacity for good outweighs the capacity of bad. And so you said that I'm naive. It is true. I'm naively optimistic.

1:46:11.880 --> 1:46:26.880
 I would say you're naively cynical about technology. Here we have one overdressed naive optimist and one brilliant, but nevertheless, technologically naive cynic and we don't know.

1:46:26.880 --> 1:46:33.880
 We don't know that whether the capacity for good or the capacity for evil wins out in the end.

1:46:33.880 --> 1:46:34.880
 Right.

1:46:34.880 --> 1:46:44.880
 And like we've been talking about, the trajectory of human history seems to pivot on a lot of random, seeming moments. So we don't know.

1:46:44.880 --> 1:46:45.880
 Right.

1:46:45.880 --> 1:47:01.880
 As a builder of technology, I remain optimistic. And I should say kind of when you are optimistic, it is often easy to sound naive.

1:47:01.880 --> 1:47:17.880
 And I'm not sure what to make of that small effect and not to linger on specific words, but I've noticed that people who kind of are cynical about the world somehow sound more intelligent.

1:47:17.880 --> 1:47:28.880
 No, no, the issue is how do you, how are you, how can you be realistic about the world? It's not optimistic or pessimistic. It's not cynical. The question is, how can you be a realist?

1:47:28.880 --> 1:47:29.880
 Right.

1:47:29.880 --> 1:47:30.880
 Yes.

1:47:30.880 --> 1:47:46.880
 You know, realism depends on a combination of knowledge and wisdom and good instincts and that sort of thing. And that is, that's what we strive for, you know, is a kind of realism.

1:47:46.880 --> 1:47:48.880
 We both strive for that kind of realism.

1:47:48.880 --> 1:47:49.880
 Yes.

1:47:49.880 --> 1:47:59.880
 But I mean, here's an example I would give you. You know, what about, again, we've got this environmental issue, right? And technology has created it.

1:47:59.880 --> 1:48:16.880
 It's created it. I mean, the growth of technology, I mean, we all like to be heated well in our homes and we want to have cars that run quickly and fast on, you know, gas and that sort of, I mean, there's all, we're all consumers and we all profit from this.

1:48:16.880 --> 1:48:28.880
 I don't, I don't, not everybody profits from it, but, you know, but we want to be comfortable. And technology has provided us with a comfortable life. And it's also provided us, you know, with this incredible danger.

1:48:28.880 --> 1:48:30.880
 Which it's not solving, at least not now.

1:48:30.880 --> 1:48:31.880
 Okay.

1:48:31.880 --> 1:48:47.880
 And it may solve, but it may, it's only, my view is, you know, what's going to, what's going to happen? A horrible catastrophe. It's the only way, it's the only way we will direct ourselves to actually trying to do something about it.

1:48:47.880 --> 1:49:09.880
 We don't have the wisdom and the realism and the sense of purpose. You know, what's your name? Greta goes blah, blah, blah, something like that in her last talk about the, about the environmental summit in Glasgow or whatever it was.

1:49:09.880 --> 1:49:32.880
 And, you know, we just, we just don't have it unless we're hit upside the head really, really hard. And then maybe, you know, the business with nuclear weapons, you know, I think somehow we got hit upside the head and we realize, oh man, you know, this could really do it to the whole world.

1:49:32.880 --> 1:49:50.880
 And so we started, you know, serious arms control stuff. And, you know, but up to that point, you know, I mean, there was just something about, you know, Khrushchev's big bomb, his big hydrogen bomb, which he exploded in the times, I think it was the anniversary or something like that.

1:49:50.880 --> 1:49:53.880
 You know, I mean, just think what we could have done to each other.

1:49:53.880 --> 1:49:55.880
 Well, that's the double edge of the technology.

1:49:55.880 --> 1:50:19.880
 I agree. There's a lot of people, there's a lot of people that argue that nuclear weapons is the reason we haven't had a World War Three. So nuclear weapons, the mutually assured destruction leads to a kind of like, we've reached a certain level of destructiveness with our weapons, where we were able to catch ourselves, not to create, like you said, hit really hard.

1:50:19.880 --> 1:50:46.880
 This is the, this is the interesting question about kind of hard, hard and really hard upside the head with the, with the environment, I would argue, see, we can't know the future, but I would argue, as the pressure builds, there's already, because of this created urgency, the amount of innovation that I've seen that sometimes is unrelated to the environment,

1:50:46.880 --> 1:51:05.880
 but kind of sparked by this urgency. It's been humongous, including the work of Elon Musk, including the work of just, you could argue that the SpaceX and the new exploration of space is kind of sparked by this environmental like urgency.

1:51:05.880 --> 1:51:22.880
 I mean, connected to Tesla and everything they're doing with electric vehicles and so on. There's a huge amount of innovation in the space that's happening. I could see the effect of climate change, resulting in more positive innovation that improves the quality of life across the world,

1:51:22.880 --> 1:51:37.880
 than the actual catastrophic events that we're describing, which we cannot even currently predict. It's not like there's going to be, there's going to be more extreme weather events. What does that even mean? There's going to be a gradual increase of the level of water.

1:51:37.880 --> 1:51:56.880
 What does that even mean in terms of catastrophic events? It's going to be pretty gradual. There's going to be migration of people. We can't predict what that means. And in response to that, there's going to be a huge amount of innovators born today that have dreams and that will build devices and inventions

1:51:56.880 --> 1:52:10.880
 and from space to vehicles to in the software world that enable education across the world, all those kinds of things that will en masse, on average, increase the quality of life, on average, across the world.

1:52:10.880 --> 1:52:30.880
 So it's not at all obvious that the technologies that are creating climate change, global warming, are going to have a negative and that negative effect. We don't know this. And I'm kind of inspired by the dreamers, the engineers, the innovators,

1:52:30.880 --> 1:52:42.880
 the entrepreneurs that wake up in the morning and see problems in the world and dream that they're going to be the ones who solve those problems. That's the human spirit.

1:52:42.880 --> 1:52:56.880
 And I'm not exactly, it is true that we need those deadlines. We need to be freaking out about stuff. And the reason we need to study history and the worst of human history is that we can say, oh, shit, this too can happen.

1:52:56.880 --> 1:53:16.880
 It's a slap in the face. It's a wake up call that if you get complacent, if you get lazy, this is going to happen. And that, listen, there's a lot of really intelligent people, ambitious people, dreamers, skilled dreamers that build solutions that make sure this stuff doesn't happen anymore.

1:53:16.880 --> 1:53:28.880
 So there's, I think there's reason to be optimistic about technology, not in a naive way. There's an argument to be made in a realistic way that like with technology, we can build a better future.

1:53:28.880 --> 1:53:46.880
 And then Facebook is a lesson in the way Facebook has been done, is a lesson how not to do it. And that lesson serves as a guide of how to do it better, how to do it right, how to do it in a positive way.

1:53:46.880 --> 1:54:00.880
 The same every single sort of failed technology contains the lessons of how to do it better. And I mean, without that, what's the source of hope for human civilization?

1:54:00.880 --> 1:54:16.880
 You know, that, I mean, by way of question, you have truly studied some of the darkest moments in human history. Put on your optimist hat. Where? That one. Yes.

1:54:16.880 --> 1:54:24.880
 The glimmers of it. Yes. What is your source of hope for the future of human civilization?

1:54:24.880 --> 1:54:46.880
 Well, I think it resides in, you know, some of what you've been saying, which is the in the persistence of this civilization over time, despite, you know, the incredible setbacks, you know, to enormous world wars, you know, the nuclear standoff.

1:54:46.880 --> 1:55:00.880
 You know, the horrible things we're experiencing now with climate change and migration and stuff like that, that despite these things, you know, we are persisting.

1:55:00.880 --> 1:55:10.880
 And we are continuing and like you say, we're continuing to invent and we're continuing to try to solve these problems. And you know, we're continuing to love as well as hate.

1:55:10.880 --> 1:55:22.880
 And, you know, that, you know, I'm basically, I mean, I have children and grandchildren, and I think they're going to be just fine.

1:55:22.880 --> 1:55:32.880
 You know, I'm not a doom and gloomer. You know, I'm not a Cassandra saying the world is coming to an end. I'm not like that at all.

1:55:32.880 --> 1:55:51.880
 You know, I think that, you know, things will persist. And other by the way, a source of tremendous optimism on my part, the kids I teach, you know, I teach some unbelievably fantastic young people, you know, who are sort of like you say, they're

1:55:51.880 --> 1:56:05.880
 dreamers and they're problem solvers and they're, I mean, they have enormously humane values and ways of thinking about the world and they want to do good.

1:56:05.880 --> 1:56:16.880
 You know, if you take the kind of, I mean, this has probably been true all the way along, but I mean, the percentage of do gooders, you know, is really enormously large.

1:56:16.880 --> 1:56:30.880
 Whether they end up working for some kind of shark law firm or something, you know, or, or, you know, that, that, that kind of thing, or whether they end up human rights lawyers is they all want to be, right?

1:56:30.880 --> 1:56:46.880
 You know, is a different kind of question. But, but certainly, you know, these young people are talented, they're smart, they're wonderful values, they're energetic, they work hard, you know, they're focused.

1:56:46.880 --> 1:56:54.880
 And of course, it's not just Stanford. I mean, it's all over the country. You know, you have young people who really want to contribute.

1:56:54.880 --> 1:57:03.880
 And they want to contribute. I mean, you, I mean, it's true some of them end up, you know, working to get rich. I mean, that's inevitable, right?

1:57:03.880 --> 1:57:15.880
 But, but the percentages are actually rather small, at least at this age, you know, maybe when they get a mortgage and a family and that sort of thing, you know, the financial well being will be more important to them.

1:57:15.880 --> 1:57:32.880
 But right now, you know, you catch this young generation and they're fantastic. They're fantastic. And, and they're not what they're often portrayed as being, you know, kind of silly and naive and knee jerk leftists and that they're not at all like that.

1:57:32.880 --> 1:57:39.880
 You know, they're really, they're really fine young people. So that's a source of optimism to me, too.

1:57:39.880 --> 1:57:54.880
 What advice would you give to those young people today, maybe in high school and college at Stanford, maybe to your grandchildren about how to have a career they can be proud of, have a life they can be proud of?

1:57:54.880 --> 1:58:02.880
 Pursue careers that are in the public interest, you know, in one fashion or another, and not just in their interests.

1:58:02.880 --> 1:58:15.880
 And that would be, I mean, it's not bad to pursue a career in your own interests. I mean, as long as you're, it's something that's useful and positive for the, you know, for their families or whatever.

1:58:15.880 --> 1:58:26.880
 But yeah, so I mean, I try to, I try to advise kids to find themselves somehow, you know, find it who they want to be and what they want to be and try to pursue it.

1:58:26.880 --> 1:58:40.880
 And the NGO world is growing, as you know. And a lot of young people are kind of throwing themselves into it and, you know, human rights watch and that kind of stuff.

1:58:40.880 --> 1:58:46.880
 And, you know, they want to do that kind of work. And it's very admirable.

1:58:46.880 --> 1:59:07.880
 I tend to think that even if you're not working in human rights, there's a certain way in which if you live with integrity, the, I believe that all of us, or many of us have a bunch of moments in our lives when we're posed with the decision.

1:59:07.880 --> 1:59:28.880
 It's a quiet one. Maybe you'll never be written about or talked about. When you get to choose, whether you, there's a choice that is difficult to make, may require sacrifice, but it's the choice that the best version of that person would make.

1:59:28.880 --> 1:59:48.880
 That's the best way I can sort of say how to act with integrity. It's the very thing that would resist the early days in Nazi Germany. It sounds dramatic to say, but those little actions, and I feel like the best you can do to avoid genocide on scale is for all of us to live in that way,

1:59:48.880 --> 1:59:59.880
 to within those moments, unrelated potentially to human rights to anything else is to take those actions. Like, I believe that all of us know the right thing to do.

1:59:59.880 --> 2:00:22.880
 No, that's right. I think that's right. You put it very well. I couldn't have done it better myself. No, no, I agree. I agree completely that there are, you know, to live with truth, which is what Vassal Havel used to say, this famous Czech dissident, you know, talked about living in truth, but also to live with integrity.

2:00:22.880 --> 2:00:23.880
 Yeah.

2:00:23.880 --> 2:00:26.880
 And that's really super important.

2:00:26.880 --> 2:00:43.880
 Well, let me ask you about love. What role does love play in this whole thing in the human condition? In all the study of genocide, it does seem that hardship in moments brings out the best in human nature and the best in human nature is expressed to love.

2:00:43.880 --> 2:00:58.880
 Well, as I already mentioned to you, I think hardship is not a good thing for, you know, it's not the best thing for love. I mean, it's better to not have to suffer and not have to.

2:00:58.880 --> 2:01:11.880
 Yes, I think it is. I think it's, you know, as I mentioned to you, you know, studying concentration camps, you know, this is not a place for love. It happens.

2:01:11.880 --> 2:01:40.880
 But it's not really a place for love. It's a place for rape. It's a place for torture. It's a place for killing. And it's a place for inhuman action, one to another, you know, and also, as I said, among those who are suffering, not just between those who are, and then their whole gradations, you know, the same thing in the gulag, you know, their gradations all the way from the criminal prisoners who beat the hell out of them.

2:01:40.880 --> 2:01:47.880
 Political prisoners who beat the hell out of the political prisoners, you know, who then have others below them who they beat down, you know, so everybody's being the hell out of everybody else.

2:01:47.880 --> 2:01:57.880
 So I would not idealize in any way suffering as, you know, a source of beauty and love. A source of beauty and love. I wouldn't do that.

2:01:57.880 --> 2:02:20.880
 I think it's a whole lot better for people to be relatively prosperous. I'm not saying super prosperous, but to be able to feed themselves and to be able to feed their families and house their families and take care of themselves, you know, to foster loving relations between people.

2:02:20.880 --> 2:02:40.880
 And, you know, I think it's no accident that, you know, poor families have much worse records when it comes to crime and things like that, you know, and also to wife beating and to child abuse and stuff like that.

2:02:40.880 --> 2:02:52.880
 I mean, you just, you don't want to be poor and indigent and not have a roof over your head, be homeless. I mean, it doesn't mean again, you know, homeless people are mean people.

2:02:52.880 --> 2:03:00.880
 That's not what I'm trying to say. What I'm trying to say is that, you know, what we want to try to foster in this country and around the world.

2:03:00.880 --> 2:03:10.880
 And one of the reasons, you know, I mean, I'm very critical of the Chinese in a lot of ways, but I mean, we have to remember they pulled that country out of horrible poverty, right?

2:03:10.880 --> 2:03:21.880
 And I mean, there's still poor people on the countryside. There's still problems, you know, with want and need among the Chinese people.

2:03:21.880 --> 2:03:33.880
 But, you know, there were millions and millions of Chinese who were living at the bare minimum of life, which is no way to live, you know, and no way, again, to foster love and compassion and getting along.

2:03:33.880 --> 2:03:46.880
 So, I want to be clear, I don't speak for history, right? I'm giving you, I mean, there used to be historians, you know, in the 19th century who really thought they were speaking for history, you know, I don't think that way at all.

2:03:46.880 --> 2:03:53.880
 I mean, I understand I'm a subjective human being with my own, my own points of view and my own opinions, but...

2:03:53.880 --> 2:04:01.880
 I'm trying to remember this in this conversation that you're, despite the fact that you're brilliant and you've written brilliant books, that you're just human.

2:04:01.880 --> 2:04:02.880
 Well, I am.

2:04:02.880 --> 2:04:03.880
 With an opinion.

2:04:03.880 --> 2:04:12.880
 That's it. Yeah. No, no, that's absolutely true. And I tell my students that too. I mean, I make sure they understand this is not history speaking.

2:04:12.880 --> 2:04:24.880
 This is me and Norman and I'm, you know, and this is, this is what it's about. I mean, I spent a long time studying history and have enjoyed it enormously.

2:04:24.880 --> 2:04:41.880
 But, you know, I'm an individual with my points of view and one of them is that I've developed over time is that, you know, you know, human want is a real tragedy for people and it hurts people.

2:04:41.880 --> 2:04:55.880
 And it also causes upheavals and difficulties and stuff. So I feel for people, you know, I feel for people in Syria, I feel for people in, you know, in Ethiopia and Tigray, you know, when they don't have enough to eat.

2:04:55.880 --> 2:05:02.880
 And, you know, what that does, I mean, it doesn't mean they don't love each other, right? It doesn't mean they don't love their kids.

2:05:02.880 --> 2:05:07.880
 But it does mean that it's harder, you know, to do that and to...

2:05:07.880 --> 2:05:12.880
 I'm not so sure. It's obvious to me that it's harder. There's suffering. There is suffering.

2:05:12.880 --> 2:05:19.880
 But the numbers we've been talking about deaths, we've been talking about suffering, but the numbers we're not quantifying.

2:05:19.880 --> 2:05:30.880
 The history that you haven't perhaps been looking at is all the times that people have fallen in love deeply with friends, with romantic love, the positive emotion that people have felt.

2:05:30.880 --> 2:05:39.880
 And I'm not so sure that amidst the suffering, those moments of beauty and love can't be discovered. And if we look at the numbers, I'm not so sure the story is obvious.

2:05:39.880 --> 2:05:48.880
 That, you know, I mean, again, I suppose you may disagree with Victor Franco. I mean, too, maybe depending on the day.

2:05:48.880 --> 2:05:55.880
 I mean, he says that if there's meaning to this life at all, there's meaning to the suffering too, because suffering is part of life.

2:05:55.880 --> 2:06:06.880
 There's something about accepting the ups and downs, even when the downs go very low and within all of it, finding a source of meaning.

2:06:06.880 --> 2:06:14.880
 I mean, he's arguing from the perspective of psychology, but just this life is an incredible gift, almost no matter what.

2:06:14.880 --> 2:06:27.880
 And I'm not, it's easy to look at suffering and think if we just escape the suffering, it will all be better. But we all die.

2:06:27.880 --> 2:06:38.880
 There's beauty in the whole thing. And it is true that it's just from all the stories I've read, especially in famine and starvation, it's just horrible.

2:06:38.880 --> 2:06:46.880
 It is horrible suffering. But I also just want to say that there's love amidst it, and we can't forget that.

2:06:46.880 --> 2:06:49.880
 No, no, I don't. I don't forget it. I don't forget it.

2:06:49.880 --> 2:07:03.880
 And I think it's from the stories. Now, I don't want to make that compromise or that trade, but the intensity of friendship in war, the intensity of love in war is very high.

2:07:03.880 --> 2:07:13.880
 So I'm not sure what to make of these calculations. But if you look at the stories, some of the people I'm closest with, and I've never experienced anything even close to any of this.

2:07:13.880 --> 2:07:19.880
 But some of the people I'm closest with is people I've gone through difficult times with. There's something about that.

2:07:19.880 --> 2:07:28.880
 There's a society or a group where things are easy. The intensity of the connection between human beings is not as strong.

2:07:28.880 --> 2:07:36.880
 I don't know what to do with that calculus, because I, too, agree with you. I want to have as little suffering in the world as possible.

2:07:36.880 --> 2:07:44.880
 But we have to remember about the love and the depth of human connection and find the right balance there.

2:07:44.880 --> 2:07:48.880
 No, there's something to what you're saying. There's clearly something to what you're saying.

2:07:48.880 --> 2:07:55.880
 I was just thinking about the Soviet Union when I lived there, and people on the streets were so mean to one another, and they never smiled.

2:07:55.880 --> 2:08:01.880
 You grew up there? No, but you were too young. No, I remember. I came here when I was 13.

2:08:01.880 --> 2:08:06.880
 Okay, so anyway, I remember living there and just how hard people were on each other on the streets.

2:08:06.880 --> 2:08:14.880
 And when you got inside people's apartments, when they started to trust you, the friendships were so intense and so wonderful.

2:08:14.880 --> 2:08:22.880
 So in that sense, I mean, they did live a hard life. But there wasn't a food on the table, and there was a roof over their heads.

2:08:22.880 --> 2:08:29.880
 There's a certain line. There are lines. I don't think there's one line, but it's kind of a shading.

2:08:29.880 --> 2:08:43.880
 And the other story I was thinking of as you were talking was, it's not a story, it's a history, a book by a friend of mine who wrote about love in the camps,

2:08:43.880 --> 2:08:47.880
 in the refugee camps for Jews in Germany after the war.

2:08:47.880 --> 2:08:55.880
 So these were Jews who had come mostly from Poland and some survived the camps, came from awful circumstances,

2:08:55.880 --> 2:09:02.880
 and then they were put in in these camps, which were not joyful places. I mean, they were guarded sometimes by Germans even,

2:09:02.880 --> 2:09:11.880
 but they're basically under the British control, and they were trying to get to Israel, trying to get to Palestine right after the war.

2:09:11.880 --> 2:09:17.880
 And how many pairs there were, how many people coupled up. But remember, this is after being in the concentration camps,

2:09:17.880 --> 2:09:33.880
 but it's not being in the concentration camps. And it's also being free to more or less free, to express their emotions and to be human beings after this horrible thing which they suffered.

2:09:33.880 --> 2:09:46.880
 So I wonder whether there's, you know, as you say, some kind of calculus there where, you know, the level of suffering is such that it's just too much for humans to bear.

2:09:46.880 --> 2:09:56.880
 And, you know, which I would suggest, I haven't studied this myself, I'm just giving you my point of view, you know, off the cuff remarks here,

2:09:56.880 --> 2:10:05.880
 but it was very inspiring to read about these couples who had met right in these camps and started to couple up, you know, and get married,

2:10:05.880 --> 2:10:10.880
 and try to find their way to Palestine, which was a difficult thing to do then.

2:10:10.880 --> 2:10:15.880
 When did you live in Russia and the Soviet Union? What's your memory of that time?

2:10:15.880 --> 2:10:21.880
 Well, so a number of different times. So I went there, I first went there in 69 and 70.

2:10:21.880 --> 2:10:34.880
 Wow. A long time ago. And then I lived in Leningrad mostly, but also in Moscow in 1975. So it was detente time.

2:10:34.880 --> 2:10:45.880
 But it was also a time of political uncertainty and also hardship, you know, for Russians themselves, standing in long lines.

2:10:45.880 --> 2:10:51.880
 I mean, you must remember this for food and for getting anything was almost impossible.

2:10:51.880 --> 2:10:55.880
 It was a time when Jews were trying to get out.

2:10:55.880 --> 2:11:05.880
 In fact, I just talked to a friend of mine from those days who I helped get out and get to Boston and the lovely people who managed to have a good life

2:11:05.880 --> 2:11:09.880
 in the United States after they left. But it wasn't an easy time.

2:11:09.880 --> 2:11:17.880
 It wasn't an easy time at all. I remember people set fire to their doors and, you know, their daughter was persecuted in school.

2:11:17.880 --> 2:11:26.880
 You know, once they declared that they wanted to immigrate and that sort of thing. So it was a very, it was a lot of antisemitism.

2:11:26.880 --> 2:11:34.880
 So it was a tough time. Dissidents, you know, hung out with some dissidents and one guy was actually killed.

2:11:34.880 --> 2:11:45.880
 We think nobody knows exactly by the KGB, but his art studio was, he had a separate studio in Leningrad in St. Petersburg today.

2:11:45.880 --> 2:11:52.880
 You know, just a small studio where he did his art and somebody set it on fire and we think it was KGB.

2:11:52.880 --> 2:11:57.880
 But, you know, you never really know. And he died in that fire.

2:11:57.880 --> 2:12:04.880
 So, you know, it was not, it was a tough time. And, you know, you knew you were followed.

2:12:04.880 --> 2:12:08.880
 You knew you were being reported on as a foreign scholar, as I was.

2:12:08.880 --> 2:12:13.880
 There was a formal exchange between the United States and the Soviet Union.

2:12:13.880 --> 2:12:23.880
 And, you know, they let me work in the archives, but then, you know, Ivana got to work in the physics lab at Rochester or something like that.

2:12:23.880 --> 2:12:32.880
 You know, so it was an exchange which sent historians and literary people and some social scientists to Russia.

2:12:32.880 --> 2:12:38.880
 And they sent all scientists here to, you know, grab what they could from MIT in nice places.

2:12:38.880 --> 2:12:45.880
 How's your Russian? Do you have any knowledge of Russian language that has helped you to understand?

2:12:45.880 --> 2:12:49.880
 Oh, yeah. Yeah. I mean, I can read it fine.

2:12:49.880 --> 2:12:56.880
 And the speaking, you know, comes and goes, depending on whether I'm there or whether I've been there recently or if I spend some time there.

2:12:56.880 --> 2:13:00.880
 Because I really need, you know, I have Russian friends who speak just Russian.

2:13:00.880 --> 2:13:05.880
 So, you know, when I'm there, I then, you know, I can communicate pretty well.

2:13:05.880 --> 2:13:11.880
 I can't really write it, unfortunately. I mean, I can, but it's not very good.

2:13:11.880 --> 2:13:13.880
 But I get along fine.

2:13:13.880 --> 2:13:17.880
 What's your fondest memory of the Soviet Union of Russia?

2:13:17.880 --> 2:13:20.880
 Friends.

2:13:20.880 --> 2:13:24.880
 Was it vodka involved or is it just vodka involved?

2:13:24.880 --> 2:13:26.880
 A little bit. You know, I'm not much of a drinker.

2:13:26.880 --> 2:13:27.880
 Yeah.

2:13:27.880 --> 2:13:31.880
 So I would, you know, they just make fun of me and I'd make fun of myself.

2:13:31.880 --> 2:13:35.880
 That was easy enough. I don't really like, you know, a heavy drink.

2:13:35.880 --> 2:13:42.880
 I've done a lot of that. Not a lot. I've done some of that, but I never really enjoyed it and would get sick and stuff.

2:13:42.880 --> 2:13:48.880
 No, it's friends. You know, one friend I made in the dormitory.

2:13:48.880 --> 2:13:57.880
 You know, it was a dormitory for foreigners, but also Siberians who had come, you know, to Leningrad to study.

2:13:57.880 --> 2:14:06.880
 And so I met a couple of guys and one in particular from Omsk became a wonderful friend and we talked and talked and talked outside.

2:14:06.880 --> 2:14:11.880
 You know, we would go walk outside because we both knew they were, you know, people were listening and stuff.

2:14:11.880 --> 2:14:18.880
 And he would say, well, this is, he was an historian, you know, and so we would talk history and he'd say, well, this was the case, wasn't it?

2:14:18.880 --> 2:14:26.880
 I said, no, I'm sorry. Sasha, it wasn't the case. It was, you know, we think Stalin actually had a role in killing Kirov.

2:14:26.880 --> 2:14:29.880
 I mean, we're not sure, but he said, no, I said, yeah.

2:14:29.880 --> 2:14:37.880
 You know, so, you know, we had these conversations and he was, he was, what I would, I don't know if he would agree with me or not.

2:14:37.880 --> 2:14:40.880
 I mean, we're still friends. So he was,

2:14:40.880 --> 2:14:47.880
 maybe he'll listen to the blog or I'll send it to him or something. He was a kind of naive Marxist Leningradist.

2:14:47.880 --> 2:14:53.880
 And he thought I was, you know, I was, you know, I had this capitalist idea. He'd say, what ideology you have.

2:14:53.880 --> 2:15:03.880
 And I said, I don't have an ideology. You know, I tried to just put together kind of reason and facts and accurate stories and try to tell them in that way.

2:15:03.880 --> 2:15:08.880
 No, no, no, no, you must, you know, you're a bourgeois, you know, this or that. I said, no, I'm really not.

2:15:08.880 --> 2:15:24.880
 And so we would have these talks and these kind of arguments. And then I mean, sure enough, you know, we corresponded for a while and then he had to stop corresponding because he became a kind of local official in Omsk.

2:15:24.880 --> 2:15:36.880
 And he sort of migrated more and more to being a Democrat. And he was then in the, you know, Democratic movement under Gorbachev and, you know,

2:15:36.880 --> 2:15:48.880
 and the council people's deputies, which they set up, which was, you know, elected as a Democrat from Omsk and had a political career through the Eltsin period.

2:15:48.880 --> 2:15:58.880
 And once Putin came along, you know, it was over. He didn't like Putin and, you know, and Putin didn't like the Eltsin people, right?

2:15:58.880 --> 2:16:07.880
 Who were tried to be, some of them tried to be Democrats. And Sasha was one who really did. He just publishes memoirs in Russian, by the way, which are very good, I think.

2:16:07.880 --> 2:16:09.880
 I think.

2:16:09.880 --> 2:16:21.880
 Commander Ofkov of last. That's what it's called. It's, it's hard, it's hard to translate in English, Commander Ofkov of last, but I mean, I translated it once for him.

2:16:21.880 --> 2:16:30.880
 This is so beautiful. Like the, do you find that the translation is a problem or no? It's such a different translation is very difficult with the Russian language.

2:16:30.880 --> 2:16:43.880
 I mean, it's the only language I know deeply, except right, except English. And it seems like so much is lost of the pain, the poetry, the beauty of the people's and translators are to be treasured and good ones.

2:16:43.880 --> 2:16:54.880
 Yes. To be treasured. I mean, those who do the translations, you know, when you read, you know, things in translation, sometimes they're quite beautiful, you know, whether it's Russian or Polish or German or anything French.

2:16:54.880 --> 2:17:08.880
 Yeah, I'm actually traveling to Paris to talk to the famous translators, the Dostoevsky Tolstoy. And I'm just going to do a several conversations with them about, like, you could just sometimes just grab a single sentence and just talk about the translation.

2:17:08.880 --> 2:17:27.880
 And also, as you said, I would love to be a fly on the wall with some of those friends he had because the perspective on history, nonacademic, sort of without just as human beings, is so different from the United States versus Russia.

2:17:27.880 --> 2:17:41.880
 When you talk about the way the World War Two is perceived and all those kinds of things, it's fascinating. History also has in it opinion and perspective. And so sometimes stripping that away is really difficult.

2:17:41.880 --> 2:17:55.880
 And then I guess that is your job and at its highest form, that is what you do as a historian. Well, Norman, I really appreciate your valuable time. It's truly an honor to talk to you.

2:17:55.880 --> 2:18:07.880
 And thank you for taking us through a trip through some of the worst parts of human history and talking about hope and love at the end. So I really appreciate your time today.

2:18:07.880 --> 2:18:10.880
 Okay, thank you. Thank you for having me.

2:18:10.880 --> 2:18:20.880
 Thanks for listening to this conversation with Norman Neymarck. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Stalin.

2:18:20.880 --> 2:18:26.880
 A single death is a tragedy. A million deaths is a statistic.

2:18:26.880 --> 2:18:51.880
 Thank you for listening and hope to see you next time.

