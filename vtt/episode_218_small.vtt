WEBVTT

00:00.000 --> 00:03.060
 The following is a conversation with Jaren Lanier,

00:03.060 --> 00:06.200
 a computer scientist, visual artist, philosopher,

00:06.200 --> 00:08.080
 writer, futurist, musician,

00:08.080 --> 00:11.680
 and the founder of the field of virtual reality.

00:11.680 --> 00:12.800
 To support this podcast,

00:12.800 --> 00:15.880
 please check out our sponsors in the description.

00:15.880 --> 00:17.480
 As a side note, you may know

00:17.480 --> 00:20.720
 that Jaren is a staunch critic of social media platforms.

00:20.720 --> 00:23.760
 Him and I agree on many aspects of this,

00:23.760 --> 00:26.360
 except perhaps I am more optimistic

00:26.360 --> 00:29.700
 about it being possible to build better platforms.

00:29.700 --> 00:32.200
 And better artificial intelligence systems

00:32.200 --> 00:33.880
 that put longterm interests

00:33.880 --> 00:36.640
 and happiness of human beings first.

00:36.640 --> 00:38.480
 Let me also say a general comment

00:38.480 --> 00:40.240
 about these conversations.

00:40.240 --> 00:42.520
 I try to make sure I prepare well,

00:42.520 --> 00:44.400
 remove my ego from the picture,

00:44.400 --> 00:47.200
 and focus on making the other person shine

00:47.200 --> 00:49.140
 as we try to explore the most beautiful

00:49.140 --> 00:51.800
 and insightful ideas in their mind.

00:51.800 --> 00:53.320
 This can be challenging

00:53.320 --> 00:55.280
 when the ideas that are close to my heart

00:55.280 --> 00:57.200
 are being criticized.

00:57.200 --> 00:59.960
 In those cases, I do offer a little pushback,

00:59.960 --> 01:02.720
 but respectfully, and then move on,

01:02.720 --> 01:04.320
 trying to have the other person come out

01:04.320 --> 01:06.640
 looking wiser in the exchange.

01:06.640 --> 01:08.560
 I think there's no such thing as winning

01:08.560 --> 01:11.600
 in conversations nor in life.

01:11.600 --> 01:14.040
 My goal is to learn and to have fun.

01:14.040 --> 01:15.880
 I ask that you don't see my approach

01:15.880 --> 01:18.000
 to these conversations as weakness.

01:18.000 --> 01:19.240
 It is not.

01:19.240 --> 01:21.560
 It is my attempt at showing respect

01:21.560 --> 01:24.160
 and love for the other person.

01:24.160 --> 01:28.560
 That said, I also often just do a bad job of talking,

01:28.560 --> 01:30.840
 but you probably already knew that.

01:30.840 --> 01:33.480
 So please give me a pass on that as well.

01:33.480 --> 01:35.560
 This is the Lex Friedman podcast,

01:35.560 --> 01:38.660
 and here is my conversation with Jaren Lanier.

01:39.560 --> 01:43.200
 You're considered the founding father of virtual reality.

01:44.640 --> 01:47.360
 Do you think we will one day spend most

01:47.360 --> 01:51.580
 or all of our lives in virtual reality worlds?

01:51.580 --> 01:56.420
 I have always found the very most valuable moment

01:56.420 --> 01:58.380
 in virtual reality to be the moment

01:58.380 --> 02:01.220
 when you take off the headset and your senses are refreshed

02:01.220 --> 02:05.180
 and you perceive physicality afresh,

02:05.180 --> 02:07.020
 as if you were a newborn baby,

02:07.020 --> 02:08.980
 but with a little more experience.

02:08.980 --> 02:13.740
 So you can really notice just how incredibly strange

02:13.740 --> 02:18.740
 and delicate and peculiar and impossible the real world is.

02:18.740 --> 02:21.860
 So the magic is, and perhaps forever,

02:21.860 --> 02:23.700
 will be in the physical world?

02:23.700 --> 02:25.340
 Well, that's my take on it.

02:25.340 --> 02:26.180
 That's just me.

02:26.180 --> 02:29.580
 I mean, I think I don't get to tell everybody else

02:29.580 --> 02:32.180
 how to think or how to experience virtuality.

02:32.180 --> 02:33.020
 And at this point,

02:33.020 --> 02:36.460
 there have been multiple generations of younger people

02:36.460 --> 02:39.580
 who've come along and liberated me

02:39.580 --> 02:41.980
 from having to worry about these things.

02:41.980 --> 02:45.940
 But I should say also, even in what some,

02:45.940 --> 02:48.820
 well, I called it mixed reality back in the day.

02:48.820 --> 02:51.620
 In these days, it's called augmented reality,

02:51.620 --> 02:53.580
 but with something like a HoloLens,

02:53.580 --> 02:56.500
 even then, like one of my favorite things

02:56.500 --> 02:57.860
 is to augment a forest,

02:57.860 --> 03:00.220
 not because I think the forest needs augmentation,

03:00.220 --> 03:04.100
 but when you look at the augmentation next to a real tree,

03:04.100 --> 03:07.220
 the real tree just pops out as being astounding.

03:07.220 --> 03:12.220
 It's interactive, it's changing slightly all the time

03:12.220 --> 03:13.060
 if you pay attention,

03:13.060 --> 03:15.060
 and it's hard to pay attention to that

03:15.060 --> 03:18.500
 but when you compare to virtuality, all of a sudden you do.

03:18.500 --> 03:20.740
 And even in practical applications,

03:20.740 --> 03:24.700
 my favorite early application of virtuality,

03:24.700 --> 03:27.380
 which we prototype going back to the 80s

03:27.380 --> 03:30.660
 when I was working with Dr. Joe Rosen at Stanford Med

03:30.660 --> 03:32.660
 near where we are now,

03:32.660 --> 03:34.940
 we made the first surgical simulator.

03:34.940 --> 03:39.940
 And to go from the fake anatomy of the simulation,

03:39.940 --> 03:42.500
 which is incredibly valuable for many things,

03:42.500 --> 03:43.700
 for designing procedures,

03:43.700 --> 03:45.180
 for training for all kinds of things,

03:45.180 --> 03:47.100
 then to go to the real person,

03:47.100 --> 03:49.700
 boy, it's really something like,

03:49.700 --> 03:52.740
 surgeons really get woken up by that transition.

03:52.740 --> 03:53.580
 It's very cool.

03:53.580 --> 03:55.580
 So I think the transition is actually more valuable

03:55.580 --> 03:56.980
 than the simulation.

03:57.980 --> 04:01.180
 That's fascinating, I never really thought about that.

04:01.180 --> 04:05.100
 It's almost, it's like traveling elsewhere

04:05.100 --> 04:07.700
 in the physical space can help you appreciate

04:07.700 --> 04:11.380
 how much you value your home once you return.

04:11.380 --> 04:13.100
 Well, that's how I take it.

04:13.100 --> 04:14.820
 I mean, once again,

04:14.820 --> 04:17.140
 people have different attitudes towards it.

04:17.140 --> 04:18.340
 All are welcome.

04:18.340 --> 04:19.940
 What do you think is the difference

04:19.940 --> 04:23.380
 between the virtual world and the physical meat space world

04:23.380 --> 04:25.460
 that you are still drawn,

04:25.460 --> 04:28.500
 for you personally, still drawn to the physical world?

04:28.500 --> 04:31.180
 Like they're clearly then as a distinction.

04:31.180 --> 04:32.780
 Is there some fundamental distinction

04:32.780 --> 04:37.100
 or is it the peculiarities of the current set of technology?

04:37.100 --> 04:41.060
 In terms of the kind of virtual reality that we have now,

04:41.060 --> 04:44.740
 it's made of software and software is terrible stuff.

04:44.740 --> 04:49.100
 Software is always the slave of its own history,

04:49.100 --> 04:50.780
 its own legacy.

04:50.780 --> 04:55.780
 It's always infinitely arbitrarily messy and arbitrary.

04:56.300 --> 04:58.300
 Working with it brings out

04:58.300 --> 05:00.300
 a certain kind of nerdy personality in people,

05:00.300 --> 05:04.300
 or at least in me, which I'm not that fond of.

05:04.300 --> 05:07.620
 And there are all kinds of things about software I don't like.

05:07.620 --> 05:09.940
 And so that's different from the physical world.

05:09.940 --> 05:13.540
 It's not something we understand as you just pointed out.

05:13.540 --> 05:14.740
 On the other hand,

05:14.740 --> 05:16.740
 I'm a little mystified when people ask me,

05:16.740 --> 05:19.820
 well, do you think the universe is a computer?

05:19.820 --> 05:22.100
 And I have to say, well, I mean,

05:23.100 --> 05:24.740
 what on earth could you possibly mean

05:24.740 --> 05:26.700
 if you say it isn't a computer?

05:26.700 --> 05:28.580
 If it isn't a computer,

05:28.580 --> 05:32.540
 it wouldn't follow principles consistently

05:32.540 --> 05:34.260
 and it wouldn't be intelligible

05:34.260 --> 05:37.140
 because what else is a computer ultimately?

05:37.140 --> 05:40.140
 And we have physics, we have technology,

05:40.140 --> 05:42.620
 so we can do technology, so we can program it.

05:42.620 --> 05:44.820
 So, I mean, of course it's some kind of computer,

05:44.820 --> 05:48.140
 but I think trying to understand it as a Turing machine

05:48.140 --> 05:51.620
 is probably a foolish approach.

05:51.620 --> 05:53.540
 Right, that's the question.

05:53.540 --> 05:57.540
 Whether it performs this computer, we call the universe,

05:57.540 --> 06:00.220
 performs the kind of computation that can be modeled

06:00.220 --> 06:02.780
 as a universal Turing machine,

06:02.780 --> 06:05.620
 or is it something much more fancy

06:05.620 --> 06:08.540
 or fancy, so fancy, in fact,

06:08.540 --> 06:11.020
 that it may be beyond our cognitive capabilities

06:11.020 --> 06:12.660
 to understand.

06:12.660 --> 06:14.660
 Turing machines are kind of,

06:16.380 --> 06:18.660
 I call them teases in a way,

06:18.660 --> 06:23.180
 because if you have an infinitely smart programmer

06:23.180 --> 06:24.660
 with an infinite amount of time,

06:24.660 --> 06:25.900
 an infinite amount of memory,

06:25.900 --> 06:28.260
 and an infinite clock speed,

06:28.260 --> 06:31.380
 then they're universal, but that cannot exist.

06:31.380 --> 06:33.140
 So they're not universal in practice,

06:33.140 --> 06:36.260
 and they actually are, in practice,

06:36.260 --> 06:38.260
 a very particular sort of machine

06:38.260 --> 06:40.660
 within the constraints,

06:40.660 --> 06:44.020
 within the conservation principles of any reality

06:44.020 --> 06:46.460
 that's worth being in, probably.

06:46.460 --> 06:51.460
 And so, I think universality of a particular model

06:55.660 --> 06:58.540
 is probably a deceptive way to think,

06:58.540 --> 07:00.740
 even though at some sort of limit,

07:00.740 --> 07:05.100
 of course, something like that's gotta be true

07:05.100 --> 07:07.380
 at some sort of high enough limit,

07:07.380 --> 07:10.460
 but it's just not accessible to us, so what's the point?

07:10.460 --> 07:12.980
 Well, to me, the question of whether we're living

07:12.980 --> 07:15.460
 inside a computer or a simulation

07:15.460 --> 07:17.260
 is interesting in the following way.

07:18.500 --> 07:20.940
 There's a technical question is here.

07:20.940 --> 07:25.860
 How difficult does it to build a machine

07:25.860 --> 07:28.380
 not that simulates the universe,

07:28.380 --> 07:31.500
 but that makes it sufficiently realistic

07:31.500 --> 07:33.460
 that we wouldn't know the difference,

07:33.460 --> 07:36.220
 or better yet, sufficiently realistic

07:36.220 --> 07:37.860
 that we would kind of know the difference,

07:37.860 --> 07:41.020
 but we would prefer to stay in the virtual world anyway?

07:41.020 --> 07:42.460
 I wanna give you a few different answers.

07:42.460 --> 07:43.980
 I wanna give you the one that I think

07:43.980 --> 07:45.860
 has the most practical importance

07:45.860 --> 07:47.460
 to human beings right now,

07:47.460 --> 07:51.580
 which is that there's a kind of an assertion

07:51.580 --> 07:54.260
 sort of built into the way the question's usually asked

07:54.260 --> 07:55.700
 that I think is false,

07:55.700 --> 07:59.500
 which is a suggestion that people have a fixed level

07:59.500 --> 08:03.100
 of ability to perceive reality in a given way.

08:03.100 --> 08:08.100
 And actually, people are always learning, evolving,

08:08.140 --> 08:09.100
 forming themselves.

08:09.100 --> 08:10.380
 We're fluid too.

08:10.380 --> 08:13.700
 We're also programmable, self programmable,

08:13.700 --> 08:18.700
 changing, adapting, and so my favorite way to get at this

08:18.740 --> 08:20.980
 is to talk about the history of other media.

08:20.980 --> 08:23.580
 So for instance, there was a peer review paper

08:23.580 --> 08:26.420
 that showed that an early wire recorder

08:26.420 --> 08:28.580
 playing back an opera singer behind a curtain

08:28.580 --> 08:31.260
 was indistinguishable from a real opera singer.

08:31.260 --> 08:32.380
 And so now, of course, to us,

08:32.380 --> 08:34.140
 it would not only be distinguishable,

08:34.140 --> 08:35.460
 but it would be very blatant

08:35.460 --> 08:37.620
 because the recording would be horrible,

08:37.620 --> 08:39.140
 but to the people at the time,

08:39.140 --> 08:43.740
 without the experience of it, it seemed plausible.

08:43.740 --> 08:46.300
 There was an early demonstration

08:46.300 --> 08:49.540
 of extremely crude video teleconferencing

08:49.540 --> 08:53.420
 between New York and DC in the 30s,

08:53.420 --> 08:55.100
 I think so, that people viewed

08:55.100 --> 08:57.260
 as being absolutely realistic and indistinguishable,

08:57.260 --> 08:59.820
 which to us would be horrible.

08:59.820 --> 09:00.940
 And there are many other examples.

09:00.940 --> 09:02.180
 Another one, one of my favorite ones

09:02.180 --> 09:04.140
 is in the Civil War era,

09:04.140 --> 09:06.100
 there were itinerant photographers

09:06.100 --> 09:07.740
 who collected photographs of people

09:07.740 --> 09:10.660
 who just looked kind of like a few archetypes.

09:10.660 --> 09:12.420
 So you could buy a photo of somebody

09:12.420 --> 09:14.140
 who looked kind of like your loved one

09:15.420 --> 09:17.060
 to remind you of that person

09:17.060 --> 09:20.500
 because actually photographing them was inconceivable

09:20.500 --> 09:22.340
 and hiring a painter was too expensive

09:22.340 --> 09:23.860
 and you didn't have any way for the painter

09:23.860 --> 09:25.420
 to represent them remotely anyway.

09:25.420 --> 09:27.620
 How would they even know what they looked like?

09:27.620 --> 09:29.540
 So these are all great examples

09:29.540 --> 09:32.260
 of how in the early days of different media,

09:32.260 --> 09:34.260
 we perceived the media as being really great,

09:34.260 --> 09:37.740
 but then we evolved through the experience of the media.

09:37.740 --> 09:38.780
 This gets back to what I was saying,

09:38.780 --> 09:40.740
 maybe the greatest gift of photography

09:40.740 --> 09:42.620
 is that we can see the flaws in a photograph

09:42.620 --> 09:44.460
 and appreciate reality more.

09:44.460 --> 09:46.700
 Maybe the greatest gift of audio recording

09:46.700 --> 09:49.900
 is that we can distinguish that opera singer now

09:49.900 --> 09:52.500
 from that recording of the opera singer

09:52.500 --> 09:53.740
 on the horrible wire recorder.

09:53.740 --> 09:57.420
 So we shouldn't limit ourselves

09:57.420 --> 10:01.220
 by some assumption of stasis that's incorrect.

10:01.220 --> 10:03.780
 So that's my first answer,

10:03.780 --> 10:05.260
 which is I think the most important one.

10:05.260 --> 10:07.260
 Now, of course, somebody might come back and say,

10:07.260 --> 10:09.300
 oh, but technology can go so far,

10:09.300 --> 10:11.500
 there must be some point at which it would surpass.

10:11.500 --> 10:13.060
 That's a different question.

10:13.060 --> 10:14.700
 I think that's also an interesting question,

10:14.700 --> 10:16.020
 but I think the answer I just gave you

10:16.020 --> 10:17.540
 is actually the more important answer

10:17.540 --> 10:18.900
 to the more important question.

10:18.900 --> 10:20.260
 That's profound, yeah.

10:20.260 --> 10:23.140
 But can you, the second question,

10:23.140 --> 10:26.820
 which you're now making me realize is way different.

10:26.820 --> 10:28.500
 Is it possible to create worlds

10:28.500 --> 10:31.580
 in which people would want to stay

10:31.580 --> 10:32.900
 instead of the real world?

10:32.900 --> 10:35.740
 Well, like unmasked,

10:35.740 --> 10:38.220
 like large numbers of people.

10:38.220 --> 10:41.340
 What I hope is, as I said before,

10:41.340 --> 10:44.260
 I hope that the experience of virtual worlds

10:44.260 --> 10:48.740
 helps people appreciate this physical world

10:48.740 --> 10:51.740
 we have and feel tender towards it

10:51.740 --> 10:54.580
 and keep it from getting too fucked up.

10:54.580 --> 10:55.740
 That's my hope.

10:56.980 --> 10:58.740
 Do you see all technology in that way?

10:58.740 --> 11:01.900
 So basically, technology helps us appreciate

11:02.820 --> 11:06.300
 the more sort of technology free aspect of life.

11:08.220 --> 11:10.740
 Well, media technology.

11:10.740 --> 11:13.460
 You know, I mean, you can stretch that.

11:13.460 --> 11:15.260
 I mean, you can, let me say,

11:15.260 --> 11:17.340
 I could definitely play McLuhan

11:17.340 --> 11:19.060
 and turn this into a general theory.

11:19.060 --> 11:20.060
 It's totally doable.

11:20.060 --> 11:23.180
 The program you just described is totally doable.

11:23.180 --> 11:25.100
 In fact, I will psychically predict

11:25.100 --> 11:26.100
 that if you did the research,

11:26.100 --> 11:29.260
 you could find 20 PhD theses that do that already.

11:29.260 --> 11:31.300
 I don't know, but they might exist.

11:31.300 --> 11:34.900
 But I don't know how much value there is

11:34.900 --> 11:38.780
 in pushing a particular idea that far.

11:38.780 --> 11:40.980
 Claiming that reality isn't a computer,

11:40.980 --> 11:42.780
 in some sense, seems incoherent to me

11:42.780 --> 11:44.860
 because we can program it.

11:44.860 --> 11:46.220
 We have technology.

11:46.220 --> 11:48.820
 It has, it seems to obey physical laws.

11:48.820 --> 11:50.700
 What more do you want from it to be a computer?

11:50.700 --> 11:52.180
 I mean, it's a computer of some kind.

11:52.180 --> 11:53.500
 We don't know exactly what kind.

11:53.500 --> 11:54.820
 We might not know how to think about it.

11:54.820 --> 11:56.420
 We're working on it.

11:56.420 --> 11:59.140
 But sorry to draw, but you're absolutely right.

11:59.140 --> 12:01.900
 Like that's my fascination with the AI as well.

12:01.900 --> 12:05.180
 Is it helps, in the case of AI,

12:05.180 --> 12:07.260
 I see as a set of techniques

12:07.260 --> 12:10.140
 that help us understand ourselves, understand us humans.

12:10.140 --> 12:12.380
 In the same way, virtual reality,

12:12.380 --> 12:14.340
 and you're putting it brilliantly,

12:14.340 --> 12:17.900
 it's a way to help us understand reality.

12:18.900 --> 12:23.740
 I appreciate and open our eyes more richly to reality.

12:23.740 --> 12:26.100
 That's certainly how I see it.

12:26.100 --> 12:29.860
 And I wish people who become incredibly fascinated,

12:29.860 --> 12:33.940
 who go down the rabbit hole of the different fascinations

12:33.940 --> 12:35.900
 with whether we're in a simulation or not,

12:35.900 --> 12:39.340
 or there's a whole world of variations on that.

12:40.540 --> 12:42.900
 I wish they'd step back and think about their own motivations

12:42.900 --> 12:45.780
 and exactly what they mean, you know what?

12:45.780 --> 12:50.020
 And I think the danger with these things is,

12:52.860 --> 12:56.340
 so if you say, is the universe some kind of computer broadly?

12:56.340 --> 12:57.180
 It has to be,

12:57.180 --> 12:59.820
 because it's not coherent to say that it isn't.

12:59.820 --> 13:02.260
 On the other hand, to say that that means,

13:02.260 --> 13:05.140
 you know, anything about what kind of computer,

13:05.140 --> 13:06.340
 that's something very different.

13:06.340 --> 13:07.900
 And the same thing is true for the brain.

13:07.900 --> 13:10.460
 The same thing is true for anything

13:10.460 --> 13:12.060
 where you might use computational metaphors.

13:12.060 --> 13:14.940
 Like we have to have a bit of modesty about where we stand.

13:14.940 --> 13:19.340
 And the problem I have with these framings of computation

13:19.340 --> 13:21.060
 as these ultimate cosmic questions

13:21.060 --> 13:23.940
 is that it has a way of getting people to pretend

13:23.940 --> 13:25.340
 they know more than they do.

13:25.340 --> 13:28.180
 Can you maybe, this is a therapy session.

13:28.180 --> 13:30.380
 Is that going to last me for a second?

13:30.380 --> 13:32.260
 I really like the Elder Scrolls series.

13:32.260 --> 13:36.780
 It's a role playing game, Skyrim, for example.

13:36.780 --> 13:42.340
 Why do I enjoy so deeply just walking around that world?

13:42.340 --> 13:45.140
 And then there's people you could talk to

13:45.140 --> 13:48.060
 and you can just like, it's an escape.

13:48.060 --> 13:49.820
 But you know, my life is awesome.

13:49.820 --> 13:51.300
 I'm truly happy.

13:51.300 --> 13:55.140
 But I also am happy with the music that's playing

13:55.140 --> 13:59.220
 and the mountains and carrying around a sword

13:59.220 --> 14:02.380
 and just that, I don't know what that is.

14:02.380 --> 14:04.620
 It's very pleasant though to go there.

14:04.620 --> 14:06.540
 And I miss it sometimes.

14:06.540 --> 14:12.380
 I think it's wonderful to love artistic creations.

14:12.380 --> 14:15.980
 It's wonderful to love contact with other people.

14:15.980 --> 14:22.300
 It's wonderful to love play and ongoing, evolving meaning

14:22.300 --> 14:24.140
 and patterns with other people.

14:24.140 --> 14:27.660
 I think it's a good thing.

14:27.660 --> 14:31.860
 You know, I'm not like anti tech

14:31.860 --> 14:34.420
 and I'm certainly not anti digital tech.

14:34.420 --> 14:37.260
 I'm anti, as everybody knows by now,

14:37.260 --> 14:40.500
 I think the, you know, manipulative economy

14:40.500 --> 14:42.380
 of social media is making everybody nuts and all that.

14:42.380 --> 14:43.980
 So I'm anti that stuff.

14:43.980 --> 14:47.620
 But the core of it, of course, I worked for many, many years

14:47.620 --> 14:49.180
 on trying to make that stuff happen

14:49.180 --> 14:51.020
 because I think it can be beautiful.

14:51.020 --> 14:54.620
 Like I don't like, why not?

14:54.620 --> 14:59.140
 You know, and by the way, there's a thing about humans

14:59.140 --> 15:06.980
 which is we're problematic, any kind of social interaction

15:06.980 --> 15:10.140
 with other people is going to have its problems.

15:10.140 --> 15:13.980
 People are political and tricky.

15:13.980 --> 15:16.220
 And like, I love classical music,

15:16.220 --> 15:18.540
 but when you actually go to a classical music thing

15:18.540 --> 15:21.020
 and it turns out, oh, actually this is like a backroom power

15:21.020 --> 15:24.180
 deal kind of place and a big status ritual as well.

15:24.180 --> 15:27.860
 And that's kind of not as fun.

15:27.860 --> 15:28.980
 That's part of the package.

15:28.980 --> 15:30.660
 And the thing is it's always going to be.

15:30.660 --> 15:34.700
 There's always going to be a mix of things.

15:34.700 --> 15:39.780
 I don't think the search for purity is going to get you

15:39.780 --> 15:42.300
 anywhere, so I'm not worried about that.

15:42.300 --> 15:44.500
 I worry about the really bad cases

15:44.500 --> 15:47.460
 where we're becoming, where we're making ourselves crazy

15:47.460 --> 15:49.220
 or cruel enough that we might not survive.

15:49.220 --> 15:52.060
 And I think, you know, the social media criticism

15:52.060 --> 15:53.420
 rises to that level.

15:53.420 --> 15:54.900
 But I'm glad you enjoy it.

15:54.900 --> 15:57.340
 I think it's great.

15:57.340 --> 16:00.060
 And I like that you basically say that every experience

16:00.060 --> 16:03.620
 has both beauty and darkness as in with classical music.

16:03.620 --> 16:07.140
 I also play classical piano, so I appreciate it very much.

16:07.140 --> 16:08.020
 But it's interesting.

16:08.020 --> 16:11.220
 I mean, every and even the darkest man's search

16:11.220 --> 16:15.780
 for meaning with Victor Franco and concentration camps,

16:15.780 --> 16:20.860
 even there, there's opportunity to discover beauty.

16:20.860 --> 16:25.060
 And so that's the interesting thing about humans

16:25.060 --> 16:28.580
 is the capacity to discover beautiful and the darkest

16:28.580 --> 16:29.100
 moments.

16:29.100 --> 16:31.580
 But there's always the dark parts, too.

16:31.580 --> 16:37.020
 Well, I mean, our situation is structurally difficult.

16:37.020 --> 16:40.740
 We are structurally different.

16:40.740 --> 16:41.260
 No, it is.

16:41.260 --> 16:42.140
 It's true.

16:42.140 --> 16:43.540
 We perceive socially.

16:43.540 --> 16:48.700
 We depend on each other for our sense of place

16:48.700 --> 16:50.780
 and perception of the world.

16:50.780 --> 16:52.340
 I mean, we're dependent on each other.

16:52.340 --> 16:58.780
 And yet there's also a degree in which we inevitably

16:58.780 --> 17:01.060
 let each other down.

17:01.060 --> 17:05.180
 We are set up to be competitive as well as supportive.

17:05.180 --> 17:08.300
 I mean, our fundamental situation

17:08.300 --> 17:10.620
 is complicated and challenging.

17:10.620 --> 17:13.540
 And I wouldn't have it any other way.

17:13.540 --> 17:17.060
 OK, let's talk about one of the most challenging things.

17:17.060 --> 17:19.100
 One of the things I, unfortunately,

17:19.100 --> 17:23.420
 am very afraid of being human, allegedly.

17:23.420 --> 17:26.300
 You wrote an essay on death and consciousness,

17:26.300 --> 17:29.980
 in which you write a note, certainly the fear of death

17:29.980 --> 17:31.980
 has been one of the greatest driving forces

17:31.980 --> 17:35.180
 in the history of thought and in the formation

17:35.180 --> 17:37.340
 of the character of civilization.

17:37.340 --> 17:39.780
 And yet it is under acknowledged.

17:39.780 --> 17:42.300
 The great book on the subject, The Denial of Death

17:42.300 --> 17:45.180
 by Ernest Becker deserves a reconsideration.

17:45.180 --> 17:47.100
 I'm Russian, so I have to ask you about this.

17:47.100 --> 17:48.860
 What's the role of death in life?

17:48.860 --> 17:51.620
 See, you would have enjoyed coming to our house,

17:51.620 --> 17:54.060
 because my wife is Russian.

17:54.060 --> 17:58.420
 And we also have a piano of such spectacular qualities.

17:58.420 --> 18:00.740
 You wouldn't have freaked out.

18:00.740 --> 18:04.220
 But anyway, we'll let all that go.

18:04.220 --> 18:08.980
 So the context in which I remember that essay,

18:08.980 --> 18:12.020
 sort of, this was from maybe the 90s or something.

18:12.020 --> 18:16.100
 And I used to publish in a journal called

18:16.100 --> 18:17.660
 The Journal of Consciousness Studies,

18:17.660 --> 18:21.140
 because I was interested in these endless debates

18:21.140 --> 18:24.500
 about consciousness and science,

18:24.500 --> 18:28.380
 which certainly continue today.

18:28.380 --> 18:35.380
 And I was interested in how the fear of death

18:35.380 --> 18:39.380
 and the denial of death played into different forms

18:39.380 --> 18:42.900
 and the denial of death played into different

18:42.900 --> 18:45.700
 philosophical approaches to consciousness.

18:45.700 --> 18:58.740
 Because I think on the one hand, the sort of sentimental school

18:58.740 --> 19:01.340
 of dualism, meaning the feeling that there's something

19:01.340 --> 19:04.340
 apart from the physical brain, some kind of soul

19:04.340 --> 19:07.620
 or something else, is obviously motivated,

19:07.620 --> 19:11.580
 a hope that whatever that is will survive death and continue.

19:11.580 --> 19:14.940
 And that's a very core aspect of a lot of the world

19:14.940 --> 19:21.220
 religions, not all of them, not really, but most of them.

19:21.220 --> 19:26.900
 The thing I noticed is that the opposite of those,

19:26.900 --> 19:29.220
 which might be the sort of hardcore, no,

19:29.220 --> 19:31.300
 the brain's a computer and that's it,

19:31.300 --> 19:36.300
 in a sense, we're motivated in the same way

19:36.300 --> 19:40.700
 with a remarkably similar chain of arguments,

19:40.700 --> 19:43.740
 which is, no, the brain's a computer

19:43.740 --> 19:45.580
 and I'm going to figure it out in my lifetime

19:45.580 --> 19:48.180
 and upload it, upload myself and I'll live forever.

19:48.180 --> 19:50.540
 That's interesting.

19:50.540 --> 19:53.540
 Yeah, that's like the implied thought, right?

19:53.540 --> 19:56.700
 Yeah, and so it's kind of this, in a funny way,

19:56.700 --> 19:58.460
 it's the same thing.

19:58.460 --> 20:07.060
 It's peculiar to notice that these people who would appear

20:07.060 --> 20:11.500
 to be opposites in character and cultural references

20:11.500 --> 20:16.580
 and their ideas actually are remarkably similar.

20:16.580 --> 20:23.580
 And to an incredible degree, the sort of hardcore computationalist

20:23.580 --> 20:28.900
 idea about the brain has turned into medieval Christianity

20:28.900 --> 20:31.420
 with together, like there's the people who are afraid

20:31.420 --> 20:32.620
 that if you have the wrong thought,

20:32.620 --> 20:34.660
 you'll piss off the super eyes of the future

20:34.660 --> 20:38.540
 who will come back and zap you and all that stuff.

20:38.540 --> 20:41.700
 It's really turned into medieval Christianity

20:41.700 --> 20:43.060
 all over again.

20:43.060 --> 20:47.580
 So the Ernest Becker's idea that death, the fear of death

20:47.580 --> 20:52.180
 is the warm of the core, which is like that's

20:52.180 --> 20:57.020
 the core motivator of everything we see humans have created.

20:57.020 --> 20:59.740
 The question is if that fear of mortality is somehow

20:59.740 --> 21:06.460
 core is like a prerequisite to what you just moved

21:06.460 --> 21:11.540
 across this vast cultural chasm that separates me

21:11.540 --> 21:13.180
 from most of my colleagues in a way.

21:13.180 --> 21:15.460
 And I can't answer what you just said on the level

21:15.460 --> 21:17.660
 without this huge deconstruction.

21:17.660 --> 21:18.140
 Yes.

21:18.140 --> 21:18.900
 Should I do it?

21:18.900 --> 21:20.220
 Yes, what's the chasm?

21:20.220 --> 21:21.300
 OK.

21:21.300 --> 21:23.100
 Let us travel across this vast.

21:23.100 --> 21:24.900
 OK, I don't believe in AI.

21:24.900 --> 21:26.140
 I don't think there's any AI.

21:26.140 --> 21:27.220
 There's just algorithms.

21:27.220 --> 21:27.780
 We make them.

21:27.780 --> 21:28.380
 We control them.

21:28.380 --> 21:29.860
 Now, they're tools.

21:29.860 --> 21:30.700
 They're not creatures.

21:30.700 --> 21:34.660
 Now, this is something that rubs a lot of people the wrong way.

21:34.660 --> 21:36.060
 And don't I know it?

21:36.060 --> 21:38.700
 When I was young, my main mentor was Marvin

21:38.700 --> 21:43.340
 Minsky, who's the principal author of the computer

21:43.340 --> 21:46.940
 as creature rhetoric that we still use.

21:46.940 --> 21:48.780
 He was the first person to have the idea at all.

21:48.780 --> 21:52.900
 But he certainly populated the AI culture

21:52.900 --> 21:55.300
 with most of its tropes, I would say.

21:55.300 --> 21:56.940
 Because a lot of the stuff people will say,

21:56.940 --> 21:58.580
 oh, did you hear this new idea about AI?

21:58.580 --> 22:00.340
 And I'm like, yeah, I heard it in 1978.

22:00.340 --> 22:01.900
 Sure, yeah, I remember that.

22:01.900 --> 22:03.620
 So Marvin was really the person.

22:03.620 --> 22:08.460
 And Marvin and I used to argue all the time about this stuff

22:08.460 --> 22:10.260
 because I always rejected it.

22:10.260 --> 22:17.740
 And of all of his, I wasn't formally his student,

22:17.740 --> 22:19.780
 but I worked for him as a researcher.

22:19.780 --> 22:22.220
 But of all of his students and student

22:22.220 --> 22:26.620
 like people of his young adoptees,

22:26.620 --> 22:29.420
 I think I was the one who argued with him about this stuff

22:29.420 --> 22:30.100
 in particular.

22:30.100 --> 22:31.140
 And he loved it.

22:31.140 --> 22:33.180
 Yeah, I would have loved to hear that conversation.

22:33.180 --> 22:34.100
 It was fun.

22:34.100 --> 22:36.660
 Did you ever converse to a place?

22:36.660 --> 22:37.420
 Oh, no, no.

22:37.420 --> 22:40.220
 So the very last time I saw him, he was quite frail.

22:40.220 --> 22:44.100
 And I was in Boston.

22:44.100 --> 22:45.740
 And I was going to the old house in Brookline,

22:45.740 --> 22:47.340
 his amazing house.

22:47.340 --> 22:49.100
 And one of our mutual friends said,

22:49.100 --> 22:51.980
 hey, listen, Marvin's so frail.

22:51.980 --> 22:54.020
 Don't do the argument with him.

22:54.020 --> 22:56.380
 Don't argue about AI.

22:56.380 --> 22:58.820
 And so I said, but Marvin loves that.

22:58.820 --> 23:00.020
 And so I showed up.

23:00.020 --> 23:01.540
 And he was frail.

23:01.540 --> 23:04.260
 He looked up and he said, are you ready to argue?

23:08.140 --> 23:10.220
 He's such an amazing person for that.

23:10.220 --> 23:16.180
 So it's hard to summarize this because it's decades of stuff.

23:16.180 --> 23:19.100
 The first thing to say is that nobody

23:19.100 --> 23:23.140
 can claim absolute knowledge about whether somebody

23:23.140 --> 23:25.900
 or something else is conscious or not.

23:25.900 --> 23:27.740
 This is all a matter of faith.

23:27.740 --> 23:31.780
 And in fact, I think the whole idea of faith

23:31.780 --> 23:32.900
 needs to be updated.

23:32.900 --> 23:36.180
 So it's not about God, but it's just about stuff in the universe.

23:36.180 --> 23:39.340
 We have faith in each other being conscious.

23:39.340 --> 23:42.700
 And then I used to frame this as a thing called

23:42.700 --> 23:45.300
 the circle of empathy in my old papers.

23:45.300 --> 23:49.020
 And then it turned into a thing for the animal rights movement.

23:49.020 --> 23:50.460
 So I noticed Peter Singer using it.

23:50.460 --> 23:53.780
 I don't know if it was coincident or but anyway,

23:53.780 --> 23:56.140
 there's this idea that you draw a circle around yourself

23:56.140 --> 23:59.220
 and the stuff inside is more like you, might be conscious,

23:59.220 --> 24:02.180
 might be deserving of your empathy, of your consideration,

24:02.180 --> 24:04.300
 and the stuff outside the circle isn't.

24:04.300 --> 24:12.700
 And outside the circle might be a rock or I don't know.

24:12.700 --> 24:15.460
 And that circle is fundamentally based on faith.

24:15.460 --> 24:17.940
 Well, your faith and what isn't, what isn't.

24:17.940 --> 24:21.380
 The thing about this circle is it can't be pure faith.

24:21.380 --> 24:23.820
 It's also a pragmatic decision.

24:23.820 --> 24:26.020
 And this is where things get complicated.

24:26.020 --> 24:29.900
 If you try to make it too big, you suffer from incompetence.

24:29.900 --> 24:33.300
 If you say, I don't want to kill a bacteria,

24:33.300 --> 24:34.540
 I will not brush my teeth.

24:34.540 --> 24:35.980
 I don't know, what do you do?

24:35.980 --> 24:39.100
 Like there's a competence question

24:39.100 --> 24:40.980
 where you do have to draw the line.

24:40.980 --> 24:44.380
 People who make it too small become cruel.

24:44.380 --> 24:46.380
 People are so clannish and political

24:46.380 --> 24:48.620
 and so worried about themselves ending up

24:48.620 --> 24:52.140
 on the bottom of society that they are always

24:52.140 --> 24:54.180
 ready to gang up on some designated group.

24:54.180 --> 24:56.220
 And so there's always these people who are being trying.

24:56.220 --> 24:58.820
 We're always trying to shove somebody out of the circle.

24:58.820 --> 25:01.540
 And so aren't you shoving AI outside the circle?

25:01.540 --> 25:02.220
 Well, give me a second.

25:02.220 --> 25:02.700
 All right.

25:02.700 --> 25:05.740
 So there's a pragmatic consideration here.

25:05.740 --> 25:09.780
 And so the biggest questions are probably

25:09.780 --> 25:13.380
 fetuses and animals lately, but AI is getting there.

25:13.380 --> 25:20.500
 Now, with AI, I think, and I've had this discussion

25:20.500 --> 25:22.500
 so many times, people say, but aren't you

25:22.500 --> 25:26.340
 afraid if you exclude AI, you'd be cruel to some consciousness?

25:26.340 --> 25:29.500
 And then I would say, well, if you include AI,

25:29.500 --> 25:32.820
 you make yourself, you exclude yourself

25:32.820 --> 25:35.860
 from being able to be a good engineer or designer.

25:35.860 --> 25:38.780
 And so you're facing incompetence immediately.

25:38.780 --> 25:41.460
 So I really think we need to subordinate algorithms

25:41.460 --> 25:43.580
 and be much more skeptical of them.

25:43.580 --> 25:45.900
 Your intuition, you speak about this brilliantly

25:45.900 --> 25:48.980
 with social media, how things can go wrong.

25:48.980 --> 25:56.300
 Isn't it possible to design systems that show compassion,

25:56.300 --> 25:59.860
 not to manipulate you, but give you control

25:59.860 --> 26:02.740
 and make your life better if you so choose to?

26:02.740 --> 26:04.020
 Grow together with systems.

26:04.020 --> 26:07.100
 And the way we grow with dogs and cats with pets

26:07.100 --> 26:09.420
 with significant others in that way,

26:09.420 --> 26:11.540
 they grow to become better people.

26:11.540 --> 26:14.460
 I don't understand why that's fundamentally not possible.

26:14.460 --> 26:18.100
 You're saying oftentimes you get into trouble

26:18.100 --> 26:20.220
 by thinking you know what's good for people.

26:20.220 --> 26:23.260
 Well, look, there's this question of what

26:23.260 --> 26:25.620
 frame we're speaking in.

26:25.620 --> 26:27.660
 Do you know who Alan Watts was?

26:27.660 --> 26:32.140
 So Alan Watts once said, morality is like gravity,

26:32.140 --> 26:34.500
 that in some absolute cosmic sense,

26:34.500 --> 26:36.460
 there can't be morality, because at some point

26:36.460 --> 26:37.700
 it all becomes relative.

26:37.700 --> 26:39.100
 And who are we anyway?

26:39.100 --> 26:42.100
 Like morality is relative to us tiny creatures.

26:42.100 --> 26:45.540
 But here on Earth, we're with each other.

26:45.540 --> 26:46.420
 This is our frame.

26:46.420 --> 26:47.900
 And morality is a very real thing.

26:47.900 --> 26:48.780
 Same thing with gravity.

26:48.780 --> 26:52.140
 At some point, you get into interstellar space

26:52.140 --> 26:53.980
 and you might not feel much of it.

26:53.980 --> 26:55.180
 But here we are on Earth.

26:55.180 --> 26:58.460
 And I think in the same sense, I think

26:58.460 --> 27:04.420
 this identification with a frame that's quite remote

27:04.420 --> 27:07.540
 cannot be separated from a feeling

27:07.540 --> 27:11.020
 of wanting to feel sort of separate from and superior

27:11.020 --> 27:12.660
 to other people or something like that.

27:12.660 --> 27:16.100
 There's an impulse behind it that I really have to reject.

27:16.100 --> 27:18.860
 And we're just not competent yet to talk

27:18.860 --> 27:20.980
 about these kinds of absolutes.

27:20.980 --> 27:24.540
 OK, so I agree with you that a lot of technologies sort

27:24.540 --> 27:27.700
 of lack this basic respect, understanding,

27:27.700 --> 27:29.180
 and love for humanity.

27:29.180 --> 27:30.620
 There's a separation there.

27:30.620 --> 27:32.420
 The thing I'd like to push back against,

27:32.420 --> 27:33.620
 it's not that you disagree.

27:33.620 --> 27:36.220
 But I believe you can create technologies

27:36.220 --> 27:41.300
 and you can create a new kind of technologist engineer that

27:41.300 --> 27:45.380
 does build systems that respect humanity, not just respect

27:45.380 --> 27:49.500
 but admire humanity, that have empathy for common humans,

27:49.500 --> 27:51.460
 have compassion.

27:51.460 --> 27:52.580
 So I mean, no, no, no.

27:52.580 --> 27:57.300
 I think, yeah, I mean, I think musical instruments

27:57.300 --> 27:58.780
 are a great example of that.

27:58.780 --> 28:00.260
 Musical instruments or technologies

28:00.260 --> 28:02.260
 that help people connect in fantastic ways.

28:02.260 --> 28:06.580
 And that's a great example.

28:06.580 --> 28:11.300
 My invention or design during the pandemic period

28:11.300 --> 28:12.500
 was this thing called Together Mode,

28:12.500 --> 28:17.980
 where people see themselves seated sort of in a classroom

28:17.980 --> 28:20.260
 or a theater instead of in squares.

28:20.260 --> 28:26.060
 And it allows them to semi consciously perform to each other

28:26.060 --> 28:29.500
 as if they have proper eye contact,

28:29.500 --> 28:31.620
 as if they're paying attention to each other nonverbally

28:31.620 --> 28:34.020
 and weirdly that turns out to work.

28:34.020 --> 28:36.980
 And so it promotes empathy so far as I can tell.

28:36.980 --> 28:40.620
 I hope it is of some use to somebody.

28:40.620 --> 28:43.100
 The AI idea isn't really new.

28:43.100 --> 28:47.060
 I would say it was born with Adam Smith's Invisible Hand

28:47.060 --> 28:49.660
 with this idea that we build this algorithmic thing

28:49.660 --> 28:52.260
 and it gets a bit beyond us and then we

28:52.260 --> 28:53.940
 think it must be smarter than us.

28:53.940 --> 28:55.660
 And the thing about the Invisible Hand

28:55.660 --> 28:59.460
 is absolutely everybody has some line they draw where they say,

28:59.460 --> 29:01.660
 now, we're going to take control of this thing.

29:01.660 --> 29:03.260
 They might have different lines, they

29:03.260 --> 29:04.460
 might care about different things,

29:04.460 --> 29:06.780
 but everybody ultimately became a Keynesian

29:06.780 --> 29:07.900
 because it just didn't work.

29:07.900 --> 29:09.180
 It really wasn't that smart.

29:09.180 --> 29:11.700
 It was sometimes smart and sometimes it failed.

29:11.700 --> 29:16.980
 And so if you really, people who really, really, really

29:16.980 --> 29:20.860
 want to believe in the Invisible Hand as infinitely smart

29:20.860 --> 29:22.700
 screw up their economies terribly,

29:22.700 --> 29:27.380
 you have to recognize the economy as a subservient tool.

29:27.380 --> 29:29.860
 Everybody does when it's to their advantage.

29:29.860 --> 29:31.780
 They might not when it's not to their advantage.

29:31.780 --> 29:34.220
 That's kind of an interesting game that happens.

29:34.220 --> 29:38.140
 But the thing is, it's just like that with our algorithms.

29:38.140 --> 29:45.060
 You can have a Chicago economic philosophy

29:45.060 --> 29:47.340
 about your computer and say, no, no, no, my thing's come alive.

29:47.340 --> 29:49.060
 It's smarter than anything.

29:49.060 --> 29:52.820
 I think that there is a deep loneliness within all of us.

29:52.820 --> 29:54.020
 This is what we seek.

29:54.020 --> 29:56.300
 We seek love from each other.

29:56.300 --> 29:59.700
 I think AI can help us connect deeper.

29:59.700 --> 30:02.300
 This is what you criticize social media for.

30:02.300 --> 30:05.060
 I think there's much better ways of doing social media that

30:05.060 --> 30:07.420
 doesn't lead to manipulation, but instead

30:07.420 --> 30:10.020
 leads to deeper connection between humans, leads

30:10.020 --> 30:11.900
 to you becoming a better human being.

30:11.900 --> 30:15.540
 And what that requires is some agency on the part of AI

30:15.540 --> 30:18.620
 to be almost like a therapist, I mean a companion.

30:18.620 --> 30:22.060
 It's not telling you what's right.

30:22.060 --> 30:25.340
 It's not guiding you as if it's an all knowing thing.

30:25.340 --> 30:28.740
 It's just another companion that you can leave at any time.

30:28.740 --> 30:31.860
 You have complete transparency control over.

30:31.860 --> 30:33.380
 There's a lot of mechanisms that you

30:33.380 --> 30:38.900
 can have that are counter to how current social media operates

30:38.900 --> 30:44.580
 that I think is subservient to humans or no, deeply respects

30:44.580 --> 30:47.780
 human beings and empathetic to their experience

30:47.780 --> 30:48.860
 and all those kinds of things.

30:48.860 --> 30:51.580
 I think it's possible to create AI systems like that.

30:51.580 --> 30:54.620
 And I think that's a technical discussion

30:54.620 --> 31:02.020
 of whether they need to have something that looks like AI

31:02.020 --> 31:05.980
 versus algorithms, something that has identity, something

31:05.980 --> 31:09.060
 that has a personality, all those kinds of things.

31:09.060 --> 31:11.460
 AI systems, and you've spoken extensively

31:11.460 --> 31:17.180
 how AI systems manipulate you within social networks.

31:17.180 --> 31:21.140
 And the biggest problem isn't necessarily

31:21.140 --> 31:28.380
 that there's advertisements that social networks present you

31:28.380 --> 31:31.140
 with advertisements that then get you to buy stuff.

31:31.140 --> 31:32.300
 That's not the biggest problem.

31:32.300 --> 31:36.300
 The biggest problem is they then manipulate you.

31:36.300 --> 31:41.420
 They alter your human nature to get you to buy stuff

31:41.420 --> 31:46.620
 or to get you to do whatever the advertiser wants.

31:46.620 --> 31:47.460
 Maybe you can correct me.

31:47.460 --> 31:49.820
 Yeah, I don't see it quite that way,

31:49.820 --> 31:52.020
 but we can work with that as an approximation.

31:52.020 --> 31:53.140
 Sure.

31:53.140 --> 31:56.340
 I think the actual thing is even more ridiculous and stupider

31:56.340 --> 31:58.140
 than that, but that's OK.

31:58.140 --> 32:02.380
 So my question is, let's not use the word AI,

32:02.380 --> 32:05.340
 but how do we fix it?

32:05.340 --> 32:07.900
 Oh, fixing social media.

32:07.900 --> 32:11.020
 That diverts us into this whole other field in my view,

32:11.020 --> 32:14.180
 which is economics, which I always thought was really boring,

32:14.180 --> 32:16.340
 but we have no choice but to turn it to economists

32:16.340 --> 32:18.300
 if we want to fix this problem, because it's

32:18.300 --> 32:19.820
 all about incentives.

32:19.820 --> 32:24.260
 But I've been around this thing since it started,

32:24.260 --> 32:30.300
 and I've been in the meetings where the social media companies

32:30.300 --> 32:33.860
 sell themselves to the people who put the most money into them,

32:33.860 --> 32:36.260
 which are usually the big advertising holding companies

32:36.260 --> 32:36.780
 and whatnot.

32:36.780 --> 32:41.340
 And there's this idea that I think is kind of a fiction.

32:41.340 --> 32:45.100
 And maybe it's even been recognized as that by everybody

32:45.100 --> 32:48.860
 that the algorithm will get really good at getting people

32:48.860 --> 32:51.260
 to buy something, because I think people have looked

32:51.260 --> 32:53.180
 at their returns and looked at what happens,

32:53.180 --> 32:56.340
 and everybody recognizes it's not exactly right.

32:56.340 --> 33:02.020
 It's more like a cognitive access blackmail payment

33:02.020 --> 33:03.940
 at this point.

33:03.940 --> 33:06.020
 Just to be connected, you're paying the money.

33:06.020 --> 33:08.660
 It's not so much that the persuasion algorithms.

33:08.660 --> 33:10.700
 So Stanford renamed its program, but it used

33:10.700 --> 33:12.340
 to be called Engaged Persuade.

33:12.340 --> 33:13.540
 The Engaged Part works.

33:13.540 --> 33:16.340
 The Persuade Part is iffy, but the thing

33:16.340 --> 33:19.460
 is that once people are engaged, in order for you

33:19.460 --> 33:21.940
 to exist as a business, in order for you to be known at all,

33:21.940 --> 33:23.140
 you have to put money into it.

33:23.140 --> 33:24.460
 Oh, that's dark.

33:24.460 --> 33:27.020
 Oh, no, that doesn't work, but they have to.

33:27.020 --> 33:31.460
 But it's a giant cognitive access blackmail scheme

33:31.460 --> 33:34.100
 at this point, because the science

33:34.100 --> 33:39.580
 behind the Persuade Part, it's not entirely a failure,

33:39.580 --> 33:46.940
 but we play make believe that it works more than it does.

33:46.940 --> 33:48.820
 The damage doesn't come.

33:48.820 --> 33:51.260
 Honestly, as I've said in my books,

33:51.260 --> 33:53.380
 I'm not anti advertising.

33:53.380 --> 33:58.260
 I actually think advertising can be demeaning, and annoying,

33:58.260 --> 34:03.220
 and banal, and ridiculous, and take up a lot of our time

34:03.220 --> 34:04.300
 with stupid stuff.

34:04.300 --> 34:06.980
 Like, there's a lot of ways to criticize advertising

34:06.980 --> 34:09.020
 that's accurate.

34:09.020 --> 34:11.580
 And it can also lie, and all kinds of things.

34:11.580 --> 34:13.980
 However, if I look at the biggest picture,

34:13.980 --> 34:17.380
 I think advertising, at least as it was understood before,

34:17.380 --> 34:20.580
 social media, helped bring people into modernity in a way

34:20.580 --> 34:24.620
 that overall actually did benefit people overall.

34:24.620 --> 34:27.300
 And you might say, am I contradicting myself,

34:27.300 --> 34:29.140
 because I was saying you shouldn't manipulate people?

34:29.140 --> 34:29.900
 Yeah, I am.

34:29.900 --> 34:30.460
 Probably here.

34:30.460 --> 34:33.740
 I mean, I'm not pretending to have this perfect, airtight

34:33.740 --> 34:35.460
 worldview without some contradictions.

34:35.460 --> 34:37.900
 I think there's a bit of a contradiction there.

34:37.900 --> 34:39.380
 Well, looking at the long arc of history,

34:39.380 --> 34:43.660
 advertisement has, in some parts, benefited society.

34:43.660 --> 34:46.620
 Yeah, because it funded some efforts that perhaps

34:46.620 --> 34:47.340
 benefited society.

34:47.340 --> 34:51.820
 I mean, I think there's a thing where sometimes I think

34:51.820 --> 34:53.940
 it's actually been of some use.

34:53.940 --> 34:59.060
 Now, where the damage comes is a different thing, though.

34:59.060 --> 35:03.340
 Social media, algorithms on social media

35:03.340 --> 35:06.060
 have to work on feedback loops, where they present you

35:06.060 --> 35:06.820
 with stimulus.

35:06.820 --> 35:09.020
 They have to see if you respond to the stimulus.

35:09.020 --> 35:12.500
 Now, the problem is that the measurement mechanism

35:12.500 --> 35:16.460
 for telling if you respond in the engagement feedback loop

35:16.460 --> 35:17.660
 is very, very crude.

35:17.660 --> 35:19.540
 It's things like whether you click more,

35:19.540 --> 35:21.620
 or occasionally if you're staring at the screen more,

35:21.620 --> 35:23.900
 if there's a forward facing camera that's activated,

35:23.900 --> 35:25.540
 but typically there isn't.

35:25.540 --> 35:28.940
 So you have this incredibly crude back channel of information.

35:28.940 --> 35:31.260
 And so it's crude enough that it only

35:31.260 --> 35:35.740
 catches sort of the more dramatic responses from you.

35:35.740 --> 35:37.700
 And those are the fight or flight responses.

35:37.700 --> 35:40.100
 Those are the things where you get scared or pissed off,

35:40.100 --> 35:43.420
 or aggressive, or horny.

35:43.420 --> 35:46.140
 These are these ancient, what are sometimes called

35:46.140 --> 35:48.980
 the lizard brain circuits or whatever.

35:48.980 --> 35:54.100
 These fast response, old, old, old evolutionary business

35:54.100 --> 35:58.300
 circuits that we have that are helpful in survival

35:58.300 --> 36:00.500
 once in a while, but are not us at our best.

36:00.500 --> 36:01.660
 They're not who we want to be.

36:01.660 --> 36:03.460
 They're not how we relate to each other.

36:03.460 --> 36:05.140
 They're this old business.

36:05.140 --> 36:08.180
 So then just when you're engaged using those intrinsically,

36:08.180 --> 36:11.100
 totally aside from whatever the topic is,

36:11.100 --> 36:14.140
 you start to get incrementally just a little bit more

36:14.140 --> 36:17.260
 paranoid, xenophobic, aggressive.

36:17.260 --> 36:20.980
 You get a little stupid, and you become a jerk.

36:20.980 --> 36:22.420
 And it happens slowly.

36:22.420 --> 36:23.500
 It happens.

36:23.500 --> 36:26.060
 It's not like everybody is instantly transformed.

36:26.060 --> 36:28.020
 But it does happen progressively,

36:28.020 --> 36:30.740
 where people who get hooked kind of get drawn more and more

36:30.740 --> 36:33.660
 into this pattern of being at their worst.

36:33.660 --> 36:35.780
 Would you say that people are able to,

36:35.780 --> 36:37.500
 when they get hooked in this way,

36:37.500 --> 36:41.460
 look back at themselves from 30 days ago and say,

36:41.460 --> 36:45.100
 I am less happy with who I am now,

36:45.100 --> 36:48.780
 or I'm not happy with why I'm now versus who I was 30 days ago?

36:48.780 --> 36:51.420
 Are they able to self reflect when you take yourself

36:51.420 --> 36:52.620
 outside of the lizard brain?

36:52.620 --> 36:54.180
 Sometimes.

36:54.180 --> 36:56.420
 I wrote a book about people suggesting

36:56.420 --> 36:57.940
 people take a break from their social media

36:57.940 --> 36:58.900
 to see what happens.

36:58.900 --> 37:01.780
 And maybe even the title of the book

37:01.780 --> 37:04.180
 was just the arguments to delete your account.

37:04.180 --> 37:05.700
 Yeah, 10 arguments.

37:05.700 --> 37:06.460
 10 arguments.

37:06.460 --> 37:08.500
 Although I always said, I don't know that you should.

37:08.500 --> 37:09.620
 I can give you the arguments.

37:09.620 --> 37:10.420
 It's up to you.

37:10.420 --> 37:11.780
 I'm always very clear about that.

37:11.780 --> 37:15.580
 But I don't have a social media account, obviously.

37:15.580 --> 37:18.900
 And it's not that easy for people to reach me.

37:18.900 --> 37:21.300
 They have to search out an old fashioned email address

37:21.300 --> 37:23.780
 on a super crappy, antiquated website.

37:23.780 --> 37:26.140
 It's actually a bit, I don't make it easy.

37:26.140 --> 37:28.700
 And even with that, I get this huge flood of mail

37:28.700 --> 37:30.580
 from people who say, oh, I quit my social media.

37:30.580 --> 37:33.260
 I'm doing so much better, I can't believe how bad it was.

37:33.260 --> 37:36.060
 But the thing is, for me, a huge flood of mail

37:36.060 --> 37:38.620
 would be an imperceptible trickle from the perspective

37:38.620 --> 37:39.980
 of Facebook, right?

37:39.980 --> 37:43.620
 And so I think it's rare for somebody

37:43.620 --> 37:45.340
 to look at themselves and say, oh, boy,

37:45.340 --> 37:47.780
 I just screwed myself over.

37:47.780 --> 37:49.620
 It's a really hard thing to ask of somebody.

37:49.620 --> 37:51.300
 None of us find that easy, right?

37:51.300 --> 37:54.580
 Well, the reason I asked is, is it

37:54.580 --> 37:58.580
 possible to design social media systems that

37:58.580 --> 38:03.180
 optimize for some longer term metrics of you

38:03.180 --> 38:04.580
 being happy with yourself?

38:04.580 --> 38:07.140
 Well, see, I don't think you should try to engineer

38:07.140 --> 38:08.380
 personal growth or happiness.

38:08.380 --> 38:11.020
 I think what you should do is design a system that's

38:11.020 --> 38:13.700
 just respectful of the people and subordinates itself

38:13.700 --> 38:16.780
 to the people and doesn't have perverse incentives.

38:16.780 --> 38:18.180
 And then at least there's a chance

38:18.180 --> 38:19.780
 of something decent happening.

38:19.780 --> 38:22.100
 You'll have to recommend stuff, right?

38:22.100 --> 38:24.420
 So you're saying, be respectful.

38:24.420 --> 38:26.900
 What does that actually mean engineering wise?

38:26.900 --> 38:30.260
 Yeah, curation, people have to be responsible.

38:30.260 --> 38:31.700
 Algorithms shouldn't be recommending.

38:31.700 --> 38:33.500
 Algorithms don't understand enough to recommend.

38:33.500 --> 38:35.260
 Algorithms are crap in this era.

38:35.260 --> 38:37.020
 I mean, I'm sorry, they are.

38:37.020 --> 38:38.420
 And I'm not saying this as somebody

38:38.420 --> 38:39.420
 is a critic from the outside.

38:39.420 --> 38:40.260
 I'm in the middle of it.

38:40.260 --> 38:41.260
 I know what they can do.

38:41.260 --> 38:41.940
 I know the math.

38:41.940 --> 38:45.300
 I know what the corpora are.

38:45.300 --> 38:46.980
 I know the best ones.

38:46.980 --> 38:49.860
 Our office is funding GPT3 and all these things

38:49.860 --> 38:53.500
 that are at the edge of what's possible.

38:53.500 --> 38:57.380
 And they do not have yet.

38:57.380 --> 39:02.100
 I mean, it still is statistical emergent pseudo semantics.

39:02.100 --> 39:04.140
 It doesn't actually have the representation

39:04.140 --> 39:05.100
 emerging of anything.

39:05.100 --> 39:07.700
 It's just not like, I mean, that I'm speaking the truth here

39:07.700 --> 39:08.580
 and you know it.

39:08.580 --> 39:11.900
 Well, let me push back on this.

39:11.900 --> 39:13.100
 There's several truths here.

39:13.100 --> 39:16.060
 So you're speaking to the way certain companies operate

39:16.060 --> 39:16.980
 currently.

39:16.980 --> 39:20.380
 I don't think it's outside the realm of what's technically

39:20.380 --> 39:21.740
 feasible to do.

39:21.740 --> 39:23.660
 They're just not incentive like companies are not

39:23.660 --> 39:26.060
 why fix this thing.

39:26.060 --> 39:29.820
 I am aware that, for example, the YouTube search

39:29.820 --> 39:33.380
 and discovery has been very helpful to me.

39:33.380 --> 39:37.660
 And there's a huge number of there's so many videos

39:37.660 --> 39:39.700
 that it's nice to have a little bit of help.

39:39.700 --> 39:40.380
 Have you done.

39:40.380 --> 39:41.380
 But I'm still in control.

39:41.380 --> 39:42.180
 Let me ask you something.

39:42.180 --> 39:45.020
 Have you done the experiment of letting YouTube

39:45.020 --> 39:47.260
 recommend videos to you either starting

39:47.260 --> 39:50.380
 from a absolutely anonymous random place

39:50.380 --> 39:52.580
 where it doesn't know who you are or from knowing who you

39:52.580 --> 39:55.300
 or somebody else is and then going 15 or 20 hops?

39:55.300 --> 39:58.940
 Have you ever done that and just let it go top video recommend

39:58.940 --> 40:00.140
 and then just go 20 hops?

40:00.140 --> 40:00.900
 No, I haven't.

40:00.900 --> 40:03.100
 I've done that many times now.

40:03.100 --> 40:07.020
 I have because of how large YouTube is and how widely it's

40:07.020 --> 40:10.700
 used, it's very hard to get to enough scale

40:10.700 --> 40:14.300
 to get a statistically solid result on this.

40:14.300 --> 40:15.820
 I've done it with high school kids,

40:15.820 --> 40:18.380
 with dozens of kids doing it at a time.

40:18.380 --> 40:21.140
 Every time I've done an experiment, the majority

40:21.140 --> 40:23.460
 of times after about 17 or 18 hops,

40:23.460 --> 40:27.180
 you end up in really weird, paranoid, bizarre territory.

40:27.180 --> 40:29.980
 Because ultimately, that is the stuff, the algorithm

40:29.980 --> 40:31.940
 rewards the most because of the feedback

40:31.940 --> 40:34.060
 creepiness I was just talking about.

40:34.060 --> 40:37.140
 So I'm not saying that the video never

40:37.140 --> 40:38.340
 recommends something cool.

40:38.340 --> 40:40.460
 I'm saying that its fundamental core

40:40.460 --> 40:44.660
 is one that promotes a paranoid style, that promotes

40:44.660 --> 40:48.020
 increasing irritability, that promotes xenophobia,

40:48.020 --> 40:51.340
 that promotes fear, anger, promotes selfishness,

40:51.340 --> 40:55.100
 promotes separation between people.

40:55.100 --> 40:58.220
 The thing is, it's very hard to do this work solidly.

40:58.220 --> 40:59.980
 Many have repeated this experiment,

40:59.980 --> 41:02.220
 and yet it still is kind of anecdotal.

41:02.220 --> 41:05.540
 I'd like to do a large citizen science thing sometime

41:05.540 --> 41:07.300
 and do it, but then I think the problem with that

41:07.300 --> 41:09.660
 is YouTube would detect it and then change it.

41:09.660 --> 41:12.100
 Yes, I love that kind of stuff.

41:12.100 --> 41:16.420
 So Jack Dorsey has spoken about doing healthy conversations

41:16.420 --> 41:19.140
 on Twitter or optimizing for healthy conversations.

41:19.140 --> 41:21.980
 What that requires within Twitter are most likely

41:21.980 --> 41:25.940
 citizen experiments of what does healthy conversations

41:25.940 --> 41:28.620
 actually look like and how do you incentivize

41:28.620 --> 41:30.100
 those healthy conversations.

41:30.100 --> 41:33.100
 You're describing what often happens

41:33.100 --> 41:34.780
 and what is currently happening.

41:34.780 --> 41:38.140
 What I'd like to argue is it's possible to strive

41:38.140 --> 41:42.780
 for healthy conversations, not in a dogmatic way of saying,

41:42.780 --> 41:45.540
 I know what healthy conversations are and I will tell you.

41:45.540 --> 41:48.420
 I think one way to do this is to try to look around

41:48.420 --> 41:51.860
 at social, maybe not things that are officially social media,

41:51.860 --> 41:54.020
 but things where people are together online

41:54.020 --> 41:56.780
 and see which ones have more healthy conversations.

41:56.780 --> 42:00.580
 Even if it's hard to be completely objective

42:00.580 --> 42:03.180
 in that measurement, you can kind of at least crudely

42:03.180 --> 42:04.020
 agree.

42:04.020 --> 42:05.860
 You could do subjective annotation of this,

42:05.860 --> 42:08.300
 like have a large crowdsource.

42:08.300 --> 42:11.620
 One that I've been really interested in is GitHub,

42:11.620 --> 42:16.060
 because it could change, I'm not saying it'll always be,

42:16.060 --> 42:19.940
 but for the most part, GitHub has had a relatively

42:19.940 --> 42:24.500
 quite low poison quotient and I think there's a few things

42:24.500 --> 42:26.620
 about GitHub that are interesting.

42:26.620 --> 42:29.580
 One thing about it is that people have a stake in it.

42:29.580 --> 42:31.860
 It's not just empty status games.

42:31.860 --> 42:35.180
 There's actual code or there's actual stuff being done.

42:35.180 --> 42:37.500
 And I think as soon as you have a real world stake

42:37.500 --> 42:41.860
 in something, you have a motivation to not screw

42:41.860 --> 42:42.700
 up that thing.

42:42.700 --> 42:45.500
 And I think that that's often missing,

42:45.500 --> 42:49.100
 that there's no incentive for the person to really preserve

42:49.100 --> 42:51.540
 something if they get a little bit of attention

42:51.540 --> 42:55.980
 from dumping on somebody's TikTok or something.

42:55.980 --> 42:57.780
 They don't pay any price for it, but you

42:57.780 --> 43:00.780
 have to kind of get decent with people

43:00.780 --> 43:03.180
 when you have a shared stake, a little secret.

43:03.180 --> 43:06.900
 So GitHub does a bit of that.

43:06.900 --> 43:08.620
 GitHub is wonderful, yes.

43:08.620 --> 43:13.340
 But I'm tempted to play the Jaren back at you,

43:13.340 --> 43:16.460
 which is that, so GitHub is currently is amazing,

43:16.460 --> 43:18.420
 but the thing is, if you have a stake,

43:18.420 --> 43:20.460
 then if it's a social media platform,

43:20.460 --> 43:23.420
 they can use the fact that you have a stake to manipulate you

43:23.420 --> 43:25.300
 because you want to preserve the stake.

43:25.300 --> 43:26.220
 So like.

43:26.220 --> 43:29.260
 Right, well, this gets us into the economics.

43:29.260 --> 43:30.900
 So there's this thing called Data Dignity

43:30.900 --> 43:33.020
 that I've been studying for a long time.

43:33.020 --> 43:35.220
 I wrote a book about an earlier version of it called

43:35.220 --> 43:39.300
 The Future, and the basic idea of it

43:39.300 --> 43:43.380
 is that, once again, this is a third year conversation.

43:43.380 --> 43:44.260
 It's a fascinating topic.

43:44.260 --> 43:46.780
 Let me do the fastest version of this I can do.

43:46.780 --> 43:48.780
 The fastest way I know how to do this

43:48.780 --> 43:51.940
 is to compare two futures, all right?

43:51.940 --> 43:55.620
 So future one is then the normative one,

43:55.620 --> 43:56.900
 the one we're building right now,

43:56.900 --> 44:00.180
 and future two is going to be Data Dignity.

44:00.180 --> 44:03.100
 And I'm going to use a particular population.

44:03.100 --> 44:05.340
 I live on the hill in Berkeley,

44:05.340 --> 44:07.020
 and one of the features about the hill

44:07.020 --> 44:09.380
 is that as the climate changes, we might burn down

44:09.380 --> 44:11.500
 and I'll lose our houses or die or something.

44:11.500 --> 44:14.260
 Like it's dangerous, you know, and it didn't used to be.

44:14.260 --> 44:17.020
 And so who keeps us alive?

44:17.020 --> 44:18.380
 Well, the city does.

44:18.380 --> 44:19.540
 The city does some things.

44:19.540 --> 44:21.500
 The electric company kind of sort of,

44:21.500 --> 44:26.060
 maybe hopefully better, individual people who own property,

44:26.060 --> 44:27.660
 take care of their property, that's all nice.

44:27.660 --> 44:29.300
 But there's this other middle layer,

44:29.300 --> 44:30.980
 which is fascinating to me,

44:30.980 --> 44:33.580
 which is that the groundskeepers

44:33.580 --> 44:35.340
 who work up and down that hill,

44:35.340 --> 44:38.700
 many of whom are not legally here,

44:38.700 --> 44:40.540
 many of whom don't speak English,

44:40.540 --> 44:44.340
 cooperate with each other to make sure trees don't touch

44:44.340 --> 44:46.660
 to transfer fire easily from lot to lot.

44:46.660 --> 44:49.180
 They have this whole little web that's keeping us safe.

44:49.180 --> 44:50.500
 I didn't know about this at first.

44:50.500 --> 44:52.500
 I just started talking to them

44:52.500 --> 44:54.340
 because they were out there during the pandemic.

44:54.340 --> 44:56.820
 And so I'd try to just see who are these people?

44:56.820 --> 44:59.340
 Who are these people who are keeping us alive?

44:59.340 --> 45:01.460
 Now, I want to talk about the two different faiths

45:01.460 --> 45:04.900
 for those people under future one and future two.

45:04.900 --> 45:09.900
 Future one, some weird kindergarten paint job van

45:10.420 --> 45:12.500
 with all these cameras and weird things drives up,

45:12.500 --> 45:15.580
 observes what the gardeners and groundskeepers are doing.

45:15.580 --> 45:18.220
 A few years later, some amazing robots

45:18.220 --> 45:20.500
 that can show me up trees and all this show up,

45:20.500 --> 45:21.620
 all those people are out of work

45:21.620 --> 45:23.140
 and there are these robots doing the thing.

45:23.140 --> 45:26.380
 And the robots are good and they can scale to more land

45:26.380 --> 45:28.460
 and they're actually good.

45:28.460 --> 45:29.860
 But then there are all these people out of work

45:29.860 --> 45:31.340
 and these people have lost dignity.

45:31.340 --> 45:32.940
 They don't know what they're going to do.

45:32.940 --> 45:35.500
 And then somebody will say, well, they go on basic income,

45:35.500 --> 45:38.180
 whatever they become wards of the state.

45:39.060 --> 45:42.620
 My problem with that solution is every time in history

45:42.620 --> 45:44.380
 that you've had some centralized thing

45:44.380 --> 45:45.660
 that's doling out the benefits,

45:45.660 --> 45:47.300
 that things get seized by people

45:47.300 --> 45:49.540
 because it's too centralized and it gets seized.

45:49.540 --> 45:52.340
 This happened to every communist experiment I can find.

45:53.260 --> 45:56.060
 So I think that turns into a poor future

45:56.060 --> 45:57.740
 that will be these unstable.

45:57.740 --> 45:59.220
 I don't think people will feel good in it.

45:59.220 --> 46:01.460
 I think it'll be a political disaster

46:01.460 --> 46:02.540
 where the sequence of people

46:02.540 --> 46:06.820
 seizing this central source of the basic income.

46:06.820 --> 46:08.380
 And you'll say, oh, no, an algorithm can do it.

46:08.380 --> 46:09.700
 Then people will seize the algorithm.

46:09.700 --> 46:11.220
 They'll seize control.

46:11.220 --> 46:13.540
 Unless the algorithm is decentralized

46:13.540 --> 46:15.580
 and it's impossible to seize the control.

46:15.580 --> 46:20.580
 Yeah, but 60 something people own a quarter of all the Bitcoin.

46:22.660 --> 46:24.100
 The things that we think are decentralized

46:24.100 --> 46:25.940
 are not decentralized.

46:25.940 --> 46:27.820
 So let's go to future two.

46:27.820 --> 46:32.460
 Future two, the gardener see that van with all the cameras

46:32.460 --> 46:33.660
 and the kindergarten paint job.

46:33.660 --> 46:35.420
 And they say, the groundskeepers,

46:35.420 --> 46:37.660
 and they say, hey, the robots are coming.

46:37.660 --> 46:38.940
 We're gonna form a data union.

46:38.940 --> 46:42.740
 And amazingly, California has a little baby data union.

46:42.740 --> 46:43.580
 Really?

46:43.580 --> 46:44.420
 A law emerging in the books.

46:44.420 --> 46:45.260
 Yes. Interesting.

46:45.260 --> 46:46.100
 That's interesting.

46:46.100 --> 46:49.180
 And so they'll, and what they say,

46:49.180 --> 46:53.860
 we're gonna form a data union and we're gonna,

46:53.860 --> 46:56.340
 not only are we gonna sell our data to this place,

46:56.340 --> 46:57.940
 but we're gonna make it better than it would have been

46:57.940 --> 47:00.100
 if they were just grabbing it without our cooperation.

47:00.100 --> 47:01.780
 And we're gonna improve it.

47:01.780 --> 47:03.380
 We're gonna make the robots more effective.

47:03.380 --> 47:04.220
 We're gonna make them better

47:04.220 --> 47:05.340
 and we're gonna be proud of it.

47:05.340 --> 47:09.900
 We're gonna become a new class of experts that are respected.

47:09.900 --> 47:11.740
 And then here's the interesting,

47:11.740 --> 47:14.540
 there's two things that are different about that world

47:14.540 --> 47:15.660
 from future one.

47:15.660 --> 47:17.660
 One thing, of course, the people have more pride.

47:17.660 --> 47:27.260
 They have more sense of ownership of agency, but what the robots do changes.

47:27.260 --> 47:29.980
 Instead of just like this functional,

47:29.980 --> 47:33.540
 like we'll figure out how to keep the neighborhood from burning down,

47:33.540 --> 47:35.340
 you have this whole creative community

47:35.340 --> 47:36.500
 that wasn't there before thinking,

47:36.500 --> 47:38.020
 well, how can we make these robots better

47:38.020 --> 47:39.700
 so we can keep on earning money?

47:39.700 --> 47:44.300
 There'll be waves of creative grounds keeping

47:44.300 --> 47:47.980
 with spiral pumping, pumping patches and waves of cultural things.

47:47.980 --> 47:49.500
 There'll be new ideas like,

47:49.500 --> 47:53.180
 wow, I wonder if we could do something about climate change mitigation

47:53.180 --> 47:54.460
 with how we do this.

47:54.460 --> 47:56.420
 What about, what about fresh water?

47:56.420 --> 47:59.220
 Can we, what about, can we make the food healthier?

47:59.220 --> 48:00.500
 What about, what about all of a sudden,

48:00.500 --> 48:03.300
 there'll be this whole creative community on the case?

48:03.300 --> 48:06.140
 And isn't it nicer to have a high tech future

48:06.140 --> 48:07.580
 with more creative classes

48:07.580 --> 48:09.220
 than one with more dependent classes?

48:09.220 --> 48:10.460
 Isn't that a better future?

48:10.460 --> 48:12.500
 But, but, but, but, but.

48:12.500 --> 48:16.460
 Future one and future two have the same robots

48:16.460 --> 48:17.620
 and the same algorithms.

48:17.620 --> 48:19.380
 There's no technological difference.

48:19.380 --> 48:20.780
 There's only a human difference.

48:20.780 --> 48:21.620
 Yeah.

48:21.620 --> 48:24.140
 And that second future two, that's data dignity.

48:25.700 --> 48:26.780
 The economy that you're,

48:26.780 --> 48:29.260
 I mean, the game theory here is on the humans.

48:29.260 --> 48:31.780
 And then the technology is just the tools

48:31.780 --> 48:34.060
 that enable, you know, I mean,

48:34.060 --> 48:37.620
 I think you can believe in AI and be in future two.

48:37.620 --> 48:38.740
 I just think it's a little harder.

48:38.740 --> 48:40.940
 You have to do, you have to do more

48:40.940 --> 48:42.660
 contortions.

48:42.660 --> 48:43.500
 It's possible.

48:43.500 --> 48:46.140
 So in the case of social media,

48:46.140 --> 48:49.260
 what is a data dignity look like?

48:49.260 --> 48:51.540
 Is it people getting paid for their data?

48:51.540 --> 48:52.380
 Yeah.

48:52.380 --> 48:55.420
 I think what should happen is in the future,

48:55.420 --> 48:58.380
 there should be massive data unions

48:59.460 --> 49:04.060
 for people putting content into the system.

49:04.060 --> 49:06.060
 And those data unions should smooth out

49:06.060 --> 49:07.020
 the results a little bit.

49:07.020 --> 49:08.700
 So it's not winter take all,

49:08.700 --> 49:10.540
 but at the same time,

49:10.540 --> 49:11.700
 and people have to pay for it too.

49:11.700 --> 49:13.700
 They have to pay for Facebook

49:13.700 --> 49:14.980
 the way they pay for Netflix

49:14.980 --> 49:17.460
 with an allowance for the poor.

49:17.460 --> 49:20.340
 There has to be a way out too.

49:20.340 --> 49:22.260
 But the thing is people do pay for Netflix.

49:22.260 --> 49:23.540
 It's a going concern.

49:24.420 --> 49:26.340
 People pay for Xbox and PlayStation.

49:26.340 --> 49:27.180
 Like people,

49:27.180 --> 49:29.020
 there's enough people to pay for stuff they want

49:29.020 --> 49:29.860
 this could happen too.

49:29.860 --> 49:31.420
 It's just that this precedent started

49:31.420 --> 49:33.140
 that moved in the wrong direction.

49:33.140 --> 49:35.140
 And then what has to happen,

49:36.460 --> 49:38.100
 the economy's a measuring device.

49:38.100 --> 49:40.980
 If it's an honest measuring device,

49:40.980 --> 49:44.340
 the outcomes for people form a normal distribution,

49:44.340 --> 49:45.500
 a bell curve.

49:45.500 --> 49:47.020
 And then so there should be a few people

49:47.020 --> 49:47.860
 who do really well,

49:47.860 --> 49:49.460
 a lot of people who do okay.

49:49.460 --> 49:51.500
 And then we should have an expanding economy

49:51.500 --> 49:54.700
 reflecting more and more creativity and expertise

49:54.700 --> 49:56.420
 flowing through the network.

49:56.420 --> 49:58.700
 And that expanding economy moves the result

49:58.700 --> 49:59.540
 just a bit forward.

49:59.540 --> 50:01.740
 So more people are getting money out of it

50:01.740 --> 50:02.980
 than are putting money into it.

50:02.980 --> 50:04.620
 So it gradually expands the economy

50:04.620 --> 50:05.620
 and lifts all boats.

50:05.620 --> 50:09.420
 And the society has to support the lower wing

50:09.420 --> 50:10.740
 of the bell curve too,

50:10.740 --> 50:12.140
 but not universal basic income.

50:12.140 --> 50:14.340
 It has to be for the,

50:14.340 --> 50:16.740
 because if it's an honest economy,

50:16.740 --> 50:19.260
 there will be that lower wing.

50:19.260 --> 50:20.820
 And we have to support those people.

50:20.820 --> 50:22.900
 There has to be a safety net.

50:22.900 --> 50:25.100
 But see what I believe,

50:25.100 --> 50:26.100
 I'm not gonna talk about AI,

50:26.100 --> 50:28.860
 but I will say that I think there'll be

50:28.860 --> 50:31.220
 more and more algorithms that are useful.

50:31.220 --> 50:34.820
 And so I don't think everybody's gonna be supplying data

50:34.820 --> 50:36.140
 to groundskeeping robots,

50:36.140 --> 50:38.020
 nor do I think everybody's gonna make their living

50:38.020 --> 50:38.860
 with TikTok videos.

50:38.860 --> 50:40.220
 I think in both cases,

50:40.220 --> 50:42.820
 there'll be a rather small contingent

50:42.820 --> 50:45.220
 that do well enough at either of those things.

50:45.220 --> 50:48.340
 But I think there might be many, many, many, many

50:48.340 --> 50:49.940
 of those niches that start to evolve

50:49.940 --> 50:51.140
 as they're more and more algorithms,

50:51.140 --> 50:52.180
 more and more robots.

50:52.180 --> 50:54.620
 And it's that large number

50:54.620 --> 50:56.660
 that will create the economic potential

50:56.660 --> 50:58.620
 for a very large part of society

50:58.620 --> 51:01.620
 to become members of new creative classes.

51:01.620 --> 51:06.340
 So do you think it's possible to create a social network

51:06.340 --> 51:07.980
 that competes with Twitter and Facebook

51:07.980 --> 51:10.100
 that's large and centralized in this way?

51:10.100 --> 51:12.220
 Not centralized, sort of large, large.

51:12.220 --> 51:14.620
 How to get, all right, so I gotta tell you

51:14.620 --> 51:16.620
 how to get from what I'm talking,

51:16.620 --> 51:19.500
 how to get from where we are to anything kind of in the zone

51:19.500 --> 51:22.440
 of what I'm talking about is challenging.

51:23.740 --> 51:26.020
 I know some of the people who run,

51:26.020 --> 51:27.140
 like I know Jack Dorsey,

51:27.140 --> 51:32.140
 and I view Jack as somebody who's actually,

51:34.860 --> 51:36.980
 I think he's really striving and searching

51:36.980 --> 51:39.140
 and trying to find a way to make it better,

51:40.100 --> 51:44.260
 but is kind of like, it's very hard to do it while in flight.

51:44.260 --> 51:46.460
 And he's under enormous business pressure too.

51:47.460 --> 51:49.660
 So Jack Dorsey to me is a fascinating study

51:49.660 --> 51:52.700
 because I think his mind is in a lot of good places.

51:52.700 --> 51:54.540
 He's a good human being,

51:54.540 --> 51:56.500
 but there's a big Titanic ship

51:56.500 --> 51:58.020
 that's already moving in one direction.

51:58.020 --> 51:59.220
 It's hard to know what to do with it.

51:59.220 --> 52:00.940
 I think that's the story of Twitter.

52:00.940 --> 52:02.740
 I think that's the story of Twitter.

52:02.740 --> 52:04.660
 One of the things that I observed is that

52:04.660 --> 52:06.580
 if you just wanna look at the human side,

52:06.580 --> 52:08.740
 meaning like how are people being changed?

52:08.740 --> 52:09.620
 How do they feel?

52:09.620 --> 52:11.500
 What does the culture like?

52:11.500 --> 52:15.940
 Almost all of the social media platforms that get big

52:15.940 --> 52:18.020
 have an initial sort of honeymoon period

52:18.020 --> 52:20.300
 where they're actually kind of sweet and cute.

52:20.300 --> 52:22.340
 Like if you look at the early years of Twitter,

52:22.340 --> 52:23.740
 it was really sweet and cute,

52:23.740 --> 52:27.500
 but also look at Snap, TikTok.

52:27.500 --> 52:30.420
 And then what happens is as they scale

52:30.420 --> 52:32.740
 and the algorithms become more influential

52:32.740 --> 52:34.100
 instead of just the early people,

52:34.100 --> 52:36.900
 when it gets big enough that it's the algorithm running it,

52:36.900 --> 52:39.620
 then you start to see the rise of the paranoid style

52:39.620 --> 52:40.780
 and then they start to get dark.

52:40.780 --> 52:43.820
 And we've seen that shift in TikTok rather recently.

52:43.820 --> 52:48.700
 But I feel like that scaling reveals the flaws

52:48.700 --> 52:50.140
 within the incentives.

52:51.660 --> 52:52.860
 I feel like I'm torturing you.

52:52.860 --> 52:53.700
 I'm sorry.

52:53.700 --> 52:54.540
 No, it's not torturing.

52:54.540 --> 52:59.540
 No, because I have hope for the world with humans

53:00.380 --> 53:02.860
 and I have hope for a lot of things that humans create,

53:02.860 --> 53:04.380
 including technology.

53:04.380 --> 53:06.860
 And I just, I feel it is possible

53:06.860 --> 53:09.020
 to create social media platforms

53:09.020 --> 53:13.420
 that incentivize different things than the current.

53:13.420 --> 53:15.820
 I think the current incentivization

53:15.820 --> 53:18.100
 is around like the dumbest possible thing

53:18.100 --> 53:21.780
 that was invented like 20 years ago, however long.

53:21.780 --> 53:24.180
 And it just works and so nobody's changing it.

53:24.180 --> 53:26.660
 I just think that there could be a lot of innovation

53:26.660 --> 53:29.540
 for more, see, you kind of push back this idea

53:29.540 --> 53:33.180
 that we can't know what longterm growth or happiness is.

53:33.180 --> 53:35.660
 I, if you give control to people

53:35.660 --> 53:39.460
 to define what their longterm happiness and goals are,

53:39.460 --> 53:42.500
 then that optimization can happen

53:42.500 --> 53:44.300
 for each of those individual people.

53:45.980 --> 53:49.300
 Well, I mean, imagine a future

53:49.300 --> 53:54.300
 where probably a lot of people would love

53:55.300 --> 53:59.220
 to make their living doing TikTok dance videos,

53:59.220 --> 54:01.340
 but people recognize generally

54:01.340 --> 54:03.100
 that's kind of hard to get into.

54:03.100 --> 54:06.900
 Nonetheless, dance crews have an experience

54:06.900 --> 54:09.580
 that's very similar to programmers working together

54:09.580 --> 54:10.420
 on GitHub.

54:10.420 --> 54:13.300
 So the future is like a cross between TikTok and GitHub

54:13.300 --> 54:16.900
 and they get together and they have, they're,

54:16.900 --> 54:17.740
 they have rights.

54:17.740 --> 54:20.860
 They're negotiating, they're negotiating for returns.

54:20.860 --> 54:23.660
 They join different artist societies in order

54:23.660 --> 54:26.380
 to soften the blow of the randomness

54:26.380 --> 54:28.660
 of who gets the network effect benefit

54:28.660 --> 54:30.540
 because nobody can know that.

54:30.540 --> 54:35.020
 And they, and I think an individual person

54:35.020 --> 54:37.260
 might join a thousand different data unions

54:37.260 --> 54:39.780
 in the course of their lives or maybe even 10,000.

54:39.780 --> 54:42.380
 I don't know, but the point is that we'll have like these

54:42.380 --> 54:45.180
 very hedge distributed portfolios

54:45.180 --> 54:47.100
 of different data unions were part of.

54:47.100 --> 54:49.580
 And some of them might just trickle in a little money

54:49.580 --> 54:52.300
 for nonsense stuff where we're contributing

54:52.300 --> 54:53.820
 to health studies or something.

54:53.820 --> 54:56.300
 And, but I think people will find their way,

54:56.300 --> 54:59.580
 they'll find their way to the right GitHub like community

54:59.580 --> 55:03.140
 in which they find their value in the context

55:03.140 --> 55:08.140
 of supplying inputs and data and taste and correctives

55:08.140 --> 55:10.700
 and all of this into the algorithms

55:10.700 --> 55:12.100
 and the robots of the future.

55:12.100 --> 55:17.100
 And that is a way to resist the lizard brain based

55:18.580 --> 55:20.420
 funding assist mechanism.

55:20.420 --> 55:22.740
 It's an alternate economic system

55:22.740 --> 55:26.020
 that rewards productivity, creativity,

55:26.020 --> 55:27.860
 value as perceived by others.

55:27.860 --> 55:28.860
 It's a genuine market.

55:28.860 --> 55:30.500
 It's not doled out from a center.

55:30.500 --> 55:33.740
 There's not some communist person deciding who's valuable.

55:33.740 --> 55:35.100
 It's actual market.

55:35.100 --> 55:41.420
 And the, the money is made by supporting that instead of just

55:41.420 --> 55:44.100
 grabbing people's attention in the cheapest possible way,

55:44.100 --> 55:46.260
 which is definitely how you get the lizard brain.

55:46.260 --> 55:47.100
 Yeah.

55:47.100 --> 55:47.940
 Okay.

55:47.940 --> 55:49.700
 So we're finally at the agreement.

55:49.700 --> 55:56.700
 But I, I just think that so, yeah, I'll tell you what,

55:56.700 --> 56:00.580
 how I think the fake social media, there's a few things.

56:00.580 --> 56:03.100
 There's a few things that I think are important.

56:03.100 --> 56:05.540
 There's a few things, there's a few things.

56:05.540 --> 56:08.180
 So one, I think people should have complete control over

56:08.180 --> 56:11.780
 their data and transparency of what that data is

56:11.780 --> 56:14.820
 and how it's being used if they do hand over the control.

56:14.820 --> 56:17.220
 Another thing they should be able to delete, walk away

56:17.220 --> 56:19.740
 with their data at any moment, easy.

56:19.740 --> 56:22.180
 Like with a single click of a button, maybe two buttons.

56:22.180 --> 56:23.020
 I don't know.

56:23.020 --> 56:25.220
 Just easily walk away with their data.

56:26.140 --> 56:28.180
 The other is control of the algorithm,

56:28.180 --> 56:31.300
 individualized control of the algorithm for them.

56:31.300 --> 56:33.540
 So each one has their own algorithm.

56:33.540 --> 56:34.900
 Each person has their own algorithm.

56:34.900 --> 56:39.180
 They get to be the decider of what they see in this world.

56:39.180 --> 56:41.300
 And to me, that, I mean, that's,

56:41.300 --> 56:43.820
 I guess fundamentally decentralized

56:43.820 --> 56:46.180
 in terms of the key decisions being made.

56:46.180 --> 56:47.500
 But if that's made transparent,

56:47.500 --> 56:50.180
 I feel like people will choose that system

56:50.180 --> 56:53.620
 over Twitter of today, over Facebook of today.

56:53.620 --> 56:55.340
 When they have the ability to walk away,

56:55.340 --> 56:57.500
 to control their data and to control

56:57.500 --> 56:59.100
 the kinds of thing they see.

56:59.100 --> 57:03.060
 Now, let's walk away from the term AI, you're right.

57:03.060 --> 57:06.060
 In this case, you have full control

57:06.060 --> 57:09.340
 of the algorithms that help you if you want

57:09.340 --> 57:11.740
 to use their help, but you can also say a few

57:11.740 --> 57:15.980
 to those algorithms and just consume the raw,

57:15.980 --> 57:19.500
 beautiful waterfall of the internet.

57:19.500 --> 57:23.620
 I think that, to me, that's not only fix the social media,

57:23.620 --> 57:25.460
 but I think it would make a lot more money.

57:25.460 --> 57:27.060
 So I would like to challenge the idea.

57:27.060 --> 57:28.420
 I know you're not presenting that,

57:28.420 --> 57:31.900
 but that the only way to make a ton of money

57:31.900 --> 57:33.940
 is to operate like Facebook is.

57:33.940 --> 57:37.780
 I think you can make more money by giving people control.

57:37.780 --> 57:39.980
 Yeah, I mean, I certainly believe that.

57:39.980 --> 57:41.660
 We're definitely in the territory

57:41.660 --> 57:45.300
 of wholehearted agreement here.

57:46.460 --> 57:48.660
 I do want to caution against one thing,

57:48.660 --> 57:53.100
 which is making a future that benefits programmers versus,

57:53.100 --> 57:55.340
 like this idea that people are in control of their data.

57:55.340 --> 57:59.860
 So years ago, I cofounded an advisory board for the EU

57:59.860 --> 58:02.220
 with a guy named Giovanni Bottarelli who passed away.

58:02.220 --> 58:03.540
 It's one of the reasons I wanted to mention it.

58:03.540 --> 58:06.140
 A remarkable guy who'd been,

58:06.140 --> 58:07.740
 he was originally a prosecutor

58:07.740 --> 58:12.060
 who was throwing mafioso and gel in Sicily.

58:12.060 --> 58:15.060
 So he was like this intense guy who was like,

58:15.060 --> 58:17.180
 I've dealt with death threats.

58:17.180 --> 58:19.020
 Mark Zuckerberg doesn't scare me or whatever.

58:19.020 --> 58:22.220
 So we worked on this path of saying,

58:22.220 --> 58:24.260
 let's make it all about transparency and consent.

58:24.260 --> 58:25.580
 And it was one of the feeders

58:25.580 --> 58:30.580
 that led to this huge data privacy

58:30.700 --> 58:34.020
 and protection framework in Europe called the GDPR.

58:34.020 --> 58:36.460
 And so therefore we've been able

58:36.460 --> 58:39.140
 to have empirical feedback on how that goes.

58:39.140 --> 58:44.060
 And the problem is that most people actually get stymied

58:44.060 --> 58:46.940
 by the complexity of that kind of management.

58:46.940 --> 58:49.740
 They have trouble and reasonably so.

58:49.740 --> 58:51.580
 I don't, I'm like a techie.

58:51.580 --> 58:54.500
 I can go in and I can figure out what's going on.

58:54.500 --> 58:56.820
 But most people really do.

58:56.820 --> 59:01.820
 And so there's a problem that it differentially benefits

59:03.180 --> 59:06.220
 those who kind of have a technical mindset and can go in

59:06.220 --> 59:09.020
 and sort of have a feeling for how this stuff works.

59:09.020 --> 59:11.580
 I kind of still want to come back to incentives.

59:11.580 --> 59:15.100
 And so if the incentive for whoever's,

59:15.100 --> 59:17.620
 if the commercial incentive is to help the creative people

59:17.620 --> 59:20.500
 of the future make more money because you get a cut of it,

59:20.500 --> 59:22.300
 that's how you grow an economy.

59:22.300 --> 59:24.100
 Not the programmers.

59:24.100 --> 59:25.660
 Well, some of them will be programmers.

59:25.660 --> 59:26.700
 It's not anti programmer.

59:26.700 --> 59:29.860
 I'm just saying that it's not only programmers.

59:29.860 --> 59:34.860
 So yeah, you have to make sure the incentives are right.

59:35.660 --> 59:40.500
 I mean, I like control is an interface problem

59:40.500 --> 59:41.780
 to where you have to create something

59:41.780 --> 59:45.100
 that's compelling to everybody,

59:45.100 --> 59:48.100
 to the creatives, to the public.

59:48.100 --> 59:52.020
 I mean, there's a, I don't know, creative commons,

59:52.020 --> 59:57.020
 like the licensing, there's a bunch of legal speak

59:57.300 --> 1:00:00.340
 just in general, the whole legal profession.

1:00:00.340 --> 1:00:01.860
 It's nice when it can be simplified

1:00:01.860 --> 1:00:04.020
 in the way that you can truly simply understand,

1:00:04.020 --> 1:00:07.860
 everybody can simply understand the basics.

1:00:07.860 --> 1:00:11.580
 In the same way, it should be very simple to understand

1:00:12.660 --> 1:00:14.900
 how the data is being used

1:00:14.900 --> 1:00:17.580
 and what data is being used for people.

1:00:17.580 --> 1:00:20.580
 But then you're arguing that in order for that to happen,

1:00:20.580 --> 1:00:22.460
 you have to have the incentives alike.

1:00:22.460 --> 1:00:26.620
 I mean, a lot of the reason that money works

1:00:26.620 --> 1:00:30.260
 is actually information hiding and information loss.

1:00:30.260 --> 1:00:33.900
 Like one of the things about money is a particular dollar

1:00:33.900 --> 1:00:36.460
 you might have passed through your enemy's hands

1:00:36.460 --> 1:00:37.780
 and you don't know it.

1:00:37.780 --> 1:00:40.380
 But also, I mean, this is what Adam Smith,

1:00:40.380 --> 1:00:42.860
 if you wanna give the most charitable interpretation

1:00:42.860 --> 1:00:46.020
 possible to the invisible hand is what he was saying,

1:00:46.020 --> 1:00:48.620
 is that there's this whole complicated thing

1:00:48.620 --> 1:00:50.660
 and not only do you not need to know about it,

1:00:50.660 --> 1:00:52.220
 the truth is you'd never be able to follow it

1:00:52.220 --> 1:00:55.860
 if you tried and just let the economic incentives

1:00:55.860 --> 1:01:00.300
 solve for this whole thing and that in a sense,

1:01:00.300 --> 1:01:02.580
 every transaction is like a neuron and a neural net.

1:01:02.580 --> 1:01:05.700
 If he'd had that metaphor, he would have used it

1:01:05.700 --> 1:01:08.060
 and let the whole thing settle to a solution

1:01:08.060 --> 1:01:09.740
 and don't worry about it.

1:01:09.740 --> 1:01:13.700
 I think this idea of having incentives

1:01:13.700 --> 1:01:17.380
 that reduce complexity for people can be made to work.

1:01:17.380 --> 1:01:19.260
 And that's an example of an algorithm

1:01:19.260 --> 1:01:20.620
 that could be manipulative or not,

1:01:20.620 --> 1:01:22.020
 going back to your question before about,

1:01:22.020 --> 1:01:24.500
 can you do it in a way that's not manipulative?

1:01:24.500 --> 1:01:28.140
 And I would say a GitHub like,

1:01:28.140 --> 1:01:29.340
 if you just have this vision,

1:01:29.340 --> 1:01:33.340
 GitHub plus TikTok combined, is it possible?

1:01:33.340 --> 1:01:34.860
 I think it is, I really think it is.

1:01:34.860 --> 1:01:37.540
 I'm not gonna be able to unsee that idea

1:01:38.740 --> 1:01:41.100
 of creatives on TikTok collaborating in the same way

1:01:41.100 --> 1:01:42.820
 that people on GitHub collaborate.

1:01:42.820 --> 1:01:43.660
 Why not?

1:01:43.660 --> 1:01:44.580
 I like that kind of version.

1:01:44.580 --> 1:01:45.700
 Why not?

1:01:45.700 --> 1:01:46.540
 I like it, I love it.

1:01:46.540 --> 1:01:48.940
 I just, like right now when people use,

1:01:48.940 --> 1:01:51.740
 by the way, father of teenage daughter, so.

1:01:51.740 --> 1:01:53.620
 It's all about TikTok, right?

1:01:53.620 --> 1:01:55.620
 So, you know, when people use TikTok,

1:01:55.620 --> 1:01:59.140
 there's a lot of, it's kind of funny,

1:01:59.140 --> 1:02:00.180
 I was gonna say cattyness,

1:02:00.180 --> 1:02:03.020
 but I was just using the cat as this exemplar

1:02:03.020 --> 1:02:04.700
 of what we're coming up with.

1:02:04.700 --> 1:02:06.300
 I contradict myself, but anyway,

1:02:06.300 --> 1:02:07.860
 there's all this cattyness where people are like,

1:02:07.860 --> 1:02:09.780
 ee, ee, ee, ee, ee, ee, ee.

1:02:09.780 --> 1:02:13.660
 And I just, what about people getting together

1:02:13.660 --> 1:02:16.580
 and saying, okay, we're gonna work on this move,

1:02:16.580 --> 1:02:18.780
 we're gonna get a better, can we get a better musician?

1:02:18.780 --> 1:02:22.060
 And they do that, but that's the part

1:02:22.060 --> 1:02:25.020
 that's kind of off the books right now.

1:02:25.020 --> 1:02:26.380
 You know, that should be like right there,

1:02:26.380 --> 1:02:27.220
 that should be the center.

1:02:27.220 --> 1:02:29.540
 That's where the, that's the really best part.

1:02:29.540 --> 1:02:32.060
 Well, that's where the invention of get period,

1:02:32.060 --> 1:02:33.420
 the versioning is brilliant.

1:02:33.420 --> 1:02:36.860
 And so some of the things you're talking about,

1:02:36.860 --> 1:02:40.420
 technology, algorithms, tools can empower.

1:02:40.420 --> 1:02:43.780
 And that's the thing, for humus to connect,

1:02:43.780 --> 1:02:45.100
 to collaborate and so on.

1:02:45.100 --> 1:02:48.060
 Can we upset more people a little bit?

1:02:48.060 --> 1:02:49.380
 You already.

1:02:49.380 --> 1:02:50.860
 Maybe, we'd have to try.

1:02:50.860 --> 1:02:53.900
 No, no, can we, can ask you to elaborate,

1:02:53.900 --> 1:02:57.020
 because my intuition was that you would be a supporter

1:02:57.020 --> 1:02:59.340
 of something like cryptocurrency and Bitcoin,

1:02:59.340 --> 1:03:03.140
 because it is fundamentally emphasizes decentralization.

1:03:03.140 --> 1:03:05.700
 What do you, so can you elaborate?

1:03:05.700 --> 1:03:06.900
 Yeah, okay, look.

1:03:06.900 --> 1:03:08.060
 Your thoughts on Bitcoin.

1:03:08.060 --> 1:03:11.620
 I, it's kind of funny.

1:03:11.620 --> 1:03:15.140
 I wrote, I've been advocating

1:03:15.140 --> 1:03:17.700
 some kind of digital currency for a long time.

1:03:17.700 --> 1:03:22.700
 And when the, when the, when Bitcoin came out

1:03:23.020 --> 1:03:25.780
 and the original paper on, on blockchain,

1:03:26.820 --> 1:03:30.420
 my heart kind of sank, because I thought, oh my God,

1:03:30.420 --> 1:03:32.780
 we're applying all of this fancy thought

1:03:32.780 --> 1:03:36.420
 on all these very careful distributed security measures

1:03:36.420 --> 1:03:38.620
 to recreate the gold standard.

1:03:38.620 --> 1:03:42.180
 Like it's just so retro, it's so dysfunctional.

1:03:42.180 --> 1:03:44.100
 It's so useless from an economic point of view.

1:03:44.100 --> 1:03:46.420
 So it's always, and then the other thing

1:03:46.420 --> 1:03:50.260
 is using computational inefficiency at a boundless scale

1:03:50.260 --> 1:03:54.020
 as your form of security is a crime against this atmosphere.

1:03:54.020 --> 1:03:55.540
 Obviously, a lot of people know that now,

1:03:55.540 --> 1:03:57.700
 but we knew that at the start.

1:03:57.700 --> 1:03:59.820
 Like the thing is when the first paper came out,

1:03:59.820 --> 1:04:01.500
 I remember a lot of people saying, oh my God,

1:04:01.500 --> 1:04:04.540
 this thing scales, it's a carbon disaster, you know?

1:04:04.540 --> 1:04:09.340
 And, and I, I just like, I'm just mystified,

1:04:09.340 --> 1:04:11.500
 but that's a different question than when you asked.

1:04:11.500 --> 1:04:15.220
 Can you have a cryptographic currency

1:04:15.220 --> 1:04:17.460
 or at least some kind of digital currency

1:04:17.460 --> 1:04:18.380
 that's of a benefit?

1:04:18.380 --> 1:04:20.420
 And absolutely, like I'm,

1:04:20.420 --> 1:04:22.180
 and there are people who are trying to be thoughtful

1:04:22.180 --> 1:04:23.900
 about this, you should, if you haven't,

1:04:23.900 --> 1:04:25.980
 you should interview Vitalik Buterin sometime.

1:04:25.980 --> 1:04:27.700
 Yeah, I've interviewed him twice.

1:04:27.700 --> 1:04:30.100
 Okay, so like there are people in the community

1:04:30.100 --> 1:04:31.060
 who are trying to be thoughtful

1:04:31.060 --> 1:04:33.020
 and trying to figure out how to do this better.

1:04:33.020 --> 1:04:34.420
 It has nice properties though, right?

1:04:34.420 --> 1:04:35.860
 So that one of the nice properties

1:04:35.860 --> 1:04:39.260
 is that like government centralized, it's hard to control.

1:04:39.260 --> 1:04:41.420
 And then the other one, to fix some of the issues

1:04:41.420 --> 1:04:42.260
 that you're referring to,

1:04:42.260 --> 1:04:44.340
 I'm sort of playing devil's advocate here is,

1:04:44.340 --> 1:04:45.580
 you know, there's lightning network,

1:04:45.580 --> 1:04:49.980
 there's ideas how you build stuff on top of Bitcoin,

1:04:49.980 --> 1:04:51.140
 similar with gold,

1:04:51.140 --> 1:04:54.460
 that allow you to have this kind of vibrant economy

1:04:54.460 --> 1:04:56.260
 that operates not on the blockchain,

1:04:56.260 --> 1:04:57.420
 but outside the blockchain

1:04:57.420 --> 1:05:02.300
 and use this Bitcoin for like checking the security

1:05:02.300 --> 1:05:03.340
 of those transactions.

1:05:03.340 --> 1:05:05.900
 So Bitcoin's not new, it's been around for a while.

1:05:05.900 --> 1:05:08.100
 I've been watching it closely.

1:05:08.100 --> 1:05:12.980
 I've not seen one example of it creating economic growth.

1:05:12.980 --> 1:05:14.460
 There was this obsession with the idea

1:05:14.460 --> 1:05:16.180
 that government was the problem.

1:05:16.180 --> 1:05:18.500
 That idea that government's the problem,

1:05:18.500 --> 1:05:22.860
 let's say government earned that wrath honestly,

1:05:22.860 --> 1:05:25.180
 because if you look at some of the things

1:05:25.180 --> 1:05:27.180
 that governments have done in recent decades,

1:05:27.180 --> 1:05:28.980
 it's not a pretty story.

1:05:28.980 --> 1:05:33.420
 Like after a very small number of people

1:05:33.420 --> 1:05:37.460
 in the US government decided to bomb in landmine,

1:05:37.460 --> 1:05:40.180
 Southeast Asia, it's hard to come back

1:05:40.180 --> 1:05:41.820
 and say, oh, government's a great thing.

1:05:41.820 --> 1:05:46.820
 But then the problem is that this resistance to government

1:05:48.900 --> 1:05:51.020
 is basically resistance to politics.

1:05:51.020 --> 1:05:52.380
 It's a way of saying,

1:05:52.380 --> 1:05:54.300
 if I can get rich, nobody should bother me.

1:05:54.300 --> 1:05:56.940
 It's a way of not having obligations to others.

1:05:56.940 --> 1:06:00.740
 And that ultimately is a very suspect motivation.

1:06:00.740 --> 1:06:04.180
 But does that mean that the impulse,

1:06:04.180 --> 1:06:09.180
 that the government should not overreach its power is flawed?

1:06:09.340 --> 1:06:12.100
 Well, I mean, what I wanna ask you to do

1:06:12.100 --> 1:06:15.500
 is to replace the word government with politics.

1:06:15.500 --> 1:06:19.940
 Like our politics is people having to deal with each other.

1:06:19.940 --> 1:06:23.540
 My theory about freedom is that the only authentic

1:06:23.540 --> 1:06:26.500
 form of freedom is perpetual annoyance.

1:06:26.500 --> 1:06:29.340
 All right, so annoyance means

1:06:29.340 --> 1:06:30.660
 you're actually dealing with people

1:06:30.660 --> 1:06:31.860
 because people are annoying.

1:06:31.860 --> 1:06:34.580
 Perpetual means that that annoyance is survivable

1:06:34.580 --> 1:06:36.220
 so it doesn't destroy us all.

1:06:36.220 --> 1:06:38.660
 So if you have perpetual annoyance, then you have freedom.

1:06:38.660 --> 1:06:39.820
 And that's politics.

1:06:39.820 --> 1:06:40.660
 That's politics.

1:06:40.660 --> 1:06:42.900
 If you don't have perpetual annoyance,

1:06:42.900 --> 1:06:44.340
 something's gone very wrong

1:06:44.340 --> 1:06:45.620
 and you've suppressed those people

1:06:45.620 --> 1:06:46.460
 that it's only temporary,

1:06:46.460 --> 1:06:48.420
 it's gonna come back and be horrible.

1:06:48.420 --> 1:06:51.060
 You should seek perpetual annoyance.

1:06:51.060 --> 1:06:52.900
 I'll invite you to a Berkeley City Council meeting

1:06:52.900 --> 1:06:54.060
 so you can know what that feels like.

1:06:54.060 --> 1:06:56.660
 What perfection it feels like.

1:06:57.500 --> 1:06:59.740
 But anyway, so freedom is being,

1:06:59.740 --> 1:07:02.180
 the test of freedom is that you're annoyed by other people.

1:07:02.180 --> 1:07:03.540
 If you're not, you're not free.

1:07:03.540 --> 1:07:06.180
 If you're not, you're trapped in some temporary illusion

1:07:06.180 --> 1:07:07.820
 that's gonna fall apart.

1:07:07.820 --> 1:07:10.580
 Now, this quest to avoid government

1:07:10.580 --> 1:07:13.020
 is really a quest to avoid that political feeling

1:07:13.020 --> 1:07:14.180
 but you have to have it.

1:07:14.180 --> 1:07:15.580
 You have to deal with it.

1:07:16.540 --> 1:07:19.340
 And it sucks, but that's the human situation.

1:07:19.340 --> 1:07:20.700
 That's the human condition.

1:07:20.700 --> 1:07:22.940
 And this idea that we're gonna have this abstract thing

1:07:22.940 --> 1:07:25.300
 that protects us from having to deal with each other

1:07:25.300 --> 1:07:26.780
 is always an illusion.

1:07:26.780 --> 1:07:28.740
 The idea, and I apologize,

1:07:28.740 --> 1:07:32.340
 I overstretched the use of the word government.

1:07:32.340 --> 1:07:37.340
 The idea is there should be some punishment from the people

1:07:37.340 --> 1:07:41.180
 when a bureaucracy, when a set of people

1:07:41.180 --> 1:07:44.620
 or a particular leader, like in an authoritarian regime,

1:07:44.620 --> 1:07:47.220
 which more than half the world currently lives under,

1:07:47.220 --> 1:07:51.900
 if you, like if they become,

1:07:51.900 --> 1:07:53.820
 they start, stop representing the people.

1:07:53.820 --> 1:07:56.700
 It stops being like a Berkeley meeting

1:07:56.700 --> 1:08:01.700
 and starts being more like a dictatorial kind of situation.

1:08:01.700 --> 1:08:06.100
 And so the point is, it's nice to give people,

1:08:06.100 --> 1:08:08.980
 the populace in a decentralized way,

1:08:08.980 --> 1:08:13.980
 power to resist that kind of government

1:08:14.540 --> 1:08:15.820
 becoming authoritarian.

1:08:15.820 --> 1:08:18.380
 Yeah, but people, see this idea that the problem

1:08:18.380 --> 1:08:21.580
 is always the government being powerful is false.

1:08:21.580 --> 1:08:23.660
 The problem can also be criminal gangs.

1:08:23.660 --> 1:08:25.580
 The problem can also be weird cults.

1:08:25.580 --> 1:08:28.380
 The problem can be abusive,

1:08:29.380 --> 1:08:30.500
 abusive clergy.

1:08:30.500 --> 1:08:35.220
 The problem can be infrastructure that fails.

1:08:35.220 --> 1:08:37.660
 The problem can be poisoned water.

1:08:37.660 --> 1:08:39.980
 The problem can be failed electric grids.

1:08:39.980 --> 1:08:44.980
 The problem can be a crappy education system

1:08:45.680 --> 1:08:49.460
 that makes the whole society less and less able

1:08:49.460 --> 1:08:51.420
 to create value.

1:08:51.420 --> 1:08:52.860
 There are all these other problems

1:08:52.860 --> 1:08:54.660
 that are different from an overbearing government.

1:08:54.660 --> 1:08:56.980
 Like you have to keep some sense of perspective

1:08:56.980 --> 1:08:59.300
 and not be obsessed with only one kind of problem

1:08:59.300 --> 1:09:01.220
 because then the others will pop up.

1:09:01.220 --> 1:09:02.500
 But empirically speaking,

1:09:02.500 --> 1:09:05.340
 some problems are bigger than others.

1:09:05.340 --> 1:09:08.900
 So like some groups of people,

1:09:08.900 --> 1:09:11.500
 like governments or gangs or companies lead

1:09:11.500 --> 1:09:12.340
 to problems more than others.

1:09:12.340 --> 1:09:13.580
 Are you a US citizen?

1:09:13.580 --> 1:09:14.420
 Yes.

1:09:14.420 --> 1:09:16.580
 Has the government ever really been a problem for you?

1:09:16.580 --> 1:09:17.420
 Well, okay.

1:09:17.420 --> 1:09:20.140
 So first of all, I grew up in the Soviet Union.

1:09:20.140 --> 1:09:22.340
 And actually, yeah, my wife did too.

1:09:22.340 --> 1:09:25.540
 So I have seen, you know.

1:09:25.540 --> 1:09:26.900
 Sure.

1:09:26.900 --> 1:09:28.900
 And has the government bothered me?

1:09:28.900 --> 1:09:32.820
 I would say that that's a really complicated question,

1:09:32.820 --> 1:09:35.500
 especially because the United States is such,

1:09:35.500 --> 1:09:39.660
 it's a special place in like a lot of other countries.

1:09:39.660 --> 1:09:41.820
 My wife's family were refused NICs.

1:09:41.820 --> 1:09:43.100
 And so we have like a very,

1:09:43.100 --> 1:09:46.220
 and her dad was sent to the gulag

1:09:46.220 --> 1:09:49.260
 for what it's worth on my father's side,

1:09:49.260 --> 1:09:51.460
 all but if you were killed by a pogrom

1:09:51.460 --> 1:09:56.460
 in a post Soviet pogrom in Ukraine.

1:09:57.140 --> 1:10:00.140
 So I would say because you did a little trick

1:10:00.140 --> 1:10:02.900
 of eloquent trick of language

1:10:02.900 --> 1:10:04.820
 that you switched to the United States

1:10:04.820 --> 1:10:06.260
 to talk about government.

1:10:06.260 --> 1:10:10.620
 So I believe, unlike my friend Michael Malis,

1:10:10.620 --> 1:10:12.060
 who's an anarchist,

1:10:12.060 --> 1:10:15.780
 I believe government can do a lot of good in the world.

1:10:15.780 --> 1:10:17.140
 That is exactly what you're saying,

1:10:17.140 --> 1:10:19.700
 which is it's politics.

1:10:19.700 --> 1:10:22.940
 The thing that Bitcoin folks and crypto currency folks argue

1:10:22.940 --> 1:10:25.060
 is that one of the big ways

1:10:25.060 --> 1:10:26.780
 that government can control the populace

1:10:26.780 --> 1:10:30.100
 is centralize bank, like control the money.

1:10:30.100 --> 1:10:32.300
 That was the case in the Soviet Union too.

1:10:32.300 --> 1:10:37.300
 There's inflation can really make poor people suffer.

1:10:38.620 --> 1:10:42.180
 And so what they argue is this is one way

1:10:42.180 --> 1:10:46.300
 to go around that power that government has

1:10:46.300 --> 1:10:48.580
 of controlling the monetary system.

1:10:48.580 --> 1:10:50.220
 So that's a way to resist.

1:10:50.220 --> 1:10:53.460
 That's not actually saying government bad.

1:10:53.460 --> 1:10:55.700
 That's saying some of the ways

1:10:55.700 --> 1:10:59.780
 that central banks get into trouble

1:10:59.780 --> 1:11:01.340
 can be resisted through the central.

1:11:01.340 --> 1:11:05.140
 So let me ask you unbalance today in the real world

1:11:05.140 --> 1:11:07.740
 in terms of actual facts.

1:11:07.740 --> 1:11:10.180
 Do you think cryptocurrencies are doing more

1:11:10.180 --> 1:11:13.980
 to prop up corrupt, murderous, horrible regimes

1:11:13.980 --> 1:11:15.780
 or to resist those regimes?

1:11:15.780 --> 1:11:17.580
 Where do you think the balance is right now?

1:11:17.580 --> 1:11:21.500
 I know exactly having talked to a lot of cryptocurrency folks

1:11:21.500 --> 1:11:22.940
 what they would tell me, right?

1:11:26.860 --> 1:11:27.700
 No, no, no.

1:11:27.700 --> 1:11:29.380
 I'm asking it as a real question.

1:11:29.380 --> 1:11:30.820
 There's no way to know the answer.

1:11:30.820 --> 1:11:32.700
 There's no way to know the answer perfectly.

1:11:32.700 --> 1:11:36.460
 However, I gotta say, if you look at people

1:11:36.460 --> 1:11:39.780
 who've been able to decode blockchains

1:11:39.780 --> 1:11:41.100
 and they do leak a lot of data,

1:11:41.100 --> 1:11:43.580
 they're not as secure as this widely thought.

1:11:43.580 --> 1:11:47.260
 There are a lot of unknown Bitcoin whales

1:11:47.260 --> 1:11:49.740
 from pretty early and they're huge.

1:11:49.740 --> 1:11:53.740
 And if you ask who are these people,

1:11:54.860 --> 1:11:57.620
 there's evidence that a lot of them are quite on,

1:11:57.620 --> 1:12:00.220
 not the people you'd wanna support, let's say.

1:12:00.220 --> 1:12:03.820
 And I just don't, like I think empirically,

1:12:03.820 --> 1:12:07.260
 this idea that there's some intrinsic way

1:12:07.260 --> 1:12:12.260
 that bad governments will be disempowered

1:12:13.620 --> 1:12:16.100
 and people will be able to resist them more

1:12:16.100 --> 1:12:18.900
 than new villains or even villainous governments

1:12:18.900 --> 1:12:19.740
 will be empowered.

1:12:19.740 --> 1:12:21.860
 There's no basis for that assertion.

1:12:21.860 --> 1:12:24.540
 It's just this kind of circumstantial.

1:12:24.540 --> 1:12:28.420
 And I think in general,

1:12:28.420 --> 1:12:31.220
 Bitcoin ownership is one thing,

1:12:31.220 --> 1:12:33.540
 but Bitcoin transactions have tended

1:12:33.540 --> 1:12:37.420
 to support criminality more than productivity.

1:12:37.420 --> 1:12:39.620
 Of course, they would argue that was the story

1:12:39.620 --> 1:12:40.740
 of its early days,

1:12:40.740 --> 1:12:43.860
 that now more and more Bitcoin is being used

1:12:43.860 --> 1:12:46.460
 for legitimate transactions.

1:12:46.460 --> 1:12:47.620
 But that's a different,

1:12:47.620 --> 1:12:49.260
 I didn't say for legitimate transactions,

1:12:49.260 --> 1:12:52.100
 I said for economic growth, for creativity.

1:12:52.100 --> 1:12:57.020
 Like I think what's happening is people are using it

1:12:57.020 --> 1:12:59.220
 a little bit for, I don't know,

1:12:59.220 --> 1:13:02.700
 maybe some of these companies make it available

1:13:02.700 --> 1:13:05.300
 for this and that by a Tesla with it or something.

1:13:07.380 --> 1:13:10.300
 Investing in a startup, hard,

1:13:10.300 --> 1:13:11.500
 it might have happened a little bit,

1:13:11.500 --> 1:13:13.860
 but it's not an engine of productivity,

1:13:13.860 --> 1:13:16.220
 creativity and economic growth.

1:13:16.220 --> 1:13:18.500
 Whereas old fashioned currency still is.

1:13:18.500 --> 1:13:23.500
 And anyway, I'm, look, I think something,

1:13:23.900 --> 1:13:27.020
 I'm pro the idea of digital currencies.

1:13:27.020 --> 1:13:32.020
 I am anti the idea of economics,

1:13:34.660 --> 1:13:37.740
 wiping out politics as a result.

1:13:37.740 --> 1:13:40.020
 I think they have to exist in some balance

1:13:40.020 --> 1:13:42.460
 to avoid the worst dysfunctions of each.

1:13:42.460 --> 1:13:44.780
 In some ways there's parallels to our discussion

1:13:44.780 --> 1:13:49.780
 of algorithms and cryptocurrency is you're pro the idea,

1:13:50.980 --> 1:13:54.380
 but it can be used to manipulate,

1:13:54.380 --> 1:13:59.340
 you can be used poorly by aforementioned humans.

1:13:59.340 --> 1:14:02.220
 Well, I think that you can make better designs

1:14:02.220 --> 1:14:03.500
 and worse designs.

1:14:03.500 --> 1:14:06.300
 And I think, and you know, the thing about cryptocurrency

1:14:06.300 --> 1:14:09.700
 that's so interesting is how many of us

1:14:09.700 --> 1:14:12.740
 are responsible for the poor designs

1:14:12.740 --> 1:14:16.860
 because we're all so hooked on that Horatio Alger story

1:14:16.860 --> 1:14:20.020
 on like, I'm gonna be the one who gets the viral benefit.

1:14:20.020 --> 1:14:22.860
 You know, way back when all this stuff was starting,

1:14:22.860 --> 1:14:24.820
 I remember it would have been in the 80s,

1:14:24.820 --> 1:14:26.740
 somebody had the idea of using viral

1:14:26.740 --> 1:14:29.660
 as a metaphor for network effect.

1:14:29.660 --> 1:14:32.300
 And the whole point was to talk about

1:14:32.300 --> 1:14:33.660
 how bad network effect was,

1:14:33.660 --> 1:14:35.860
 that it always created distortions

1:14:35.860 --> 1:14:39.220
 that ruined the usefulness of economic incentives

1:14:39.220 --> 1:14:42.540
 that created dangerous distortions.

1:14:42.540 --> 1:14:45.620
 Like, but then somehow even after the pandemic,

1:14:45.620 --> 1:14:47.140
 we think of viral as this good thing

1:14:47.140 --> 1:14:49.380
 because we imagine ourselves as the virus, right?

1:14:49.380 --> 1:14:52.180
 We wanna be on the beneficiary side of it.

1:14:52.180 --> 1:14:54.540
 But of course, you're not likely to be.

1:14:54.540 --> 1:14:57.020
 There is a sense because money is involved,

1:14:57.020 --> 1:15:01.580
 people are not reasoning clearly always

1:15:01.580 --> 1:15:06.580
 because they want to be part of that first viral wave

1:15:06.580 --> 1:15:07.620
 that makes them rich.

1:15:07.620 --> 1:15:11.380
 And that blinds people from their basic morality.

1:15:11.380 --> 1:15:13.460
 I had an interesting conversation.

1:15:13.460 --> 1:15:14.820
 I don't, I sort of feel like

1:15:14.820 --> 1:15:16.500
 I should respect some people's privacy,

1:15:16.500 --> 1:15:20.900
 but some of the initial people who started Bitcoin,

1:15:20.900 --> 1:15:23.060
 I remember having an argument about,

1:15:23.060 --> 1:15:26.580
 like it's intrinsically a Ponzi scheme,

1:15:26.580 --> 1:15:29.580
 like the early people have more than the later people.

1:15:29.580 --> 1:15:31.820
 And the further down the chain you get,

1:15:31.820 --> 1:15:34.900
 the more you're subject to gambling like dynamics,

1:15:34.900 --> 1:15:36.180
 where it's more and more random

1:15:36.180 --> 1:15:38.900
 and more and more subject to weird network effects and whatnot,

1:15:38.900 --> 1:15:41.420
 unless you're a very small player, perhaps,

1:15:41.420 --> 1:15:43.060
 and you're just buying something,

1:15:43.060 --> 1:15:45.260
 but even then you'll be subject to fluctuations

1:15:45.260 --> 1:15:47.220
 because the whole thing is just kind of,

1:15:47.220 --> 1:15:49.060
 like as it fluctuates,

1:15:49.060 --> 1:15:51.820
 it's going to wave around the little people more.

1:15:51.820 --> 1:15:55.380
 And I remember the conversation turned to gambling

1:15:55.380 --> 1:15:58.220
 because gambling is a pretty large economic sector.

1:15:58.220 --> 1:16:01.580
 And it's always struck me as being nonproductive.

1:16:01.580 --> 1:16:03.820
 Like somebody goes to Las Vegas and they lose money.

1:16:03.820 --> 1:16:07.060
 And so one argument is, well, they got entertainment.

1:16:07.060 --> 1:16:09.100
 They paid for entertainment as they lost money.

1:16:09.100 --> 1:16:10.460
 So that's fine.

1:16:10.460 --> 1:16:13.540
 And Las Vegas does up the losing of money

1:16:13.540 --> 1:16:14.380
 in an entertaining way.

1:16:14.380 --> 1:16:15.220
 So why not?

1:16:15.220 --> 1:16:16.180
 It's like going to a show.

1:16:16.180 --> 1:16:17.700
 So that's one argument.

1:16:17.700 --> 1:16:19.860
 The argument that was made to me was different from that.

1:16:19.860 --> 1:16:21.420
 It's that, no, what they're doing

1:16:21.420 --> 1:16:23.900
 is they're getting a chance to experience hope.

1:16:23.900 --> 1:16:25.540
 And a lot of people don't get that chance.

1:16:25.540 --> 1:16:26.700
 And so that's really worth it,

1:16:26.700 --> 1:16:27.660
 even if they're going to lose.

1:16:27.660 --> 1:16:29.100
 They have that moment of hope

1:16:29.100 --> 1:16:31.300
 and they need to be able to experience that.

1:16:31.300 --> 1:16:33.980
 And it's a very interesting argument.

1:16:35.020 --> 1:16:40.100
 That's so heartbreaking because I've seen that way.

1:16:40.100 --> 1:16:41.780
 I have that a little bit of a sense.

1:16:41.780 --> 1:16:46.020
 I've talked to some young people who invest in cryptocurrency.

1:16:46.020 --> 1:16:48.500
 And what I see is this hope.

1:16:48.500 --> 1:16:50.420
 This is the first thing that gave them hope.

1:16:50.420 --> 1:16:52.060
 And that's so heartbreaking to me

1:16:52.980 --> 1:16:55.580
 that you've gotten hope from that.

1:16:55.580 --> 1:16:56.860
 So much is invested.

1:16:56.860 --> 1:17:00.060
 It's like hope from somehow becoming rich

1:17:00.060 --> 1:17:02.380
 as opposed to something to me, I apologize.

1:17:02.380 --> 1:17:04.980
 But money is in the longterm

1:17:04.980 --> 1:17:07.940
 not going to be a source of that deep meaning.

1:17:07.940 --> 1:17:09.820
 It's good to have enough money,

1:17:09.820 --> 1:17:12.140
 but it should not be the source of hope.

1:17:12.140 --> 1:17:13.180
 And it's heartbreaking to me

1:17:13.180 --> 1:17:16.260
 how many people is the source of hope.

1:17:16.260 --> 1:17:17.100
 Yeah.

1:17:18.460 --> 1:17:21.340
 You've just described the psychology of virality

1:17:21.340 --> 1:17:25.780
 or the psychology of trying to base the civilization

1:17:25.780 --> 1:17:29.740
 on semi random occurrences of network effect peaks.

1:17:29.740 --> 1:17:32.300
 And it doesn't really work.

1:17:32.300 --> 1:17:34.220
 I mean, I think we need to get away from that.

1:17:34.220 --> 1:17:36.180
 We need to soften those peaks

1:17:38.060 --> 1:17:40.460
 and accept Microsoft, which deserves every penny,

1:17:40.460 --> 1:17:42.020
 but in every other case.

1:17:42.020 --> 1:17:43.980
 Well, you mentioned GitHub.

1:17:43.980 --> 1:17:46.140
 I think what Microsoft did with GitHub was brilliant.

1:17:46.140 --> 1:17:51.140
 I was very, okay, if I can give a, not a critical,

1:17:51.180 --> 1:17:54.340
 but on Microsoft,

1:17:54.340 --> 1:17:57.100
 because they recently purchased Bethesda,

1:17:57.100 --> 1:17:59.900
 so Elder Scrolls is in their hands.

1:17:59.900 --> 1:18:01.380
 I'm watching you, Microsoft,

1:18:01.380 --> 1:18:03.900
 not screw up my favorite game, so.

1:18:03.900 --> 1:18:07.060
 Yeah, look, I'm not speaking for Microsoft.

1:18:07.060 --> 1:18:09.100
 I have an explicit arrangement with them

1:18:09.100 --> 1:18:10.580
 where I don't speak for them.

1:18:10.580 --> 1:18:12.220
 Obviously, that should be very clear.

1:18:12.220 --> 1:18:13.500
 I do not speak for them.

1:18:14.500 --> 1:18:17.420
 I am not saying, I like them.

1:18:17.420 --> 1:18:19.380
 I think Satcha's amazing.

1:18:20.620 --> 1:18:23.700
 The term data dignity was coined by Satcha.

1:18:23.700 --> 1:18:27.180
 Like, so we have, it's kind of extraordinary,

1:18:27.180 --> 1:18:29.420
 but Microsoft's this giant thing.

1:18:29.420 --> 1:18:31.180
 It's gonna screw up this or that.

1:18:31.180 --> 1:18:33.500
 It's not, I don't know.

1:18:33.500 --> 1:18:35.020
 It's kind of interesting.

1:18:35.020 --> 1:18:36.820
 I've had a few occasions in my life

1:18:36.820 --> 1:18:39.900
 to see how things work from the inside of some big thing.

1:18:39.900 --> 1:18:42.620
 And, you know, it's always just people kind of,

1:18:42.620 --> 1:18:44.700
 it's, I don't know.

1:18:44.700 --> 1:18:48.220
 There's always like coordination problems.

1:18:48.220 --> 1:18:49.540
 And there's always.

1:18:49.540 --> 1:18:50.660
 There's human problems.

1:18:50.660 --> 1:18:51.500
 Oh, God.

1:18:51.500 --> 1:18:52.700
 And there's some good people, there's some bad people.

1:18:52.700 --> 1:18:53.540
 It's always.

1:18:53.540 --> 1:18:56.260
 I hope Microsoft doesn't screw up your game.

1:18:56.260 --> 1:18:57.900
 And I hope they bring Clippy back.

1:18:57.900 --> 1:18:59.500
 You should never kill Clippy.

1:18:59.500 --> 1:19:00.340
 Bring Clippy back.

1:19:00.340 --> 1:19:04.060
 Oh, Clippy, but Clippy promotes the myth of AI.

1:19:04.060 --> 1:19:06.340
 Well, that's why I think you're wrong.

1:19:06.340 --> 1:19:07.980
 How about if we, all right,

1:19:07.980 --> 1:19:10.260
 could we bring back Bob instead of Clippy?

1:19:10.260 --> 1:19:11.220
 Which one was Bob?

1:19:11.220 --> 1:19:13.180
 Oh, Bob was another thing.

1:19:13.180 --> 1:19:15.260
 Bob was this other screen character

1:19:15.260 --> 1:19:16.900
 who was supposed to be the voice of AI.

1:19:16.900 --> 1:19:19.340
 Cortana, Cortana, would Cortana do it for you?

1:19:19.340 --> 1:19:21.340
 No, Cortana is too corporate.

1:19:21.340 --> 1:19:23.020
 I like it.

1:19:23.020 --> 1:19:23.860
 I like it.

1:19:23.860 --> 1:19:24.700
 It was fine.

1:19:24.700 --> 1:19:26.260
 There's a woman in Seattle

1:19:26.260 --> 1:19:27.580
 who's like the model for Cortana.

1:19:27.580 --> 1:19:29.260
 Did Cortana's voice and was that voice?

1:19:29.260 --> 1:19:30.100
 There was like.

1:19:30.100 --> 1:19:31.140
 No, the voice is great.

1:19:31.140 --> 1:19:34.380
 We had her as a, she used to walk around

1:19:34.380 --> 1:19:36.300
 and if you were wearing HoloLens for a bit,

1:19:36.300 --> 1:19:38.180
 I don't think that's happening anymore.

1:19:38.180 --> 1:19:39.180
 I think, I don't think you should

1:19:39.180 --> 1:19:41.140
 turn a software into a creature.

1:19:41.140 --> 1:19:41.980
 I think.

1:19:41.980 --> 1:19:42.820
 Well, you and I.

1:19:42.820 --> 1:19:43.660
 Get a cat, just get a cat.

1:19:43.660 --> 1:19:46.060
 You and I, you and I, well, get a dog.

1:19:46.060 --> 1:19:46.900
 Get a dog.

1:19:46.900 --> 1:19:47.980
 Get a dog, yeah.

1:19:47.980 --> 1:19:49.100
 Yeah, you're a.

1:19:49.100 --> 1:19:49.940
 A hedgehog.

1:19:49.940 --> 1:19:50.780
 A hedgehog.

1:19:50.780 --> 1:19:51.900
 Yeah.

1:19:51.900 --> 1:19:54.340
 You coauthored a paper.

1:19:54.340 --> 1:19:56.900
 You mentioned Lee Smollin titled

1:19:56.900 --> 1:20:00.180
 The Autodagdactic Universe,

1:20:00.180 --> 1:20:01.900
 which describes our universe as one

1:20:01.900 --> 1:20:06.420
 that learns its own physical laws.

1:20:06.420 --> 1:20:09.300
 That's a trippy and beautiful and powerful idea.

1:20:09.300 --> 1:20:13.140
 What are, what would you say are the key ideas in this paper?

1:20:13.140 --> 1:20:13.980
 Okay.

1:20:13.980 --> 1:20:18.780
 Well, I should say that paper reflected work from last year

1:20:18.780 --> 1:20:21.700
 and the project, the program has moved quite a lot.

1:20:21.700 --> 1:20:23.460
 So it's a little, there's a lot of stuff

1:20:23.460 --> 1:20:25.380
 that's not published that I'm quite excited about.

1:20:25.380 --> 1:20:27.900
 So I have to kind of keep my frame

1:20:27.900 --> 1:20:30.340
 in that, in that last year's thing.

1:20:30.340 --> 1:20:33.940
 So I have to try to be a little careful about that.

1:20:33.940 --> 1:20:37.380
 We can think about it in a few different ways.

1:20:37.380 --> 1:20:40.740
 The core of the paper, the technical core of it

1:20:40.740 --> 1:20:43.860
 is a triple correspondence.

1:20:43.860 --> 1:20:47.140
 One part of it was already established

1:20:47.140 --> 1:20:49.820
 and then another part is in the process.

1:20:49.820 --> 1:20:53.180
 The part that was established was, of course,

1:20:53.180 --> 1:20:55.540
 understanding different theories of physics

1:20:55.540 --> 1:20:57.260
 as matrix models.

1:20:57.260 --> 1:21:01.780
 The part that was fresher is understanding those

1:21:01.780 --> 1:21:03.580
 as a machine learning system,

1:21:03.580 --> 1:21:04.980
 so that we could move fluidly

1:21:04.980 --> 1:21:07.540
 between these different ways of describing systems.

1:21:07.540 --> 1:21:10.420
 And the reason to wanna do that

1:21:10.420 --> 1:21:12.740
 is just to have more tools and more options

1:21:12.740 --> 1:21:17.700
 because, well, theoretical physics is really hard

1:21:17.700 --> 1:21:22.700
 and a lot of programs have kind of run into a state

1:21:23.540 --> 1:21:25.500
 where they feel a little stalled, I guess.

1:21:25.500 --> 1:21:26.940
 I wanna be delicate about this

1:21:26.940 --> 1:21:27.860
 because I'm not a physicist.

1:21:27.860 --> 1:21:29.700
 I'm the computer scientist collaborating.

1:21:29.700 --> 1:21:32.380
 So I don't mean to diss anybody's.

1:21:32.380 --> 1:21:33.540
 So this is almost like,

1:21:33.540 --> 1:21:36.860
 gives a framework for generating new ideas in physics.

1:21:36.860 --> 1:21:40.140
 As we start to publish more about where it's gone,

1:21:40.140 --> 1:21:43.620
 I think you'll start to see there's tools

1:21:43.620 --> 1:21:46.540
 and ways of thinking about theories

1:21:46.540 --> 1:21:50.660
 that I think open up some new paths

1:21:50.660 --> 1:21:52.500
 that will be of interest.

1:21:53.580 --> 1:21:55.100
 There's the technical core of it,

1:21:55.100 --> 1:21:57.500
 which is this idea of a correspondence

1:21:57.500 --> 1:21:58.860
 to give you more facility.

1:21:58.860 --> 1:22:01.500
 But then there's also the storytelling part of it.

1:22:01.500 --> 1:22:06.500
 And this is something Lee loves stories and I do.

1:22:06.700 --> 1:22:08.980
 And the idea here is that

1:22:11.060 --> 1:22:15.300
 a typical way of thinking about physics

1:22:15.300 --> 1:22:18.420
 is that there's some kind of starting condition

1:22:18.420 --> 1:22:19.620
 and then there's some principle

1:22:19.620 --> 1:22:22.620
 by which the starting condition evolves.

1:22:22.620 --> 1:22:26.460
 And the question is like, why the starting condition?

1:22:26.460 --> 1:22:30.940
 Like how the starting condition has to get kind of,

1:22:30.940 --> 1:22:32.660
 there's this has to be fine tuned

1:22:32.660 --> 1:22:35.980
 and all these things about it have to be kind of perfect.

1:22:35.980 --> 1:22:40.020
 And so we were thinking, well, look, what if we could push

1:22:40.020 --> 1:22:42.220
 the storytelling about where the universe comes from

1:22:42.220 --> 1:22:45.460
 much further back by starting with really simple things

1:22:45.460 --> 1:22:47.460
 that evolve and then through that evolution,

1:22:47.460 --> 1:22:48.580
 explain how things got to be,

1:22:48.580 --> 1:22:51.420
 how they are through very simple principles, right?

1:22:51.420 --> 1:22:55.260
 And so we've been exploring a variety of ways

1:22:55.260 --> 1:22:57.820
 to push the start of the storytelling

1:22:57.820 --> 1:23:02.540
 further and further back, which, and it's an interesting,

1:23:02.540 --> 1:23:03.780
 it's really kind of interesting

1:23:03.780 --> 1:23:07.100
 because like for all of his,

1:23:07.100 --> 1:23:09.740
 Lee is sometimes considered to be,

1:23:11.580 --> 1:23:13.940
 to have a radical quality in the physics world.

1:23:13.940 --> 1:23:18.380
 But he still is like, no, this is gonna be like

1:23:18.380 --> 1:23:19.980
 the kind of time we're talking about

1:23:19.980 --> 1:23:22.540
 and which evolution happens is the same time we're now

1:23:22.540 --> 1:23:25.900
 and we're talking about something that starts and continues.

1:23:25.900 --> 1:23:28.500
 And I'm like, well, what if there's some other kind of time

1:23:28.500 --> 1:23:31.220
 that's time like and sounds like metaphysics,

1:23:31.220 --> 1:23:34.740
 but there's an ambiguity, you know, like,

1:23:34.740 --> 1:23:38.100
 it has to start from something and it's kind of interesting.

1:23:38.100 --> 1:23:42.620
 So there's this, a lot of the math can be thought of either way,

1:23:42.620 --> 1:23:44.180
 which is kind of interesting.

1:23:44.180 --> 1:23:46.700
 So pushes so far back that basically all the things

1:23:46.700 --> 1:23:48.820
 we take for granted in physics start becoming

1:23:48.820 --> 1:23:51.180
 and emergent, it's emergent.

1:23:51.180 --> 1:23:53.580
 I really want to emphasize this is all super baby steps.

1:23:53.580 --> 1:23:54.580
 I don't want to over claim.

1:23:54.580 --> 1:23:57.580
 It's like, I think a lot of the things we're doing,

1:23:57.580 --> 1:23:59.180
 we're approaching some old problems

1:23:59.180 --> 1:24:02.380
 in a pretty fresh way informed.

1:24:02.380 --> 1:24:04.940
 There's been a zillion papers about how you can think of

1:24:04.940 --> 1:24:06.340
 the universe as a big neural net

1:24:06.340 --> 1:24:09.260
 or how you can think of different ideas in physics

1:24:09.260 --> 1:24:12.420
 as being quite similar to or even equivalent to

1:24:12.420 --> 1:24:14.420
 some of the ideas in machine learning.

1:24:14.420 --> 1:24:18.820
 And that actually works out crazy well.

1:24:18.820 --> 1:24:21.140
 Like, I mean, that is actually kind of eerie

1:24:21.140 --> 1:24:24.580
 when you look at it, like there's probably

1:24:24.580 --> 1:24:26.940
 two or three dozen papers that have this quality

1:24:26.940 --> 1:24:28.620
 and some of them are just crazy good

1:24:28.620 --> 1:24:30.700
 and it's very interesting.

1:24:30.700 --> 1:24:34.140
 What we're trying to do is take those kinds of observations

1:24:34.140 --> 1:24:35.940
 and turn them into an actionable framework

1:24:35.940 --> 1:24:38.860
 where you can then start to do things

1:24:38.860 --> 1:24:40.660
 with landscapes of theories that you couldn't do before

1:24:40.660 --> 1:24:42.580
 and that sort of thing.

1:24:42.580 --> 1:24:46.220
 So in that context, or maybe beyond,

1:24:46.220 --> 1:24:48.060
 how do you explain us humans?

1:24:48.060 --> 1:24:51.100
 How unlikely are we, this intelligent civilization?

1:24:51.100 --> 1:24:53.340
 Or is there a lot of others

1:24:53.340 --> 1:24:55.220
 or are we alone in this universe?

1:24:57.380 --> 1:24:58.220
 Yeah.

1:25:00.020 --> 1:25:02.020
 You seem to appreciate humans very much.

1:25:03.460 --> 1:25:04.940
 I've grown fond of us.

1:25:04.940 --> 1:25:06.780
 We're okay.

1:25:06.780 --> 1:25:10.980
 We have our nice qualities.

1:25:13.100 --> 1:25:14.700
 I like that.

1:25:14.700 --> 1:25:16.380
 I mean, we're kind of weird.

1:25:16.380 --> 1:25:18.300
 We spread this here on our heads and then we're,

1:25:18.300 --> 1:25:20.380
 I don't know, we're sort of weird animal.

1:25:20.380 --> 1:25:23.900
 That's the feature, not a bug, I think, the weirdness.

1:25:23.900 --> 1:25:24.740
 I hope so.

1:25:30.740 --> 1:25:33.700
 I think if I'm just gonna answer you

1:25:33.700 --> 1:25:36.980
 in terms of truth, the first thing I'd say

1:25:36.980 --> 1:25:40.860
 is we're not in a privileged enough position,

1:25:40.860 --> 1:25:43.380
 at least as yet, to really know much

1:25:43.380 --> 1:25:46.660
 about who we are, how we are,

1:25:47.580 --> 1:25:50.260
 what we're really like in the context of something larger,

1:25:50.260 --> 1:25:52.700
 what that context is, like all that stuff,

1:25:52.700 --> 1:25:54.020
 we might learn more in the future,

1:25:54.020 --> 1:25:55.220
 our descendants might learn more,

1:25:55.220 --> 1:25:57.540
 but we don't really know very much.

1:25:57.540 --> 1:26:00.620
 Which you can either view as frustrating or charming

1:26:00.620 --> 1:26:04.540
 like that first year of TikTok or something.

1:26:04.540 --> 1:26:06.140
 All roads lead back to TikTok.

1:26:06.140 --> 1:26:06.980
 I like it.

1:26:06.980 --> 1:26:09.500
 Well, lately, but in terms of,

1:26:09.500 --> 1:26:13.020
 there's another level at which I can think about it where

1:26:16.140 --> 1:26:21.140
 I sometimes think that if you are just quiet

1:26:22.020 --> 1:26:23.980
 and you do something that gets you in touch

1:26:23.980 --> 1:26:25.860
 with the way reality happens,

1:26:25.860 --> 1:26:28.180
 and for me, it's playing music,

1:26:28.180 --> 1:26:31.500
 sometimes it seems like you can feel a bit

1:26:31.500 --> 1:26:32.940
 of how the universe is,

1:26:32.940 --> 1:26:36.140
 and it feels like there's a lot more going on in it,

1:26:36.140 --> 1:26:37.540
 and there is a lot more life

1:26:37.540 --> 1:26:39.620
 and a lot more stuff happening

1:26:39.620 --> 1:26:41.460
 and a lot more stuff flowing through it.

1:26:41.460 --> 1:26:42.980
 I'm not speaking as a scientist now,

1:26:42.980 --> 1:26:46.220
 this is kind of a more, my artists side talking,

1:26:46.220 --> 1:26:49.420
 and it's, I feel like I'm suddenly

1:26:49.420 --> 1:26:51.420
 in multiple personalities with you, but.

1:26:51.420 --> 1:26:55.260
 Well, Kerouac, Jack Kerouac said that music

1:26:55.260 --> 1:26:56.580
 is the only truth.

1:26:56.580 --> 1:27:01.500
 What do you, it sounds like you might be, at least in part.

1:27:01.500 --> 1:27:05.580
 There's a passage in Kerouac's book, Dr. Sacks,

1:27:05.580 --> 1:27:08.020
 where somebody tries to just explain the whole situation

1:27:08.020 --> 1:27:10.140
 with reality and people in like a paragraph,

1:27:10.140 --> 1:27:11.980
 and I couldn't reproduce it for you here,

1:27:11.980 --> 1:27:15.020
 but it's like, yeah, like there are these boldest things

1:27:15.020 --> 1:27:16.500
 that walk around and they make these sounds,

1:27:16.500 --> 1:27:17.700
 you can sort of understand them,

1:27:17.700 --> 1:27:19.300
 but only kind of, and then there's like this,

1:27:19.300 --> 1:27:22.020
 and it's just like this amazing, like just really quick,

1:27:22.020 --> 1:27:25.020
 like if some spirit being or something

1:27:25.020 --> 1:27:26.460
 was gonna show up in our reality

1:27:26.460 --> 1:27:27.580
 and hadn't you nothing about it,

1:27:27.580 --> 1:27:29.540
 it's like a little basic intro of like,

1:27:29.540 --> 1:27:31.300
 okay, here's what's going on here,

1:27:31.300 --> 1:27:32.660
 an incredible passage.

1:27:32.660 --> 1:27:33.940
 Yeah, yeah.

1:27:33.940 --> 1:27:36.620
 It's like a one or two sentence summary

1:27:36.620 --> 1:27:38.820
 in H. Heiko's Guide to the Galaxy, right?

1:27:38.820 --> 1:27:40.340
 Of what this.

1:27:40.340 --> 1:27:41.380
 Mostly harmless.

1:27:41.380 --> 1:27:43.060
 Mostly harmless.

1:27:43.060 --> 1:27:43.900
 Yeah.

1:27:43.900 --> 1:27:44.740
 But do you think there's truth to that,

1:27:44.740 --> 1:27:47.100
 that music somehow connects to something

1:27:47.100 --> 1:27:48.980
 that words cannot?

1:27:48.980 --> 1:27:52.780
 Yeah, music is something that just towers above me.

1:27:52.780 --> 1:27:54.900
 I don't, I don't,

1:27:54.900 --> 1:27:57.860
 I don't feel like I have an overview of it.

1:27:57.860 --> 1:27:58.820
 It's just the reverse.

1:27:58.820 --> 1:28:00.740
 I don't, I don't fully understand it

1:28:00.740 --> 1:28:02.260
 because on one level it's simple.

1:28:02.260 --> 1:28:03.660
 Like you can say, oh, it's,

1:28:03.660 --> 1:28:07.580
 it's a thing people evolved to coordinate our brains

1:28:07.580 --> 1:28:11.940
 on a pattern level or a, or something like that.

1:28:11.940 --> 1:28:13.820
 There's all these things you can say about music,

1:28:13.820 --> 1:28:16.900
 which are, you know, some of that's probably true.

1:28:16.900 --> 1:28:21.900
 It's also, there's kind of like this,

1:28:21.900 --> 1:28:26.140
 this is the mystery of meaning.

1:28:26.140 --> 1:28:29.820
 Like there's a way that just instead

1:28:29.820 --> 1:28:31.300
 of just being pure abstraction,

1:28:31.300 --> 1:28:33.180
 music can have like this kind of

1:28:33.180 --> 1:28:38.020
 substantiality to it that is philosophically impossible.

1:28:39.940 --> 1:28:41.180
 I don't know what to do with it.

1:28:41.180 --> 1:28:42.020
 Yeah.

1:28:42.020 --> 1:28:44.060
 The amount of understanding I feel I have

1:28:44.060 --> 1:28:48.220
 when I hear the right song at the right time

1:28:48.220 --> 1:28:51.620
 is not comparable to anything I can read

1:28:51.620 --> 1:28:52.580
 on Wikipedia.

1:28:53.660 --> 1:28:56.940
 Anything I can understand, read through in language.

1:28:56.940 --> 1:28:59.700
 There's, the music does connect us to something.

1:28:59.700 --> 1:29:00.820
 There's this thing there.

1:29:00.820 --> 1:29:03.140
 Yeah, there's, there's,

1:29:03.140 --> 1:29:04.980
 there's some kind of a thing in it.

1:29:04.980 --> 1:29:06.980
 And I've never ever,

1:29:06.980 --> 1:29:09.860
 I've read across a lot of explanations

1:29:09.860 --> 1:29:12.220
 from all kinds of interesting people,

1:29:12.220 --> 1:29:16.500
 like that it's some kind of a flow language

1:29:16.500 --> 1:29:18.980
 between people or between people and how they perceive

1:29:18.980 --> 1:29:19.940
 and that kind of thing.

1:29:19.940 --> 1:29:24.060
 There's, and that sort of explanation is fine,

1:29:24.060 --> 1:29:26.540
 but it's not, it's not quite it either.

1:29:26.540 --> 1:29:27.380
 Yeah.

1:29:27.380 --> 1:29:29.580
 There's a, there's something about music

1:29:29.580 --> 1:29:34.100
 that makes me believe that panpsychism could possibly be true,

1:29:34.100 --> 1:29:36.820
 which is that everything in the universe is conscious.

1:29:36.820 --> 1:29:37.780
 It makes me think,

1:29:39.620 --> 1:29:44.020
 makes me be humble in how much or how little

1:29:44.020 --> 1:29:48.340
 I understand about the functions of our universe

1:29:48.340 --> 1:29:50.580
 that everything might be conscious.

1:29:50.580 --> 1:29:54.220
 Most people interested in theoretical physics

1:29:54.220 --> 1:29:56.540
 eventually land in panpsychism,

1:29:57.980 --> 1:30:00.180
 but I, I'm not one of them.

1:30:00.180 --> 1:30:05.180
 I, I still think there's this pragmatic imperative

1:30:06.020 --> 1:30:09.180
 to treat people as special.

1:30:09.180 --> 1:30:11.820
 So I will proudly be a dualist.

1:30:12.820 --> 1:30:14.300
 Without people and cats.

1:30:14.300 --> 1:30:15.140
 People and cats.

1:30:15.140 --> 1:30:19.300
 I'm not, I'm not, I'm not quite sure where to draw the line

1:30:19.300 --> 1:30:21.340
 or why the lines there or anything like that,

1:30:21.340 --> 1:30:23.660
 but I don't think I should be required to all the same

1:30:23.660 --> 1:30:26.020
 questions or equally mysterious for no line.

1:30:26.020 --> 1:30:28.620
 So I don't, I'm not, I don't feel disadvantaged by that.

1:30:28.620 --> 1:30:30.500
 So I shall remain a dualist,

1:30:30.500 --> 1:30:35.500
 but if you listen to anyone trying to explain

1:30:36.140 --> 1:30:38.660
 where consciousness is in a dualistic sense,

1:30:38.660 --> 1:30:41.220
 either believing in souls or some special thing

1:30:41.220 --> 1:30:42.420
 in the brain or something,

1:30:42.420 --> 1:30:44.300
 you pretty much say, screw this,

1:30:44.300 --> 1:30:45.660
 I'm going to be panpsychist.

1:30:45.660 --> 1:30:46.500
 Hahaha.

1:30:51.500 --> 1:30:52.340
 Fair enough.

1:30:52.340 --> 1:30:53.460
 Well put.

1:30:53.460 --> 1:30:55.940
 Is there moments in your life that happened

1:30:55.940 --> 1:30:59.980
 that were defining in the way that you hope others,

1:30:59.980 --> 1:31:01.340
 your daughters might have thought about it?

1:31:01.340 --> 1:31:02.620
 Well, listen, I gotta say,

1:31:02.620 --> 1:31:06.340
 the moments that defined me were not the good ones.

1:31:06.340 --> 1:31:09.620
 The moments that defined me were often horrible.

1:31:09.620 --> 1:31:14.620
 I've had successes, you know,

1:31:14.900 --> 1:31:17.900
 but if you ask what defined me,

1:31:17.900 --> 1:31:22.900
 my mother's death being under the World Trade Center

1:31:24.700 --> 1:31:29.700
 and the attack, the things that have had an effect on me

1:31:30.780 --> 1:31:35.260
 were the most were sort of real world terrible things,

1:31:35.260 --> 1:31:37.580
 which I don't wish on young people at all.

1:31:37.580 --> 1:31:41.220
 And this is the thing that's hard

1:31:41.220 --> 1:31:42.820
 about giving advice to young people

1:31:42.820 --> 1:31:47.820
 that they have to learn their own lessons

1:31:48.420 --> 1:31:53.020
 and lessons don't come easily.

1:31:53.020 --> 1:31:56.380
 And a world which avoids hard lessons

1:31:56.380 --> 1:31:58.380
 is will be a stupid world, you know,

1:31:58.380 --> 1:32:00.180
 and I don't know what to do with it.

1:32:00.180 --> 1:32:03.060
 That's a little bundle of truth

1:32:03.060 --> 1:32:05.220
 that has a bit of a fatalistic quality to it,

1:32:05.220 --> 1:32:07.940
 but I don't, this is like what I was saying

1:32:07.940 --> 1:32:09.940
 that, you know, freedom equals eternal annoyance.

1:32:09.940 --> 1:32:14.660
 Like you can't, like, there's a degree

1:32:14.660 --> 1:32:19.660
 to which honest advice is not that pleasant to give.

1:32:20.460 --> 1:32:24.300
 And I don't want young people to have to know

1:32:24.300 --> 1:32:25.740
 about everything.

1:32:25.740 --> 1:32:26.580
 I think I think...

1:32:26.580 --> 1:32:28.020
 You don't wanna wish hardship on them.

1:32:28.020 --> 1:32:30.620
 Yeah, I think they deserve to have

1:32:31.940 --> 1:32:34.780
 a little grace period of naivety that's pleasant.

1:32:34.780 --> 1:32:37.660
 I mean, I do, you know, if it's possible,

1:32:37.660 --> 1:32:38.500
 if it's...

1:32:40.180 --> 1:32:42.540
 These things are, this is like, this is tricky stuff.

1:32:42.540 --> 1:32:45.540
 I mean, if you...

1:32:48.180 --> 1:32:51.020
 Okay, so let me try a little bit on this advice thing.

1:32:51.020 --> 1:32:55.660
 I think one thing, any serious broad advice

1:32:55.660 --> 1:32:58.340
 will have been given 1,000 times before for 1,000 years.

1:32:58.340 --> 1:33:03.020
 So I'm not gonna, I'm not going to claim originality,

1:33:03.020 --> 1:33:06.420
 but I think trying to find a way

1:33:07.980 --> 1:33:12.980
 to really pay attention to what you're feeling fundamentally,

1:33:13.220 --> 1:33:14.740
 what your sense of the world is,

1:33:14.740 --> 1:33:17.820
 what your intuition is, if you feel like an intuitive person,

1:33:17.820 --> 1:33:18.660
 what you're...

1:33:22.620 --> 1:33:26.700
 Like to try to escape the constant sway

1:33:26.700 --> 1:33:30.220
 of social perception or manipulation, whatever you wish,

1:33:30.220 --> 1:33:32.180
 not to escape it entirely, that would be horrible,

1:33:32.180 --> 1:33:37.180
 but to find, to find cover from it once in a while,

1:33:37.420 --> 1:33:41.100
 to find a sense of being anchored in that,

1:33:41.100 --> 1:33:44.140
 to believe in experience as a real thing.

1:33:44.140 --> 1:33:47.220
 Believing in experience as a real thing is very dualistic.

1:33:47.220 --> 1:33:50.820
 That goes with my philosophy of dualism.

1:33:50.820 --> 1:33:52.660
 I believe there's something magical,

1:33:52.660 --> 1:33:55.980
 and instead of squirting the magic dust on the programs,

1:33:55.980 --> 1:33:58.260
 I think experience is something real

1:33:58.260 --> 1:34:00.420
 and something apart and something mystical and something...

1:34:00.420 --> 1:34:04.740
 Your own personal experience that you just have,

1:34:04.740 --> 1:34:06.140
 and then you're saying,

1:34:06.140 --> 1:34:08.260
 silence the rest of the world enough to hear that,

1:34:08.260 --> 1:34:11.340
 like whatever that magic dust is from that experience.

1:34:11.340 --> 1:34:13.540
 Find what is there.

1:34:13.540 --> 1:34:18.140
 And I think that's one thing.

1:34:18.140 --> 1:34:23.140
 Another thing is to recognize that kindness requires genius,

1:34:24.900 --> 1:34:27.180
 that it's actually really hard,

1:34:27.180 --> 1:34:30.020
 that facile kindness is not kindness,

1:34:30.020 --> 1:34:33.500
 and that it'll take you a while to have the skills

1:34:33.500 --> 1:34:35.620
 to have kind impulses to want to be kind

1:34:35.620 --> 1:34:37.540
 you can have right away.

1:34:37.540 --> 1:34:40.100
 To be effectively kind is hard.

1:34:40.100 --> 1:34:41.860
 To be effectively kind, yeah.

1:34:41.860 --> 1:34:46.260
 It takes skill, it takes hard lessons.

1:34:50.980 --> 1:34:52.780
 You'll never be perfect at it.

1:34:53.860 --> 1:34:55.540
 To the degree you get anywhere with it,

1:34:55.540 --> 1:35:00.340
 it's the most rewarding thing ever.

1:35:00.340 --> 1:35:04.980
 Let's see, what else would I say?

1:35:04.980 --> 1:35:07.700
 I would say when you're young,

1:35:07.700 --> 1:35:12.500
 you can be very overwhelmed

1:35:12.500 --> 1:35:16.660
 by social and interpersonal emotions.

1:35:16.660 --> 1:35:20.580
 You'll have broken hearts and jealousies.

1:35:20.580 --> 1:35:24.020
 You'll feel socially down the ladder

1:35:24.020 --> 1:35:25.780
 instead of up the ladder.

1:35:25.780 --> 1:35:27.860
 It feels horrible when that happens.

1:35:27.860 --> 1:35:29.300
 All of these things.

1:35:29.300 --> 1:35:33.780
 And you have to remember what a fragile crust

1:35:33.780 --> 1:35:35.380
 all that stuff is.

1:35:35.380 --> 1:35:37.460
 And it's hard because right when it's happening,

1:35:37.460 --> 1:35:38.660
 it's just so intense.

1:35:43.060 --> 1:35:48.260
 And if I was actually giving this advice to my daughter,

1:35:48.260 --> 1:35:49.460
 she'd already be out of the room.

1:35:49.460 --> 1:35:55.620
 So this is for some hypothetical teenager

1:35:55.620 --> 1:35:56.500
 that doesn't really exist,

1:35:56.500 --> 1:35:59.220
 that really wants to sit and listen to my wisdom.

1:35:59.220 --> 1:36:00.820
 Or for your daughter 10 years from now.

1:36:01.780 --> 1:36:02.100
 Maybe.

1:36:03.140 --> 1:36:06.500
 Can I ask you a difficult question?

1:36:06.500 --> 1:36:07.380
 Yeah, sure.

1:36:07.380 --> 1:36:10.660
 You talked about losing your mom.

1:36:10.660 --> 1:36:10.900
 Yeah.

1:36:11.860 --> 1:36:13.540
 Do you miss her?

1:36:14.980 --> 1:36:17.620
 Yeah, I mean, I still connected her through music.

1:36:17.620 --> 1:36:24.820
 She was a young prodigy piano player in Vienna.

1:36:24.820 --> 1:36:27.860
 And she survived the concentration camp

1:36:27.860 --> 1:36:32.180
 and then died in a car accident here in the US.

1:36:33.620 --> 1:36:35.540
 What music makes you think of her?

1:36:35.540 --> 1:36:38.100
 Is there a song that connects you?

1:36:38.100 --> 1:36:40.580
 Well, you know, she was in Vienna.

1:36:40.580 --> 1:36:48.340
 So she had the whole Viennese music thing going,

1:36:48.340 --> 1:36:54.580
 which is this incredible school of absolute skill

1:36:54.580 --> 1:36:56.180
 and romance bundled together.

1:36:56.180 --> 1:36:58.740
 And wonderful on the piano, especially.

1:36:58.740 --> 1:37:01.780
 I learned to play some of the Beethoven sonatas for her.

1:37:01.780 --> 1:37:04.500
 And I played them in this exaggerated, drippy way.

1:37:04.500 --> 1:37:05.940
 I remember when I was a kid.

1:37:05.940 --> 1:37:09.460
 And exaggerated, meaning too full of emotion?

1:37:09.460 --> 1:37:13.060
 Yeah, it's not the only way to play Beethoven.

1:37:13.060 --> 1:37:14.820
 I mean, I didn't know there's any other way.

1:37:14.820 --> 1:37:16.180
 That's a reasonable question.

1:37:16.180 --> 1:37:18.820
 I mean, the fashion these days is to be slightly

1:37:18.820 --> 1:37:20.900
 Apollonian even with Beethoven.

1:37:20.900 --> 1:37:24.740
 But one imagines that actual Beethoven playing

1:37:24.740 --> 1:37:25.860
 might have been different.

1:37:25.860 --> 1:37:26.340
 I don't know.

1:37:28.420 --> 1:37:30.740
 I've gotten to play a few instruments he played

1:37:30.740 --> 1:37:32.260
 and try to see if I could feel anything

1:37:32.260 --> 1:37:33.540
 about how it might have been for him.

1:37:33.540 --> 1:37:34.420
 I don't know, really.

1:37:34.980 --> 1:37:37.460
 I was always against the clinical precision

1:37:37.460 --> 1:37:38.420
 of classical music.

1:37:38.420 --> 1:37:46.420
 I thought a great piano player should be in pain.

1:37:46.420 --> 1:37:55.540
 Emotionally, like, truly feel the music and make it messy.

1:37:55.540 --> 1:37:56.180
 Sure.

1:37:56.180 --> 1:38:00.420
 Maybe play classical music the way, I don't know, blues.

1:38:00.420 --> 1:38:01.940
 Pianist plays blues.

1:38:04.420 --> 1:38:06.740
 It seems like they actually got happier.

1:38:06.740 --> 1:38:08.980
 And I'm not sure if Beethoven got happier.

1:38:08.980 --> 1:38:12.500
 I think it's a different kind of concept

1:38:12.500 --> 1:38:14.020
 of the place of music.

1:38:16.020 --> 1:38:20.660
 I think the blues, the whole African American tradition

1:38:20.660 --> 1:38:24.500
 was initially surviving awful, awful circumstances.

1:38:24.500 --> 1:38:27.060
 You could say there were some of that in the concentration

1:38:27.060 --> 1:38:28.260
 camps and all that, too.

1:38:29.540 --> 1:38:33.540
 And it's not that Beethoven's circumstances were brilliant,

1:38:33.540 --> 1:38:38.820
 but he kind of also, I don't know, this is hard.

1:38:38.820 --> 1:38:41.460
 I mean, it would seem to be his misery

1:38:41.460 --> 1:38:44.820
 was somewhat self imposed, maybe, through, I don't know.

1:38:44.820 --> 1:38:45.940
 It's kind of interesting.

1:38:45.940 --> 1:38:48.420
 I've known some people who loathed Beethoven.

1:38:48.420 --> 1:38:51.700
 The late composer, Pauline Oliveiros,

1:38:51.700 --> 1:38:53.140
 this wonderful modernist composer,

1:38:53.140 --> 1:38:54.980
 I played in her band for a while.

1:38:54.980 --> 1:38:58.260
 And she was like, oh, Beethoven, that's the worst music ever.

1:38:58.260 --> 1:38:59.460
 It's all ego.

1:38:59.460 --> 1:39:04.020
 It completely, it turns information into,

1:39:04.020 --> 1:39:06.820
 I mean, it turns emotion into your enemy.

1:39:06.820 --> 1:39:11.220
 And it's ultimately all about your own self importance,

1:39:11.220 --> 1:39:13.540
 which has to be at the expense of others could,

1:39:13.540 --> 1:39:15.460
 but what else could it be?

1:39:15.460 --> 1:39:16.820
 And blah, blah, blah.

1:39:16.820 --> 1:39:19.220
 So she had, I shouldn't say, I don't mean it to be dismissive.

1:39:19.220 --> 1:39:21.860
 I'm just saying, like, her position on Beethoven

1:39:21.860 --> 1:39:24.820
 was very negative and very unimpressed,

1:39:24.820 --> 1:39:26.180
 which is really interesting for me.

1:39:26.180 --> 1:39:27.220
 The manner of the music.

1:39:27.220 --> 1:39:29.460
 I think, I don't know.

1:39:29.460 --> 1:39:30.980
 I mean, she's not here to speak for herself,

1:39:30.980 --> 1:39:33.780
 so it's a little hard for me to answer that question.

1:39:33.780 --> 1:39:35.780
 But it was interesting, because I'd always thought of Beethoven.

1:39:35.780 --> 1:39:37.780
 It's like, whoa, you know, this is like Beethoven.

1:39:37.780 --> 1:39:40.180
 It's like, really, the dude, you know?

1:39:40.180 --> 1:39:43.620
 And she's like, eh, you know, Beethoven, Schmidhoven,

1:39:43.620 --> 1:39:44.980
 you know, it's like not really happening.

1:39:44.980 --> 1:39:46.580
 Yeah, still, even though it's cliche,

1:39:46.580 --> 1:39:49.060
 I like playing personally just for myself,

1:39:49.060 --> 1:39:50.020
 Moonlight Sonata.

1:39:50.020 --> 1:39:52.180
 I mean, I just...

1:39:52.180 --> 1:39:53.620
 Moonlight's amazing.

1:39:53.620 --> 1:40:00.180
 You know, you're talking about comparing the blues

1:40:00.180 --> 1:40:02.180
 in that sensibility from Europe.

1:40:02.180 --> 1:40:04.180
 It's so different in so many ways.

1:40:04.180 --> 1:40:07.220
 One of the musicians I play with is John Batiste,

1:40:07.220 --> 1:40:09.060
 who has the band on Colbert's show.

1:40:09.060 --> 1:40:11.380
 And he'll sit there playing jazz

1:40:11.380 --> 1:40:12.660
 and suddenly go into Moonlight.

1:40:12.660 --> 1:40:13.620
 He loves Moonlight.

1:40:13.620 --> 1:40:19.620
 And what's kind of interesting is he's found a way

1:40:19.620 --> 1:40:20.660
 to do Beethoven.

1:40:20.660 --> 1:40:22.660
 And he, by the way, he can really do Beethoven.

1:40:22.660 --> 1:40:27.220
 Like, he went through Juilliard and one time he was at my house

1:40:27.220 --> 1:40:29.220
 and he's like, hey, do you have the book of Beethoven's Sonatas

1:40:29.220 --> 1:40:31.220
 to say, yeah, I want to find one I haven't played.

1:40:31.220 --> 1:40:33.220
 And then he sight read through the whole damn thing perfectly.

1:40:33.220 --> 1:40:35.780
 And I'm like, oh, God, I just can't get out of here.

1:40:35.780 --> 1:40:37.220
 I can't even deal with this.

1:40:37.220 --> 1:40:45.220
 But anyway, he has this way of, with the same persona

1:40:45.220 --> 1:40:48.660
 and the same philosophy, moving from the blues into Beethoven,

1:40:48.660 --> 1:40:50.820
 that's really, really fascinating to me.

1:40:50.820 --> 1:40:55.620
 It's like, I don't want to say he plays it as if it were jazz,

1:40:55.620 --> 1:40:56.980
 but he kind of does.

1:40:56.980 --> 1:40:59.620
 It's kind of really, and he talks,

1:40:59.620 --> 1:41:02.420
 while he was sight reading, he talks like Beethoven's talking to him.

1:41:02.420 --> 1:41:04.420
 Like, he's like, oh, yeah, here he's doing this.

1:41:04.420 --> 1:41:05.380
 I can't do John.

1:41:05.380 --> 1:41:08.420
 But it's like, it's really interesting.

1:41:08.420 --> 1:41:09.220
 Like, it's very different.

1:41:09.220 --> 1:41:11.860
 Like, for me, I was introduced to Beethoven

1:41:11.860 --> 1:41:14.020
 as like almost like this godlike figure.

1:41:14.020 --> 1:41:16.020
 And I presume Pauline was too.

1:41:16.020 --> 1:41:18.020
 That was really kind of a press for an art to deal with.

1:41:18.020 --> 1:41:19.380
 And for him, it's just like...

1:41:19.380 --> 1:41:21.220
 It's a conversation he's having.

1:41:21.220 --> 1:41:23.620
 He's playing James P. Johnson or something.

1:41:23.620 --> 1:41:25.940
 It's like another musician who did something and they're talking.

1:41:25.940 --> 1:41:27.780
 And it's very cool to be around.

1:41:27.780 --> 1:41:34.500
 It's very kind of freeing to see someone have that relationship.

1:41:34.500 --> 1:41:36.020
 I would love to hear him play Beethoven.

1:41:36.020 --> 1:41:37.700
 That sounds amazing.

1:41:37.700 --> 1:41:38.340
 He's great.

1:41:39.540 --> 1:41:46.660
 We talked about Ernest Becker and how much value he puts on our mortality

1:41:46.660 --> 1:41:49.620
 and our denial of our mortality.

1:41:49.620 --> 1:41:51.780
 Do you think about your mortality?

1:41:51.780 --> 1:41:53.460
 Do you think about your own death?

1:41:53.460 --> 1:41:56.100
 You know, what's funny is I used to not be able to,

1:41:56.100 --> 1:41:58.340
 but as you get older, you just know people who die

1:41:58.340 --> 1:42:00.820
 and there's all these things that just becomes familiar

1:42:00.820 --> 1:42:05.860
 and more of a more ordinary, which is what it is.

1:42:06.660 --> 1:42:08.580
 But are you afraid?

1:42:10.020 --> 1:42:11.860
 Sure, although less so.

1:42:11.860 --> 1:42:18.740
 And it's not like I didn't have some kind of insight or revelation to become less afraid.

1:42:18.740 --> 1:42:23.220
 I think I just, like I say, it's kind of familiarity.

1:42:23.220 --> 1:42:30.180
 It's just knowing people who've died and I really believe in the future.

1:42:30.180 --> 1:42:35.380
 I have this optimism that people or this whole thing of life on earth,

1:42:35.380 --> 1:42:37.780
 this whole thing we're part of, I don't know where to draw that circle,

1:42:37.780 --> 1:42:45.700
 but this thing is going somewhere and has some kind of value.

1:42:45.700 --> 1:42:49.700
 And you can't both believe in the future and want to live forever.

1:42:49.700 --> 1:42:50.900
 You have to make room for it.

1:42:50.900 --> 1:42:55.860
 You know, like you have to, that optimism has to also come with its own like humility.

1:42:55.860 --> 1:42:59.060
 You have to make yourself small to believe in the future.

1:42:59.060 --> 1:43:02.660
 And so it actually in a funny way comforts me.

1:43:04.180 --> 1:43:05.860
 Wow, that's so funny.

1:43:05.860 --> 1:43:08.180
 Wow, that's powerful.

1:43:10.580 --> 1:43:15.220
 And optimism requires you to kind of step down after time.

1:43:16.660 --> 1:43:20.580
 Yeah, I mean, that said, life seems kind of short, but you know, whatever.

1:43:21.620 --> 1:43:24.580
 Do you think there's, I've tried to find, I can't find the complaint department.

1:43:24.580 --> 1:43:26.820
 You know, I really want to, I want to bring this up,

1:43:26.820 --> 1:43:30.820
 but the customer service number never answers and like the email bounces one way.

1:43:31.860 --> 1:43:34.260
 Do you think there's meaning to it, to life?

1:43:34.260 --> 1:43:38.100
 Ah, well, see, meaning's a funny word.

1:43:38.100 --> 1:43:40.260
 Like we say all these things as if we know what they mean,

1:43:40.260 --> 1:43:42.980
 but meaning, we don't know what we mean when we say meaning.

1:43:42.980 --> 1:43:44.260
 Like we obviously do not.

1:43:44.260 --> 1:43:48.340
 And it's a funny little mystical thing.

1:43:48.340 --> 1:43:54.340
 I think it ultimately connects to that sense of experience that dualists tend to believe in.

1:43:56.100 --> 1:44:01.460
 Because there are why, like if you look up to the stars and you experience that awe inspiring,

1:44:01.460 --> 1:44:07.060
 like joy, whatever, when you look up to the stars, I don't know why.

1:44:07.060 --> 1:44:11.940
 For me, that kind of makes me feel joyful, maybe a little bit melancholy,

1:44:11.940 --> 1:44:13.940
 just some weird soup of feelings.

1:44:14.820 --> 1:44:19.380
 And ultimately the question is like, why are we here in this vast universe?

1:44:22.020 --> 1:44:23.140
 That question, why?

1:44:23.140 --> 1:44:30.580
 Have you been able in some way, maybe through music, answer it for yourself?

1:44:38.260 --> 1:44:42.980
 My impulse is to feel like it's not quite the right question to ask,

1:44:42.980 --> 1:44:48.020
 but I feel like going down that path is just too tedious for the moment.

1:44:48.020 --> 1:44:49.860
 And I don't want to do it, but.

1:44:49.860 --> 1:44:53.940
 The wrong question.

1:44:53.940 --> 1:44:57.780
 Well, just because, you know, I don't know what meaning is.

1:44:57.780 --> 1:45:00.660
 And I think I do know that sense of awe.

1:45:01.540 --> 1:45:05.620
 I grew up in southern New Mexico and the stars were so vivid.

1:45:08.580 --> 1:45:15.220
 I've had some weird misfortunes, but I've had some weird luck also.

1:45:15.220 --> 1:45:20.980
 One of our near neighbors was the head of optics research at White Sands.

1:45:20.980 --> 1:45:22.900
 And when he was young, he discovered Pluto.

1:45:22.900 --> 1:45:24.260
 His name was Clyde Tombow.

1:45:25.060 --> 1:45:28.820
 And he taught me how to make telescopes as grinding mirrors and stuff.

1:45:28.820 --> 1:45:31.380
 And my dad had also made telescopes when he was a kid.

1:45:31.380 --> 1:45:36.020
 But Clyde had, like, backyard telescopes that would put to shame a lot.

1:45:37.140 --> 1:45:39.860
 I mean, he really, he did his telescopes, you know?

1:45:39.860 --> 1:45:46.100
 And so I remember he'd let me go and play with them and just like looking at a globular cluster.

1:45:46.100 --> 1:45:47.620
 And you're seeing the actual photons.

1:45:47.620 --> 1:45:49.940
 And with a good telescope, it's really like this object.

1:45:49.940 --> 1:45:55.220
 Like, you can really tell this isn't coming through some intervening information structure.

1:45:55.220 --> 1:45:56.820
 This is like the actual photons.

1:45:56.820 --> 1:45:58.900
 And it's really a three dimensional object.

1:45:59.540 --> 1:46:02.580
 And you have even a feeling for the vastness of it.

1:46:02.580 --> 1:46:06.740
 And it's, I don't know.

1:46:06.740 --> 1:46:14.340
 So I definitely, I was very, very fortunate to have a connection to this guy that way when I was a kid.

1:46:15.220 --> 1:46:18.980
 To have had that experience, again, the emphasis on experience.

1:46:22.580 --> 1:46:23.460
 It's kind of funny.

1:46:23.460 --> 1:46:28.500
 Like, I feel like sometimes, like I've taken, when she was younger,

1:46:28.500 --> 1:46:31.780
 I took my daughter and her friends to the telescope.

1:46:31.780 --> 1:46:34.500
 There are a few around here that kids can go and use.

1:46:34.500 --> 1:46:37.140
 And they would like look at Jupiter's moons or something.

1:46:37.140 --> 1:46:38.980
 I think like Galilean moons.

1:46:38.980 --> 1:46:42.980
 And I don't know if they quite had that because it's like too,

1:46:45.140 --> 1:46:46.980
 it's been just too normalized.

1:46:46.980 --> 1:46:52.020
 And I think maybe when I was growing up, screens weren't that common yet.

1:46:52.020 --> 1:46:55.060
 And maybe it's like too confusable with the screen.

1:46:55.060 --> 1:46:55.540
 I don't know.

1:46:56.180 --> 1:47:01.060
 You know, somebody brought up in conversation to me somewhere.

1:47:01.060 --> 1:47:06.340
 I don't remember who, but they kind of posited this idea that if humans,

1:47:06.340 --> 1:47:11.140
 early humans weren't able to see the stars, like if earth atmosphere or such, there was cloudy,

1:47:12.020 --> 1:47:14.740
 that we would not develop human civilization.

1:47:14.740 --> 1:47:20.420
 There's something about being able to look up and see a vast universe is like,

1:47:20.420 --> 1:47:23.060
 that's fundamental to the development of human civilization.

1:47:23.620 --> 1:47:25.700
 I thought that was a curious kind of thought.

1:47:25.700 --> 1:47:33.060
 That reminds me of that old Isaac Asimov story where there's this planet where they finally get

1:47:33.060 --> 1:47:34.900
 to see what's in the sky once in a while.

1:47:34.900 --> 1:47:36.820
 And it turns out there in the middle of a globular cluster.

1:47:38.340 --> 1:47:39.620
 I forget what happens exactly.

1:47:39.620 --> 1:47:41.860
 God, that's from when I was the same age as a kid.

1:47:41.860 --> 1:47:42.820
 I don't really remember.

1:47:44.260 --> 1:47:46.020
 But yeah, I don't know.

1:47:47.300 --> 1:47:47.940
 It might be right.

1:47:47.940 --> 1:47:51.300
 I'm just thinking of all the civilizations that grew up under clouds.

1:47:51.300 --> 1:47:58.580
 I mean, the Vikings needed a special diffracting piece of Micah to navigate

1:47:58.580 --> 1:47:59.940
 because they could never see the sun.

1:47:59.940 --> 1:48:02.740
 They had this thing called a sunstone that they found from this one cave.

1:48:02.740 --> 1:48:03.380
 Do you know about that?

1:48:03.940 --> 1:48:11.620
 So they were trying to navigate boats in the North Atlantic without being able to see the sun

1:48:11.620 --> 1:48:12.420
 because it was cloudy.

1:48:12.420 --> 1:48:21.940
 And so they used a chunk of Micah to diffract it in order to be able to align where the sun

1:48:21.940 --> 1:48:24.580
 really was because they couldn't tell by eye and navigate.

1:48:24.580 --> 1:48:27.620
 So I'm just saying there are a lot of civilizations that are pretty impressive

1:48:27.620 --> 1:48:29.540
 that had to deal with a lot of clouds.

1:48:31.540 --> 1:48:36.020
 The Amazonians invented our agriculture and they were probably under clouds a lot.

1:48:36.020 --> 1:48:36.500
 I don't know.

1:48:36.500 --> 1:48:37.300
 I don't know.

1:48:37.300 --> 1:48:46.020
 To me personally, the question of the meaning of life becomes most vibrant, most apparent

1:48:46.020 --> 1:48:50.420
 when you look up at the stars because it makes me feel very small.

1:48:52.100 --> 1:48:53.060
 We are small.

1:48:54.580 --> 1:48:58.580
 But then you ask, it still feels that we're special.

1:48:59.380 --> 1:49:04.420
 And then the natural question is like, well, if we are special as I think we are,

1:49:04.420 --> 1:49:07.860
 why the heck are we here in this vast universe?

1:49:09.220 --> 1:49:13.540
 That ultimately is the question of the meaning of life.

1:49:13.540 --> 1:49:24.420
 I mean, look, there's a confusion sometimes in trying to use, to set up a question or a

1:49:24.420 --> 1:49:30.180
 thought experiment or something that's defined in terms of a context to explain something

1:49:30.180 --> 1:49:31.860
 where there is no larger context.

1:49:31.860 --> 1:49:34.580
 And that's a category error.

1:49:34.580 --> 1:49:42.180
 If we want to do it in physics or in computer science, it's hard to talk about the universe

1:49:42.180 --> 1:49:46.980
 as a Turing machine because a Turing machine has an external clock and an observer and

1:49:46.980 --> 1:49:48.100
 an input and output.

1:49:48.100 --> 1:49:51.460
 There's a larger context implied in order for it to be defined at all.

1:49:51.460 --> 1:49:55.700
 And so if you're talking about the universe, you can't talk about it coherently as a Turing

1:49:55.700 --> 1:49:56.100
 machine.

1:49:56.100 --> 1:49:57.780
 Quantum mechanics is like that.

1:49:57.780 --> 1:50:02.500
 Quantum mechanics has an external clock and has some kind of external context,

1:50:02.500 --> 1:50:08.020
 depending on your interpretation, that's either the observer or whatever.

1:50:09.060 --> 1:50:11.220
 And they're similar that way.

1:50:11.220 --> 1:50:17.220
 So maybe Turing machines and quantum mechanics can be better friends or something because

1:50:17.220 --> 1:50:18.340
 they have a similar setup.

1:50:18.340 --> 1:50:22.820
 But the thing is, if you have something that's defined in terms of an outer context,

1:50:22.820 --> 1:50:28.100
 you can't talk about ultimates with it because obviously it's not suited for that.

1:50:28.100 --> 1:50:31.220
 So there's some ideas that are their own context.

1:50:31.220 --> 1:50:33.460
 General relativity is its own context.

1:50:33.460 --> 1:50:34.260
 It's different.

1:50:34.260 --> 1:50:35.460
 It's why it's hard to unify.

1:50:35.460 --> 1:50:42.820
 And I think the same thing is true when we talk about these types of questions.

1:50:42.820 --> 1:50:52.020
 Like meaning is in a context and to talk about ultimate meaning, is there a four category

1:50:52.020 --> 1:50:59.140
 or it's not a resolvable way of thinking?

1:50:59.140 --> 1:51:08.900
 It might be a way of thinking that is experientially or aesthetically valuable

1:51:08.900 --> 1:51:14.580
 because it is awesome in the sense of awe inspiring.

1:51:16.020 --> 1:51:19.460
 But to try to treat it analytically is not sensible.

1:51:19.460 --> 1:51:22.260
 Maybe that's what music and poetry are for.

1:51:22.260 --> 1:51:22.980
 Yeah, maybe.

1:51:22.980 --> 1:51:27.060
 I think music actually does escape any particular context.

1:51:27.060 --> 1:51:28.980
 That's how it feels to me, but I'm not sure about that.

1:51:28.980 --> 1:51:31.780
 That's once again, crazy artists talking, not scientists.

1:51:33.300 --> 1:51:36.420
 Well, you do both masterfully.

1:51:36.980 --> 1:51:40.980
 Jared, like I said, I'm a big fan of everything you've done, of you as a human being.

1:51:41.940 --> 1:51:48.500
 I appreciate the fun argument we had today that will, I'm sure, continue for 30 years.

1:51:48.500 --> 1:51:50.340
 As it did with Martin Minsky.

1:51:51.540 --> 1:51:55.540
 Honestly, I deeply appreciate that you spend your really valuable time with me today.

1:51:55.540 --> 1:51:56.740
 It was a really great conversation.

1:51:56.740 --> 1:51:57.380
 Thank you so much.

1:51:58.340 --> 1:52:01.060
 Thanks for listening to this conversation with Jared Lanier.

1:52:01.620 --> 1:52:05.300
 To support this podcast, please check out our sponsors in the description.

1:52:06.020 --> 1:52:09.620
 And now let me leave you with some words from Jared Lanier himself.

1:52:10.740 --> 1:52:16.420
 A real friendship ought to introduce each person to unexpected weirdness in the other.

1:52:16.420 --> 1:52:20.420
 Thank you for listening and hope to see you next time.

