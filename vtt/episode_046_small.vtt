WEBVTT

00:00.000 --> 00:03.600
 The following is a conversation with Gary Kasparov.

00:03.600 --> 00:07.700
 He's considered by many to be the greatest chess player of all time.

00:07.700 --> 00:13.400
 From 1986 until his retirement in 2005, he dominated the chess world,

00:13.400 --> 00:17.200
 ranking world number one for most of those 19 years.

00:17.200 --> 00:20.800
 While he has many historical matches against human chess players,

00:20.800 --> 00:26.500
 in the long arc of history, he may be remembered for his match against the machine,

00:26.500 --> 00:28.800
 IBM's Deep Blue.

00:28.800 --> 00:34.600
 His initial victories and eventual loss to Deep Blue captivated the imagination of the world,

00:34.600 --> 00:39.700
 of what role artificial intelligence systems may play in our civilization's future.

00:39.700 --> 00:43.800
 That excitement inspired an entire generation of AI researchers,

00:43.800 --> 00:47.200
 including myself, to get into the field.

00:47.200 --> 00:51.300
 Gary is also a pro democracy political thinker and leader,

00:51.300 --> 00:54.900
 a fearless human rights activist and author of several books,

00:54.900 --> 01:00.000
 including How Life Imitates Chess, which is a book on strategy and decision making.

01:00.000 --> 01:05.000
 Winter is Coming, which is a book articulating his opposition to the Putin regime,

01:05.000 --> 01:09.400
 and Deep Thinking, which is a book on the role of both artificial intelligence

01:09.400 --> 01:13.500
 and human intelligence in defining our future.

01:13.500 --> 01:16.500
 This is the Artificial Intelligence Podcast.

01:16.500 --> 01:21.000
 If you enjoy it, subscribe on YouTube, give it five stars on iTunes,

01:21.000 --> 01:24.300
 support it on Patreon, or simply connect with me on Twitter.

01:24.300 --> 01:28.100
 Alex Friedman spelled F R I D M A N.

01:28.100 --> 01:33.400
 And now here's my conversation with Gary Kasparov.

01:33.400 --> 01:35.900
 As perhaps the greatest chess player of all time,

01:35.900 --> 01:40.700
 when you look introspectively at your psychology throughout your career,

01:40.700 --> 01:46.900
 what was the bigger motivator, the love of winning or the hatred of losing?

01:46.900 --> 01:49.100
 Tough question.

01:49.100 --> 01:53.000
 I have to confess I never heard it before, which is again,

01:53.000 --> 01:58.700
 congratulations, it's quite an accomplishment.

01:58.700 --> 02:01.100
 Losing was always painful.

02:01.100 --> 02:09.600
 For me, it was almost like a physical pain because I knew that if I lost the game,

02:09.600 --> 02:12.700
 it's just because I made a mistake.

02:12.700 --> 02:20.900
 I always believed that the result of the game had to be decided by the quality of my play.

02:20.900 --> 02:26.500
 Okay, you may say it sounds arrogant, but it helped me to move forward

02:26.500 --> 02:31.000
 because I always knew that there was room for improvement.

02:31.000 --> 02:32.900
 Was there the fear of the mistake?

02:32.900 --> 02:36.600
 Actually, fear of mistake guarantees mistakes.

02:36.600 --> 02:40.800
 And the difference between top players at the very top is that

02:40.800 --> 02:46.300
 it's the ability to make a decision without predictable consequences.

02:46.300 --> 02:47.500
 You don't know what's happening.

02:47.500 --> 02:50.500
 It's just intuitively, I can go this way or that way.

02:50.500 --> 02:52.600
 And there are always hesitations.

02:52.600 --> 02:55.000
 People are like, you are just at the crossroad.

02:55.000 --> 02:57.200
 You can go right, you can go left, you can go straight.

02:57.200 --> 02:58.700
 You can turn and go back.

02:58.700 --> 03:03.100
 And the consequences are just very uncertain.

03:03.100 --> 03:07.500
 Yes, you have certain ideas what happens on the right or on the left

03:07.500 --> 03:13.400
 or just if you go straight, but it's not enough to make well calculated choice.

03:13.400 --> 03:18.700
 And when you play chess at the very top, it's about your inner strength.

03:18.700 --> 03:21.100
 So I can make this decision.

03:21.100 --> 03:24.900
 I will stand firm and I'm not going to waste my time

03:24.900 --> 03:29.600
 because I have full confidence that I will go through.

03:29.600 --> 03:34.300
 Going back to the original question is, I would say neither.

03:34.300 --> 03:39.000
 It's just it's the it's lawful winning, hateful losing.

03:39.000 --> 03:44.400
 There were important elements, psychological elements, but the key element,

03:44.400 --> 03:50.100
 it's the I would say the the driving force was always my passion

03:50.100 --> 03:53.300
 for for making a difference.

03:53.300 --> 03:59.100
 It's just I can move forward and I can always it's I can always enjoy

03:59.100 --> 04:03.100
 not just playing, but creating something new, creating something new.

04:03.100 --> 04:04.500
 How do you think about that?

04:04.500 --> 04:09.600
 It's just finding new ideas in the openings, you know, some original plan in the middle game.

04:09.600 --> 04:14.500
 It's actually that helped me to make a transition from the game of chess

04:14.500 --> 04:20.200
 where I was on the very top to to another life where I knew I would not be number one.

04:20.200 --> 04:25.600
 I would not be necessarily on the top, but I could still be very active

04:25.600 --> 04:32.000
 and productive by my ability to make a difference by influencing people,

04:32.000 --> 04:36.600
 say, joining the democratic movement in Russia or talking to people

04:36.600 --> 04:42.800
 about human machine relations, there's so many things where I knew my influence

04:42.800 --> 04:49.100
 may not be as decisive as in chess, but still strong enough to help people

04:49.100 --> 04:51.700
 to make their choices.

04:51.700 --> 04:57.200
 So you can still create something new that makes a difference in the world outside of chess.

04:57.200 --> 05:02.800
 But wait, you've kind of painted a beautiful picture of your motivations

05:02.800 --> 05:09.400
 of chess to create something new to look for those moments of some brilliant new ideas.

05:09.400 --> 05:11.100
 But were you haunted by something?

05:11.100 --> 05:15.200
 See, you make it seem like to be at the level you're at.

05:15.200 --> 05:21.800
 You can get away without having demons without without having fears

05:21.800 --> 05:26.900
 without being driven by some of the darker forces.

05:26.900 --> 05:32.900
 I mean, you sound almost religious, you know, darker forces, spiritual demons.

05:32.900 --> 05:36.400
 I mean, do you have a call for a priest?

05:36.400 --> 05:37.600
 So I'm dressed like this.

05:37.600 --> 05:42.500
 Now, just let's go back to these crucial chess moments

05:42.500 --> 05:44.600
 where I had to make big decisions.

05:44.600 --> 05:50.200
 As I said, it's, you know, it was all about my belief from very early days

05:50.200 --> 05:54.100
 that I can make all the difference by playing well or by making mistakes.

05:54.100 --> 06:00.300
 So the, yes, I always had an opponent across the chess board, opposite me.

06:00.300 --> 06:04.400
 But no matter how strong the opponent was, whether he just ordered a player

06:04.400 --> 06:08.600
 or another world champion like Anatoly Karpov,

06:08.600 --> 06:14.900
 I having all respect for my opponent, I still believe that it's up to me to make the difference.

06:14.900 --> 06:21.600
 And I, you know, I knew I was not invincible.

06:21.600 --> 06:22.600
 I made mistakes.

06:22.600 --> 06:28.300
 I made some blunders and, you know, with age, I made more blunders.

06:28.300 --> 06:29.800
 Okay, good.

06:29.800 --> 06:30.400
 I knew it.

06:30.400 --> 06:37.000
 But it's still, you know, it's very much for me to be the size of factor in the game.

06:37.000 --> 06:40.400
 I mean, even now, look, I just, you know, my latest chess experience was horrible.

06:40.400 --> 06:45.000
 I mean, I played Karoana, Fabi Karoana.

06:45.000 --> 06:47.900
 It's number two, number two, number three player in the world these days.

06:47.900 --> 06:53.000
 We play this 960 with the fish or so called fish or random chess reshuffling pieces.

06:53.000 --> 06:56.300
 Yeah, I lost very badly, but it's because I made mistakes.

06:56.300 --> 06:57.800
 I mean, I had so many winning positions.

06:57.800 --> 07:00.100
 I mean, 15 years ago, I would have crushed him.

07:00.100 --> 07:05.200
 So, and it's, you know, while I lost, I was not so much upset.

07:05.200 --> 07:09.500
 I mean, I know, as I said in my interview, I can fight any opponent,

07:09.500 --> 07:10.900
 but not my biological clock.

07:10.900 --> 07:16.700
 So it's fighting time is always a losing proposition.

07:16.700 --> 07:22.200
 But even today at age 56, you know, I knew that, you know, I could play great game.

07:22.200 --> 07:25.600
 I couldn't finish it because I didn't have enough energy or just, you know,

07:25.600 --> 07:27.700
 I couldn't have the same level of concentration.

07:27.700 --> 07:32.400
 But, you know, in a number of games where I completely outplayed one of the top less in the world,

07:32.400 --> 07:35.400
 I mean, gave me a certain amount of pleasure.

07:35.400 --> 07:38.500
 That is, even today, I haven't lost my touch.

07:38.500 --> 07:44.800
 Not the same, you know, okay, the jaws are not as strong and the teeth are not as sharp.

07:44.800 --> 07:49.100
 But I could get him just, you know, almost, you know, on the ropes.

07:49.100 --> 07:49.900
 Still got it.

07:49.900 --> 07:50.600
 Still got it.

07:50.600 --> 07:54.500
 And it's, you know, and it's, I mean, it's my wife said it well.

07:54.500 --> 07:59.700
 I mean, she said, look, Gary, it's somehow, it's something you're just fighting by your biological clock.

07:59.700 --> 08:03.700
 It's just, you know, maybe it's a signal because, you know, the goddess of chess,

08:03.700 --> 08:07.500
 since you spoke great or deep religious, the goddess of chess, Keisha,

08:07.500 --> 08:13.100
 maybe she didn't want you to win because, you know, if you could beat number two,

08:13.100 --> 08:17.900
 number three player in the world, I mean, that's, that's one of the top players who just recently played

08:17.900 --> 08:19.300
 World Championship match.

08:19.300 --> 08:23.000
 If you could beat him, that would be really bad for the game of chess.

08:23.000 --> 08:28.400
 But just what people will say, oh, look, the game of chess, you know, it's, it's, it's not making any progress.

08:28.400 --> 08:34.100
 The game is just, you know, it's, it's totally devalued because the, the guy coming out of retirement,

08:34.100 --> 08:37.800
 you know, just, you know, winning games, maybe that was good for chess, not good for you.

08:37.800 --> 08:41.500
 But it's, look, I've been following your logic.

08:41.500 --> 08:47.500
 We should always look for, you know, demons, you know, superior forces and other things that could, you know,

08:47.500 --> 08:55.600
 if not dominate our lives, but somehow, you know, play a significant role in, in, uh, the outcome.

08:55.600 --> 08:58.200
 Yeah. So the goddess of chess had to send a message.

08:58.200 --> 08:59.800
 Yeah. That's okay. Okay.

08:59.800 --> 09:04.000
 So Gary, you should do something else. Time.

09:04.000 --> 09:09.300
 Now for a question that you have heard before, but give me a chance.

09:09.300 --> 09:14.200
 You've dominated the chess world for 20 years and even still got it.

09:14.200 --> 09:17.500
 Is there a moment you said you always looked to create something new?

09:17.500 --> 09:27.200
 Is there, is there games or moments where you're especially proud of in terms of your brilliance of a new creative move?

09:27.200 --> 09:33.400
 You've talked about Mikhail Tall as somebody who was aggressive and creative chess player in your own game.

09:33.400 --> 09:42.200
 Look, you mentioned Mikhail Tall. It's very aggressive, very sharp player, famous for his combinations and sacrifices,

09:42.200 --> 09:44.100
 even called magician from Riga.

09:44.100 --> 09:53.100
 So for his very unique style, but any, any world champion, you know, it's, yeah, was a creator.

09:53.100 --> 09:57.600
 Some of them were so flamboyant and flash like tall.

09:57.600 --> 10:04.000
 Some of them were no, just, you know, less discerned at the chess board like the Grand Petrosian,

10:04.000 --> 10:09.000
 but every world champion, every top player brought something into the game of chess.

10:09.000 --> 10:13.700
 And each contribution was priceless because it's not just about sacrifices.

10:13.700 --> 10:18.800
 Of course, amateurs, they enjoy, you know, the brilliant games where pieces being sacrificed.

10:18.800 --> 10:25.500
 It's all just, you know, it's an old piece of hanging and, and it's all of a sudden, you know, being material down,

10:25.500 --> 10:36.200
 the rook down or just, you know, queen down, the, the, the weaker side delivers the final blow on just, you know, mating opponent's king.

10:36.200 --> 10:38.600
 But there's other kinds of beauty.

10:38.600 --> 10:51.100
 I mean, it's a slow positional maneuvering, you know, looking for weaknesses and just, and, and gradually strangling your opponent and eventually delivering sort of a positional masterpiece.

10:51.100 --> 10:58.800
 Yeah. So I think I, I made more difference in the game of chess than I could, I could have imagined when I started playing.

10:58.800 --> 11:14.800
 And the reason I thought it was time for me to leave is just, I mean, I knew that I was not, I was not no longer the position to bring, bring the same kind of contribution,

11:14.800 --> 11:18.300
 the same kind of new knowledge into the game.

11:18.300 --> 11:25.200
 So, and going back, I could immediately look at my games against Anatoly Karpov.

11:25.200 --> 11:31.100
 It's not just I won the match in 1985 and became a world champion at age 22.

11:31.100 --> 11:34.800
 But there were at least two games in that match.

11:34.800 --> 11:40.700
 Of course, the last one game 24, that was the size of game of the match I won and became world champion.

11:40.700 --> 11:52.300
 But also the way I won, it was, it was a very sharp game and I found a unique maneuver that was absolutely new and it became some sort of just a typical now.

11:52.300 --> 12:00.400
 Though this, when the move was made, was made on the board and put on display, a lot of people thought it was ugly.

12:00.400 --> 12:13.300
 And another game, game 16 in the match, where I just also managed to outplay Karpov completely with black pieces, just paralyzing his entire army in its own, its own camp.

12:13.300 --> 12:17.600
 Technically or psychologically, or is that a mix of both in game 16?

12:17.600 --> 12:20.000
 Yeah, I think it was a big blow to Karpov.

12:20.000 --> 12:22.900
 I think it was a big psychological victory for a number of reasons.

12:22.900 --> 12:30.800
 One, this core was equal at a time and the world champion by the rules could retain his title in case of a tie.

12:30.800 --> 12:35.200
 So we still have, you know, before game 16, we have nine games to go.

12:35.200 --> 12:42.900
 And also it was some sort of a bluff because neither me nor Karpov saw the refutation of this opening idea.

12:42.900 --> 12:48.900
 And I think it says for Karpov, it was double blow because not that he lost the game, I should triple blow.

12:48.900 --> 12:55.300
 He lost the game, it was a brilliant game and I played impeccably after, you know, just this opening bluff.

12:55.300 --> 12:57.500
 And then, you know, they discovered that it was a bluff.

12:57.500 --> 13:00.600
 So it's the, again, I didn't know, I was not bluffing.

13:00.600 --> 13:04.600
 So that's why it happens very often, you know, some ideas could be refuted.

13:04.600 --> 13:13.100
 And it's just, what I found out, and this is, again, going back to your, you know, spiritual theme is that you could spend a lot of time working.

13:13.100 --> 13:18.900
 When I say you could, it's in the 80s, in the 90s, it doesn't happen these days because everybody has a computer.

13:18.900 --> 13:21.500
 You could immediately see if it works or it doesn't work.

13:21.500 --> 13:24.600
 Machine shows your refutation in a split of a second.

13:24.600 --> 13:31.600
 But many of the analysis in the 80s or in the 90s, they were not perfect simply because we were humans

13:31.600 --> 13:40.800
 and they just, you analyze the game, you look for some fresh ideas and then just it happens that there was something that you missed.

13:40.800 --> 13:49.500
 Because the level of concentration at the chessboard is different from one that when you analyze the game, moving the pieces around.

13:49.500 --> 13:59.900
 But somehow, if you spend a lot of time at the chessboard preparing, so in your studies, with your coaches, hours and hours and hours,

13:59.900 --> 14:09.000
 and nothing of what you found could, you know, had materialized on the chessboard.

14:09.000 --> 14:14.200
 Somehow, these hours helped, I don't know why, always helped you.

14:14.200 --> 14:27.400
 It's as if, you know, the amount of work you did could be transformed into some sort of spiritual energy that helped you to come up with other great ideas during the board.

14:27.400 --> 14:33.900
 Again, even if it was, there was no direct connection between your preparation and your victory in the game,

14:33.900 --> 14:45.300
 there was always some sort of invisible connection between the amount of work you did, your dedication to actually to and your passion to discover new ideas

14:45.300 --> 14:49.300
 and your ability during the game at the chessboard when the clock was ticking.

14:49.300 --> 14:52.100
 We still had ticking clock, not digital clock at the time.

14:52.100 --> 14:59.800
 So to come up with some some some brilliance and and I also can mention many games from the 90s.

14:59.800 --> 15:07.800
 So it's the obviously all amateurs would pick up my game against Veselin Topolov in 1999 and Vykonzey again,

15:07.800 --> 15:09.700
 because it was a Berlin game.

15:09.700 --> 15:17.800
 The Black King traveled from from its own camp to into the into in the White's camp across the entire board.

15:17.800 --> 15:24.600
 It doesn't happen often, trust me, as you know, in the games with professional players, top professional players.

15:24.600 --> 15:28.400
 So that's why visually it was one of the most impressive victories.

15:28.400 --> 15:37.600
 But I could bring to to our attention many other games that were not so impressive for for amateurs,

15:37.600 --> 15:41.400
 not so not so beautiful.

15:41.400 --> 15:44.900
 Just guess it's sacrifice, always beautiful sacrifices.

15:44.900 --> 15:53.700
 And then and then eventually you have so very few resources left and you you you use them just to to to to crush your your opponent.

15:53.700 --> 16:01.200
 Basically to you have to make the king because you have almost almost nothing nothing nothing left at your disposal.

16:01.200 --> 16:07.800
 But I you know, I up to the very end get less and less but still up to the very end.

16:07.800 --> 16:14.800
 I always had games with some sort of, you know, interesting ideas and and games that gave me great satisfaction.

16:14.800 --> 16:24.600
 But I think it's what happened from 2005 up to these days was also a very very big accomplishment.

16:24.600 --> 16:28.600
 Since, you know, I had to find myself to sort of relocate myself.

16:28.600 --> 16:30.700
 Yeah, rechannel the creative energies.

16:30.700 --> 16:41.400
 Exactly. And to to find something where I feel comfortable, even confident that my participation still makes the difference.

16:41.400 --> 16:48.400
 Beautifully put, so let me ask perhaps a silly question, but sticking on chest for just a little longer.

16:48.400 --> 16:54.100
 Where do you put Magnus Carlson, the current world champion in the list of all time greats?

16:54.100 --> 16:57.800
 In terms of style, moments of brilliance, consistency.

16:57.800 --> 16:58.900
 It's a tricky question.

16:58.900 --> 17:01.600
 You know, the moment you start ranking.

17:01.600 --> 17:03.500
 Yeah, well, you lose something.

17:03.500 --> 17:15.100
 It's the I think it's it's it's not fair because it's the any new generation knows much more about the game than the previous one.

17:15.100 --> 17:19.600
 So when people say, oh, Gary was the greatest, Fisher was the greatest, Magnus the greatest.

17:19.600 --> 17:26.700
 It disregard the fact that the great place of the past, the last year, Capa Planca, Alocan.

17:26.700 --> 17:29.900
 I mean, they knew so little about chess by today's standards.

17:29.900 --> 17:38.200
 I mean, today, just any kid, you know, that spent a few years, you know, with his or her chess computer and knows much more about the games.

17:38.200 --> 17:40.900
 Simply just because you have access to this information.

17:40.900 --> 17:43.500
 And it has been discovered generation after generation.

17:43.500 --> 17:46.800
 We added more and more knowledge to the game of chess.

17:46.800 --> 17:51.700
 It's about the gap between the world champion and the rest of the field.

17:51.700 --> 17:59.800
 So it's the now if you look at the gap, then probably Fisher, you know, could be on top, but very short period of time.

17:59.800 --> 18:01.900
 Then you should also add a time factor.

18:01.900 --> 18:05.600
 I was on top, not as big as but much longer.

18:05.600 --> 18:11.600
 So so I know so unlike Fisher, I will succeed in beating next generation.

18:11.600 --> 18:12.900
 Here's the question.

18:12.900 --> 18:19.000
 Yeah, let's see if you still got the fire speaking to the next generation because you did succeed beating the next generation next.

18:19.000 --> 18:19.600
 It's close.

18:19.600 --> 18:24.400
 OK, and I'm short and and the sheer of crumbly because I'm already 12 years young.

18:24.400 --> 18:28.200
 So that's a neck that's but still get I I competed with them.

18:28.200 --> 18:34.200
 And I just beat most of them and I was still dominant when I left at age of 41.

18:34.200 --> 18:40.300
 So back to Magnus Magnus, I mean, consistency is phenomenal.

18:40.300 --> 18:46.700
 The reason Magnus is is on top and it seems unbeatable today.

18:46.700 --> 18:54.900
 Magnus is a lethal combination of Fisher and Karpov, which is very it's very unusual because Fisher style is very dynamic.

18:54.900 --> 18:59.200
 Just fighting to the last poem, just using every resource available.

18:59.200 --> 19:01.400
 Karpov was very different.

19:01.400 --> 19:11.600
 It's just yet an unparalleled ability to use the every piece with a maximum effect, just its minimal resources always produce maximum effect.

19:11.600 --> 19:15.200
 So now imagine that you merge these two styles.

19:15.200 --> 19:21.000
 So it's it's it's like, you know, it's squeezing every stone for drop of water.

19:21.000 --> 19:28.900
 But but doing it, you know, just, you know, for 50, 60, 70, 80 moves, I mean, Magnus could go on as long as Fisher was always passion and energy.

19:28.900 --> 19:36.800
 And at the same time being as meticulous and and and and deadly as Karpov by just, you know, using every little advantage.

19:36.800 --> 19:40.600
 So and he has good, you know, very good health.

19:40.600 --> 19:43.400
 It's important. I mean, physical conditions are, by the way, very important.

19:43.400 --> 19:44.800
 So a lot of people don't recognize it.

19:44.800 --> 19:51.000
 Their latest study shows that chess players burn thousands of calories during the game.

19:51.000 --> 19:56.000
 So that puts him on the top of this field of the world champions.

19:56.000 --> 20:06.600
 But again, it's it's the discussion that is I saw recently on Internet whether Gary Kasparov of his peak, let's say late 80s could be Magnus Carlson today.

20:06.600 --> 20:10.400
 I mean, certainly irrelevant because Gary Kasparov in 1989.

20:10.400 --> 20:18.900
 OK, it's played great chess, but still I knew very little about chess compared to Magnus Carlson 2019, who, by the way, learned from me as well.

20:18.900 --> 20:20.500
 So that's why. Yeah.

20:20.500 --> 20:26.600
 I'm extremely cautious in making any judgment that involves, you know, time gaps.

20:26.600 --> 20:28.800
 You ask, you know, soccer fans.

20:28.800 --> 20:32.000
 So who is your favorite, Pelle Maradona or Messi?

20:32.000 --> 20:34.000
 Yeah. Yeah. Who's your favorite?

20:34.000 --> 20:36.800
 Messi. Messi. Why?

20:36.800 --> 20:40.100
 Because maybe Maradona maybe not because he younger, but that's simple.

20:40.100 --> 20:44.500
 Your instinctive answer is correct because you saw you didn't say Maradona in action.

20:44.500 --> 20:45.900
 I saw all of them in action.

20:45.900 --> 20:53.700
 So that's why. But since, you know, when I was, you know, just following it, you know, just its Pelle and Maradona, they were just, you know, they were big stars.

20:53.700 --> 20:58.800
 And it's Messi's already just I was gradually losing interest in other things.

20:58.800 --> 21:02.200
 So I remember Pelle in 1970, the final match, Brazil Italy.

21:02.200 --> 21:05.800
 So that's the first World Cup soccer I watched.

21:05.800 --> 21:12.500
 So that's the and actually my answer when I just, when I just, you know, I, because I was asked this question as well.

21:12.500 --> 21:15.600
 So I say that is just why it's impossible to make a choice.

21:15.600 --> 21:18.400
 I would still probably go with Maradona for simple reason.

21:18.400 --> 21:21.900
 The Brazilian team in 1970 could have won without Pelle.

21:21.900 --> 21:23.200
 It was absolutely great.

21:23.200 --> 21:24.600
 Still could have won maybe.

21:24.600 --> 21:29.600
 But it is Argentinean team in 1986 without Maradona would not be unified.

21:29.600 --> 21:33.300
 So this is and Messi, he still hasn't won the title.

21:33.300 --> 21:39.900
 That's, that's could argue for that for an hour. But you could say if you ask Maradona, if you look in his eyes,

21:39.900 --> 21:48.000
 especially let's say Gary Kasparov in 1989, he would have said, I was sure as hell would beat Magnus Carlson.

21:48.000 --> 21:54.000
 Yeah, just simply because the confidence fire simply because simply because again, they saw me in action.

21:54.000 --> 21:56.800
 So this again, it's, it's the age factor is important.

21:56.800 --> 22:04.000
 Therefore, with the passion and energy and being equipped with all modern ideas, but again, then you make, you know,

22:04.000 --> 22:11.500
 a very just important assumption that you could empower Gary Kasparov for 89 with all ideas that have accumulated over 30 years.

22:11.500 --> 22:12.700
 That would not be Gary Kasparov.

22:12.700 --> 22:16.200
 That would be someone else because again, I belong to 1989.

22:16.200 --> 22:23.100
 I was way ahead of the field and I, you know, I beat Karpov several times in the World Championship matches

22:23.100 --> 22:31.400
 and I crossed 2800, which by the way, if you look at the in just in rating, which is just it's even today.

22:31.400 --> 22:33.600
 So this is this is the rating that I retire.

22:33.600 --> 22:37.000
 So this is it's still, you know, it's just it's a it's a top two, two, three.

22:37.000 --> 22:40.500
 So this is Karwan and Ding. It's about the same rating now.

22:40.500 --> 22:44.900
 And I crossed 2800 in 1990. We just look at the inflation.

22:44.900 --> 22:50.700
 When I crossed 2800 in 1990, there was only one player in 2700 category and not only Karpov.

22:50.700 --> 22:53.600
 Now we had more than 50. So just when you see this.

22:53.600 --> 23:04.200
 So if you add inflation, so I think my 2851, it could probably could be more valuable as Magnus 2882, which was his highest rating.

23:04.200 --> 23:07.100
 But anyway, again, too many hypotheticals.

23:07.100 --> 23:10.900
 You're lost to IBM D blue in 1997.

23:10.900 --> 23:15.000
 In my eyes, there's one of the most seminal moments in the history.

23:15.000 --> 23:20.500
 Again, I apologize for being romanticizing the notion, but in the history of our civilization

23:20.500 --> 23:27.200
 because humans as the civilizations for centuries saw chess as, you know,

23:27.200 --> 23:31.700
 the peak of what man can accomplish of intellectual mastery, right?

23:31.700 --> 23:40.200
 And that moment when a machine could beat a human being was inspiring to just an entire

23:40.200 --> 23:46.300
 anyone who cares about science, innovation, an entire generation of AI researchers.

23:46.300 --> 23:53.600
 And yet, to you, that loss, at least if reading your face was seemed like a tragedy, extremely painful.

23:53.600 --> 23:59.700
 Like you said, physically painful. Why? When you look back at your psychology of that loss,

23:59.700 --> 24:07.200
 why was it so painful when you're not able to see the seminal nature of that moment?

24:07.200 --> 24:11.100
 Or was that exactly why it was that painful?

24:11.100 --> 24:17.000
 As I already said, losing was painful, physically painful.

24:17.000 --> 24:22.000
 And the match I lost in 1997 was not the first match I lost to a machine.

24:22.000 --> 24:23.700
 It was the first match I lost, period.

24:23.700 --> 24:27.000
 Yeah, that's, yeah.

24:27.000 --> 24:29.200
 Oh, wow.

24:29.200 --> 24:30.400
 Oh, wow.

24:30.400 --> 24:32.300
 Yeah, it's right.

24:32.300 --> 24:35.900
 Yeah. That makes all the difference to me.

24:35.900 --> 24:36.500
 Yes.

24:36.500 --> 24:46.200
 The first time I lost, it's just now I lost and the reason I was so angry that I just, you know, I had suspicions

24:46.200 --> 24:49.300
 that my loss was not just the result of my bad play.

24:49.300 --> 24:49.800
 Yes.

24:49.800 --> 24:53.300
 So though I played quite poorly, you know, just when you started looking at the games today,

24:53.300 --> 24:55.000
 I made tons of mistakes.

24:55.000 --> 25:01.800
 But, you know, I had all reasons to believe that, you know, there were other other factors that had nothing to do with the game of chess.

25:01.800 --> 25:03.000
 And that's why I was angry.

25:03.000 --> 25:07.300
 But look, it was 22 years ago, it's more than the bridge.

25:07.300 --> 25:10.800
 We can analyze this match and this is with everything you said.

25:10.800 --> 25:20.300
 I agree with probably one exception is that considering chess, you know, as the sort of as a pinnacle of intellectual activities,

25:20.300 --> 25:25.800
 was our mistake because, you know, we just thought, oh, it's it's a game of the highest intellect.

25:25.800 --> 25:28.700
 And it just, you know, you have to be so, you know, intelligent.

25:28.700 --> 25:37.400
 And as you could see things that, you know, the ordinary mortals could not see, it's a game.

25:37.400 --> 25:45.600
 And all machines had to do with this game is just to make fewer mistakes, not to solve the game because the game cannot be solved.

25:45.600 --> 25:51.100
 I mean, according to what Shannon, the number of legal moves is 10 to the 46 power, too many zeros.

25:51.100 --> 25:58.600
 So just for any computer to finish the job, you know, in next few billion years.

25:58.600 --> 26:00.200
 But it doesn't have to.

26:00.200 --> 26:02.700
 It's all about making fewer mistakes.

26:02.700 --> 26:04.900
 And I think that's the this match, actually.

26:04.900 --> 26:12.600
 And what's happened afterwards with other games, with with go, with shogi, with video games.

26:12.600 --> 26:19.400
 It's a demonstration that it's the machines will always be humans in what I call closed systems.

26:19.400 --> 26:28.500
 The moment you build a closed system, no matter how the system is called, chess, go, shogi, daughter.

26:28.500 --> 26:35.900
 Machines will prevail simply because they will bring down number of mistakes.

26:35.900 --> 26:37.600
 Machines don't have to solve it.

26:37.600 --> 26:40.800
 They just have to the way they outplay us.

26:40.800 --> 26:43.300
 It's not by just being more intelligent.

26:43.300 --> 26:46.100
 It's just by by doing something else.

26:46.100 --> 26:49.800
 But eventually it's just it's capitalizing on our mistakes.

26:49.800 --> 26:58.400
 When you look at the chess machines ratings today in compare, compare this to Magnus Carlson is the same as comparing Ferrari to Usain Bolt.

26:58.400 --> 27:04.200
 It's the gap is, I mean, by chess standards is insane.

27:04.200 --> 27:08.400
 34, 3500 to 2800, 2850 on Magnus.

27:08.400 --> 27:13.900
 It's like difference between Magnus and an ordinary player from an open international tournament.

27:13.900 --> 27:21.300
 It's not because machine understanding is better than Magnus Carlson, but simply because it's steady.

27:21.300 --> 27:23.300
 Machine has steady hand.

27:23.300 --> 27:37.400
 And I think that is what we we we we have to learn from 1997 experience and from further encounters with computers and sort of the current state state of affairs was alpha zero.

27:37.400 --> 27:39.600
 You are beating other machines.

27:39.600 --> 27:45.200
 The idea that we can compete with computers in so called intellectual fields.

27:45.200 --> 27:49.000
 It's it was wrong from the very beginning.

27:49.000 --> 27:57.400
 It's just it's by the way, the 1997 match was not the first victory of machines over or grandmasters over grandmasters.

27:57.400 --> 27:57.600
 Yeah.

27:57.600 --> 28:04.100
 No, actually, it's I played against first decent chess computers from late from late eighties.

28:04.100 --> 28:10.500
 So I played with the prototype of deep blue called Deep Thought in 1989 to rapid chess games in New York.

28:10.500 --> 28:13.100
 I won handily to both games.

28:13.100 --> 28:18.800
 We played against new chess engines like Fritz and other programs.

28:18.800 --> 28:23.300
 And then it's the was Israeli program junior that appeared in 1985.

28:23.300 --> 28:23.700
 Yeah.

28:23.700 --> 28:25.500
 So there were there were several programs.

28:25.500 --> 28:28.300
 I you know, I lost few games in Blitz.

28:28.300 --> 28:33.200
 I lost one match against the computer chess in 1994 rapid chess.

28:33.200 --> 28:38.200
 So I lost one game to the blue in 1996 match the manner the match I won.

28:38.200 --> 28:41.400
 Some people, you know, tend to forget about it that I won the first match.

28:41.400 --> 28:42.300
 Yes.

28:42.300 --> 28:52.400
 But it's it's we we made a very important psychological mistake thinking that the reason we lost Blitz matches five five minutes games.

28:52.400 --> 28:58.200
 The reason we lost some of the rapid chess matches, 25 minutes because we didn't have enough time.

28:58.200 --> 29:02.100
 If you play a longer match, we will not make the same mistakes.

29:02.100 --> 29:03.000
 Nonsense.

29:03.000 --> 29:08.400
 So this yeah, we had more time, but we still make mistakes and machine also has more time and machines.

29:08.400 --> 29:15.400
 Machine will always, you know, we always be stated and consistent compared to humans.

29:15.400 --> 29:18.100
 Instabilities and inconsistencies.

29:18.100 --> 29:27.600
 And today we are at the point where nobody talks about, you know, humans playing as machines that machines can offer handicap to to top players.

29:27.600 --> 29:31.300
 Still, you know, will will will be favoring.

29:31.300 --> 29:35.400
 I think we're just learning that it's it's it's no longer human versus machines.

29:35.400 --> 29:37.900
 It's about human working with machines.

29:37.900 --> 29:41.800
 That's what I recognized in 1998.

29:41.800 --> 29:48.400
 Just after leaking my wounds and spending one year and just, you know, ruminating so the so what's happened in this match.

29:48.400 --> 29:51.600
 And I knew that though we still could play against the machines.

29:51.600 --> 29:56.700
 I had two more matches in 2003 playing both deep fritz and deep junior.

29:56.700 --> 29:59.700
 Both matches ended as a tie.

29:59.700 --> 30:05.000
 Though these machines were not weaker, at least, actually probably stronger and deep blue.

30:05.000 --> 30:10.500
 And by the way, today, chess app on your mobile phone is probably stronger than the blue and deep blue.

30:10.500 --> 30:14.000
 I'm not speaking about chess engines that are so much superior.

30:14.000 --> 30:19.300
 And by the way, when you analyze games, we play against the blue 997 on your chess engine.

30:19.300 --> 30:20.600
 They'll be laughing.

30:20.600 --> 30:25.500
 So this is and it's also shows that's how chess changed because chess commentators.

30:25.500 --> 30:29.400
 They look at some of our games like game four, game five, brilliant idea.

30:29.400 --> 30:37.600
 Now you ask Stockfish, you ask Houdini, you ask Commodore all the leading chess engines.

30:37.600 --> 30:46.300
 Within 30 seconds, they will show you how many mistakes both Gary and the blue made in the game that was

30:46.300 --> 30:50.900
 trumpet it as the as a great chess match in 1997.

30:50.900 --> 30:56.400
 Well, OK, so you've made an interesting if you can untangle that comment.

30:56.400 --> 31:03.500
 So now in retrospect, it was a mistake to see chess as the peak of human intellect.

31:03.500 --> 31:06.600
 Nevertheless, that was done for centuries.

31:06.600 --> 31:13.600
 So in Europe, because, you know, you move to the far east, they will go there.

31:13.600 --> 31:20.000
 They show games, games, some of the games like, you know, board games.

31:20.000 --> 31:22.000
 Yes. Yeah, I agree.

31:22.000 --> 31:26.700
 So if I push back a little bit, so now you say that, OK,

31:26.700 --> 31:29.300
 but it was a mistake to see chess as the epitome.

31:29.300 --> 31:34.900
 And now and then now there's other things maybe like language, that conversation,

31:34.900 --> 31:40.800
 like some of the things that in your view is still way out of reach of computers, but inside humans.

31:40.800 --> 31:44.300
 Do you think can you talk about what those things might be?

31:44.300 --> 31:51.000
 And do you think just like chess that might fall soon with the same set of approaches?

31:51.000 --> 31:57.300
 If you look at Alpha zero, the same kind of learning approaches as the machines grow in size.

31:57.300 --> 31:59.300
 No, no, it's not about growing in size.

31:59.300 --> 32:05.200
 It's about again, it's about understanding the difference between closed system and open ended system.

32:05.200 --> 32:06.900
 So you think that key difference.

32:06.900 --> 32:13.400
 So the board games are closed in terms of the rules that the actions, the state space.

32:13.400 --> 32:15.900
 Everything is just constrained.

32:15.900 --> 32:19.800
 You think once you open it, the machines are lost.

32:19.800 --> 32:25.600
 Not lost, but again, the effectiveness is very different because machine does not understand the moment

32:25.600 --> 32:28.500
 it's reaching territory of diminishing returns.

32:28.500 --> 32:32.500
 It's the simply put it in a different way.

32:32.500 --> 32:35.900
 Machine doesn't know how to ask right questions.

32:35.900 --> 32:39.400
 It can ask questions, but it will never tell you which questions are relevant.

32:39.400 --> 32:42.300
 So this is the it's like about the it's the it's a direction.

32:42.300 --> 32:45.000
 So these it's I think it's in human relations.

32:45.000 --> 32:48.300
 We have to consider so our role and people.

32:48.300 --> 32:55.700
 Many people feel uncomfortable that this the territory that that belongs to us is is shrinking.

32:55.700 --> 33:00.700
 I'm saying so what, you know, this is eventually will belong to the last few decimal points.

33:00.700 --> 33:05.400
 But it's like having so very powerful gun.

33:05.400 --> 33:11.600
 That's and and and all you can do there is slightly, you know, outer direction of the bullet.

33:11.600 --> 33:16.100
 Maybe, you know, point one degree of this angle.

33:16.100 --> 33:21.100
 But that means a mile away, 10 meters of the target.

33:21.100 --> 33:33.000
 So so that's we have to recognize that is a certain unique human qualities that machines in a foreseeable future will not be able to reproduce.

33:33.000 --> 33:40.400
 And and the effectiveness of this cooperation collaboration depends on our understanding what exactly we can bring into the game.

33:40.400 --> 33:45.600
 So the greatest danger is when we try to interfere with machine super knowledge.

33:45.600 --> 33:51.600
 So that's why I always say that sometimes you'd rather have by reading these pictures in radiology.

33:51.600 --> 34:02.200
 You may probably prefer an experienced nurse than rather than having top professor because she will not try to interfere with machines understanding.

34:02.200 --> 34:11.200
 So this it's very important to know that if machines knows how to do better things in 95%, 96% territory, we should not touch it because it's it's it's happened.

34:11.200 --> 34:17.200
 It's like in chess recognize they they do it better. See where we can make the difference.

34:17.200 --> 34:35.200
 You mentioned Alpha Zero Alpha Zero is it's it's actually a first step into what you may call AI because everything that's been called AI today is just it's it's it's one or another variation of what Claude Shannon characterized as a brute force is a type A machine.

34:35.200 --> 34:43.200
 Whether it's the blue whether it's what's on it and all these this is the modern technologies that are being trumpeted as as AI.

34:43.200 --> 34:48.200
 It's still brute force. It's the all they do it's they do optimization.

34:48.200 --> 34:56.200
 It's this they are you know they they keep you know improving the way to process human generated data.

34:56.200 --> 35:11.200
 Now, Alpha Zero is is the first step towards you know, machine produced knowledge, which is by the way, by the way, it's quite ironic that the first company that championed that was IBM.

35:11.200 --> 35:15.200
 Oh, it's in backgammon. Interesting in backgammon.

35:15.200 --> 35:19.200
 Yes, you just you should you should you should look at IBM is it's a neurogammon.

35:19.200 --> 35:29.200
 It's the it's the scientist. He's still working at IBM. They had an early nineties. It says it's the it's in the program that played in all the Alpha Zero type.

35:29.200 --> 35:31.200
 So just trying to come up with own strategies.

35:31.200 --> 35:39.200
 But because of success of the blue, this project had been not abandoned, but just you know, it's it's it wasn't it was put on calls.

35:39.200 --> 35:49.200
 And now we just you know, it's it's it's you know, it's every talks about about this the the machines generated knowledge. So as a revolutionary and it is.

35:49.200 --> 35:53.200
 But there's still, you know, many open ended questions.

35:53.200 --> 35:57.200
 Yes, Alpha Zero generates its own data.

35:57.200 --> 36:02.200
 Many ideas that Alpha Zero generated chess were quite intriguing.

36:02.200 --> 36:17.200
 So I I looked at these games with not just with interest, but with, you know, it's quite exciting to learn how machine could actually, you know, juggle all the pieces and just play positions with a broken material balance,

36:17.200 --> 36:30.200
 sacrificing material always being ahead of other programs, you know, one or two moves ahead by by foreseeing the consequence, not over calculating, because machines, other machines were at least as powerful in calculating.

36:30.200 --> 36:37.200
 But it's having this unique knowledge based on discovered patterns after playing 60 million games.

36:37.200 --> 36:39.200
 Almost something that feels like intuition.

36:39.200 --> 36:41.200
 Exactly. But there's one problem.

36:41.200 --> 36:42.200
 Yeah.

36:42.200 --> 36:52.200
 Now, the simple question, if if Alpha Zero faces superior point, let's say another powerful computer,

36:52.200 --> 36:58.200
 accompanied by human who could help just to discover certain problems, because I already I look at many Alpha Zero games.

36:58.200 --> 37:01.200
 I visited their lab, we spoke to them as Khasabis and his team.

37:01.200 --> 37:03.200
 And I know there's certain witnesses there.

37:03.200 --> 37:09.200
 Now, if these witness are exposed, the question is how many games will it take for Alpha Zero to correct it?

37:09.200 --> 37:11.200
 The answer is hundreds of thousands.

37:11.200 --> 37:15.200
 Even if it keeps losing, it it's just because the whole system is based.

37:15.200 --> 37:16.200
 Yeah.

37:16.200 --> 37:21.200
 So it's now imagine so this is you can have a human by just make a few tweaks.

37:21.200 --> 37:24.200
 So humans are still more flexible.

37:24.200 --> 37:34.200
 And and as long as we recognize what is what is our role where we can play sort of so the most valuable part in this collaboration.

37:34.200 --> 37:40.200
 So it's it will help us to understand what are the next steps in human machine collaboration.

37:40.200 --> 37:41.200
 Beautifully put.

37:41.200 --> 37:47.200
 So let's talk about the thing that machines certainly don't know how to do yet, which is morality, machines and morality.

37:47.200 --> 37:51.200
 It's another question that you know, just it's it's being asked all the time these days.

37:51.200 --> 38:07.200
 And I think it's another phantom that is haunting a general public because it's just being fed with this, you know, illusions is that how can we avoid machines, you know, having bias, big prejudices.

38:07.200 --> 38:12.200
 You cannot because it's like looking in the mirror and complaining about what you see.

38:12.200 --> 38:17.200
 If you have certain bias in the society, machine will will just follow it.

38:17.200 --> 38:25.200
 It's just it's it's you know, you look at the mirror, you don't like what you see there, you can, you know, you can break it, you can try to distort it.

38:25.200 --> 38:30.200
 Or you can try to actually change something just by yourself by yourself.

38:30.200 --> 38:37.200
 So it's very important to understand is that you cannot expect machines to improve the yields of our society.

38:37.200 --> 38:41.200
 And moreover, machines will simply, you know, just, you know, amplify it.

38:41.200 --> 38:42.200
 Yes.

38:42.200 --> 38:50.200
 But the thing is, people are more comfortable with other people doing injustice with being biased.

38:50.200 --> 38:54.200
 We're not comfortable with machines having the same kind of bias.

38:54.200 --> 39:00.200
 So that's a that's an interesting standard that we place on machines with autonomous vehicles.

39:00.200 --> 39:03.200
 They have to be much safer with automated systems.

39:03.200 --> 39:05.200
 Of course, of course, they're much safer.

39:05.200 --> 39:07.200
 Statistically, they're much safer than that.

39:07.200 --> 39:13.200
 And of course, why would it? It's not of course, it's it's not given.

39:13.200 --> 39:19.200
 Autonomous vehicles, you have to work really hard to make them safer.

39:19.200 --> 39:29.200
 I think it just goes without saying is the outcome of the of this, I would call a competition with comparison is very clear.

39:29.200 --> 39:32.200
 But the problem is not about being, you know, safer.

39:32.200 --> 39:38.200
 It's the 40,000 people or so every year died in car accidents in the United States.

39:38.200 --> 39:40.200
 And it's it's statistics.

39:40.200 --> 39:44.200
 One accident with with autonomous vehicle and its front page of a newspaper.

39:44.200 --> 39:47.200
 Yes. So it's again, it's both psychological.

39:47.200 --> 39:52.200
 So it's while people, you know, kill each other in car accidents, because they make mistakes, they make more mistakes.

39:52.200 --> 39:54.200
 For me, it's it's it's not a question.

39:54.200 --> 39:57.200
 Of course, we make more mistakes because we're human.

39:57.200 --> 39:58.200
 Yes, machines old.

39:58.200 --> 40:01.200
 And by the way, no machine will ever reach 100% perfection.

40:01.200 --> 40:05.200
 That's another that's another important fake story that that is being fed to the public.

40:05.200 --> 40:08.200
 If machine doesn't reach 100% performance is not safe.

40:08.200 --> 40:18.200
 No, all you can ask any computer, whether it's, you know, playing chess or or doing the stock market calculations or driving your autonomous vehicle.

40:18.200 --> 40:20.200
 It's to make few mistakes.

40:20.200 --> 40:29.200
 And yes, I know it's not, you know, it's not easy for us to accept because ah, if you know, if you have two humans, you know, colliding in their cars.

40:29.200 --> 40:33.200
 Okay, it's like if one of one of these cars is autonomous vehicle.

40:33.200 --> 40:42.200
 And by the way, even if it's humans fault, terrible, how could you allow a machine to to to run without a driver at the wheel?

40:42.200 --> 40:46.200
 So, you know, let's linger that for a second, that double standard.

40:46.200 --> 40:55.200
 The way you felt with your first loss against D blue, were you treating the machine differently than you would have a human?

40:55.200 --> 41:01.200
 So what do you think about that difference between the way we see machines and humans?

41:01.200 --> 41:03.200
 No, it's the at that time, you know, for me, it was a match.

41:03.200 --> 41:08.200
 And that's why I was angry because I believe that the match was not, you know, fairly organized.

41:08.200 --> 41:16.200
 So it's definitely they weren't fair advantages for IBM and I want to play their another match like rubber.

41:16.200 --> 41:24.200
 So you're angered or displeasure was aimed more like at the humans behind IBM versus the actual pure algorithm.

41:24.200 --> 41:26.200
 Absolutely. Look, I mean, I knew at the time.

41:26.200 --> 41:30.200
 And by the way, I was objectively speaking, I was stronger at that time.

41:30.200 --> 41:33.200
 So that's that probably added to my anger because I knew I could beat machine.

41:33.200 --> 41:34.200
 Yeah.

41:34.200 --> 41:37.200
 So this and that's the and as I lost and I knew I was not well prepared.

41:37.200 --> 41:42.200
 So because they have to give them credit, they did some good work from 1996.

41:42.200 --> 41:44.200
 And I but I still could beat the machine.

41:44.200 --> 41:46.200
 So I made too many mistakes.

41:46.200 --> 41:49.200
 Also, this is the whole is this publicity around the match.

41:49.200 --> 41:57.200
 So I underestimated the effect, you know, just it's and being called the, you know, the brains last stand, you know, it's okay.

41:57.200 --> 42:01.200
 No pressure.

42:01.200 --> 42:03.200
 Okay. Well, let me ask.

42:03.200 --> 42:06.200
 So I was born also in the Soviet Union.

42:06.200 --> 42:18.200
 What lessons do you draw from the rise and fall of the Soviet Union in the 20th century when you just look at this nation that is now look pushing forward into what Russia is.

42:18.200 --> 42:26.200
 If you look at the long arc of history of the 20th century, what do we take away?

42:26.200 --> 42:28.200
 What do we take away from that?

42:28.200 --> 42:35.200
 I think the lesson of history is clear.

42:35.200 --> 42:52.200
 Undemocratic systems, totalitarian regimes, systems that are based on controlling their citizens and just every aspect of their life, not offering opportunities to for private initiative.

42:52.200 --> 42:55.200
 Central planning systems, they doomed.

42:55.200 --> 43:00.200
 They just, you know, they, they cannot be driving force for innovation.

43:00.200 --> 43:02.200
 So they in history timeline.

43:02.200 --> 43:10.200
 I mean, they could cause certain, you know, distortion of the concept of progress.

43:10.200 --> 43:19.200
 They, by the way, they may call themselves progressive, but we know that is this, the damage that they caused to humanity is just it's yet to be measured.

43:19.200 --> 43:21.200
 But at the end of the day, they fail.

43:21.200 --> 43:27.200
 They fail and it's at the end of the Cold War was a great time of the free will.

43:27.200 --> 43:29.200
 It's not that free world is perfect.

43:29.200 --> 43:32.200
 It's very important to recognize its factors.

43:32.200 --> 43:41.200
 I always like to mention, you know, one of my favorite books, The Lord of the Rings, that the there's no, there's no absolute good, but there is an absolute evil.

43:41.200 --> 43:51.200
 Good, you know, comes in many forms, but we all, you know, it's being humans or being even, you know, humans from fairy tales or just some sort of mythical creatures.

43:51.200 --> 43:57.200
 It's the, you can always find spots on the sound.

43:57.200 --> 44:03.200
 So this is conducting war and just and fighting for justice.

44:03.200 --> 44:06.200
 There are always things that, you know, can be easily criticized.

44:06.200 --> 44:10.200
 And human history is the is a never ending quest for perfection.

44:10.200 --> 44:13.200
 But we know that there's absolutely evil.

44:13.200 --> 44:15.200
 We know it's for me, it's now clear.

44:15.200 --> 44:21.200
 It's nobody argues about Hitler being absolutely evil, but I think it's very important to recognize Stalin was absolutely evil.

44:21.200 --> 44:26.200
 Communism caused more damage than any other ideology in the 20th century.

44:26.200 --> 44:32.200
 And unfortunately, while we all know that fascism was condemned, but there was no nerve for common communism.

44:32.200 --> 44:39.200
 And that's why we could see, you know, still is the successors of Stalin are feeling far more comfortable.

44:39.200 --> 44:45.200
 So you, you, as one of them, you highlight a few interesting connections actually between Stalin and Hitler.

44:45.200 --> 44:54.200
 I mean, they're in terms of the adjusting or clarifying the history of World War Two, which is very interesting.

44:54.200 --> 44:56.200
 Of course, we don't have time, so let me ask.

44:56.200 --> 45:02.200
 You can ask, you know, I just I just recently delivered a speech in Toronto at eighties and roaster of Molotov ribbon compact.

45:02.200 --> 45:11.200
 It's something that I believe, you know, just, you know, has must must be taught in the schools that the World War Two had been started by two dictators

45:11.200 --> 45:21.200
 by signing these these criminal criminal treaty, collusion of two tyrants in August 1939 that led to the beginning of the World World War Two.

45:21.200 --> 45:27.200
 And the fact is that eventually Stalin had no choice but to join allies because Hitler attacked him.

45:27.200 --> 45:34.200
 So it just doesn't, you know, eliminate the fact that Stalin helped Hitler to start World War Two.

45:34.200 --> 45:40.200
 And he was one of the beneficiaries at early at early stage by annexing part of Eastern Europe.

45:40.200 --> 45:44.200
 And as a result of World War Two, he annex almost entire Eastern Europe.

45:44.200 --> 45:50.200
 And for many Eastern European nations, the end of the World War Two was the beginning of communist occupation.

45:50.200 --> 46:00.200
 So Putin, you've talked about as a man who stands between Russia and democracy, essentially today.

46:00.200 --> 46:03.200
 You've been a strong opponent and critic of Putin.

46:03.200 --> 46:09.200
 Let me ask again, how much does fear enter your mind and heart?

46:09.200 --> 46:17.200
 So in 2007, there's this interesting comment from Oleg Kalugin, KGB general.

46:17.200 --> 46:23.200
 He said that I do not talk details. People who knew them are all dead now because they were vocal.

46:23.200 --> 46:28.200
 I'm quiet. There's only one man who's vocal and he may be in trouble.

46:28.200 --> 46:33.200
 World chess champion Kasparov. He has been very outspoken in his attacks on Putin.

46:33.200 --> 46:36.200
 And I believe he's probably next on the list.

46:36.200 --> 46:41.200
 So clearly your life has been and perhaps continues to be in danger.

46:41.200 --> 46:54.200
 How do you think about having the views you have, the ideas you have, being in opposition as you are in this kind of context when your life could be in danger?

46:54.200 --> 46:57.200
 That's the reason I live in New York.

46:57.200 --> 47:05.200
 So it was not my first choice, but I knew I had to live Russia at one point and among other places, New York is the safest.

47:05.200 --> 47:07.200
 Is it safe? No.

47:07.200 --> 47:14.200
 I mean, I know what happened, what is happening with many of Putin's enemies.

47:14.200 --> 47:18.200
 But at the end of the day, I mean, what can I do?

47:18.200 --> 47:24.200
 I could be very proactive by trying to change things I can influence.

47:24.200 --> 47:30.200
 But here are our facts. I cannot stop doing what I've been doing for a long time.

47:30.200 --> 47:32.200
 It's the right thing to do.

47:32.200 --> 47:41.200
 I grew up with my family teaching me sort of the wisdom of Soviet dissidents, do what you must and so be.

47:41.200 --> 47:49.200
 I could try to be cautious by not traveling to certain places where my security could be at risk.

47:49.200 --> 48:01.200
 There are so many invitations to speak at different locations in the world and I have to say that many countries are just now, are not destinations that I can afford to travel.

48:01.200 --> 48:05.200
 My mother still lives in Moscow and meet her a few times a year.

48:05.200 --> 48:16.200
 She was devastated when I had to leave Russia because since my father died in 1971, so she was 33 and she dedicated her entire life to her only son.

48:16.200 --> 48:26.200
 But she recognized in just a year or so since I left Russia that it was the only chance for me to continue my normal life.

48:26.200 --> 48:35.200
 So just to be relatively safe and to do what she taught me to do to make the difference.

48:35.200 --> 48:39.200
 Do you think you will ever return to Russia or let me ask a different way?

48:39.200 --> 48:40.200
 Well, I'm sure.

48:40.200 --> 48:46.200
 Maybe one sooner than many people think because I think Putin's regime is facing answering all the different difficulties.

48:46.200 --> 48:57.200
 And again, I read enough historical books to know that dictatorships they end suddenly.

48:57.200 --> 49:00.200
 It's just on Sunday dictator feels comfortable.

49:00.200 --> 49:04.200
 He believes he's popular on Monday morning.

49:04.200 --> 49:05.200
 He's bust.

49:05.200 --> 49:07.200
 The good news and bad news.

49:07.200 --> 49:12.200
 I mean, the bad news is that I don't know when and how Putin rule ends.

49:12.200 --> 49:14.200
 The good news he also doesn't know.

49:14.200 --> 49:19.200
 Okay, well put.

49:19.200 --> 49:28.200
 Let me ask a question that seems to preoccupy the American mind from the perspective of Russia.

49:28.200 --> 49:42.200
 One, did Russia interfere in the 2016 US election government sanction and future to will Russia interfere in the 2020 US election?

49:42.200 --> 49:45.200
 And what does that interference look like?

49:45.200 --> 49:46.200
 It's very odd.

49:46.200 --> 49:55.200
 You know, we had such an intelligent conversation and you are ruining everything by asking such a stupid question.

49:55.200 --> 49:57.200
 It's been going downhill the entire way.

49:57.200 --> 50:00.200
 But it's insulting from my intellect.

50:00.200 --> 50:01.200
 Okay.

50:01.200 --> 50:03.200
 Of course they didn't interfere.

50:03.200 --> 50:05.200
 Of course they did absolutely everything to elect Trump.

50:05.200 --> 50:07.200
 I mean, they said it many times.

50:07.200 --> 50:14.200
 He says, you know, I met enough KGB kernels in my life to tell you that, you know, just the way Putin looks at Trump.

50:14.200 --> 50:15.200
 Yeah.

50:15.200 --> 50:16.200
 This is the way looks.

50:16.200 --> 50:19.200
 And I don't have to hear what he says, what Trump says.

50:19.200 --> 50:22.200
 It just says, I don't need to go through congressional investigations.

50:22.200 --> 50:28.200
 The way Putin looks at Trump is the way the KGB officers looked at the assets.

50:28.200 --> 50:34.200
 It's just and following to 2020, of course, they will do absolutely everything to help Trump to survive.

50:34.200 --> 50:39.200
 Because I think the damage that Trump's elections could cause to America and to the free world.

50:39.200 --> 50:42.200
 It's just, it's beyond one's imagination.

50:42.200 --> 50:47.200
 I think basically if Trump is reelected, he will ruin NATO because he's already heading in this direction.

50:47.200 --> 50:55.200
 But now he's just, he's still limited by the reelection hurdles.

50:55.200 --> 51:03.200
 If he's still in the office after November 2020, okay, January 2021.

51:03.200 --> 51:05.200
 I don't want to think about it.

51:05.200 --> 51:09.200
 My problem is not just Trump, because Trump is basically a symptom.

51:09.200 --> 51:25.200
 But the problem is that I don't see it just, it's the in American political horizon, politicians who could take on Trump for, for all damage that he's doing for the free world.

51:25.200 --> 51:28.200
 Not just things that just happened that went wrong in America.

51:28.200 --> 51:37.200
 So there's the, it seems to me that the campaign political campaign on the Democratic side is, is fixed on certain important, but still secondary issues.

51:37.200 --> 51:43.200
 Because when you have the foundation of the Republican jeopardy, you cannot talk about healthcare.

51:43.200 --> 51:50.200
 I mean, I understand how important it is, but it's still secondary because the entire framework of American political life is at risk.

51:50.200 --> 52:00.200
 And you have Vladimir Putin just, you know, just it's having virtually free hands by, by his, by attacking America and other free countries.

52:00.200 --> 52:07.200
 And by the way, we have so much evidence about Russia interference in Brexit in elections in almost every European country.

52:07.200 --> 52:12.200
 And thinking that they will be shy of attacking America in 2020.

52:12.200 --> 52:23.200
 Now with, with Trump in the office, yeah, I think it's, yeah, it definitely diminishes the intellectual quality of our conversation.

52:23.200 --> 52:33.200
 I do what I can. Last question, if you can go back, just look at the entirety of your life you accomplished more than most humans will ever do.

52:33.200 --> 52:39.200
 If you can go back and relive a single moment in your life, what would that moment be?

52:39.200 --> 52:51.200
 Ah, um, yeah, there are moments in my life when I think about what could be done differently, but.

52:51.200 --> 52:58.200
 No, experience happiness, enjoy and pride, just, just to, just to touch once again.

52:58.200 --> 53:01.200
 I know, I know, but it's the, it's the, it's look, I made many mistakes in my life.

53:01.200 --> 53:07.200
 So I just, it's the, I know that at the end of the day, it's, I believe in the butterfly effect.

53:07.200 --> 53:24.200
 So it's the, it's the, I knew moments where I could, now if I'm there at that point in 89 and 93, pick up a year, I could improve my actions by not doing this stupid thing.

53:24.200 --> 53:27.200
 But then how do you know that I will have all other accomplishments?

53:27.200 --> 53:37.200
 Yeah, I just, I'm, I'm afraid that, you know, we just have to just follow this, if you may call it wisdom or forest gum.

53:37.200 --> 53:44.200
 You know, it's the life is this, you know, it's, it's, it's a box of, of, of, of chocolate and you don't know what's inside, but you have to go one by one.

53:44.200 --> 53:48.200
 So it's the, I'm, I'm happy with who I am and where I am today.

53:48.200 --> 53:54.200
 And I am very proud, not only was my chess accomplishments, but that I made this transition.

53:54.200 --> 54:05.200
 And since I left chess, you know, I built my own reputation that had some influence on the game of chess, but not, it's not, you know, directly derived from, from, from the game.

54:05.200 --> 54:07.200
 I'm grateful for my wife.

54:07.200 --> 54:09.200
 So help me to build this life.

54:09.200 --> 54:11.200
 We actually married in 2005.

54:11.200 --> 54:12.200
 It wasn't my third marriage.

54:12.200 --> 54:14.200
 That's why I said that made mistakes in my life.

54:14.200 --> 54:18.200
 But, and by the way, I'm close with two kids from my previous marriages.

54:18.200 --> 54:25.200
 So that's, that's the, I mean, I managed to sort of balance my life and, and here in, I live in New York.

54:25.200 --> 54:27.200
 So we have two kids born here in New York.

54:27.200 --> 54:31.200
 It's, it's new life and it's, you know, it's, it's busy.

54:31.200 --> 54:41.200
 Sometimes I wish I could, you know, I could limit my engagement in many other things that are still, you know, taking time and energy.

54:41.200 --> 54:44.200
 But life is exciting.

54:44.200 --> 54:53.200
 And as long as I can feel that I have energy, I have strengths, I have passion to make the difference.

54:53.200 --> 54:55.200
 I'm happy.

54:55.200 --> 54:58.200
 I think that's a beautiful moment to end on.

54:58.200 --> 55:00.200
 Gary's possible by sure.

55:00.200 --> 55:02.200
 Thank you very much for talking to me.

55:02.200 --> 55:03.200
 Thank you.

55:03.200 --> 55:24.200
 Thank you.

