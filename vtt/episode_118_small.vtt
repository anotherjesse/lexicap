WEBVTT

00:00.000 --> 00:04.720
 The following is a conversation with Grant Sanderson, his second time on the podcast.

00:04.920 --> 00:09.800
 He's known to millions of people as the mind behind Three Blue One Brown, a YouTube

00:10.000 --> 00:15.560
 channel where he educates and inspires the world with the beauty and power of mathematics.

00:15.760 --> 00:19.760
 Quick summary of the sponsors, Dollar Shave Club, DoorDash and Cash App.

00:19.960 --> 00:24.280
 Click the sponsor links in the description to get a discount and to support this podcast,

00:24.480 --> 00:28.800
 especially for the two new sponsors, Dollar Shave Club and DoorDash.

00:28.800 --> 00:33.360
 Let me say as a side note, I think that this pandemic challenged millions of

00:33.560 --> 00:38.320
 educators to rethink how they teach, to rethink the nature of education.

00:38.520 --> 00:43.440
 As people know, Grant is a master elucidator of mathematical concepts that may

00:43.640 --> 00:47.560
 otherwise seem difficult or out of reach for students and curious minds.

00:47.760 --> 00:52.240
 But he's also an inspiration to teachers, researchers and people who just enjoy

00:52.440 --> 00:55.920
 sharing knowledge, like me, for what it's worth.

00:55.920 --> 00:58.960
 It's one thing to give a semester's worth of multi hour lectures.

00:59.160 --> 01:02.960
 It's another to extract from those lectures the most important, interesting,

01:03.160 --> 01:07.680
 beautiful and difficult concepts and present them in a way that makes everything fall

01:07.880 --> 01:11.080
 into place. That is the challenge that is worth taking on.

01:11.280 --> 01:15.400
 My dream is to see more and more of my colleagues at MIT and world experts

01:15.600 --> 01:20.440
 across the world, someone their inner Three Blue One Brown and create the canonical

01:20.640 --> 01:25.520
 explainer videos on a topic that they know more than almost anyone else in the world.

01:25.520 --> 01:28.600
 Amidst the political division, the economic pain,

01:28.800 --> 01:31.520
 the psychological medical toll of the virus,

01:31.720 --> 01:36.240
 masterfully crafted educational content feels like one of the beacons of hope

01:36.440 --> 01:38.480
 that we can hold on to.

01:38.680 --> 01:42.880
 If you enjoy this thing, subscribe on YouTube, review it with 5,000 up a podcast,

01:43.080 --> 01:48.520
 follow on Spotify, support on Patreon or connect with me on Twitter at Lex Friedman.

01:48.720 --> 01:52.680
 Of course, after you go immediately, which you already probably have done a long

01:52.680 --> 01:58.760
 time ago and subscribe to Three Blue One Brown YouTube channel, you will not regret it.

01:58.960 --> 02:01.880
 As usual, I'll do a few minutes of as now and no ads in the middle.

02:02.080 --> 02:06.560
 I try to make these interesting, but I give you timestamps so you can skip.

02:06.760 --> 02:10.280
 But still, please do check out the sponsors by clicking the links in the description,

02:10.480 --> 02:13.800
 especially the two new ones, DoorDash and Dollar Shave Club.

02:14.000 --> 02:18.000
 They're evaluating us, looking at how many people go to their site and get their

02:18.000 --> 02:21.040
 stuff in order to determine if they want to support us for the long term.

02:21.040 --> 02:23.080
 So you know what to do.

02:23.280 --> 02:26.240
 It's the best way to support this podcast, as always.

02:26.440 --> 02:28.480
 This show is sponsored by Dollar Shave Club.

02:28.680 --> 02:33.200
 Try them out with a one time offer for only five dollars in free shipping at

02:33.400 --> 02:35.920
 dollarshaveclub.com slash Lex.

02:36.120 --> 02:40.720
 The starter kit comes with a six blade razor, refills and all kinds of other

02:40.920 --> 02:42.880
 stuff that makes shaving feel great.

02:43.080 --> 02:46.520
 I've been a member of Dollar Shave Club for over five years now and actually

02:46.720 --> 02:50.400
 signed up when I first heard about them on the Joe Rogan podcast.

02:50.400 --> 02:52.840
 And now we have come full circle.

02:53.040 --> 02:57.560
 I feel like I've made it now that I can do a read for them just like Joe did all

02:57.760 --> 03:01.360
 those years ago. For the most part, I've just used the razor and the refills,

03:01.560 --> 03:05.040
 but they encourage me to try the shave butter, which I've never used before.

03:05.240 --> 03:07.400
 So I did and I love it.

03:07.600 --> 03:11.360
 I'm not sure how the chemistry of it works out, but it's translucent somehow,

03:11.560 --> 03:13.280
 which is a cool new experience.

03:13.480 --> 03:17.640
 Again, try the ultimate shave starter set today for just five bucks plus free

03:17.640 --> 03:21.080
 shipping at dollarshaveclub.com slash Lex.

03:21.280 --> 03:24.040
 This show is also sponsored by DoorDash.

03:24.240 --> 03:28.640
 Get five bucks off and zero delivery fees on your first order of $15 or more.

03:28.840 --> 03:32.960
 When you download the DoorDash app and enter code Lex.

03:33.160 --> 03:34.960
 I have so many memories of working late

03:34.960 --> 03:38.760
 nights for deadline with a team of engineers and eventually taking a break

03:38.960 --> 03:41.720
 to argue about which DoorDash restaurant to order from.

03:41.920 --> 03:45.640
 And when the food came, those moments of bonding, of exchanging ideas,

03:45.640 --> 03:52.720
 of pausing to shift attention from the programs to the humans or special.

03:52.920 --> 03:57.920
 These days, for a bit of time, I'm on my own, sadly, so I miss that camaraderie.

03:58.120 --> 04:00.160
 But actually, DoorDash is still there for me.

04:00.360 --> 04:03.720
 There's a million options that fit into my keto diet ways.

04:03.920 --> 04:07.280
 Also, it's a great way to support restaurants in these challenging times.

04:07.480 --> 04:12.000
 Once again, download the DoorDash app and enter code Lex to get five bucks off

04:12.000 --> 04:16.360
 and zero delivery fees on your first order of $15 or more.

04:16.560 --> 04:21.400
 Finally, this show is presented by Cash App, the number one finance app in the App Store.

04:21.600 --> 04:24.240
 When you get it, use code Lex Podcast.

04:24.440 --> 04:26.720
 Cash App lets you send money to friends, buy

04:26.920 --> 04:30.640
 Bitcoin and invest in the stock market with as little as one dollar.

04:30.840 --> 04:34.400
 It's one of the best design interfaces of an app that I've ever used.

04:34.600 --> 04:37.760
 To me, good design is when everything is easy and natural.

04:37.760 --> 04:42.400
 Bad design is when the app gets in the way either because it's buggy because it

04:42.600 --> 04:44.560
 tries too hard to be helpful.

04:44.760 --> 04:46.040
 I'm looking at you, Clippy.

04:46.240 --> 04:50.480
 Anyway, there's a big part of my brain and heart that love to design things and also

04:50.680 --> 04:52.360
 to appreciate grade design by others.

04:52.560 --> 04:57.440
 So again, if you get Cash App from the App Store, Google Play and use code Lex Podcast,

04:57.640 --> 05:03.280
 you get $10 and Cash App will also donate $10 to first an organization that is helping

05:03.280 --> 05:08.160
 to advance robotics and STEM education for young people around the world.

05:08.360 --> 05:13.320
 And now here's my conversation with Grant Sanderson.

05:13.520 --> 05:17.480
 You've spoken about Richard Feynman as someone you admire.

05:17.680 --> 05:21.040
 I think last time we spoke, we ran out of time.

05:21.240 --> 05:24.400
 So I wanted to talk to you about him.

05:24.600 --> 05:27.120
 Who is Richard Feynman to you in your eyes?

05:27.320 --> 05:29.120
 What impact did he have on you?

05:29.320 --> 05:31.120
 I mean, I think a ton of people like Feynman.

05:31.120 --> 05:34.080
 He's probably it's a little bit cliche to say that you like Feynman, right?

05:34.080 --> 05:38.200
 That's almost like when you don't know what to say about sports and you just point

05:38.200 --> 05:40.960
 to the Super Bowl or something or something you enjoy watching.

05:41.160 --> 05:45.200
 But I do actually think there's a layer to Feynman that sits behind the iconography.

05:45.400 --> 05:50.200
 One thing that just really struck me was this letter that he wrote to his wife

05:50.200 --> 05:51.440
 two years after she died.

05:51.640 --> 05:54.120
 So during the Manhattan Project, she had polio.

05:54.320 --> 05:55.200
 Tragically, she died.

05:55.400 --> 05:57.400
 They were just young, madly in love.

05:57.400 --> 06:04.320
 And, you know, the icon of Feynman is this almost this like mildly sexist womanizing

06:04.520 --> 06:07.720
 philanderer, at least on the personal side.

06:07.920 --> 06:10.680
 But you read this letter and I can try to pull it up for you if I want.

06:10.880 --> 06:15.320
 And it's just this absolutely heartfelt letter to his wife saying how much he loves her,

06:15.520 --> 06:19.680
 even though she's dead and kind of what she means to him, how no woman can ever

06:19.880 --> 06:21.040
 measure up to her.

06:21.240 --> 06:26.520
 And it shows you that the Feynman that we've all seen in like surely you're joking is

06:26.520 --> 06:28.480
 different from the Feynman in reality.

06:28.680 --> 06:33.600
 And I think the same kind of goes in his science where, you know, he kind of sometimes

06:33.800 --> 06:37.840
 has this output of being this Ashok's character, like everyone else is coming in.

06:37.840 --> 06:39.880
 There's with these fancyfalutin formulas.

06:39.880 --> 06:43.120
 But I'm just going to try to whittle it down to its essentials, which is so appealing

06:43.120 --> 06:44.720
 because we love to see that kind of thing.

06:44.920 --> 06:49.800
 But when you get into it, like what he was doing was actually quite deep, very much

06:50.000 --> 06:52.880
 mathematical that should go without saying.

06:52.880 --> 06:55.200
 But I remember reading a book about Feynman in a cafe once.

06:55.200 --> 06:58.640
 And this woman looked at me and was like, saw that it was about Feynman.

06:58.640 --> 06:59.760
 She was like, oh, I love him.

06:59.760 --> 07:00.840
 I read really you're joking.

07:01.040 --> 07:04.360
 And she started explaining to me how he was never really a math person.

07:04.560 --> 07:09.440
 And I don't understand how that can possibly be a public perception about any

07:09.440 --> 07:12.880
 physicist, but for whatever reason that like worked into his or that he sort of

07:13.080 --> 07:15.720
 shoot off math in place of true science.

07:15.920 --> 07:18.840
 The reality of it is he was deeply in love with math and was much more going in

07:18.840 --> 07:22.200
 that direction and had a clicking point into seeing that physics was a way to

07:22.200 --> 07:26.840
 realize that and all the creativity that he could output in that direction was

07:26.840 --> 07:29.880
 instead poured towards things like fundamental, not even fundamental theories,

07:30.080 --> 07:32.400
 just emergent phenomena and everything like that.

07:32.600 --> 07:35.280
 So to answer your actual question,

07:35.480 --> 07:41.000
 what I like about his way of going at things is this constant desire to reinvent

07:41.000 --> 07:44.480
 it for himself, like when he would consume papers the way he described it,

07:44.480 --> 07:47.400
 he would start to see what problem he was trying to solve and then just try to

07:47.400 --> 07:49.680
 solve it himself to get a sense of personal ownership.

07:49.680 --> 07:52.240
 And then from there, see what others had done.

07:52.440 --> 07:54.040
 Is that how you see problems yourself?

07:54.240 --> 07:58.160
 Like that's actually an interesting point when you first

07:58.360 --> 08:03.680
 are inspired by a certain idea that you maybe want to teach or visualize or just

08:03.680 --> 08:04.800
 explore on your own.

08:05.000 --> 08:08.080
 I'm sure you're captured by some possibility and magic of it.

08:08.280 --> 08:10.520
 Do you read the work of others?

08:10.520 --> 08:11.880
 Like, do you go through the proof?

08:11.880 --> 08:14.600
 Do you try to rediscover everything yourself?

08:14.800 --> 08:18.880
 So I think the things that I've learned best and have the deepest ownership of

08:18.880 --> 08:21.000
 are the ones that have some element of rediscovery.

08:21.200 --> 08:22.920
 The problem is that really slows you down.

08:23.120 --> 08:25.320
 And this is for my part, it's actually a big fall.

08:25.320 --> 08:28.240
 Like this is part of why I'm not an active researcher.

08:28.240 --> 08:29.920
 I'm not like at the depth of the field.

08:29.920 --> 08:32.200
 A lot of other people are the stuff that I do learn.

08:32.200 --> 08:34.560
 I try to learn it really well.

08:34.760 --> 08:37.440
 But other times you do need to get through it at a certain pace.

08:37.440 --> 08:39.640
 You do need to get to a point of a problem you're trying to solve.

08:39.640 --> 08:42.600
 So obviously you need to be well equipped to read things

08:42.800 --> 08:45.640
 without that reinvention component and see how others have done it.

08:45.840 --> 08:48.680
 But I think if you choose a few core building blocks along the way and you

08:48.680 --> 08:52.600
 say, I'm really going to try to approach this

08:52.800 --> 08:55.880
 before I see how this person went at it, I'm really going to try to approach it for

08:56.080 --> 09:00.160
 myself, no matter what you gain, all sorts of inarticulatable intuitions about

09:00.360 --> 09:04.280
 that topic, which aren't going to be there if you simply go through the proof.

09:04.480 --> 09:07.720
 For example, you're going to be trying to come up with counter examples.

09:07.920 --> 09:09.720
 You're going to try to come up with

09:09.920 --> 09:12.960
 intuitive examples, all sorts of things where you're populating your brain with

09:12.960 --> 09:15.760
 data and the ones that you come up with are likely to be different than the one

09:15.760 --> 09:18.880
 that the text comes up with and that lends at a different angle.

09:19.080 --> 09:22.680
 So that aspect also slowed Feynman down in a lot of respects.

09:22.680 --> 09:26.880
 I think there was a period when like the rest of physics was running away from him.

09:27.080 --> 09:30.200
 But insofar as it got him to where he was,

09:30.400 --> 09:32.200
 I kind of resonate with that.

09:32.400 --> 09:36.360
 I just I would be nowhere near it because I not like him at all.

09:36.560 --> 09:41.000
 But it's like a state to aspire to.

09:41.200 --> 09:45.400
 You know, just to link in a small point you made that you're not

09:45.400 --> 09:47.920
 a quote unquote active researcher.

09:48.120 --> 09:55.480
 Do you hear swimming often in reasonably good depth about a lot of topics?

09:55.680 --> 09:58.560
 Do you sometimes want to like dive deep?

09:58.760 --> 10:02.560
 That's a certain moment and say like because you probably built up a hell

10:02.760 --> 10:08.080
 of an amazing intuition about what is and isn't true within these worlds.

10:08.280 --> 10:14.720
 Do you ever want to just dive in and see if you can discover something new?

10:14.720 --> 10:19.880
 Yeah, I think one of my biggest regrets from undergrad is not having built better

10:19.880 --> 10:21.680
 relationships with the professors I had there.

10:21.680 --> 10:26.200
 And I think a big part of success and research is that element of like mentorship

10:26.200 --> 10:29.440
 and like people giving you the kind of scaffolded problems to carry along.

10:29.640 --> 10:34.600
 For my own like goals right now, I feel like I'm pretty good at exposing math

10:34.800 --> 10:37.720
 to others and like want to continue doing that.

10:37.920 --> 10:39.440
 For my personal learning,

10:39.440 --> 10:44.400
 I, are you familiar with like the Hedgehog Fox dynamic?

10:44.600 --> 10:48.440
 I think this was either the ancient Greeks came up with it or it was

10:48.640 --> 10:52.280
 pretended to be something drawn from the ancient Greeks that I don't know who to

10:52.480 --> 10:54.800
 point it to, but they probably marked Twain.

10:55.000 --> 10:58.760
 It is that you've got two types of people or especially two types of researchers.

10:58.960 --> 11:01.600
 There's the Fox that knows many different things.

11:01.800 --> 11:04.240
 And then the Hedgehog that knows one thing very deeply.

11:04.440 --> 11:06.760
 So like Von Neumann would have been the Fox.

11:06.760 --> 11:08.200
 He's someone who knows many different things.

11:08.200 --> 11:10.880
 Just very foundational, a lot of different fields.

11:11.080 --> 11:13.840
 Einstein would have been more of a Hedgehog thinking really deeply about one

11:14.040 --> 11:17.960
 particular thing and both are very necessary for making progress.

11:18.160 --> 11:22.240
 So between those two, I would definitely see myself as like the Fox, where

11:22.440 --> 11:24.760
 I'll try to get my paws in like a whole bunch of different things.

11:24.960 --> 11:28.200
 And at the moment, I just think I don't know enough of anything to make like a

11:28.400 --> 11:32.600
 significant contribution to any of them, but I do see value in

11:32.800 --> 11:36.400
 like having a decently deep understanding of a wide variety of things.

11:36.400 --> 11:40.760
 Like most people who know computer science really deeply,

11:40.960 --> 11:45.520
 don't necessarily know physics very deeply, or many of the like different fields

11:45.520 --> 11:49.120
 in math, even let's say you have like an analytic number theory versus an algebraic

11:49.120 --> 11:52.240
 number theory, like these two things end up being related to very different fields,

11:52.240 --> 11:55.760
 like some of them more complex analysis, some of them more like algebraic geometry.

11:55.960 --> 11:59.560
 And then when you just go out so far as to take those adjacent fields, place one,

11:59.760 --> 12:02.000
 you know, PhD student into a seminar of another ones.

12:02.000 --> 12:03.920
 They don't understand what the other one's saying at all.

12:03.920 --> 12:07.600
 Like you take the complex analysis specialist inside the algebraic geometry

12:07.600 --> 12:11.960
 seminar, there is lost as you or I would be, but I think going around and like

12:11.960 --> 12:16.160
 trying to have some sense of what this big picture is certainly has personal value

12:16.160 --> 12:19.880
 for me. I don't know if I would ever make like new contributions in those fields,

12:19.880 --> 12:24.200
 but I do think I could make new like expositional contributions where there's

12:24.200 --> 12:29.560
 kind of a notion of things that are known, but like haven't been explained very well.

12:29.560 --> 12:33.960
 Well, first of all, I think most people would agree your videos, your teaching,

12:34.160 --> 12:39.360
 the way you see the world is fundamentally often new, like you're creating something

12:39.560 --> 12:45.960
 new and it almost feels like research, even just like the visualizations,

12:46.160 --> 12:48.480
 the multidimensional visualization we'll talk about.

12:48.680 --> 12:52.600
 I mean, you're revealing something very interesting that,

12:52.800 --> 12:57.280
 yeah, just feels like research, feels like science, feels like the cutting edge

12:57.280 --> 13:02.880
 of the very thing of which like new ideas and new discoveries are made of.

13:03.080 --> 13:06.440
 I do think you're being a little bit more generous than is necessarily.

13:06.640 --> 13:10.640
 And I promise that's not even false humility, because I sometimes think when I

13:10.640 --> 13:13.920
 research a video, I'll learn like 10 times as much as I need for the video itself.

13:13.920 --> 13:16.400
 And it ends up feeling kind of elementary.

13:16.600 --> 13:22.160
 So I have a sense of just how far away like the stuff that I cover is from the actual depth.

13:22.360 --> 13:26.040
 I think that's natural, but I think that could also be a mathematics thing.

13:26.040 --> 13:29.800
 I feel like in the machine learning world, you like two weeks in,

13:30.000 --> 13:32.840
 you feel like you've basically mastered.

13:33.040 --> 13:37.080
 And mathematics is like everything is either trivial or impossible.

13:37.280 --> 13:40.800
 And it's like a shockingly thin line between the two where you can find

13:40.800 --> 13:42.240
 something that's totally impenetrable.

13:42.240 --> 13:43.840
 And then after you get a feel for it's like, oh, yeah,

13:44.040 --> 13:47.720
 that whole that whole subject is actually trivial in some way.

13:47.920 --> 13:49.880
 So maybe that's what goes on.

13:50.080 --> 13:52.240
 Every researcher is just on the other end of that hump.

13:52.240 --> 13:55.800
 And it feels like it's so far away, but one step actually gets them there.

13:55.800 --> 13:59.840
 What do you think about sort of Feynman's teaching style or

14:00.040 --> 14:05.320
 another perspective is of use of visualization?

14:05.520 --> 14:08.960
 Well, his teaching style is interesting because people have described like the

14:09.160 --> 14:12.800
 Feynman effect where while you're watching his lectures or while you're reading his

14:13.000 --> 14:14.960
 lectures, everything makes such perfect sense.

14:15.160 --> 14:20.560
 So as an entertainment session, it's wonderful because it gives you this

14:20.760 --> 14:24.680
 this intellectual satisfaction that you don't get from anywhere else that you

14:24.680 --> 14:26.080
 like finally understand it.

14:26.280 --> 14:28.160
 But the Feynman effect is that you

14:28.360 --> 14:32.240
 can't really recall what it is that gave you that insight, you know, even a week later.

14:32.440 --> 14:35.840
 And this is this is true of a lot of books and a lot of lectures where

14:36.040 --> 14:38.960
 the retention is never quite what we hope it is.

14:39.160 --> 14:41.200
 So

14:41.400 --> 14:43.880
 there is a risk that

14:44.080 --> 14:47.720
 the stuff that I do also fits that same bill where at best it's giving this kind

14:47.920 --> 14:51.360
 of intellectual candy on giving a glimpse of feeling like you understand something.

14:51.360 --> 14:55.320
 But unless you do something active, like reinventing it yourself, like doing

14:55.520 --> 15:00.800
 problems to solidify it, even things like space repetition memory to just make sure

15:00.800 --> 15:03.880
 that you have like the building blocks of what do all the terms mean.

15:04.080 --> 15:06.640
 Unless you're doing something like that, it's not actually going to stick.

15:06.840 --> 15:12.200
 So the very same thing that's so admirable about Feynman's lectures, which is how

15:12.400 --> 15:18.280
 damn satisfying they are to consume, might actually also reveal a little bit of the

15:18.280 --> 15:22.160
 flaw that we should, as educators, all look out for, which is that that does not

15:22.360 --> 15:23.960
 correlate with long term learning.

15:24.160 --> 15:25.560
 We'll talk about it a little bit.

15:25.760 --> 15:28.640
 I think you've done some interactive stuff.

15:28.840 --> 15:31.200
 I mean, even in your videos,

15:31.400 --> 15:35.640
 the awesome thing that Feynman couldn't do at the time is you could,

15:35.840 --> 15:40.520
 since it's programmed, you can like tinker, like play with stuff.

15:40.720 --> 15:42.520
 You could take this value and change it.

15:42.720 --> 15:46.840
 You can like, here, let's take the value of this variable and change it to build

15:46.840 --> 15:51.720
 up an intuition to move along the surface or to change the shape of something.

15:51.920 --> 15:57.080
 I think that's almost an equivalent of you doing it yourself.

15:57.280 --> 16:00.280
 It's not quite there, but as a viewer,

16:00.520 --> 16:04.400
 yeah, do you think there's some value in that interactive element?

16:04.600 --> 16:06.320
 Yeah, well, so what's interesting is you're

16:06.320 --> 16:09.040
 saying that and the videos are non interactive in the sense that there's a

16:09.040 --> 16:12.360
 play button and a pause button and you could ask like, hey, while you're

16:12.360 --> 16:15.400
 programming these things, why don't you program it into an interactable version

16:15.400 --> 16:18.200
 that, you know, make it a Jupyter notebook that people can play with,

16:18.400 --> 16:20.520
 which I should do and that like would be better.

16:20.720 --> 16:24.920
 I think the thing about interactives, though, is most people consuming them

16:25.120 --> 16:27.960
 just sort of consume what the author had in mind.

16:28.160 --> 16:29.480
 And that's kind of what they want.

16:29.680 --> 16:32.960
 Like I have a ton of friends who make interactive explanations.

16:33.160 --> 16:36.720
 And when you look into the analytics of how people use them,

16:36.840 --> 16:40.040
 there's a small sliver that genuinely use it as a playground to have experiments.

16:40.240 --> 16:42.840
 And maybe that small sliver is actually who you're targeting and the rest don't

16:42.840 --> 16:46.520
 matter, but most people consume it just as a piece of

16:46.720 --> 16:50.280
 like well constructed literature that maybe you tweak with the example a little

16:50.280 --> 16:51.560
 bit to see what it's getting at.

16:51.760 --> 16:55.880
 But in that way, I do think like a video can get most of the benefits of the

16:56.080 --> 17:00.280
 interactive, like the interactive app, as long as you make the interactive for

17:00.280 --> 17:04.120
 yourself and you decide what the best narrative to spin is.

17:04.320 --> 17:07.760
 As a more concrete example, like my process with I made this video about

17:07.760 --> 17:12.840
 SIR models for epidemics and it's like this agent based bottling thing where you

17:13.040 --> 17:15.680
 tweak some things about how the epidemic spreads and you want to see how that

17:15.880 --> 17:18.000
 affects its evolution.

17:18.200 --> 17:21.240
 My format for making that was very different than others,

17:21.240 --> 17:25.040
 where rather than scripting it ahead of time, I just made the playground and then

17:25.240 --> 17:30.040
 I played a bunch and then I saw what stories there were to tell within that.

17:30.240 --> 17:30.760
 Yeah, that's cool.

17:30.960 --> 17:32.800
 So your video had that kind of structure.

17:33.000 --> 17:36.720
 It had like five or six stories or whatever it was.

17:36.720 --> 17:41.600
 And like it was basically, OK, here's a simulation, here's a model.

17:41.800 --> 17:44.040
 What can we discover with this model?

17:44.240 --> 17:46.800
 And here's five things I found after playing with it.

17:47.000 --> 17:51.040
 Well, because here the thing is a way that you could do that project is you make

17:51.040 --> 17:54.040
 the model and then you put it out and you say, here's a thing for the world to

17:54.040 --> 17:57.280
 play with, like come to my website where you interact with this thing.

17:57.480 --> 18:01.880
 And people did like sort of remake it in a JavaScript way so that you can go to

18:01.880 --> 18:04.320
 that website and you can test your own hypotheses.

18:04.320 --> 18:08.160
 But I think a meaningful part of the value to add is not just the technology,

18:08.160 --> 18:10.240
 but to give the story around it as well.

18:10.440 --> 18:12.480
 And like that's kind of my job.

18:12.680 --> 18:16.080
 It's not just to like make the the visuals that someone will look at.

18:16.080 --> 18:20.680
 It's to be the one to decide what's the interesting thing to walk through here.

18:20.880 --> 18:23.680
 And even though there's lots of other interesting paths that one could take,

18:23.680 --> 18:26.480
 that can be kind of daunting when you're just sitting there in a sandbox and

18:26.480 --> 18:29.280
 you're given this tool with like five different sliders and you're told to

18:29.280 --> 18:31.040
 like play and discover things.

18:31.040 --> 18:34.400
 It's like, where do you do? What do you start? What are my hypotheses?

18:34.400 --> 18:35.400
 What should I be asking?

18:35.400 --> 18:39.200
 Like a little bit of guidance in that direction can be what actually sparks

18:39.200 --> 18:42.720
 curiosity to make someone want to imagine more about it.

18:43.000 --> 18:44.800
 A few videos I've seen you do.

18:45.000 --> 18:49.440
 I don't know how often you do it, but there's almost a tangential like pause

18:49.440 --> 18:52.040
 where you here's a cool thing.

18:52.040 --> 18:55.880
 You say like, here's a cool thing, but it's outside the scope of this video,

18:55.880 --> 19:00.200
 essentially, but I'll leave it to you as homework, essentially, to like figure

19:00.200 --> 19:02.200
 out, it's a cool thing to explore.

19:02.680 --> 19:06.080
 I wish I could say that wasn't a function of laziness, right?

19:06.080 --> 19:09.640
 And that's like you've worked so hard on making the 20 minutes already that

19:09.640 --> 19:11.800
 to extend it out even further would take more time.

19:12.040 --> 19:16.920
 And one of your cooler videos, the homomorphic, like from the mobius strip

19:16.920 --> 19:18.880
 to the mobius striped rectangle.

19:18.880 --> 19:24.840
 Yeah, that's a super and you're like, yeah, you can't, you can't transform

19:24.840 --> 19:33.040
 the mobius strip into a into a surface without intersecting itself.

19:33.560 --> 19:36.240
 But I'll leave it to you to see why that is.

19:37.680 --> 19:41.160
 I hope that's not exactly how I phrase it, because I think what my hope would be

19:41.160 --> 19:44.720
 is that I leave it to you to think about why you would expect that to be true.

19:45.000 --> 19:49.520
 And then to want to know what aspects of a mobius strip do you want to formalize

19:49.520 --> 19:51.480
 such that you can prove that intuition that you have?

19:51.480 --> 19:55.920
 Because at some point now you're starting to invent algebraic topology.

19:56.280 --> 20:00.040
 If you have these vague instincts, like I want to get this mobius strip.

20:00.040 --> 20:06.640
 I want to fit it such that it's all above the plane, but its boundary sits

20:06.640 --> 20:07.640
 exactly on the plane.

20:07.800 --> 20:10.920
 I don't think I can do that without crossing itself, but that feels really vague.

20:10.920 --> 20:11.800
 How do I formalize it?

20:11.800 --> 20:15.920
 And as you're starting to formalize that, that's what's going to get you to try

20:15.920 --> 20:19.080
 to come up with a definition for what it means to be orientable or not orientable.

20:19.080 --> 20:22.440
 And once you have that motivation, a lot of the otherwise arbitrary things that

20:22.440 --> 20:26.440
 are sitting at the very beginning of a topology textbook start to make a little more sense.

20:27.000 --> 20:31.920
 Yeah, and I mean that whole video beautifully was a motivation for topology school.

20:32.320 --> 20:36.800
 Well, my hope with that is I feel like topology is, I don't want to say it's taught wrong,

20:36.800 --> 20:42.000
 but I do think sometimes it's popularized in the wrong way, where you'll hear these

20:42.000 --> 20:45.400
 things with people saying, oh, topologists, they're very interested in surfaces that you

20:45.400 --> 20:49.240
 can bend and stretch, but you can't cut or glue.

20:49.640 --> 20:50.640
 Are they?

20:50.640 --> 20:51.640
 Why?

20:52.080 --> 20:56.560
 There's all sorts of things you can be interested in with random imaginative manipulations of

20:56.560 --> 20:57.080
 things.

20:57.080 --> 20:59.160
 Is that really what mathematicians are into?

20:59.600 --> 21:02.560
 And the short answer is not, not really.

21:02.560 --> 21:07.320
 That's, it's not as if someone was sitting there thinking like, I wonder what the properties

21:07.320 --> 21:08.120
 of clay are.

21:08.120 --> 21:12.200
 If I had some arbitrary rules about what, when I can't cut it and when I can't glue it.

21:12.200 --> 21:19.160
 Instead, it's, there's a ton of pieces of math that can actually be equivalent to like

21:19.160 --> 21:23.440
 these very general structures that's like geometry, except you don't have exact distances.

21:23.440 --> 21:25.200
 You just want to maintain a notion of closeness.

21:25.600 --> 21:30.800
 And once you get it to those general structures, constructing mappings between them translate

21:30.800 --> 21:33.640
 into non trivial facts about other parts of math.

21:34.280 --> 21:37.680
 And that, I just, I don't think that's actually like popularized.

21:38.120 --> 21:41.120
 I don't even think it's emphasized well enough when you're starting to take a topology

21:41.120 --> 21:44.960
 class, because you kind of have these two problems is like either it's too squishy,

21:44.960 --> 21:49.160
 you're just talking about coffee mugs and donuts, or it's a little bit too rigor first.

21:49.360 --> 21:53.440
 And you're talking about the axiom systems with open sets.

21:53.760 --> 21:56.240
 And an open set is not the opposite of closed set.

21:56.240 --> 21:57.520
 So sorry about that, everyone.

21:57.520 --> 22:01.040
 We have a notion of clop in sets for ones that are both at the same time.

22:02.240 --> 22:07.000
 And just, it's not, it's not an intuitive axiom system in comparison to other fields of math.

22:07.040 --> 22:10.040
 So you as a student, like really have to walk through mud to get there.

22:10.040 --> 22:13.000
 And you're constantly confused about how this relates to the beautiful things about

22:13.000 --> 22:15.360
 coffee mugs and mobius strips and such.

22:15.600 --> 22:20.200
 And it takes a really long time to actually see, like see topology in the way that

22:20.200 --> 22:21.560
 mathematicians see topology.

22:21.880 --> 22:23.400
 But I don't think it needs to take that time.

22:23.400 --> 22:27.320
 I think there's, this is making me feel like I need to make more videos on the top

22:27.320 --> 22:28.560
 because I think I've learned that to you.

22:28.560 --> 22:29.560
 100% you do.

22:29.560 --> 22:35.680
 But, you know, I've also seen it in my narrow view of like, I find game theory very beautiful.

22:35.680 --> 22:40.600
 And I know topology has been used elegantly to prove things in game theory.

22:40.600 --> 22:40.960
 Yeah.

22:40.960 --> 22:43.040
 You have like facts that seem very strange.

22:43.040 --> 22:47.200
 Like I could tell you, you stir your coffee and after you stir it and like,

22:47.200 --> 22:49.280
 let's say all the molecules settled to like not moving again.

22:49.280 --> 22:52.400
 One of the molecules will be basically in the same position it was before.

22:53.400 --> 22:56.160
 You have all sorts of fixed point theorems like this, right?

22:56.400 --> 22:59.760
 That kind of fixed point theorem directly relevant to Nash Equilibrium.

22:59.760 --> 23:00.360
 Right.

23:01.120 --> 23:05.240
 So you can imagine popularizing it by describing the coffee fact, but then you're

23:05.240 --> 23:08.840
 left to wonder like, who cares about if a molecule of coffee like stays in the same spot?

23:08.840 --> 23:10.520
 Is this what we're paying our mathematicians for?

23:11.240 --> 23:15.680
 You have this very elegant mapping onto economics in a way that's very concrete or very,

23:15.680 --> 23:20.280
 I shouldn't say concrete, very tangible, like actually adds value to people's lives

23:20.280 --> 23:21.440
 through the predictions that it makes.

23:22.560 --> 23:27.080
 But that line isn't always drawn because you have to get a little bit technical in order to

23:28.160 --> 23:29.600
 properly draw that line out.

23:30.480 --> 23:34.920
 And often I think popularized forms of media just shy away from being

23:34.920 --> 23:37.160
 a little too technical for sure.

23:37.160 --> 23:41.800
 By the way, for people who are watching the video, I do not condone the message in this mug.

23:41.800 --> 23:45.160
 It's the only one I have, which is this, the snuggle is real.

23:46.520 --> 23:49.400
 By the way, for anyone watching, I do condone the message of that mug.

23:49.400 --> 23:50.160
 The snuggle is real.

23:50.160 --> 23:51.040
 The snuggle is real.

23:51.040 --> 23:51.680
 Okay.

23:51.680 --> 23:54.800
 So you mentioned the SIR model.

23:56.480 --> 24:01.800
 I think there are certain ideas there of growth, of exponential growth.

24:01.800 --> 24:09.920
 What maybe have you learned about pandemics from making that video?

24:09.920 --> 24:11.600
 Because it was kind of exploratory.

24:11.600 --> 24:13.320
 You were kind of building up an intuition.

24:13.320 --> 24:16.160
 And it's again, people should watch the video.

24:16.160 --> 24:17.640
 It's kind of an abstract view.

24:17.640 --> 24:24.040
 It's not really modeling in detail, the whole field of epidemiology.

24:24.040 --> 24:29.600
 Those people, they go really far in terms of modeling.

24:29.600 --> 24:34.600
 Like how people move about, I don't know if you've seen it, but there is the mobility patterns.

24:34.600 --> 24:41.600
 How many people you encounter in certain situations, when you go to a school, when you go to a mall,

24:41.600 --> 24:44.600
 they model every aspect of that for a particular city.

24:44.600 --> 24:47.600
 They have maps of actual city streets.

24:47.600 --> 24:49.600
 They model it really well.

24:49.600 --> 24:52.600
 And natural patterns of the people have, it's crazy.

24:52.600 --> 24:53.600
 So you don't do any of that.

24:53.600 --> 24:56.600
 You're just doing an abstract model to explore different ideas.

24:56.600 --> 24:59.600
 Simple pedagogy.

24:59.600 --> 25:02.600
 I don't want to pretend like I'm an epidemiologist.

25:02.600 --> 25:04.600
 We have a ton of armchair epidemiologists.

25:04.600 --> 25:12.600
 And the spirit of that was more, can we through a little bit of play draw reasonableish conclusions?

25:12.600 --> 25:18.600
 And also just get ourselves in a position where we can judge the validity of a model.

25:18.600 --> 25:20.600
 I think people should look at that and they should criticize it.

25:20.600 --> 25:22.600
 They should point to all the ways that it's wrong.

25:22.600 --> 25:25.600
 Because it's definitely naive in the way that it's set up.

25:25.600 --> 25:28.600
 But to say, what lessons from that hold?

25:28.600 --> 25:33.600
 Thinking about the R0 value and what that represents and what it can imply.

25:33.600 --> 25:34.600
 What's R0?

25:34.600 --> 25:40.600
 So R0 is if you are infectious and you're in a population which is completely susceptible,

25:40.600 --> 25:46.600
 what's the average number of people that you're going to infect during your infectiousness?

25:46.600 --> 25:52.600
 So certainly during the beginning of an epidemic, this basically gives you kind of the exponential growth rate.

25:52.600 --> 25:58.600
 Like if every person infects two others, you've got that one, two, four, eight exponential growth pattern.

25:58.600 --> 26:07.600
 As it goes on, and let's say it's something endemic where you've got like a ton of people who have had it and are recovered,

26:07.600 --> 26:14.600
 then the R0 value doesn't tell you that as directly because a lot of the people you interact with aren't susceptible.

26:14.600 --> 26:16.600
 But in the early phases, it does.

26:16.600 --> 26:23.600
 And this is like the fundamental constant that it seems like epidemiologists look at and the whole goal is to get that down.

26:23.600 --> 26:26.600
 If you can get it below one, then it's no longer epidemic.

26:26.600 --> 26:30.600
 If it's equal to one, then it's endemic and it's above one, then you're epidemic.

26:30.600 --> 26:38.600
 So just teaching what that value is and giving some intuitions on how do certain changes in behavior change that value?

26:38.600 --> 26:40.600
 And then what does that imply for exponential growth?

26:40.600 --> 26:52.600
 I think those are general enough lessons and they're resilient to all of the chaos of the world that it's still valid to take from the video.

26:52.600 --> 26:55.600
 I mean, one of the interesting aspects of that is just exponential growth.

26:55.600 --> 26:57.600
 We think about growth.

26:57.600 --> 27:01.600
 Is that one of the first times you've done a video on...

27:01.600 --> 27:03.600
 No, of course not.

27:03.600 --> 27:07.600
 The whole Weller's identity.

27:07.600 --> 27:14.600
 Sure. I've done a lot of videos about exponential growth in the circular direction, only minimal in the normal direction.

27:14.600 --> 27:24.600
 I mean, another way to ask, do you think we're able to reason intuitively about exponential growth?

27:24.600 --> 27:28.600
 It's funny. I think it's extremely intuitive to humans.

27:28.600 --> 27:31.600
 And then we train it out of ourselves such that it's then really not intuitive.

27:31.600 --> 27:35.600
 And then I think it can become intuitive again when you study a technical field.

27:35.600 --> 27:47.600
 So what I mean by that is, have you ever heard of these studies where in a anthropological setting where you're studying a group that has been disassociated from a lot of modern society?

27:47.600 --> 27:51.600
 And you ask, what number is between one and nine?

27:51.600 --> 27:54.600
 And maybe you would ask, you've got one rock and you've got nine rocks.

27:54.600 --> 27:56.600
 You're like, what pile is halfway in between these?

27:56.600 --> 27:59.600
 And our instinct is usually to say five.

27:59.600 --> 28:01.600
 That's the number that sits right between one and nine.

28:01.600 --> 28:10.600
 But sometimes when numeracy and the kind of just basic arithmetic that we have isn't in a society, the natural instinct is three.

28:10.600 --> 28:18.600
 Because it's in between in an exponential sense and a geometric sense that one is three times bigger and then the next one is three times bigger than that.

28:18.600 --> 28:22.600
 So it's like, if you have one friend versus a hundred friends, what's in between that?

28:22.600 --> 28:26.600
 Ten friends seems like the social status in between those two states.

28:26.600 --> 28:30.600
 So that's deeply intuitive to us to think logarithmically like that.

28:30.600 --> 28:35.600
 And for some reason, we kind of train it out of ourselves to start thinking linearly about things.

28:35.600 --> 28:42.600
 So in the sense, the early basic math forces us to take a step back.

28:42.600 --> 28:59.600
 It's the same criticism if there's any of science is the lessons of science make us see the world in a slightly narrow sense to where we have an over exaggerated confidence that we understand everything.

28:59.600 --> 29:03.600
 It's supposed to just understanding a small slice of it.

29:03.600 --> 29:10.600
 But I think that probably only really goes for small numbers because the real counterintuitive thing about exponential growth is like as the numbers start to get big.

29:10.600 --> 29:18.600
 So I bet if you took that same setup and you asked them, oh, if I keep tripling the size of this rock pile seven times, how big will it be?

29:18.600 --> 29:23.600
 I bet it would be surprisingly big even to a society without numeracy.

29:23.600 --> 29:30.600
 And that's the side of it that I think is pretty counterintuitive to us, but that you can basically train into people.

29:30.600 --> 29:42.600
 I think computer scientists and physicists when they were looking at the early numbers of COVID, they were the ones thinking like, oh, God, this is following an exact exponential curve.

29:42.600 --> 29:45.600
 And I heard that from a number of people.

29:45.600 --> 29:51.600
 And almost all of them are techies in some capacity, probably just because I live in the Bay Area.

29:51.600 --> 30:01.600
 But for sure, they're cognizant of this kind of growth that's present in a lot of national systems and a lot of systems.

30:01.600 --> 30:16.600
 I don't know if you've seen like, I mean, there's a lot of ways to visualize this, obviously, but Raker as well, I think was the one that had this like chessboard where every square on the chessboard, you double the number of stones or something in that chessboard.

30:16.600 --> 30:26.600
 I've heard this is like an old proverb where someone, the king offered him a gift and he said, the only gift I would like very modest, give me a single grain of rice for the first chessboard.

30:26.600 --> 30:32.600
 And then two grains of rice for the next square, then twice that for the next square and just continue on.

30:32.600 --> 30:34.600
 That's my only modest ask your sire.

30:34.600 --> 30:41.600
 And it's all more grains of rice than there are anything in the world by the time you get to the end.

30:41.600 --> 30:53.600
 And my intuition falls apart there, like I would have never predicted that, like for some reason, that's a really compelling illustration how poorly breaks down.

30:53.600 --> 31:00.600
 Just like you said, maybe we're okay for the first few piles of rocks, but after a while, it's game over.

31:00.600 --> 31:11.600
 You know, the other classic example for gauging someone's intuitive understanding of exponential growth is I've got like a lily pad on a really big lake, like Lake Michigan.

31:11.600 --> 31:17.600
 And that lily pad replicates, it doubles one day and then it doubles the next day and it doubles the next day.

31:17.600 --> 31:22.600
 And after 50 days, it actually is going to cover the entire lake.

31:22.600 --> 31:26.600
 So after how many days does it cover half the lake?

31:26.600 --> 31:27.600
 49.

31:27.600 --> 31:30.600
 So you have a good instinct for exponential growth.

31:30.600 --> 31:42.600
 So I think a lot of like the knee jerk reaction is sometimes to think that it's like half the amount of time or to at least be like surprised that like after 49 days, you've only covered half of it.

31:42.600 --> 31:45.600
 Yeah, I mean, that's the reason you heard a pause from me.

31:45.600 --> 31:48.600
 I literally thought that can't be right.

31:48.600 --> 31:49.600
 Exactly.

31:49.600 --> 31:56.600
 So even when you know the fact and you do the division, it's like, wow, so you've gone like that whole time and then day 49, it's only covering half.

31:56.600 --> 31:58.600
 And then after that, it gets the whole thing.

31:58.600 --> 32:05.600
 But I think you can make that even more visceral if rather than going one day before you say how long until it's covered 1% of the lake, right?

32:05.600 --> 32:07.600
 And it's, so what would that be?

32:07.600 --> 32:10.600
 How many times you have to double to get over 100?

32:10.600 --> 32:12.600
 Like seven, six and a half times something like that.

32:12.600 --> 32:13.600
 Right.

32:13.600 --> 32:17.600
 So at that point, you're looking at 43, 44 days into it.

32:17.600 --> 32:19.600
 You're not even at 1% of the lake.

32:19.600 --> 32:24.600
 So you've experienced, you know, 44 out of 50 days and you're like, yeah, that lily pad, it's just 1% of the lake.

32:24.600 --> 32:27.600
 But then next thing you know, it's the entire lake.

32:27.600 --> 32:29.600
 You're wearing a SpaceX shirt.

32:29.600 --> 32:41.600
 So let me ask you one person who talks about exponential, you know, just the miracle of the exponential function in general is Elon Musk.

32:41.600 --> 33:02.600
 So he kind of advocates the idea of exponential thinking, you know, realizing that technological development can, at least in the short term, follow exponential improvement, which breaks apart our intuition, our ability to reason about what isn't, isn't impossible.

33:02.600 --> 33:12.600
 So he's a big, one, it's a good leadership kind of style of saying like, look, the thing that everyone thinks is impossible is actually possible because exponentials.

33:12.600 --> 33:19.600
 But what's your sense about, about that kind of way to see the world?

33:19.600 --> 33:29.600
 Well, so I think it's, it can be very inspiring to note when something like Moore's law is another great example where you have this exponential pattern that holds shockingly well.

33:29.600 --> 33:33.600
 And it enables just better lives to be led.

33:33.600 --> 33:42.600
 I think the people who took Moore's law seriously in the 60s were seeing that, wow, it's not going to be too long before like these giant computers that are either batch processing or time shared.

33:42.600 --> 33:46.600
 You could actually have one small enough to put on your desk on top of your desk and you could do things.

33:46.600 --> 33:50.600
 And if they took it seriously, like you have people predicting smartphones like a long time ago.

33:50.600 --> 33:57.600
 And it's only out of like kind of this, I don't want to say faith in exponentials, but an understanding that that's what's happening.

33:57.600 --> 34:08.600
 What's more interesting, I think, is to really understand why exponential growth happens and that the mechanism behind it is when the rate of change is proportional to the thing in and of itself.

34:08.600 --> 34:15.600
 So the reason that technology would grow exponentially is only going to be if the rate of progress is proportional to the amount that you have.

34:15.600 --> 34:20.600
 So that the software you write enables you to write more software.

34:20.600 --> 34:29.600
 And I think we see this with the internet, like the advent of the internet makes it faster to learn things, which makes it faster to create new things.

34:29.600 --> 34:41.600
 I think this is oftentimes why like investment will grow exponentially that the more resources a company has, if it knows how to use them well, the more it can actually grow.

34:41.600 --> 34:47.600
 So I mean, you know, you reference Elon Musk, I think he seems to really be into vertically integrating his companies.

34:47.600 --> 34:55.600
 And I think a big part of that is because you have the sense what you want is to make sure that the things that you develop, you have ownership of and they enable further development of the adjacent parts.

34:55.600 --> 35:00.600
 So it's not just this, you see a curve and you're blindly drawing a line through it.

35:00.600 --> 35:05.600
 What's much more interesting is to ask, when do you have this proportional growth property?

35:05.600 --> 35:11.600
 Because then you can also recognize when it breaks down, like in an epidemic, as you approach saturation, that would break down.

35:11.600 --> 35:21.600
 As you do anything that skews what that proportionality constant is, you can make it maybe not break down as being an exponential, but it can seriously slow what that exponential rate is.

35:21.600 --> 35:31.600
 The opposite of a pandemic is you want, in terms of ideas, you want to minimize barriers that prevent the spread.

35:31.600 --> 35:33.600
 You want to maximize the spread of impact.

35:33.600 --> 35:41.600
 So you want it to grow when you're doing technological development so that you do hold up, that rate holds up.

35:41.600 --> 35:53.600
 And that's almost like an operational challenge of how you run a company, how you run a group of people, is that any one invention has a ripple that's unstopped.

35:53.600 --> 35:57.600
 And that ripple effect then has its own ripple effects and so on.

35:57.600 --> 35:58.600
 And that continues.

35:58.600 --> 36:06.600
 Yeah, like Moore's Law is fascinating on a psychological level, on a human level, because it's not exponential.

36:06.600 --> 36:17.600
 It's just a consistent set of what you would call like S curves, which is like it's constantly like breakthrough innovations nonstop.

36:17.600 --> 36:18.600
 That's a good point.

36:18.600 --> 36:27.600
 It might not actually be an example of exponentials because of something which grows in proportion to itself, but instead, it's almost like a benchmark that was set out that everyone's been pressured to meet.

36:27.600 --> 36:37.600
 And it's like all these innovations and micro inventions along the way, rather than some consistent sit back and just let the lily pad grow across the lake phenomenon.

36:37.600 --> 36:41.600
 And it's also that there's a human psychological level for sure of like the four minute mile.

36:41.600 --> 36:49.600
 There's something about it like saying that, look, there is Moore's Law.

36:49.600 --> 36:50.600
 It's a law.

36:50.600 --> 37:00.600
 So like it's certainly an achievable thing, you know, we achieved it for the last decade, for the last two decades, for the last three decades, you just keep going.

37:00.600 --> 37:03.600
 And it somehow makes it happen.

37:03.600 --> 37:15.600
 I mean, it makes people, I'm continually surprised in this world how few people do the best work in the world, like in that particular, whatever that field is.

37:15.600 --> 37:34.600
 Like it's very often that like the genius, I mean, you could argue that community matters, but it's certain like I've been in groups of engineers where like one person is clearly like doing an incredible amount of work and just is the genius.

37:34.600 --> 37:52.600
 And it's fascinating to see basically it's kind of the Steve Jobs idea is maybe the whole point is to create an atmosphere where the genius can discover themselves, like have the opportunity to do the best work of their life.

37:52.600 --> 38:04.600
 And yeah, and that the exponential is just milking that it's like rippling the idea that it's possible and that idea that it's possible finds the right people for the four minute mile.

38:04.600 --> 38:11.600
 The idea that it's possible finds the right runners to run it and then expose a number of people who can run faster than four minutes.

38:11.600 --> 38:14.600
 It's kind of interesting to, I don't know.

38:14.600 --> 38:22.600
 Basically, the positive way to see that is most of us are way more intelligent, have way more potential than we ever realize.

38:22.600 --> 38:23.600
 I guess that's kind of depressing.

38:23.600 --> 38:27.600
 But I mean, like the ceiling for most of us is much higher than we ever realize.

38:27.600 --> 38:28.600
 That is true.

38:28.600 --> 38:41.600
 A good book to read if you want that sense is Peak, which essentially talks about peak performance in a lot of different ways, like, you know, chess, London cab drivers, how many push ups people can do short term memory tasks.

38:41.600 --> 38:47.600
 And if there's one, it's meant to be like a concrete manifesto about deliberate practice and such.

38:47.600 --> 38:55.600
 But the one sensation you come out with is, wow, no matter how good people are at something, they can get better and like way better than we think they could.

38:55.600 --> 39:00.600
 I don't know if that's actually related to exponential growth, but I do think it's a true phenomenon.

39:00.600 --> 39:01.600
 It's interesting.

39:01.600 --> 39:07.600
 Yeah, I mean, there's certainly no law of exponential growth in human innovation.

39:07.600 --> 39:09.600
 Well, I don't know.

39:09.600 --> 39:11.600
 Well, kind of there is.

39:11.600 --> 39:15.600
 I think it's very interesting to see when innovations in one field allow for innovations in another.

39:15.600 --> 39:19.600
 Like the advent of computing seems like a prerequisite for the advent of chaos theory.

39:19.600 --> 39:24.600
 You have this truth about physics and the world that in theory could be known.

39:24.600 --> 39:27.600
 You could find Lorenzo's equations without computers.

39:27.600 --> 39:35.600
 But in practice, it was just never going to be analyzed that way unless you were doing like a bunch of simulations and that you could computationally see these models.

39:35.600 --> 39:37.600
 So it's like physics allowed for computers.

39:37.600 --> 39:41.600
 Computers allowed for better physics and, you know, wash, rinse and repeat.

39:41.600 --> 39:45.600
 That self proportionality, that's exponential.

39:45.600 --> 39:50.600
 So I think it's too far to say that that's a law of some kind.

39:50.600 --> 40:03.600
 Yeah, a fundamental law of the universe is that these descendants of apes will exponentially improve their technology in one day be taken over by the AGI.

40:03.600 --> 40:08.600
 That's built in the simulation. That'll make the video game fun whoever created this thing.

40:08.600 --> 40:12.600
 I mean, since you're wearing a SpaceX shirt, let me ask.

40:12.600 --> 40:14.600
 I didn't realize that.

40:14.600 --> 40:15.600
 I apologize.

40:15.600 --> 40:17.600
 It's on topic.

40:17.600 --> 40:28.600
 So Crew Dragon, the first crewed mission out into space since the space shuttle.

40:28.600 --> 40:37.600
 And just by first time ever by a commercial company, I mean, it's an incredible accomplishment, I think.

40:37.600 --> 40:49.600
 But it's also just an incredible, it inspires imagination amongst people that this is the first step in a long, like, vibrant journey of humans into space.

40:49.600 --> 40:50.600
 Oh, yeah.

40:50.600 --> 40:52.600
 So what are your, how do you feel?

40:52.600 --> 40:54.600
 Is this, you know, is this exciting to you?

40:54.600 --> 40:56.600
 Yeah, it is. I think it's great.

40:56.600 --> 41:00.600
 The idea of seeing it basically done by smaller entities instead of by governments.

41:00.600 --> 41:14.600
 I mean, it's a heavy collaboration between SpaceX and NASA in this case, but moving in the direction of not necessarily requiring an entire country and its government to make it happen, but that you can have something closer to a single company doing it.

41:14.600 --> 41:20.600
 We're not there yet because it's not like they're unilaterally saying, like, we're just shooting people up into space.

41:20.600 --> 41:25.600
 It's just a sign that we're able to do more powerful things with smaller groups of people.

41:25.600 --> 41:27.600
 I find that inspiring.

41:27.600 --> 41:28.600
 Innovate quickly.

41:28.600 --> 41:30.600
 I hope we see people land on Mars in my lifetime.

41:30.600 --> 41:32.600
 Do you think we will?

41:32.600 --> 41:35.600
 I think so. I mean, I think there's a ton of challenges there, right?

41:35.600 --> 41:37.600
 Like radiation being kind of the biggest one.

41:37.600 --> 41:41.600
 And I think there's a ton of people who look at that and say, why?

41:41.600 --> 41:43.600
 Why would you want to do that?

41:43.600 --> 41:45.600
 Let's let the robots do the science for us.

41:45.600 --> 41:57.600
 But I think there's enough people who are genuinely inspired about broadening the worlds that we've touched or people who think about things like backing up the light of consciousness with super long term visions of terraforming.

41:57.600 --> 42:00.600
 Sorry, backing up the light of consciousness?

42:00.600 --> 42:06.600
 Yeah, the thought that if Earth goes to hell, we got to have a backup somewhere.

42:06.600 --> 42:12.600
 A lot of people see that as pretty out there and it's not in the short term future, but I think that's an inspiring thought.

42:12.600 --> 42:18.600
 I think that's a reason to get up in the morning and I feel like most employees at SpaceX feel that way too.

42:18.600 --> 42:20.600
 Do you think we'll colonize Mars one day?

42:20.600 --> 42:21.600
 No idea.

42:21.600 --> 42:25.600
 Like either AGI kills us first or if we're allowed, I don't know if it'll take a second.

42:25.600 --> 42:26.600
 For allowed?

42:26.600 --> 42:29.600
 Honestly, it would take such a long time.

42:29.600 --> 42:31.600
 Like, okay, you might have a small colony, right?

42:31.600 --> 42:38.600
 Something like what you see in the Martian, but not like people living comfortably there.

42:38.600 --> 42:48.600
 But if you want to talk about actual like second Earth kind of stuff, that's just like way far out there and the future moves so fast.

42:48.600 --> 42:49.600
 It's hard to predict.

42:49.600 --> 42:53.600
 It's like we might just kill ourselves before that even becomes viable.

42:53.600 --> 42:58.600
 Yeah, I mean, there's a lot of possibilities where it could be just, it doesn't have to be on a planet.

42:58.600 --> 43:04.600
 We could be floating out in space, have a space faring backup solution.

43:04.600 --> 43:09.600
 That doesn't have to deal with the constraints that a planet provides.

43:09.600 --> 43:13.600
 A planet provides a lot of possibilities and resources, but also some constraints.

43:13.600 --> 43:19.600
 Yeah, I mean, for me, for some reason, it's a deeply exciting possibility.

43:19.600 --> 43:20.600
 Oh, yeah.

43:20.600 --> 43:25.600
 All of the people who are skeptical about it are like, why do we care about going to Mars?

43:25.600 --> 43:28.600
 It's like, what makes you care about anything if that's inspiring?

43:28.600 --> 43:29.600
 It's hard.

43:29.600 --> 43:37.600
 It's hard to hear that because exactly as you put it on a philosophical level, it's hard to say why do anything.

43:37.600 --> 43:38.600
 I don't know.

43:38.600 --> 43:46.600
 It's like the people say like, you know, I've been doing like an insane challenge last 30 something days.

43:46.600 --> 43:47.600
 Your pull ups.

43:47.600 --> 43:54.600
 And the pull ups and push ups and like, you know, a bunch of people are like, awesome.

43:54.600 --> 43:56.600
 You're insane, but awesome.

43:56.600 --> 43:59.600
 And then some people are like, why?

43:59.600 --> 44:00.600
 Why do anything?

44:00.600 --> 44:02.600
 I don't know.

44:02.600 --> 44:04.600
 There's a calling.

44:04.600 --> 44:09.600
 I'm with JFK a little bit because we do these things because they're hard.

44:09.600 --> 44:13.600
 There's something in the human spirit that says like, same with like a math problem.

44:13.600 --> 44:19.600
 There's something you fail once and it's like this feeling that, you know what?

44:19.600 --> 44:21.600
 I'm not going to back down from this.

44:21.600 --> 44:24.600
 There's something to be discovered in overcoming this thing.

44:24.600 --> 44:28.600
 Well, so what I like about it is, and I also like this about the moon missions.

44:28.600 --> 44:31.600
 Sure, it's kind of arbitrary, but you can't move the target.

44:31.600 --> 44:35.600
 So you can't make it easier and say that you've accomplished the goal.

44:35.600 --> 44:38.600
 And when that happens, it just demands actual innovation, right?

44:38.600 --> 44:44.600
 Like protecting humans from the radiation in space on the flight there while there.

44:44.600 --> 44:46.600
 Hard problem demands innovation.

44:46.600 --> 44:48.600
 You can't move the goalpost to make that easier.

44:48.600 --> 44:53.600
 Almost certainly the innovations required for things like that will be relevant in a bunch of other domains too.

44:53.600 --> 44:59.600
 So like the idea of doing something merely because it's hard, it's like loosely productive, great.

44:59.600 --> 45:06.600
 But as long as you can't move the goalposts, there's probably going to be these secondary benefits that we should all strive for.

45:06.600 --> 45:14.600
 Yeah, I mean, it's hard to formulate the Mars colonization problem as something that has a deadline, which is the problem.

45:14.600 --> 45:28.600
 But if there was a deadline, then the amount of things we would come up with by forcing ourselves to figure out how to colonize that place would be just incredible.

45:28.600 --> 45:40.600
 This is what people, like the internet didn't get created because people sat down and tried to figure out how do I, you know, send TikTok videos of myself dancing to people.

45:40.600 --> 45:45.600
 They, you know, it was, there's an application. I mean, actually, I don't even know how.

45:45.600 --> 45:48.600
 What do you think the application for the internet was when it was?

45:48.600 --> 45:54.600
 It must have been very low level basic network communication within DARPA, like military based.

45:54.600 --> 46:02.600
 Like how do I send, like a networking, how do I send information securely between two places?

46:02.600 --> 46:03.600
 Maybe it was an encryption.

46:03.600 --> 46:09.600
 I'm totally speaking totally outside of my knowledge, but like it was probably intended for a very narrow small group of people.

46:09.600 --> 46:19.600
 Well, so I mean, it was, there was like this small community of people who are really interested in time sharing computing and like interactive computing in contrast with batch processing.

46:19.600 --> 46:27.600
 And then the idea that as you set up like a time sharing center, basically meaning kind of multiple people like logged in and using that like central computer.

46:27.600 --> 46:29.600
 Why not make it accessible to others?

46:29.600 --> 46:37.600
 And this was kind of what I had always thought like, oh, is this like fringe group that was interested in this new kind of computing and they all like got themselves together.

46:37.600 --> 46:43.600
 But the thing is like DARPA wouldn't actually, you wouldn't have the US government funding that just for the funds of it, right?

46:43.600 --> 46:53.600
 But in some sense, that's what DARPA was all about was like just really advanced research for the sake of having advanced research and it doesn't have to pay out with utility soon.

46:53.600 --> 47:01.600
 But the core parts of its development were happening like in the middle of the Vietnam War when there was budgetary constraints all over the place.

47:01.600 --> 47:18.600
 I only learned this recently actually like if you look at the documents, basically justifying the budget for the ARPANET as they were developing it and not just keeping it where it was but actively growing it while all sorts of other departments were having their funding cut because of the war.

47:18.600 --> 47:26.600
 A big part of it was national defense in terms of having like a more robust communication system, like the idea of packet switching versus circuit switching.

47:26.600 --> 47:43.600
 You kind of make this case that in some calamitous circumstance where a central location gets nuked, this is a much more resilient way to still have your communication lines that like traditional telephone lines weren't as resilient to, which I just found very interesting.

47:43.600 --> 48:00.600
 I think that even something that we see as so happy go lucky is just a bunch of computer nerds trying to get interactive computing out there. The actual thing that made it funded and thing that made it advance when it did was because of this direct national security question and concern.

48:00.600 --> 48:17.600
 I don't know if you've read it. I haven't read it. I've been meaning to read it but Neil deGrasse Tyson actually came out with a book that talks about like science in the context of the military like basically saying all the great science we've done in the 20th century was like because of the military.

48:17.600 --> 48:31.600
 I mean he paints a positive. It's not like a critical. It's not, you know, a lot of people say like military industrial complex and so on. Another way to see the military and national security is like a source of like you said deadlines and like hard things.

48:31.600 --> 48:37.600
 You can't move like almost, you know, almost like scaring yourself into being productive.

48:37.600 --> 48:47.600
 It is that I mean Manhattan Project is a perfect example. Probably the quintessential example that one is a little bit more macabre than others because of like what they were building.

48:47.600 --> 48:58.600
 But in terms of how many focused smart hours of human intelligence get pointed towards a topic per day, you're just maxing it out with that sense of worry in that context.

48:58.600 --> 49:07.600
 Everyone there was saying like we've got to get the bomb before Hitler does and that like that just lights a fire under you that I again like the circumstances macabre.

49:07.600 --> 49:17.600
 But I think that's actually pretty healthy, especially for researchers that are otherwise going to be really theoretical to take these like theorizers and say make this real physical thing happen.

49:17.600 --> 49:33.600
 Meaning a lot of it is going to be unsexy. A lot of it's going to be like young fine men sitting there kind of inventing a notion of computation in order to like compute what they needed to compute more quickly with like the rudimentary automated tools that they had available.

49:33.600 --> 49:45.600
 I think you see this with Bell Labs also where you've got otherwise very theorizing minds in very pragmatic contexts that I think is like really helpful for the theory as well as for the applications.

49:45.600 --> 49:49.600
 So I think that stuff can be positive for progress.

49:49.600 --> 49:57.600
 You mentioned Bell Labs and Manhattan Project. This kind of makes me curious for the things you've created which are quite singular.

49:57.600 --> 50:15.600
 Like if you look at all YouTube or just not YouTube, it doesn't matter what it is. It's just teaching content art doesn't matter. It's like, yep, that's that's Grant. Right. That's unique. I know you're teaching style and everything.

50:15.600 --> 50:28.600
 Does it? Manhattan Project and Bell Labs was like famously a lot of brilliant people, but there's a lot of them. They play off of each other. So like my question for you is that does it get lonely?

50:28.600 --> 50:38.600
 Honestly, that right there I think is the biggest part of my life that I would like to change in some way that I look at a Bell Labs type situation.

50:38.600 --> 50:46.600
 Like, goddamn, I love that whole situation and I'm so jealous of it. And you're like reading about hamming and then you see that he also shared enough with Shannon.

50:46.600 --> 50:50.600
 And you're like, of course he did. Of course they shared an office. That's how these ideas get like.

50:50.600 --> 50:53.600
 And they actually very likely worked separately.

50:53.600 --> 50:55.600
 Yeah, totally separate.

50:55.600 --> 51:05.600
 But there's a literally, and sorry to interrupt, there's a literally magic that happens when you run into each other like on the way to like getting a snack or something.

51:05.600 --> 51:11.600
 Conversations you over here, it's other projects you're pulled into. It's like puzzles that colleagues are sharing, like all of that.

51:11.600 --> 51:19.600
 I have some extent of it just because I try to stay well connected in communities of people who think in similar ways.

51:19.600 --> 51:24.600
 But it's not in the day to day in the same way, which I would like to fix somehow.

51:24.600 --> 51:43.600
 That's one of the, I would say, one of the biggest, one of the many drawbacks, negative things about this current pandemic is that whatever the term is, but like chance collisions are significantly reduced.

51:43.600 --> 51:53.600
 I saw, I don't know why I saw this, but on my brother's work calendar, he had a scheduled slot with someone that he scheduled a meeting.

51:53.600 --> 51:57.600
 And the title of the whole meeting was no specific agenda.

51:57.600 --> 52:04.600
 I just missed the happenstance serendipitous conversations that we used to have, which the pandemic and remote work has so cruelly taken away from us.

52:04.600 --> 52:05.600
 Brilliant.

52:05.600 --> 52:07.600
 That was the whole title of the meeting.

52:07.600 --> 52:08.600
 Yes, brilliant.

52:08.600 --> 52:10.600
 I'm like, that's the way to do it. You just schedule those things.

52:10.600 --> 52:11.600
 Schedule it.

52:11.600 --> 52:13.600
 You schedule the serendipitous interaction.

52:13.600 --> 52:25.600
 It's like, I mean, you can't do it in an academic setting, but it's basically like going to a bar and sitting there just for the strangers you might meet, just the strangers or striking up conversation with strangers on the train.

52:25.600 --> 52:37.600
 Harder to do when you're deeply like maybe myself or maybe a lot of academic types who are like introverted and avoid human contact as much as possible.

52:37.600 --> 52:43.600
 So it's nice when it's forced to those chance collisions, but maybe scheduling is a possibility.

52:43.600 --> 52:47.600
 But for the most part, do you work alone?

52:47.600 --> 52:50.600
 Like, I'm sure you struggle like a lot.

52:50.600 --> 53:00.600
 Like, you probably hit moments when you look at this and you say, like, this is the wrong way to show it.

53:00.600 --> 53:01.600
 It's a long way to visualize it.

53:01.600 --> 53:03.600
 I'm making it too hard for myself.

53:03.600 --> 53:05.600
 I'm going down the wrong direction.

53:05.600 --> 53:06.600
 This is too long.

53:06.600 --> 53:07.600
 This is too short.

53:07.600 --> 53:10.600
 All those self doubt that could be paralyzing.

53:10.600 --> 53:12.600
 What do you do in those moments?

53:12.600 --> 53:18.600
 Honestly, I actually much prefer work to be a solitary affair for me.

53:18.600 --> 53:19.600
 That's like a personality quirk.

53:19.600 --> 53:24.600
 I would like it to be in an environment with others and collaborative in the sense of ideas exchanged.

53:24.600 --> 53:33.600
 But those phenomena you're describing, when you say this is too long, this is too short, this visualization sucks, it's way easier to say that to yourself than it is to say to a collaborator.

53:33.600 --> 53:35.600
 And I know that's just a thing that I'm not good at.

53:35.600 --> 53:40.600
 So, in that way, it's very easy to just throw away a script because the script isn't working.

53:40.600 --> 53:42.600
 It's hard to tell someone else they should do the same.

53:42.600 --> 53:46.600
 Actually, the last time we talked, I think it was like very close to me talking to Don Knuth.

53:46.600 --> 53:47.600
 It was kind of cool.

53:47.600 --> 53:48.600
 Like two people that...

53:48.600 --> 53:50.600
 Can't believe you got that interview.

53:50.600 --> 53:51.600
 It's hard.

53:51.600 --> 53:53.600
 No, can I brag about something?

53:53.600 --> 53:54.600
 Please.

53:54.600 --> 53:57.600
 My favorite thing is Don Knuth.

53:57.600 --> 54:01.600
 After the interview, he offered to go out to hot dogs with me.

54:01.600 --> 54:03.600
 To get hot dogs.

54:03.600 --> 54:05.600
 That was never...

54:05.600 --> 54:07.600
 People ask me, what's the favorite interview you've ever done?

54:07.600 --> 54:09.600
 I mean, that has to be...

54:09.600 --> 54:11.600
 But unfortunately, I couldn't.

54:11.600 --> 54:12.600
 I had a thing after.

54:12.600 --> 54:14.600
 So, I had to turn down Don Knuth.

54:14.600 --> 54:15.600
 You missed Knuth dogs?

54:15.600 --> 54:16.600
 Knuth dogs.

54:16.600 --> 54:17.600
 Sorry.

54:17.600 --> 54:18.600
 So, that was a little bragging.

54:18.600 --> 54:21.600
 But the hot dogs, he's such a sweet.

54:21.600 --> 54:27.600
 But the reason I bring that up is he works through problems alone as well.

54:27.600 --> 54:31.600
 He prefers that struggle, the struggle of it.

54:31.600 --> 54:39.600
 You know, writers like Stephen King often talk about their process of what they do,

54:39.600 --> 54:47.600
 what they eat when they wake up, when they sit down, how they like their desk.

54:47.600 --> 54:53.600
 On a perfectly productive day, what they like to do, how long they like to work for,

54:53.600 --> 54:57.600
 what enables them to think deeply, all that kind of stuff.

54:57.600 --> 54:59.600
 Hunter Stompson did a lot of drugs.

54:59.600 --> 55:02.600
 Everybody has their own thing.

55:02.600 --> 55:05.600
 Do you have a thing?

55:05.600 --> 55:13.600
 If you were to lay out a perfect productive day, what would that schedule look like, do you think?

55:13.600 --> 55:20.600
 Part of that's hard to answer because the mode of work I do changes a lot from day to day.

55:20.600 --> 55:21.600
 Some days, I'm writing.

55:21.600 --> 55:22.600
 The thing I have to do is write a script.

55:22.600 --> 55:23.600
 Some days, I'm animating.

55:23.600 --> 55:24.600
 The thing I have to do is animate.

55:24.600 --> 55:26.600
 Sometimes, I'm working on the animation library.

55:26.600 --> 55:32.600
 The thing I have to do is, I'm not a software engineer, but something in the direction of software engineering.

55:32.600 --> 55:34.600
 Some days, it's like a variant of research.

55:34.600 --> 55:37.600
 It's like learn this topic well and try to learn it differently.

55:37.600 --> 55:41.600
 So those are like four very different modes of what it...

55:41.600 --> 55:44.600
 Some days, it's like get through the email backlog of people I've been...

55:44.600 --> 55:46.600
 The tasks I've been putting off.

55:46.600 --> 55:56.600
 It goes research, scripting, like the idea starts with research and then there's scripting and then there's programming and then there's the showtime.

55:56.600 --> 56:03.600
 And the research side, by the way, I think a problematic way to do it is to say, I'm starting this project and therefore I'm starting the research.

56:03.600 --> 56:10.600
 Instead, it should be that you're like ambiently learning a ton of things just in the background and then once you feel like you have the understanding for one,

56:10.600 --> 56:13.600
 you put it on the list of things that there can be a video for.

56:13.600 --> 56:21.600
 Otherwise, either you're going to end up roadblock forever or you're just not going to have a good way of talking about it.

56:21.600 --> 56:24.600
 But still, some of the days, it's like the thing to do is learn new things.

56:24.600 --> 56:26.600
 So what's the most painful one?

56:26.600 --> 56:28.600
 I think you mentioned scripting.

56:28.600 --> 56:30.600
 Scripting is, yeah, that's the worst.

56:30.600 --> 56:31.600
 Yeah, writing is the worst.

56:31.600 --> 56:32.600
 So what's your...

56:32.600 --> 56:34.600
 Perfectly, so let's take the hardest one.

56:34.600 --> 56:36.600
 What's a perfectly productive day?

56:36.600 --> 56:41.600
 You wake up and it's like, damn it, this is the day I need to do some scripting.

56:41.600 --> 56:45.600
 And you didn't do anything the last two days, so you came up with excuses to procrastinate.

56:45.600 --> 56:47.600
 So today must be the day.

56:47.600 --> 56:49.600
 Yeah, I wake up early.

56:49.600 --> 56:55.600
 I guess I exercise and then I turn the internet off.

56:55.600 --> 57:00.600
 If we're writing, yeah, that's what's required is having the internet off.

57:00.600 --> 57:04.600
 And then maybe you keep notes on the things that you want to Google when you're allowed to have the internet again.

57:04.600 --> 57:08.600
 I'm not great about doing that, but when I do, that makes it happen.

57:08.600 --> 57:12.600
 And then when I hit writer's block, the solution to writer's block is to read.

57:12.600 --> 57:15.600
 It doesn't even have to be related, just read something different.

57:15.600 --> 57:19.600
 Just for like 15 minutes, half an hour, and then go back to writing.

57:19.600 --> 57:22.600
 That, when it's a nice cycle, I think can work very well.

57:22.600 --> 57:27.600
 And when you're writing the script, you don't know where it ends, right?

57:27.600 --> 57:29.600
 Problem solving videos, I know where it ends.

57:29.600 --> 57:32.600
 Expositional videos, I don't know where it ends.

57:32.600 --> 57:38.600
 Coming up with the magical thing that ties this whole story together.

57:38.600 --> 57:40.600
 When does that happen?

57:40.600 --> 57:44.600
 That's the thing that makes it such that a topic gets put on the list.

57:44.600 --> 57:46.600
 Oh, that's an issue.

57:46.600 --> 57:49.600
 You shouldn't start the project unless there's one of those.

57:49.600 --> 57:51.600
 You have so many nice bags.

57:51.600 --> 57:55.600
 You have such a big bag of aha moments already that you could just pull at it.

57:55.600 --> 57:57.600
 That's one of the things.

57:57.600 --> 58:03.600
 And one of the sad things about time, and that nothing lasts forever,

58:03.600 --> 58:09.600
 and that we're all mortal, let's not get into that discussion,

58:09.600 --> 58:15.600
 is, you know, if I see like, even when I ask for people to ask,

58:15.600 --> 58:18.600
 like ask, I did a call for questions and people want to ask you questions.

58:18.600 --> 58:22.600
 And so many requests from people about like certain videos they would love you to do.

58:22.600 --> 58:24.600
 It's such a pile.

58:24.600 --> 58:30.600
 And I think that's a sign of like admiration from people for sure.

58:30.600 --> 58:34.600
 But it's like, it makes me sad because like whenever I see them, people give ideas,

58:34.600 --> 58:37.600
 they're all like very often really good ideas.

58:37.600 --> 58:43.600
 And it's like, it's such a makes me sad in the same kind of way.

58:43.600 --> 58:46.600
 When I go through a library or through a bookstore,

58:46.600 --> 58:50.600
 you see all these amazing books that you'll never get to open.

58:50.600 --> 58:54.600
 So, yeah, so you did, yeah.

58:54.600 --> 58:56.600
 Gotta enjoy the ones that you have.

58:56.600 --> 59:01.600
 Enjoy the books that are open and don't let yourself lament the ones that stay closed.

59:01.600 --> 59:04.600
 What else? Is there any other magic to that day?

59:04.600 --> 59:07.600
 Do you try to dedicate like a certain number of hours?

59:07.600 --> 59:12.600
 Do Cal Newport has this deep work kind of idea?

59:12.600 --> 59:16.600
 There's systematic people who like get really on top of, you know,

59:16.600 --> 59:19.600
 they checklist of what they're going to do in the day and they like count their hours.

59:19.600 --> 59:22.600
 And I am not a systematic person in that way.

59:22.600 --> 59:24.600
 Which is probably a problem.

59:24.600 --> 59:27.600
 I very likely would get more done if I was systematic in that way.

59:27.600 --> 59:29.600
 But that doesn't happen.

59:29.600 --> 59:34.600
 So, you know, you talk to me later in life and maybe I'll have like changed my ways

59:34.600 --> 59:36.600
 and give you a very different answer.

59:36.600 --> 59:39.600
 I think Benjamin Franklin, like later in life,

59:39.600 --> 59:44.600
 figured out the rigor is these like very rigorous schedules and how to be productive.

59:44.600 --> 59:46.600
 I think those schedules are much more fun to write.

59:46.600 --> 59:49.600
 Like it's very fun to like write a schedule and make a blog post

59:49.600 --> 59:53.600
 about like the perfect productive day that like might work for one person.

59:53.600 --> 59:55.600
 But I don't know how much people get out of like reading them

59:55.600 --> 59:58.600
 or trying to adopt someone else's style.

59:58.600 --> 1:00:01.600
 And I'm not even sure that they've ever followed.

1:00:01.600 --> 1:00:02.600
 Exactly.

1:00:02.600 --> 1:00:04.600
 You're always going to write it as the best version of yourself.

1:00:04.600 --> 1:00:09.600
 You're not going to explain the phenomenon of like wanting to get out of the bed

1:00:09.600 --> 1:00:12.600
 but not really wanting to get out of the bed and all of that.

1:00:12.600 --> 1:00:19.600
 And just like zoning out for random reasons or the one that people probably don't touch at all is

1:00:19.600 --> 1:00:22.600
 I try to check social media once a day.

1:00:22.600 --> 1:00:25.600
 But I'm like only so I post and that's it.

1:00:25.600 --> 1:00:27.600
 When I post, I check the previous days.

1:00:27.600 --> 1:00:30.600
 That's like my what I try to do.

1:00:30.600 --> 1:00:33.600
 That's what I do like 90% of the days.

1:00:33.600 --> 1:00:38.600
 But then I'll go, I'll have like a two week period where it's just like I'm checking the internet.

1:00:38.600 --> 1:00:42.600
 Like, I mean, it's some probably some scary number of times.

1:00:42.600 --> 1:00:44.600
 I think a lot of people can resonate with that.

1:00:44.600 --> 1:00:46.600
 I think it's a legitimate addiction.

1:00:46.600 --> 1:00:48.600
 It's like it's a dopamine addiction.

1:00:48.600 --> 1:00:53.600
 And I don't know if it's a problem because as long as it's the kind of socializing,

1:00:53.600 --> 1:00:57.600
 like if you're actually engaging with friends and engaging with other people's ideas,

1:00:57.600 --> 1:00:59.600
 I think it can be really useful.

1:00:59.600 --> 1:01:00.600
 Well, I don't know.

1:01:00.600 --> 1:01:05.600
 So like for sure, I agree with you, but I'm it's a it's definitely an addiction

1:01:05.600 --> 1:01:08.600
 because for me, I think it's true for a lot of people.

1:01:08.600 --> 1:01:13.600
 I am very cognizant of the fact I just don't feel that happy.

1:01:13.600 --> 1:01:17.600
 If I look at a day where I've checked social media a lot,

1:01:17.600 --> 1:01:20.600
 like if I just aggregate, I did a self report,

1:01:20.600 --> 1:01:28.600
 I'm sure I would find that I'm just like literally on like less happy with my life and myself after I've done that check.

1:01:28.600 --> 1:01:33.600
 When I check it once a day, I'm very like I'm happy.

1:01:33.600 --> 1:01:35.600
 I even like because I've seen it.

1:01:35.600 --> 1:01:43.600
 Okay, one way to measure that is when somebody says something not nice to you on the Internet is like when I check it once a day,

1:01:43.600 --> 1:01:50.600
 I'm able to just like like I smile like like I virtually I think about them positively empathetically.

1:01:50.600 --> 1:01:51.600
 I send them love.

1:01:51.600 --> 1:01:55.600
 I don't don't have a respond, but I just feel positively about the whole thing.

1:01:55.600 --> 1:02:00.600
 If I check it, if I check like more than that, it starts eating at me.

1:02:00.600 --> 1:02:06.600
 There's an eating thing that happens like anxiety.

1:02:06.600 --> 1:02:08.600
 It occupies a part of your mind.

1:02:08.600 --> 1:02:10.600
 That's not doesn't seem to be healthy.

1:02:10.600 --> 1:02:15.600
 Same with, I mean, you put stuff out on YouTube.

1:02:15.600 --> 1:02:16.600
 I think it's important.

1:02:16.600 --> 1:02:19.600
 I think you have a million dimensions that are interesting to you,

1:02:19.600 --> 1:02:28.600
 but yet one of the interesting ones is the study of education and the psychological aspect of putting stuff up on YouTube.

1:02:28.600 --> 1:02:34.600
 I like now I have completely stopped checking statistics of any kind.

1:02:34.600 --> 1:02:39.600
 I've released an episode 100 with my dad conversation with my dad.

1:02:39.600 --> 1:02:44.600
 He checks he's probably listening to this stop.

1:02:44.600 --> 1:02:49.600
 He checks the number of views on his on his video on his conversation.

1:02:49.600 --> 1:02:56.600
 So he discovered like a reason he's new to this whole addiction and he just checks and he like he'll text me or write to me.

1:02:56.600 --> 1:03:02.600
 He just passed Dawkins in the top.

1:03:02.600 --> 1:03:04.600
 I love that so much.

1:03:04.600 --> 1:03:10.600
 Can I tell you a funny story in that effect of like parental use of YouTube?

1:03:10.600 --> 1:03:14.600
 Early on in the channel, my mom would like text me.

1:03:14.600 --> 1:03:19.600
 She's like, the channel has had 990,000 views.

1:03:19.600 --> 1:03:21.600
 The channel has had 991,000 views.

1:03:21.600 --> 1:03:22.600
 I'm like, oh, that's cute.

1:03:22.600 --> 1:03:25.600
 She's going to the little part on the about page where you see the total number of channel views.

1:03:25.600 --> 1:03:27.600
 No, she didn't know about that.

1:03:27.600 --> 1:03:31.600
 She had been going every day through all the videos and then adding them up.

1:03:31.600 --> 1:03:32.600
 Adding them up.

1:03:32.600 --> 1:03:38.600
 And she thought she was like doing me this favor of providing me this like global analytic that otherwise wouldn't be visible.

1:03:38.600 --> 1:03:39.600
 That's awesome.

1:03:39.600 --> 1:03:44.600
 It's just like this addiction where you have some number you want to follow and like, yeah, it's funny that your dad had this.

1:03:44.600 --> 1:03:46.600
 I think a lot of people have it.

1:03:46.600 --> 1:03:52.600
 I think that's probably a beautiful thing for like parents because they're legitimately, they're proud.

1:03:52.600 --> 1:03:53.600
 Yeah.

1:03:53.600 --> 1:03:55.600
 It's born of love. It's great.

1:03:55.600 --> 1:04:07.600
 The downside, I feel, one of them is this is one interesting experience that you probably don't know much about because comments on your videos are super positive.

1:04:07.600 --> 1:04:11.600
 But people judge the quality of how something went.

1:04:11.600 --> 1:04:15.600
 Like I see that with these conversations by the comments.

1:04:15.600 --> 1:04:16.600
 Yeah.

1:04:16.600 --> 1:04:21.600
 Like, I'm not talking about like, you know, people in their 20s and their 30s.

1:04:21.600 --> 1:04:25.600
 I'm talking about like CEOs of major companies who don't have time.

1:04:25.600 --> 1:04:30.600
 They basically, they literally, this is their evaluation metric.

1:04:30.600 --> 1:04:32.600
 They're like, ooh, the comments seem to be positive.

1:04:32.600 --> 1:04:34.600
 And that's really concerning to me.

1:04:34.600 --> 1:04:41.600
 Most important lesson for any content creator to learn is that the commenting public is not representative of the actual public.

1:04:41.600 --> 1:04:43.600
 And this is easy to see.

1:04:43.600 --> 1:04:46.600
 Ask yourself, how often do you write comments on YouTube videos?

1:04:46.600 --> 1:04:48.600
 Most people will realize I never do it.

1:04:48.600 --> 1:04:54.600
 Some people realize they do, but the people who realize they never do it should understand that that's a sign.

1:04:54.600 --> 1:04:57.600
 The kind of people who are like you aren't the ones leaving comments.

1:04:57.600 --> 1:04:59.600
 And I think this is important to a number of respects.

1:04:59.600 --> 1:05:05.600
 Like, in my case, I think I would think my content was better than it was if I just read comments because people are super nice.

1:05:05.600 --> 1:05:12.600
 The thing is, the people who are bored by it or are put off by it in some way or frustrated by it, usually they just go away.

1:05:12.600 --> 1:05:16.600
 They're certainly not going to watch the whole video, much less leave a comment on it.

1:05:16.600 --> 1:05:23.600
 So there's a huge underrepresentation of negative feedback, well intentioned negative feedback because very few people actively do that.

1:05:23.600 --> 1:05:28.600
 Watch the whole thing that they dislike, figure out what they disliked, articulate what they disliked.

1:05:28.600 --> 1:05:33.600
 There's plenty of negative feedback that's not well intentioned, but for that golden kind.

1:05:33.600 --> 1:05:44.600
 I think a lot of YouTuber friends I have at least have gone through phases of anxiety about the nature of comments that stem from basically just this.

1:05:44.600 --> 1:05:48.600
 That it's people who aren't necessarily representative of who they were going for,

1:05:48.600 --> 1:05:51.600
 misinterpreted what they were trying to say or whatever have you.

1:05:51.600 --> 1:05:55.600
 Or we're focusing on things like personal appearances as opposed to substance.

1:05:55.600 --> 1:05:58.600
 And they come away thinking like, oh, that's what everyone thinks.

1:05:58.600 --> 1:06:01.600
 That's what everyone's response to this video was.

1:06:01.600 --> 1:06:06.600
 But a lot of the people who had the reaction you wanted them to have, they probably didn't write it down.

1:06:06.600 --> 1:06:09.600
 So very important to learn.

1:06:09.600 --> 1:06:14.600
 It also translates to realizing that you're not as important as you might think you are,

1:06:14.600 --> 1:06:20.600
 because all of the people commenting are the ones who love you the most and are really asking you to create certain things

1:06:20.600 --> 1:06:24.600
 or mad that you didn't create a past thing.

1:06:24.600 --> 1:06:26.600
 I have such a problem.

1:06:26.600 --> 1:06:30.600
 I have a very real problem with making promises about a type of content that I'll make

1:06:30.600 --> 1:06:34.600
 and then either not following up on it soon or just never following up on it.

1:06:34.600 --> 1:06:40.600
 Yeah, actually, last time we talked, I think, I'm not sure, promise to me that you'll have music incorporated into your...

1:06:40.600 --> 1:06:43.600
 I'll share with you a private link.

1:06:43.600 --> 1:06:45.600
 There's an example of what I had in mind.

1:06:45.600 --> 1:06:51.600
 I did a version of it and I'm like, I think there's a better version of this that might exist one day.

1:06:51.600 --> 1:06:55.600
 So it's now on the backboard. It's sitting there.

1:06:55.600 --> 1:06:57.600
 There was a live performance at this one thing.

1:06:57.600 --> 1:06:58.600
 Awesome.

1:06:58.600 --> 1:07:02.600
 I think next circumstance that I'm doing another recorded live performance that fits having that

1:07:02.600 --> 1:07:05.600
 and in a better recording context, maybe I'll make it nice in public.

1:07:05.600 --> 1:07:06.600
 Maybe a while.

1:07:06.600 --> 1:07:08.600
 Exactly, right?

1:07:08.600 --> 1:07:12.600
 The point I was going to make though is I know I'm bad about following up on stuff,

1:07:12.600 --> 1:07:14.600
 which is an actual problem.

1:07:14.600 --> 1:07:19.600
 It's born of the fact that I have a sense of what will be good content when it won't be,

1:07:19.600 --> 1:07:23.600
 but this can actually be incredibly disheartening because a ton of comments that I see

1:07:23.600 --> 1:07:30.600
 are people who are frustrated usually in a benevolent way that I haven't followed through on X and X, which I get.

1:07:30.600 --> 1:07:35.600
 I should do that, but what's comforting thought for me is that when there's a topic I haven't promised

1:07:35.600 --> 1:07:39.600
 but I am working on and I'm excited about, it's like the people who would really like this

1:07:39.600 --> 1:07:43.600
 don't know that it's coming and don't know to comment to that effect.

1:07:43.600 --> 1:07:49.600
 The commenting public that I'm seeing is not representative of who I think this other project will touch meaningfully.

1:07:49.600 --> 1:07:54.600
 Yes, so focus on the future, on the thing you're creating now, just like the art of it.

1:07:54.600 --> 1:08:01.600
 One of the people is really inspiring to me in that regard because I've really seen it in person.

1:08:01.600 --> 1:08:06.600
 Joe Rogan, he doesn't read comments, but not just that.

1:08:06.600 --> 1:08:09.600
 He doesn't give a damn.

1:08:09.600 --> 1:08:13.600
 He's not clueless about it.

1:08:13.600 --> 1:08:21.600
 He's just like the richness and the depth of a smile he has when he just experiences the moment with you offline.

1:08:21.600 --> 1:08:31.600
 You can tell he doesn't give a damn about anything, about what people think about whether if it's on a podcast you talk to him

1:08:31.600 --> 1:08:36.600
 or whether offline about just, it's not there.

1:08:36.600 --> 1:08:43.600
 What other people think, even what the rest of the day looks like is just deeply in the moment,

1:08:43.600 --> 1:08:51.600
 or especially is what we're doing going to make for a good Instagram photo or something like that.

1:08:51.600 --> 1:08:54.600
 It doesn't think like that at all.

1:08:54.600 --> 1:09:02.600
 I think for actually quite a lot of people he's an inspiration in that way, but it was in real life a show that you can be very successful

1:09:02.600 --> 1:09:07.600
 not giving a damn about comments.

1:09:07.600 --> 1:09:15.600
 It sounds bad not to read comments because it's like, well, there's a huge number of people who are deeply passionate about what you do,

1:09:15.600 --> 1:09:25.600
 so you're ignoring them, but at the same time the nature of our platforms is such that the cost of listening to all the positive people

1:09:25.600 --> 1:09:33.600
 who are really close to you, who are incredible people have made a great community that you can learn a lot from.

1:09:33.600 --> 1:09:46.600
 Listening to those folks is also the cost of your psychology slowly being degraded by the natural underlying toxicity of the internet.

1:09:46.600 --> 1:09:52.600
 Engage with a handful of people deeply rather than as many people as you can in a shallow way.

1:09:52.600 --> 1:09:56.600
 I think that's a good lesson for social media usage.

1:09:56.600 --> 1:09:58.600
 Platforms in general, yeah.

1:09:58.600 --> 1:10:04.600
 She's just a handful of things to engage with and engage with it very well in a way that you feel proud of and don't worry about the rest.

1:10:04.600 --> 1:10:08.600
 Honestly, I think the best social media platform is texting.

1:10:08.600 --> 1:10:12.600
 That's my favorite. That's my go to social media platform.

1:10:12.600 --> 1:10:18.600
 Well, yeah, the best social media interaction is like real life, not social media, but social interaction.

1:10:18.600 --> 1:10:21.600
 No question there. I think everyone should agree with that.

1:10:21.600 --> 1:10:29.600
 Which sucks because it's been challenged now with the current situation and we're trying to figure out what kind of platform can be created

1:10:29.600 --> 1:10:32.600
 that we can do remote communication that still is effective.

1:10:32.600 --> 1:10:35.600
 It's important for education. It's important for just...

1:10:35.600 --> 1:10:37.600
 That is the question of education right now.

1:10:37.600 --> 1:10:38.600
 Yeah.

1:10:38.600 --> 1:10:48.600
 So on that topic, you've done a series of live streams called lockdown math and you know, you want live, which is different than you usually do.

1:10:48.600 --> 1:10:52.600
 Maybe one, can you talk about how that feel?

1:10:52.600 --> 1:10:54.600
 What's that experience like?

1:10:54.600 --> 1:10:58.600
 In your own, when you look back, is that an effective way?

1:10:58.600 --> 1:11:00.600
 Did you find being able to teach?

1:11:00.600 --> 1:11:10.600
 And if so, is there a lessons for this world where all of these educators are now trying to figure out how the heck do I teach remotely?

1:11:10.600 --> 1:11:13.600
 For me, it was very different. As different as you can get.

1:11:13.600 --> 1:11:17.600
 I'm on camera, which I'm usually not. I'm doing it live, which is nerve wracking.

1:11:17.600 --> 1:11:20.600
 It was a slightly different level of topics.

1:11:20.600 --> 1:11:23.600
 Although realistically, I'm just talking about things I'm interested in no matter what.

1:11:23.600 --> 1:11:28.600
 I think the reason I did that was this thought that a ton of people are looking to learn remotely.

1:11:28.600 --> 1:11:32.600
 The rate at which I usually put out content is too slow to be actively helpful.

1:11:32.600 --> 1:11:36.600
 Let me just do some biweekly lectures that if you're looking for a place to point your students,

1:11:36.600 --> 1:11:40.600
 if you're a student looking for a place to be edified about math, just tune in at these times.

1:11:40.600 --> 1:11:44.600
 And in that sense, I think it was a success for those who followed with it.

1:11:44.600 --> 1:11:50.600
 It was a really rewarding experience for me to see how people engaged with it.

1:11:50.600 --> 1:11:56.600
 Part of the fun of the live interaction was to actually do these live quizzes and see how people would answer and try to shape the lesson based on that,

1:11:56.600 --> 1:11:59.600
 or see what questions people were asking in the audience.

1:11:59.600 --> 1:12:05.600
 I would love to, if I did more things like that in the future, kind of tighten that feedback loop even more.

1:12:05.600 --> 1:12:14.600
 I think, you ask about if this can be relevant to educators, 100% online teaching is basically a form of live streaming now.

1:12:14.600 --> 1:12:16.600
 And usually it happens through Zoom.

1:12:16.600 --> 1:12:23.600
 I think if teachers view what they're doing as a kind of performance and a kind of live stream performance,

1:12:23.600 --> 1:12:28.600
 that would probably be pretty healthy because Zoom can be kind of awkward.

1:12:28.600 --> 1:12:35.600
 And I wrote up this little blog post actually just on what our setup looked like if you want to adopt it yourself,

1:12:35.600 --> 1:12:39.600
 and how to integrate the broadcasting software OBS with Zoom or things like that.

1:12:39.600 --> 1:12:41.600
 It was really exciting to pause on that.

1:12:41.600 --> 1:12:45.600
 I mean, yeah, maybe we could look at the blog post, but it looked really nice.

1:12:45.600 --> 1:12:48.600
 The thing is, I knew nothing about any of that stuff before I started.

1:12:48.600 --> 1:12:52.600
 I had a friend who knew a fair bit, and so he kind of helped show me the roofs.

1:12:52.600 --> 1:12:59.600
 One of the things that I realized is that you could, as a teacher, it doesn't take that much to make things look and feel pretty professional.

1:12:59.600 --> 1:13:05.600
 One component of it is, as soon as you hook things up with the broadcasting software rather than just doing screen sharing,

1:13:05.600 --> 1:13:10.600
 you can set up different scenes, and then you can have keyboard shortcuts to transition between those scenes.

1:13:10.600 --> 1:13:16.600
 So you don't need a production studio with a director calling like, go to camera three, go to camera two, like onto the screen.

1:13:16.600 --> 1:13:18.600
 Instead, you can have control of that.

1:13:18.600 --> 1:13:21.600
 And it took a little bit of practice, and I would mess it up now and then.

1:13:21.600 --> 1:13:26.600
 I think I had a decently smooth such that, you know, I'm talking to the camera and then we're doing something on the paper,

1:13:26.600 --> 1:13:30.600
 then we're doing like a playing with a Desmos graph or something.

1:13:30.600 --> 1:13:33.600
 And something that I think in the past would have required a production team.

1:13:33.600 --> 1:13:37.600
 You can actually do as a solo operation, and in particular as a teacher.

1:13:37.600 --> 1:13:41.600
 And I think it's worth it to try to do that because two reasons.

1:13:41.600 --> 1:13:44.600
 One, you might get more engagement from the students.

1:13:44.600 --> 1:13:48.600
 But the biggest reason, I think one of the like best things that can come out of this pandemic education wise,

1:13:48.600 --> 1:13:51.600
 is if we turn a bunch of teachers into content creators.

1:13:51.600 --> 1:13:54.600
 And if we take lessons that are usually done in these one off settings,

1:13:54.600 --> 1:14:00.600
 and like start to get in the habit of sometimes I'll use the phrase commoditizing explanation,

1:14:00.600 --> 1:14:05.600
 where what you want is whatever a thing a student wants to learn.

1:14:05.600 --> 1:14:13.600
 It just seems inefficient to me that that lesson is taught millions of times over in parallel across many different classrooms in the world,

1:14:13.600 --> 1:14:17.600
 like year to year, you've got a given algebra one lesson that's just taught,

1:14:17.600 --> 1:14:21.600
 like literally millions of times by different people.

1:14:21.600 --> 1:14:26.600
 What should happen is that there's the small handful of explanations online that exist.

1:14:26.600 --> 1:14:29.600
 So that when someone needs that explanation, they can go to it,

1:14:29.600 --> 1:14:33.600
 that the time in classroom is spent on all of the parts of teaching and education that aren't explanation,

1:14:33.600 --> 1:14:35.600
 which is most of it, right?

1:14:35.600 --> 1:14:39.600
 And the way to get there is to basically have more people who are already explaining,

1:14:39.600 --> 1:14:43.600
 publish their explanations and have it in a publicized forum.

1:14:43.600 --> 1:14:50.600
 So if during a pandemic, you can have people automatically creating online content because it has to be online,

1:14:50.600 --> 1:14:56.600
 but getting in the habit of doing it in a way that doesn't just feel like a Zoom call that happened to be recorded,

1:14:56.600 --> 1:15:03.600
 but it actually feels like a piece that was always going to be publicized to more people than just your students.

1:15:03.600 --> 1:15:05.600
 That can be really powerful.

1:15:05.600 --> 1:15:14.600
 There's an improvement process there. So being self critical and growing, I guess YouTubers go through this process

1:15:14.600 --> 1:15:23.600
 of putting out some content and nobody caring about it and then trying to figure out, basically improving,

1:15:23.600 --> 1:15:31.600
 figure out why did nobody care, and they come up with all kinds of answers which may or may not be correct,

1:15:31.600 --> 1:15:35.600
 but doesn't matter because the answer leads to improvement.

1:15:35.600 --> 1:15:39.600
 So you're being constantly self critical, self analytical, it should be better to say,

1:15:39.600 --> 1:15:42.600
 so you think of like, how can I make the audio better?

1:15:42.600 --> 1:15:44.600
 Like all the basic things.

1:15:44.600 --> 1:15:50.600
 Maybe one question to ask, because, well, by way of Russ Tedrick,

1:15:50.600 --> 1:15:55.600
 he's a robotics professor at MIT, one of my favorite people, a big fan of yours.

1:15:55.600 --> 1:16:00.600
 He watched our first conversation. I just interviewed him a couple of weeks ago.

1:16:00.600 --> 1:16:10.600
 He teaches this course in under actuated robotics, which is robotic systems when you can't control everything.

1:16:10.600 --> 1:16:17.600
 We as humans, when we walk, we're always falling forward, which means it's gravity.

1:16:17.600 --> 1:16:21.600
 You can't control it. You just hope you can catch yourself, but that's not all guaranteed.

1:16:21.600 --> 1:16:25.600
 It depends on the surface. So that's under actuated. You can't control everything.

1:16:25.600 --> 1:16:32.600
 So the number of actuators, the degrees of freedoms you have is not enough to fully control the system.

1:16:32.600 --> 1:16:35.600
 So I don't know, it's a really, I think, beautiful, fascinating class.

1:16:35.600 --> 1:16:40.600
 He puts it online. It's quite popular. He does an incredible job teaching.

1:16:40.600 --> 1:16:45.600
 He puts online every time, but he's kind of been interested in like crisping it up,

1:16:45.600 --> 1:16:50.600
 like, you know, making it, you know, innovating in different kinds of ways.

1:16:50.600 --> 1:16:57.600
 He was inspired by the work he do because I think in his work, he can do similar kind of explanations as you're doing,

1:16:57.600 --> 1:17:03.600
 like revealing the beauty of it and spending like months and preparing a single video.

1:17:03.600 --> 1:17:07.600
 And he's interested in how to do that. That's why he listened to the conversation.

1:17:07.600 --> 1:17:16.600
 He's playing with Manum, but he had this question of, you know, like in my apartment,

1:17:16.600 --> 1:17:23.600
 where we did the interview, I have like curtains, like a black curtain, not this.

1:17:23.600 --> 1:17:29.600
 This is a adjacent mansion that I also own.

1:17:29.600 --> 1:17:33.600
 But you basically just have, I have like a black curtain, whatever, that, you know,

1:17:33.600 --> 1:17:37.600
 makes it really easy to set up a filming situation with cameras that we have here, these microphones.

1:17:37.600 --> 1:17:41.600
 He was asking, you know, what kind of equipment do you recommend?

1:17:41.600 --> 1:17:46.600
 I guess like your blog post is a good one. I said I don't recommend this is excessive

1:17:46.600 --> 1:17:48.600
 and actually really hard to work with.

1:17:48.600 --> 1:17:54.600
 So I wonder, I mean, is there something you would recommend in terms of equipment?

1:17:54.600 --> 1:18:00.600
 Like, is it, do you think like lapel mics, like USB mics?

1:18:00.600 --> 1:18:05.600
 For my narration, I use a USB mic for the streams that used a lapel mic.

1:18:05.600 --> 1:18:14.600
 The narration, it's a Blue Yeti. I'm forgetting actually the name of the lapel mic, but it was probably like a road of some kind.

1:18:14.600 --> 1:18:17.600
 Is it hard to figure out how to make the audio sound good?

1:18:17.600 --> 1:18:22.600
 Oh, I mean, listen to all the early videos on my channel and clearly, like, I'm terrible at this.

1:18:22.600 --> 1:18:25.600
 For some reason, I just couldn't get audio for a while.

1:18:25.600 --> 1:18:28.600
 I think it's weird when you hear your own voice.

1:18:28.600 --> 1:18:30.600
 So you hear it, you're like, this sounds weird.

1:18:30.600 --> 1:18:37.600
 Do you want to know, does it sound weird because you're not used to your own voice or they're like actual audio artifacts at play?

1:18:37.600 --> 1:18:42.600
 So, and then video is just for the lockdown, just the camera.

1:18:42.600 --> 1:18:45.600
 Like you said, it was probably streaming somehow through the...

1:18:45.600 --> 1:18:49.600
 Yeah, there were two GH5 cameras, one that was mounted overhead over a piece of paper.

1:18:49.600 --> 1:18:56.600
 You could also use like an iPad or a Wacom tablet to do your writing electronically, but I just wanted the paper feel.

1:18:56.600 --> 1:19:00.600
 On the face, there's two... Again, I don't know.

1:19:00.600 --> 1:19:13.600
 I'm just not actually the one to ask this because I animate stuff usually, but each of them has a compressor object that makes it such that the camera output goes into the computer USB, but gets compressed before it does that.

1:19:13.600 --> 1:19:19.600
 The live aspect of it, do you regret doing it live?

1:19:19.600 --> 1:19:21.600
 Not at all.

1:19:21.600 --> 1:19:29.600
 I do think the content might be like much less sharp and tight than if it were something, even that I just recorded like that and then edited later.

1:19:29.600 --> 1:19:36.600
 But I do like something that I do to be out there to show like, hey, this is what it's like raw, this is what it's like when I make mistakes.

1:19:36.600 --> 1:19:39.600
 This is like the pace of thinking.

1:19:39.600 --> 1:19:43.600
 I like the live interaction of it. I think that made it better.

1:19:43.600 --> 1:19:57.600
 I probably would do it on a different channel, I think, if I did series like that in the future, just because it's a different style. It's probably a different target audience and kind of keep clean what Three Blue and Brown is about versus the benefits of live lectures.

1:19:57.600 --> 1:20:16.600
 Do you suggest like in this time of COVID that people like Russ or other educators try to go like the shorter like 20 minute videos that are like really well planned out or scripted, you really think through, you slowly design, so it's not live?

1:20:16.600 --> 1:20:20.600
 Do you see like that being an important part of what they do?

1:20:20.600 --> 1:20:27.600
 Well, what I think teachers like Russ should do is choose the small handful of topics that they're going to do just really well.

1:20:27.600 --> 1:20:34.600
 They want to create the best, short explanation of it in the world that will be one of those handfuls in a world where you have commoditized explanation, right?

1:20:34.600 --> 1:20:38.600
 Most of the lectures should be done just normally, still put thought and planning into it.

1:20:38.600 --> 1:20:41.600
 I'm sure he's a wonderful teacher and like knows all about that.

1:20:41.600 --> 1:20:51.600
 But maybe choose those small handful of topics with beneficial for me sometimes as I do sample lessons with people on that topic to get some sense of how other people think about it.

1:20:51.600 --> 1:20:56.600
 Let that inform how you want to edit it or script it or whatever format you want to do.

1:20:56.600 --> 1:20:59.600
 Some people are comfortable just explaining it and editing later.

1:20:59.600 --> 1:21:02.600
 I'm more comfortable like writing it out and thinking in that setting.

1:21:02.600 --> 1:21:04.600
 Yeah, it's kind of sorry to interrupt.

1:21:04.600 --> 1:21:10.600
 It's a little bit sad to me to see how much knowledge is lost.

1:21:10.600 --> 1:21:17.600
 Like just as you mentioned, there's professors like we can take my dad, for example, to blow up his ego a little bit.

1:21:17.600 --> 1:21:23.600
 But he's a great teacher and he knows plasma, plasma chemistry, plasma physics really well.

1:21:23.600 --> 1:21:30.600
 So he can very simply explain some beautiful but otherwise complicated concepts.

1:21:30.600 --> 1:21:37.600
 And it's sad that like if you Google plasma or like for plasma physics, like there's no videos.

1:21:37.600 --> 1:21:44.600
 And just imagine if every one of those excellent teachers like your father or like Russ, even if they just chose one topic this year,

1:21:44.600 --> 1:21:47.600
 they're like, I'm going to make the best video that I can on this topic.

1:21:47.600 --> 1:21:53.600
 If every one of the great teachers did that, the internet would be replete and it's already replete with great explanations.

1:21:53.600 --> 1:21:57.600
 But it would be even more so with all the niche great explanations and like anything you want to learn.

1:21:57.600 --> 1:22:06.600
 And there's a self interest to it for in terms of teachers, in terms of even, so if you take Russ, for example, it's not that he's teaching something.

1:22:06.600 --> 1:22:10.600
 Like he teaches his main thing, his thing he's deeply passionate about.

1:22:10.600 --> 1:22:24.600
 And from a selfish perspective, it's also just like, I mean, it's like publishing a paper in a really like nature has like letters,

1:22:24.600 --> 1:22:35.600
 like accessible publication, it's just going to guarantee that your work, that your passion is seen by a huge number of people.

1:22:35.600 --> 1:22:38.600
 Whatever the definition of huge is, doesn't matter.

1:22:38.600 --> 1:22:41.600
 It's much more than it otherwise would be.

1:22:41.600 --> 1:22:46.600
 And it's those lectures that tell early students what to be interested in.

1:22:46.600 --> 1:22:51.600
 At the moment, I think students are disproportionately interested in the things that are well represented on YouTube.

1:22:51.600 --> 1:22:56.600
 So to any educator out there, if you're wondering, hey, I want more like grad students in my department.

1:22:56.600 --> 1:22:58.600
 Like what's the best way to recruit grad students?

1:22:58.600 --> 1:23:01.600
 It's like, make the best video you can and then wait eight years.

1:23:01.600 --> 1:23:04.600
 And then you're going to have a pile of like excellent grad students for that department.

1:23:04.600 --> 1:23:14.600
 And one of the lessons I think your channel teaches is there is appeal of explaining just something beautiful,

1:23:14.600 --> 1:23:20.600
 explaining it cleanly, technically, not doing a marketing video about why topology is great.

1:23:20.600 --> 1:23:23.600
 There's people interested in this stuff.

1:23:23.600 --> 1:23:30.600
 I mean, one of the greatest channels, like Matt, it's not even a math channel, but the channel with greatest math content is Vsauce.

1:23:30.600 --> 1:23:37.600
 Imagine you were to propose making a video that explains the Banak Tarski paradox.

1:23:37.600 --> 1:23:40.600
 Substantively, not shying around.

1:23:40.600 --> 1:23:47.600
 It may be not describing things in terms of like the group theoretic terminology that you'd usually seen in paper.

1:23:47.600 --> 1:23:56.600
 But the actual results that went into this idea of like breaking apart a sphere, proposing that to like a network TV station saying,

1:23:56.600 --> 1:23:59.600
 yeah, I'm going to do this in depth talk of the Banak Tarski paradox.

1:23:59.600 --> 1:24:02.600
 I'm pretty sure it's going to reach 20 million people.

1:24:02.600 --> 1:24:03.600
 It's like, get out of here.

1:24:03.600 --> 1:24:05.600
 Like no one cares about that.

1:24:05.600 --> 1:24:08.600
 No one's interested in anything even anywhere near that.

1:24:08.600 --> 1:24:14.600
 But then you have Michael's quirky personality around it and just people that are actually hungry for that kind of depth.

1:24:14.600 --> 1:24:18.600
 Then you don't need like the approval of some higher network.

1:24:18.600 --> 1:24:21.600
 You can just do it and let the people speak for themselves.

1:24:21.600 --> 1:24:29.600
 So I think if your father was to make something on plasma physics or if we were to have like under actualized robotics.

1:24:29.600 --> 1:24:30.600
 Underactuated.

1:24:30.600 --> 1:24:31.600
 Underactuated.

1:24:31.600 --> 1:24:33.600
 Yes, not under actualized.

1:24:33.600 --> 1:24:35.600
 It's plenty actualized.

1:24:35.600 --> 1:24:36.600
 Underactuated robotics.

1:24:36.600 --> 1:24:39.600
 Yeah, most robotics is under actualized currently.

1:24:39.600 --> 1:24:40.600
 That's true.

1:24:40.600 --> 1:24:48.600
 So even if it's things that you might think are niche, I bet you'll be surprised by how many people actually engage with it really deeply.

1:24:48.600 --> 1:24:51.600
 Although I just psychologically watching him.

1:24:51.600 --> 1:24:52.600
 I can't speak for a lot of people.

1:24:52.600 --> 1:24:53.600
 I can speak for my dad.

1:24:53.600 --> 1:24:59.600
 I think there's a little bit of a skill gap, but I think that could be overcome.

1:24:59.600 --> 1:25:00.600
 You know what?

1:25:00.600 --> 1:25:02.600
 None of us know how to make videos when we start.

1:25:02.600 --> 1:25:04.600
 The first thing I made was terrible in a number of respects.

1:25:04.600 --> 1:25:08.600
 Like look at the earliest videos on any YouTube channel except for Captain Disillusion.

1:25:08.600 --> 1:25:12.600
 And they're all like terrible versions of whatever they are now.

1:25:12.600 --> 1:25:24.600
 But the thing I've noticed, especially like with world experts is it's the same thing that I'm sure you went through, which is like fear of like embarrassment.

1:25:24.600 --> 1:25:29.600
 Like they definitely, it's the same reason.

1:25:29.600 --> 1:25:33.600
 Like I feel that anytime I put out a video.

1:25:33.600 --> 1:25:38.600
 I don't know if you still feel that, but like, I don't know, it's this imposter syndrome.

1:25:38.600 --> 1:25:40.600
 Like who am I to talk about this?

1:25:40.600 --> 1:25:45.600
 And that's true for like even things that you've studied for like your whole life.

1:25:45.600 --> 1:25:46.600
 I don't know.

1:25:46.600 --> 1:25:49.600
 It's scary to post stuff on YouTube.

1:25:49.600 --> 1:25:50.600
 It is scary.

1:25:50.600 --> 1:25:59.600
 I honestly wish that more of the people who had that modesty to say who am I to post this were the ones actually posting it.

1:25:59.600 --> 1:26:00.600
 That's right.

1:26:00.600 --> 1:26:09.600
 I mean, the honest problem is like a lot of the educational content is posted by people who like we're just starting to research it two weeks ago and are on a certain schedule.

1:26:09.600 --> 1:26:18.600
 And who maybe should think like who am I to explain and choose your favorite topic, quantum mechanics or something.

1:26:18.600 --> 1:26:27.600
 And the people who have the self awareness to not post are probably the people also best positioned to give a good honest explanation of it.

1:26:27.600 --> 1:26:38.600
 That's why there's a lot of value in a channel like Numberphile where they basically trap a really smart person and force them to explain stuff on a broad sheet of paper.

1:26:38.600 --> 1:26:41.600
 But of course, that's not scalable as a single channel.

1:26:41.600 --> 1:26:49.600
 If they if there's anything beautiful that they could be done as people take it in their own hands educators, which is again circling back.

1:26:49.600 --> 1:26:54.600
 I do think the pandemic will serve to force a lot of people's hands.

1:26:54.600 --> 1:26:56.600
 You're going to be making online content anyway.

1:26:56.600 --> 1:26:58.600
 It's happening, right?

1:26:58.600 --> 1:27:01.600
 Just hit that publish button and see how it goes.

1:27:01.600 --> 1:27:03.600
 Yeah, see how it goes.

1:27:03.600 --> 1:27:07.600
 The cool thing about YouTube is it might not go for a while.

1:27:07.600 --> 1:27:09.600
 But like 10 years later, right?

1:27:09.600 --> 1:27:11.600
 Yeah, it'll be like this.

1:27:11.600 --> 1:27:19.600
 The thing is what people don't understand with YouTube, at least for now, at least that's my hope with it is it's a leg.

1:27:19.600 --> 1:27:24.600
 It's a it's literally better than publishing a book in terms of the legacy.

1:27:24.600 --> 1:27:27.600
 It's it will live for a long, long time.

1:27:27.600 --> 1:27:35.600
 Of course, it's one of the things I mentioned Joe Rogan before it's kind of there's a sad thing because I'm a fan.

1:27:35.600 --> 1:27:38.600
 He's moving to Spotify.

1:27:38.600 --> 1:27:41.600
 Yeah, nine digit numbers will do that to you.

1:27:41.600 --> 1:27:46.600
 But he doesn't really that he's one a person that doesn't actually care about that much about money.

1:27:46.600 --> 1:27:50.600
 Like having talked to him here, it wasn't because of money.

1:27:50.600 --> 1:27:59.600
 It's because he legitimately thinks that they're going to do like a better job.

1:27:59.600 --> 1:28:06.600
 So they're so from his perspective, YouTube, you have to understand where they're coming from.

1:28:06.600 --> 1:28:12.600
 YouTube has been cracking down on people who they, you know, Joe Rogan talks to Alex Jones and conspiracy theories and stuff.

1:28:12.600 --> 1:28:15.600
 And YouTube is really like careful that kind of stuff.

1:28:15.600 --> 1:28:21.600
 And that's not a good feeling like and Joe didn't doesn't feel like YouTube is on his side.

1:28:21.600 --> 1:28:35.600
 You know, he's often has videos that they don't put in trending that like are obviously should be in trending because they're nervous about like, you know, if this concert is this is this content.

1:28:35.600 --> 1:28:40.600
 Going to, you know, upset people that all that kind of stuff have misinformation.

1:28:40.600 --> 1:28:49.600
 And that's not a good place for a person to be in and Spotify is giving him we're never going to censor you were never going to do that.

1:28:49.600 --> 1:28:58.600
 But the reason I bring that up, whatever you think about that, I personally think is bullshit because podcast things should be free and not constrained to a platform.

1:28:58.600 --> 1:29:07.600
 It's pirate radio. What the hell you can't as much as I lost Spotify, you can't just you can't put fences around it.

1:29:07.600 --> 1:29:13.600
 But anyway, the reason I bring that up is Joe's going to remove his entire library from YouTube.

1:29:13.600 --> 1:29:14.600
 Whoa, really?

1:29:14.600 --> 1:29:21.600
 I don't do his full link the clips are going to stay but the full length videos are all I mean me private or deleted.

1:29:21.600 --> 1:29:28.600
 That's part of the deal. And like that's the first time where I was like, oh, YouTube videos might not live forever.

1:29:28.600 --> 1:29:31.600
 Like things you find like, okay, sorry.

1:29:31.600 --> 1:29:36.600
 This is why you need IPFS or something where it's like if there's a content link.

1:29:36.600 --> 1:29:38.600
 I familiar with the system at all.

1:29:38.600 --> 1:29:45.600
 Like right now, if you have a URL that points to a server, there's like a system where the address points to content and then it's like distributed.

1:29:45.600 --> 1:29:50.600
 So you can't actually delete what's at an address because it's it's content address.

1:29:50.600 --> 1:29:56.600
 And as long as there's someone on the network who hosts it, it's always accessible at the address that it once was.

1:29:56.600 --> 1:29:58.600
 But I mean, that raises a question.

1:29:58.600 --> 1:30:02.600
 I'm not going to put you on the spot, but like somebody like Vsauce, right?

1:30:02.600 --> 1:30:07.600
 Spotify comes along and gives him, let's say $100 billion.

1:30:07.600 --> 1:30:12.600
 Okay, let's say some crazy number and then removes it from YouTube, right?

1:30:12.600 --> 1:30:18.600
 It's made me, I don't know, for some reason I thought YouTube is forever.

1:30:18.600 --> 1:30:20.600
 I don't think it will be.

1:30:20.600 --> 1:30:30.600
 I mean, you know, another variant that this might take is like that, you know, you fast forward 50 years and, you know, Google or Alphabet isn't the company that it once was.

1:30:30.600 --> 1:30:38.600
 And it's kind of struggling to make ends meet and, you know, it's been supplanted by the whoever wins on the AR game or whatever it might be.

1:30:38.600 --> 1:30:43.600
 And then they're like, you know, all of these videos that we're hosting are pretty costly.

1:30:43.600 --> 1:30:51.600
 So we're just we're going to start deleting the ones that aren't watched that much and tell people to like try to back them up on their own or whatever it is.

1:30:51.600 --> 1:30:59.600
 Or even if it does exist in some form forever, it's like if people are not habituated to watching YouTube in 50 years, they're watching something else, which seems pretty likely.

1:30:59.600 --> 1:31:06.600
 Like, it would be shocking if YouTube remained as popular as it is now indefinitely into the future.

1:31:06.600 --> 1:31:07.600
 That's true.

1:31:07.600 --> 1:31:09.600
 So it won't be forever.

1:31:09.600 --> 1:31:16.600
 It makes me sad still, but because it's such a nice, it's just like you said, of the canonical videos.

1:31:16.600 --> 1:31:17.600
 Sorry, I don't mean to interrupt.

1:31:17.600 --> 1:31:21.600
 You know, you should get Juan Bennett on the thing and then talk to him about permanence.

1:31:21.600 --> 1:31:23.600
 I think you would have a good conversation.

1:31:23.600 --> 1:31:24.600
 Who's that?

1:31:24.600 --> 1:31:28.600
 So he's the one that founded this thing called IPFS that I'm talking about.

1:31:28.600 --> 1:31:33.600
 And if you have him talk about basically what you're describing, like, oh, it's sad that this isn't forever.

1:31:33.600 --> 1:31:36.600
 Then you'll get some articulate pontification around it.

1:31:36.600 --> 1:31:39.600
 Yeah, it's like been pretty well thought through.

1:31:39.600 --> 1:31:47.600
 But yeah, I do see YouTube just like you said, as a place like what your channel creates, which is like a set of canonical videos on a topic.

1:31:47.600 --> 1:31:51.600
 Now, others could create videos on that topic as well.

1:31:51.600 --> 1:31:56.600
 But as a collection, it creates a nice set of places to go.

1:31:56.600 --> 1:32:09.600
 If you're curious about a particular topic, and it seems like coronavirus is a nice opportunity to put that knowledge out there in the world at MIT and beyond.

1:32:09.600 --> 1:32:12.600
 I have to talk to you a little bit about machine learning, deep learning and so on.

1:32:12.600 --> 1:32:15.600
 Again, we talked about last time.

1:32:15.600 --> 1:32:19.600
 You have a set of beautiful videos on your own networks.

1:32:19.600 --> 1:32:30.600
 Let me ask you first, what is the most beautiful aspect of networks and machine learning to you?

1:32:30.600 --> 1:32:42.600
 For making those videos, from watching how they feel this evolving, is there something mathematically or in applied sense just beautiful to you about them?

1:32:42.600 --> 1:32:52.600
 Well, I think what I would go to is the layered structure and how you can have what feel like qualitatively distinct things happening going from one layer to another,

1:32:52.600 --> 1:32:55.600
 but that are following the same mathematical rule.

1:32:55.600 --> 1:33:00.600
 Because if you look at it as a piece of math, it's like you got a nonlinearity and then you've got a matrix multiplication.

1:33:00.600 --> 1:33:02.600
 That's what's happening on all the layers.

1:33:02.600 --> 1:33:12.600
 But especially if you look at some of the visualizations that Chris Ola has done with respect to convolutional nets that have been trained on ImageNet,

1:33:12.600 --> 1:33:14.600
 trying to say, what does this neuron do?

1:33:14.600 --> 1:33:17.600
 What does this family of neurons do?

1:33:17.600 --> 1:33:24.600
 What you can see is that the ones closer to the input side are picking up on very low level ideas like the texture.

1:33:24.600 --> 1:33:33.600
 And then as you get further back, you have higher level ideas like what is the where the eyes in this picture and then how do the eyes form like an animal as this animal, a cat or a dog or a deer.

1:33:33.600 --> 1:33:39.600
 You have this series of qualitatively different things happening even though it's the same piece of math on each one.

1:33:39.600 --> 1:33:47.600
 So that's a pretty beautiful idea that you can have like a generalizable object that runs through the layers of abstraction,

1:33:47.600 --> 1:33:54.600
 which in some sense constitute intelligence is having those many different layers of an understanding to something.

1:33:54.600 --> 1:33:57.600
 Form abstractions in an automated way.

1:33:57.600 --> 1:33:58.600
 Exactly.

1:33:58.600 --> 1:34:02.600
 It's automated abstracting, which I mean, that just feels very powerful.

1:34:02.600 --> 1:34:06.600
 And the idea that it can be so simply mathematically represented.

1:34:06.600 --> 1:34:16.600
 I mean, a ton of like modern animal research seems a little bit like you do a bunch of ad hoc things, then you decide which one worked and then you retrospectively come up with the mathematical reason that it always had to work.

1:34:16.600 --> 1:34:18.600
 But who cares how you came to it?

1:34:18.600 --> 1:34:24.600
 When you have like that elegant piece of math, it's hard not to just smile seeing it work in action.

1:34:24.600 --> 1:34:26.600
 Well, and we talked about topology before.

1:34:26.600 --> 1:34:34.600
 One of the really interesting things is beginning to be investigated under kind of the field of like science and deep learning,

1:34:34.600 --> 1:34:43.600
 which is like the craziness of the surface that is trying to be optimized in neural networks.

1:34:43.600 --> 1:34:55.600
 I mean, the amount of local minima, local optima there is in these surfaces and somehow a dumb gradient descent algorithm is able to find really good solutions.

1:34:55.600 --> 1:34:58.600
 That's like, that's really surprising.

1:34:58.600 --> 1:35:02.600
 Well, so on the one hand it is, but also it's like not.

1:35:02.600 --> 1:35:09.600
 It's not terribly surprising that you have these interesting points that exist when you make your space so high dimensional like GPT three.

1:35:09.600 --> 1:35:12.600
 What did it have 175 billion parameters?

1:35:12.600 --> 1:35:21.600
 So it doesn't feel as mesmerizing to think about, oh, there's some surface of intelligent behavior in this crazy high dimensional space.

1:35:21.600 --> 1:35:27.600
 Like there's so many parameters that of course, but what's more interesting is like how, how is it that you're able to efficiently get there,

1:35:27.600 --> 1:35:32.600
 which is maybe what you're describing that something as dumb as gradient descent does it.

1:35:32.600 --> 1:35:41.600
 But like the reason the gradient descent works well with neural networks and not just, you know, choose however you want to parameterize this space and then like apply gradient descent to it.

1:35:41.600 --> 1:35:47.600
 Is that that layered structure lets you decompose the derivative in a way that makes it computationally feasible.

1:35:47.600 --> 1:35:58.600
 Yeah, it's just that that there's so many good solutions, probably infinitely, infinitely many good solutions, not best solutions, but good solutions.

1:35:58.600 --> 1:36:00.600
 That's that's what's interesting.

1:36:00.600 --> 1:36:11.600
 It's similar to Steven Wolfram as this idea of like the, if you just look at all space of computations of all space of basically algorithms,

1:36:11.600 --> 1:36:15.600
 that you'd be surprised how many of them are actually intelligent.

1:36:15.600 --> 1:36:19.600
 Like if you just randomly pick from the bucket, that's surprising.

1:36:19.600 --> 1:36:25.600
 We tend to think like a tiny, tiny minority of them would be intelligent.

1:36:25.600 --> 1:36:32.600
 But his sense is like, it seems weirdly easy to find computations that do something interesting.

1:36:32.600 --> 1:36:33.600
 Well, okay.

1:36:33.600 --> 1:36:39.600
 So that from like a Kalamogorov complexity standpoint, almost everything will be interesting.

1:36:39.600 --> 1:36:45.600
 What's fascinating is to find the stuff that's describable with low information, but still does interesting things.

1:36:45.600 --> 1:36:53.600
 Like one fun example of this, you know, Shannon's noisy coding and theorem, noisy coding theorem and information theory,

1:36:53.600 --> 1:36:59.600
 that basically says if, you know, I want to send some bits to you, maybe some of them are going to get flipped.

1:36:59.600 --> 1:37:01.600
 There's some noise along the channel.

1:37:01.600 --> 1:37:05.600
 I can come up with some way of coding it that's resilient to that noise.

1:37:05.600 --> 1:37:07.600
 That's very good.

1:37:07.600 --> 1:37:09.600
 And then he quantitatively describes what very good is.

1:37:09.600 --> 1:37:16.600
 What's funny about how he proves the existence of good error correction codes is rather than saying like, here's how to construct it,

1:37:16.600 --> 1:37:19.600
 or even like a sensible non constructive proof.

1:37:19.600 --> 1:37:27.600
 The nature of his non constructive proof is to say, if we chose a random encoding, it would be almost at the limit,

1:37:27.600 --> 1:37:32.600
 which is weird because then it took decades for people to actually find any that were anywhere close to the limit.

1:37:32.600 --> 1:37:35.600
 And what his proof was saying is choose a random one.

1:37:35.600 --> 1:37:38.600
 And it's like the best kind of encoding you'll ever find.

1:37:38.600 --> 1:37:45.600
 But what's what that tells us is that sometimes when you choose a random element from this ungodly huge set,

1:37:45.600 --> 1:37:49.600
 that's a very different task from finding an efficient way to actively describe it.

1:37:49.600 --> 1:37:52.600
 Because in that case, the random element to actually implement it as a bit of code,

1:37:52.600 --> 1:37:59.600
 you would just have this huge table of like telling you how to encode one thing into another that's totally computationally infeasible.

1:37:59.600 --> 1:38:04.600
 So on the side of like, how many possible programs are interesting in some way?

1:38:04.600 --> 1:38:06.600
 It's like, yeah, all tons of them.

1:38:06.600 --> 1:38:13.600
 But the much, much more delicate question is when you can have a low information description of something that still becomes interesting.

1:38:13.600 --> 1:38:17.600
 And thereby this kind of gives you a blueprint for how to engineer that kind of thing.

1:38:17.600 --> 1:38:18.600
 Right.

1:38:18.600 --> 1:38:19.600
 Yeah.

1:38:19.600 --> 1:38:23.600
 KS Theory is another good instance there where it's like, yeah, a ton of things are hard to describe.

1:38:23.600 --> 1:38:29.600
 But how do you have ones that have a simple set of governing equations that remain like arbitrarily hard to describe?

1:38:29.600 --> 1:38:32.600
 Well, let me ask you, you mentioned GPT3.

1:38:32.600 --> 1:38:41.600
 It's interesting to ask what are your thoughts about the recently released open AI GPT3 model

1:38:41.600 --> 1:38:46.600
 that I believe is already trying to learn how to communicate like Grant Sanderson.

1:38:46.600 --> 1:38:53.600
 You know, I think I got an email there too, go about someone who wanted to try to use GPT3 with Manum,

1:38:53.600 --> 1:38:59.600
 where you would like give it a high level description of something and then it'll like automatically create the mathematical animation.

1:38:59.600 --> 1:39:04.600
 Like trying to put me out of a job here.

1:39:04.600 --> 1:39:09.600
 I mean, it probably won't put you out of a job, but it'll create something visually beautiful for sure.

1:39:09.600 --> 1:39:16.600
 I would be surprised if that worked as stated, but maybe there's like variants of it like that you can get to.

1:39:16.600 --> 1:39:18.600
 I mean, like a lot of those demos, it's interesting.

1:39:18.600 --> 1:39:23.600
 I think there's a lot of failed experiments.

1:39:23.600 --> 1:39:27.600
 Like depending on how you prime the thing, you're going to have a lot of failed.

1:39:27.600 --> 1:39:31.600
 I'm certainly with code and with program synthesis, most of it won't even run.

1:39:31.600 --> 1:39:38.600
 But eventually, I think if you pick the right examples, you'll be able to generate something cool.

1:39:38.600 --> 1:39:45.600
 And I think that even that's good enough, even though if you're being very selective, it's still cool that something can be generated.

1:39:45.600 --> 1:39:47.600
 Yeah, that's huge value.

1:39:47.600 --> 1:39:49.600
 I mean, think of the writing process.

1:39:49.600 --> 1:39:54.600
 Sometimes a big part of it is just getting a bunch of stuff on the page and then you can decide what to whittle down to.

1:39:54.600 --> 1:40:02.600
 So if it can be used in like a man machine symbiosis where it's just giving you a spew of potential ideas that then you can refine down.

1:40:02.600 --> 1:40:06.600
 Like it's serving as the generator and then the human serves as the refiner.

1:40:06.600 --> 1:40:09.600
 That seems like a pretty powerful dynamic.

1:40:09.600 --> 1:40:13.600
 Yeah, have you gotten a chance to see any of the demos like on Twitter?

1:40:13.600 --> 1:40:15.600
 Is there a favorite you've seen?

1:40:15.600 --> 1:40:16.600
 Oh, my absolute favorite.

1:40:16.600 --> 1:40:17.600
 Yeah.

1:40:17.600 --> 1:40:24.600
 So Tim Blay, who runs a channel called Alcapela Science, he was tweeting a bunch about playing with it.

1:40:24.600 --> 1:40:30.600
 And so GPT3 was trained on the internet from before COVID.

1:40:30.600 --> 1:40:32.600
 So in a sense, it doesn't know about the coronavirus.

1:40:32.600 --> 1:40:40.600
 So what he seeded it with was just a short description about like a novel virus emerges in Wuhan, China and starts to spread around the globe.

1:40:40.600 --> 1:40:43.600
 What follows is a month by month description of what happens.

1:40:43.600 --> 1:40:45.600
 January colon, right?

1:40:45.600 --> 1:40:46.600
 That's what he seeds it with.

1:40:46.600 --> 1:40:51.600
 So then what GPT3 generates is like January, then a paragraph of description February and such.

1:40:51.600 --> 1:40:56.600
 And it's the funniest thing you'll ever read because it predicts a zombie apocalypse.

1:40:56.600 --> 1:41:00.600
 Which of course it would because it's trained on like the internet data.

1:41:00.600 --> 1:41:07.600
 But what you see unfolding is a description of COVID 19 if it were a zombie apocalypse.

1:41:07.600 --> 1:41:12.600
 And like the early aspects of it are kind of shockingly in line with what's reasonable.

1:41:12.600 --> 1:41:14.600
 And then it gets out of hand so quickly.

1:41:14.600 --> 1:41:20.600
 And the other flip side of that is I wouldn't be surprised if it's onto something at some point here.

1:41:20.600 --> 1:41:24.600
 You know, 2020 has been full of surprises.

1:41:24.600 --> 1:41:31.600
 Who knows, like we might all be in like this crazy militarized zone as it predicts just a couple months off.

1:41:31.600 --> 1:41:35.600
 Yeah, I think there's definitely an interesting tool of storytelling.

1:41:35.600 --> 1:41:40.600
 It has struggled with mathematics, which is interesting or just even numbers.

1:41:40.600 --> 1:41:52.600
 It's able to, it's not able to generate like patterns, you know, like you give it like five digit numbers and it's not able to figure out the sequence.

1:41:52.600 --> 1:42:01.600
 You know, or like I didn't look in too much, but I'm talking about like sequences like the Fibonacci numbers to see how far it can go.

1:42:01.600 --> 1:42:05.600
 Because obviously it's leveraging stuff from the internet and it starts to lose it.

1:42:05.600 --> 1:42:12.600
 But it is also cool that I've seen it able to generate some interesting patterns that are mathematically correct.

1:42:12.600 --> 1:42:20.600
 Yeah, I honestly haven't dug into like what's going on within it in a way that I can speak intelligently to.

1:42:20.600 --> 1:42:26.600
 I guess it doesn't surprise me that it's bad at numerical patterns because maybe I should be more impressed with it.

1:42:26.600 --> 1:42:35.600
 But like that requires having a weird combination of intuitive and formulaic worldview.

1:42:35.600 --> 1:42:38.600
 So you're not just going off of intuition when you see Fibonacci numbers.

1:42:38.600 --> 1:42:41.600
 You're not saying like intuitively, what do I think will follow the 13?

1:42:41.600 --> 1:42:44.600
 Like I've seen patterns a lot where like 13s are followed by 21s.

1:42:44.600 --> 1:42:51.600
 Instead, it's that like the way you're starting to see a shape of things is by knowing what hypotheses to test where you're saying,

1:42:51.600 --> 1:42:57.600
 oh, maybe it's generated based on the previous terms or maybe it's generated based on like multiplying by a constant or whatever it is.

1:42:57.600 --> 1:43:04.600
 You like have a bunch of different hypotheses and your intuitions are around those hypotheses, but you still need to actively test it.

1:43:04.600 --> 1:43:12.600
 And it seems like GPT three is extremely good at like that sort of pattern matching recognition that usually is very hard for computers.

1:43:12.600 --> 1:43:16.600
 That is what humans get good at through expertise and exposure to lots of things.

1:43:16.600 --> 1:43:21.600
 It's why it's good to learn from as many examples as you can rather than just from the definitions.

1:43:21.600 --> 1:43:23.600
 It's to get that level of intuition.

1:43:23.600 --> 1:43:31.600
 But to actually concretize it into a piece of math, you do need to like test your hypotheses and if not prove it,

1:43:31.600 --> 1:43:37.600
 like have an actual explanation for what's going on, not just a pattern that you've seen.

1:43:37.600 --> 1:43:45.600
 But then the flip side to play devil's advocate, that's a very kind of probably correct intuitive understanding of just like we said,

1:43:45.600 --> 1:43:48.600
 a few layers creating abstractions.

1:43:48.600 --> 1:44:02.600
 But it's been able to form something that looks like a compression of the data that it's seen that looks awfully a lot like it understands what the heck it's talking about.

1:44:02.600 --> 1:44:07.600
 Well, I think a lot of understanding is like I don't mean to denigrate pattern recognition.

1:44:07.600 --> 1:44:12.600
 Pattern recognition is most of understanding and it's super important and it's super hard.

1:44:12.600 --> 1:44:20.600
 And so like when it's demonstrating this kind of real understanding compressing down some data, like that might be pattern recognition at its finest.

1:44:20.600 --> 1:44:29.600
 My only point would be that like what differentiates math, I think to a large extent is that the pattern recognition isn't sufficient.

1:44:29.600 --> 1:44:38.600
 And that the kind of patterns that you're recognizing are not like the end goals, but instead they are the little bits and paths that get you to the end goal.

1:44:38.600 --> 1:44:41.600
 That's only true for mathematics in general.

1:44:41.600 --> 1:44:48.600
 It's an interesting question if that might for certain kinds of series of numbers, it might not be true.

1:44:48.600 --> 1:45:05.600
 Because that's a basic, like certain kinds of series, it feels like compressing the internet is enough to figure out because those patterns in some form appear in the text somewhere.

1:45:05.600 --> 1:45:15.600
 Well, I mean, there's all sorts of wonderful examples of false patterns in math where one of the earliest videos I put on the channel was talking about you kind of dividing a circle up using these chords.

1:45:15.600 --> 1:45:18.600
 And you see this pattern of 1, 2, 4, 8, 16.

1:45:18.600 --> 1:45:21.600
 I was like, okay, pretty easy to see what that pattern is.

1:45:21.600 --> 1:45:22.600
 It's powers of two.

1:45:22.600 --> 1:45:24.600
 You've seen it a million times.

1:45:24.600 --> 1:45:25.600
 But it's not powers of two.

1:45:25.600 --> 1:45:27.600
 The next term is 31.

1:45:27.600 --> 1:45:30.600
 And so it's like almost a power of two, but it's a little bit shy.

1:45:30.600 --> 1:45:33.600
 And there's actually a very good explanation for what's going on.

1:45:33.600 --> 1:45:44.600
 But I think it's a good test of whether you're thinking clearly about mechanistic explanations of things, how quickly you jump to thinking it must be powers of two.

1:45:44.600 --> 1:45:48.600
 The problem itself, there's really no good way to...

1:45:48.600 --> 1:45:53.600
 I mean, there can't be a good way to think about it as doubling a set because ultimately it doesn't.

1:45:53.600 --> 1:45:58.600
 But even before it starts to, it's not something that screams out as being a doubling phenomenon.

1:45:58.600 --> 1:46:02.600
 So at best, if it did turn out to be powers of two, it would have only been so very subtly.

1:46:02.600 --> 1:46:12.600
 And I think the difference between a math student making a mistake and a mathematician who's experienced seeing that kind of pattern is that they'll have a sense from what the problem itself is,

1:46:12.600 --> 1:46:16.600
 whether the pattern that they're observing is reasonable and how to test it.

1:46:16.600 --> 1:46:24.600
 And I would just be very impressed if there was any algorithm that was actively accomplishing that goal.

1:46:24.600 --> 1:46:27.600
 Yeah, like a learning based algorithm.

1:46:27.600 --> 1:46:30.600
 Like a little scientist, I guess, basically.

1:46:30.600 --> 1:46:38.600
 It's a fascinating thought because GPT3, these language models are already accomplishing way more than I've expected.

1:46:38.600 --> 1:46:41.600
 So I'm learning not to doubt.

1:46:41.600 --> 1:46:42.600
 I bet we'll get there.

1:46:42.600 --> 1:46:45.600
 Yeah, I'm not saying I'd be impressed, but like surprised.

1:46:45.600 --> 1:46:51.600
 I'll be impressed, but I think we'll get there on algorithms doing math like that.

1:46:51.600 --> 1:46:59.600
 So one of the amazing things you've done for the world is, to some degree,

1:46:59.600 --> 1:47:07.600
 open sourcing the tooling that you use to make your videos with Manum, this Python library.

1:47:07.600 --> 1:47:12.600
 Now it's quickly evolving because I think you're inventing new things every time you make a video.

1:47:12.600 --> 1:47:17.600
 In fact, I've been working on playing around with something.

1:47:17.600 --> 1:47:19.600
 I wanted to do like an Ode to Three Blue on Brown.

1:47:19.600 --> 1:47:21.600
 Like I love playing Hendrix.

1:47:21.600 --> 1:47:26.600
 I wanted to do like a cover of a concept I wanted to visualize and use Manum.

1:47:26.600 --> 1:47:30.600
 And I saw that you had like a little piece of code on like Mobius Strip.

1:47:30.600 --> 1:47:40.600
 And I tried to do some cool things with spinning a Mobius Strip, like continue twisting it, I guess is the term.

1:47:40.600 --> 1:47:44.600
 And it was easier to, it was tough.

1:47:44.600 --> 1:47:45.600
 So I haven't figured it out yet.

1:47:45.600 --> 1:47:51.600
 Well, so I guess the question I want to ask is so many people love it that you've put that out there.

1:47:51.600 --> 1:47:53.600
 They want to do the same thing as I do with Hendrix.

1:47:53.600 --> 1:47:54.600
 They want to cover it.

1:47:54.600 --> 1:47:57.600
 They want to explain an idea using the tool, including Rust.

1:47:57.600 --> 1:48:00.600
 How would you recommend?

1:48:00.600 --> 1:48:02.600
 They try to, I'm very sorry.

1:48:02.600 --> 1:48:07.600
 They try to go, they try to go by about it.

1:48:07.600 --> 1:48:13.600
 And what kind of choices should they choose to be most effective?

1:48:13.600 --> 1:48:14.600
 That I can answer.

1:48:14.600 --> 1:48:22.600
 So I always feel guilty if this comes up because I think of it like this scrappy tool that's like a math teacher who put together some code.

1:48:22.600 --> 1:48:23.600
 People asked what it was.

1:48:23.600 --> 1:48:26.600
 So they made it open source and they kept scrapping it together.

1:48:26.600 --> 1:48:33.600
 Like a lot of things about it that make it harder to work with than it needs to be that are a function of like me not being a software engineer.

1:48:33.600 --> 1:48:43.600
 I've put some work this year trying to like make it better and more flexible that is still just kind of like a work in process.

1:48:43.600 --> 1:48:55.600
 One thing I would love to do is just get my act together about properly integrating with what like the community wants to work with and like what stuff I work on and making that not like deviate.

1:48:55.600 --> 1:49:00.600
 And just like actually fostering that community in a way that I've been like shamefully neglectful of.

1:49:00.600 --> 1:49:02.600
 So I'm just always guilty if it comes up.

1:49:02.600 --> 1:49:04.600
 So let's put that guilt aside.

1:49:04.600 --> 1:49:09.600
 Just kind of Zen like Zen like I'll pretend like it isn't terrible for someone like Russ.

1:49:09.600 --> 1:49:19.600
 I think step one is like make sure that what you're animating should be done so programmatically because a lot of things maybe shouldn't like if you're just making a quick graph of something.

1:49:19.600 --> 1:49:28.600
 If it's a graphical intuition that maybe has a little motion to it use Desmos use graph or use Geogebra use Mathematica certain things that are like really oriented around.

1:49:28.600 --> 1:49:30.600
 Geogebra is kind of cool.

1:49:30.600 --> 1:49:31.600
 It's amazing.

1:49:31.600 --> 1:49:33.600
 You can get very, very far with it.

1:49:33.600 --> 1:49:38.600
 And in a lot of ways like it would make more sense for some stuff that I do to just do in Geogebra.

1:49:38.600 --> 1:49:43.600
 But I kind of have this cycle of liking to try to improve Manum by doing videos and such.

1:49:43.600 --> 1:49:45.600
 So do as I say not as I do.

1:49:45.600 --> 1:49:52.600
 So the original like thought I had in making Manum was that there's so many different ways of representing functions other than graphs.

1:49:52.600 --> 1:50:02.600
 In particular things like transformations like use movement over time to communicate relationships between inputs and outputs instead of like X direction and Y direction.

1:50:02.600 --> 1:50:04.600
 Or like vector fields or things like that.

1:50:04.600 --> 1:50:09.600
 So I wanted something that was flexible enough that you didn't feel constrained into a graphical environment.

1:50:09.600 --> 1:50:14.600
 By graphical I mean like graphs with like X coordinate, Y coordinate kind of stuff.

1:50:14.600 --> 1:50:20.600
 But also make sure that you're taking advantage of the fact that it's programmatic.

1:50:20.600 --> 1:50:23.600
 You have loops, you have conditionals, you have abstraction.

1:50:23.600 --> 1:50:29.600
 If any of those are like well fit for what you want to teach to have a scene type that you tweak a little bit based on parameters.

1:50:29.600 --> 1:50:32.600
 Or to have conditional so that things can go one way or another.

1:50:32.600 --> 1:50:36.600
 Or loops so that you can create these things of like arbitrarily increasing complexity.

1:50:36.600 --> 1:50:39.600
 That's the stuff that's like meant to be animated programmatically.

1:50:39.600 --> 1:50:44.600
 If it's just like writing some text on the screen or shifting around objects or something like that.

1:50:44.600 --> 1:50:47.600
 Things like that you should probably just use keynote.

1:50:47.600 --> 1:50:49.600
 You'd be a lot simpler.

1:50:49.600 --> 1:50:58.600
 So try to find a workflow that distills down that which should be programmatic into Manum and that which doesn't need to be into like other domains.

1:50:58.600 --> 1:51:00.600
 Again do as I say not as I do.

1:51:00.600 --> 1:51:03.600
 I mean Python is an integral part of it.

1:51:03.600 --> 1:51:10.600
 Just for the fun of it, let me ask what's your most and least favorite aspects of Python?

1:51:10.600 --> 1:51:12.600
 Most and least.

1:51:12.600 --> 1:51:17.600
 I mean I love that it's like object oriented and functional I guess.

1:51:17.600 --> 1:51:23.600
 That you can kind of like get both of those benefits for how you structure things.

1:51:23.600 --> 1:51:27.600
 So if you would just want to quickly whip something together the functional aspects are nice.

1:51:27.600 --> 1:51:31.600
 Is your primary language like for programmatically generating stuff?

1:51:31.600 --> 1:51:33.600
 It's home for me.

1:51:33.600 --> 1:51:35.600
 Sometimes you travel but it's home.

1:51:35.600 --> 1:51:36.600
 Got it.

1:51:36.600 --> 1:51:37.600
 It's home.

1:51:37.600 --> 1:51:39.600
 I mean the biggest disadvantage is that it's slow.

1:51:39.600 --> 1:51:47.600
 So when you're doing computationally intensive things either you have to like think about it more than you should how to make it efficient or it just like takes long.

1:51:47.600 --> 1:51:49.600
 Do you run into that at all like with your work?

1:51:49.600 --> 1:51:58.600
 Well so certainly old Manum is like way slower than it needs to be because of how it renders things on the back and is like kind of absurd.

1:51:58.600 --> 1:52:07.600
 I've rewritten things such that it's all done with like shaders in such a way that it should be just like live and actually like interactive while you're coding it if you want to.

1:52:07.600 --> 1:52:13.600
 You have like a 3D scene you can move around you can have elements respond to where your mouse is or things.

1:52:13.600 --> 1:52:19.600
 That's not something that user of a video is going to get to experience because there's just a play button and a pause button.

1:52:19.600 --> 1:52:21.600
 But while you're developing that can be nice.

1:52:21.600 --> 1:52:30.600
 So it's gotten better in speed in that sense but that's basically because the hard work is being done in the language that's not Python but GLSL right.

1:52:30.600 --> 1:52:40.600
 But yeah there are some times when it's like a there's just a lot of data that goes into the object that I want to animate that then it just like Python is slow.

1:52:40.600 --> 1:52:49.600
 Well let me ask quickly ask what do you think about the walrus operator if you're familiar with it all the reason it's interesting there's a new operator in Python 3.8.

1:52:49.600 --> 1:53:01.600
 I find it psychologically interesting because the toxicity over it led Guido to resign the step down from actually true or was it like there's a bunch of surrounding things that also was it actually the walrus operator that.

1:53:01.600 --> 1:53:16.600
 Well it was it was a text it was an accumulation of toxicity but that was the most that was the most toxic one like the discussion that's the most number of Python core developers that were opposed to Guido's decision.

1:53:16.600 --> 1:53:29.600
 He didn't particularly I don't think cared about either way he just thought it was a good idea this is where you approve it and like the structure of the idea of a BDFL is like you listen everybody hear everybody out.

1:53:29.600 --> 1:53:37.600
 You make a decision and you move forward and he didn't like the negativity that burden him after that.

1:53:37.600 --> 1:53:44.600
 People like some parts of the benevolent dictator for life mantra but once the dictator does things different than you want suddenly dictatorship doesn't seem so great.

1:53:44.600 --> 1:53:53.600
 Yeah I mean they still like that he just couldn't because he truly is the bee in the benevolent he's really he really is a nice guy I mean and.

1:53:53.600 --> 1:54:03.600
 I think he can't it's a lot of toxicity is difficult it's a difficult job that's why a lot of trouble is perhaps the way he is you have to have a thick skin to fight off.

1:54:03.600 --> 1:54:15.600
 Fight off the warring masses it's kind of surprising to me how many people can like threaten to murder each other over whether we should have braces or not like it's incredible.

1:54:15.600 --> 1:54:23.600
 Yeah I mean that's my knee jerk reaction to the walrus operators like I don't actually care that much other way I'm not going to get really passionate my initial reaction was like.

1:54:23.600 --> 1:54:36.600
 Yeah this seems to make things more confusing to read but then again so does this comprehension until you're used to it so like if there's a use for it great if not great but like let's just all calm down about our spaces versus tabs debates here and like.

1:54:36.600 --> 1:54:46.600
 Be chill yeah to me just represents the value of great leadership even in open source communities doesn't represent that if he stepped down as a leader.

1:54:46.600 --> 1:54:57.600
 Well he fought for it no he got it passed I guess but I guess I could represent multiple things to it can represent like failed dictatorships.

1:54:57.600 --> 1:55:04.600
 Or it can represent a lot of things but to me great leaders take risks even if it.

1:55:04.600 --> 1:55:17.600
 Even if it's a mistake at the end like you have to make decisions the thing is this world won't go anywhere if you can't if whenever there's a divisive thing you wait until the division is no longer there like.

1:55:17.600 --> 1:55:26.600
 That's the paralysis we experienced with like Congress and political systems it's good to be slow when there's in decision when there's.

1:55:26.600 --> 1:55:35.600
 People disagree it's good to take your time but like at a certain point results in paralysis you just have to make a decision the background of the site whether it's.

1:55:35.600 --> 1:55:48.600
 Yellow blue or red can cause people to like go to war over each other which I've seen this with design people are very touched on color color choices at the end of the day just make a decision.

1:55:48.600 --> 1:55:59.600
 And go with that I think that that's what the waters operator represents to me it represents the fighter pilot instinct of like quick action is more important than.

1:55:59.600 --> 1:56:06.600
 Then just like hearing everybody out and really think it through it because that's going to lead to paralysis.

1:56:06.600 --> 1:56:20.600
 Yeah like if that's the actual case that you know it's something where consciously hearing people's disagreement disagreeing with that disagreement and saying he wants to move forward anyway that's an admirable aspect of leadership.

1:56:20.600 --> 1:56:27.600
 So we don't have much time but I want to ask just because it's some beautiful mathematics involved.

1:56:27.600 --> 1:56:42.600
 2020 brought us a couple of in the physics world theories of everything Eric Weisstein kind of it's been working for probably decades but he put out this idea of geometric unity.

1:56:42.600 --> 1:56:48.600
 Or started sort of publicly thinking and talking about a more Stephen Wolfram put out.

1:56:48.600 --> 1:57:01.600
 His physics project which is kind of this hyper graph view of a theory of everything do you find interesting beautiful things to these theories of everything what do you think about the physics world and sort of.

1:57:01.600 --> 1:57:10.600
 The beautiful interesting insightful mathematics in that world whether we're talking about quantum mechanics which you touched on a bunch of your videos a little bit.

1:57:10.600 --> 1:57:18.600
 Quaternions like just the mathematics involved or the general relativity just more about surfaces and topology all that stuff.

1:57:18.600 --> 1:57:27.600
 Well I think as far as like popularized science is concerned people are more interested in theories of everything than they should be like.

1:57:27.600 --> 1:57:35.600
 Because the problem is whether we're talking about trying to make sense of Weinstein's lectures or Wolfram's project or let's just say like listening to.

1:57:35.600 --> 1:57:41.600
 Witten talk about string theory whatever proposed path to a theory of everything.

1:57:41.600 --> 1:57:43.600
 You're not actually going to understand it.

1:57:43.600 --> 1:57:45.600
 Some physicists will be like.

1:57:45.600 --> 1:57:51.600
 Do you just not actually going to understand the substance of what they're saying what I think is way way more productive is.

1:57:51.600 --> 1:57:57.600
 To let yourself get really interested in the phenomena that are still deep but which you have a chance of understanding.

1:57:57.600 --> 1:58:05.600
 Because the path to getting to like even understanding what questions these theories of everything are trying to answer involves like walking down that.

1:58:05.600 --> 1:58:11.600
 I mean I was watching a video before I came here about from Steve Mould talking about why sugar polarizes light in a certain way.

1:58:11.600 --> 1:58:14.600
 So fascinating like really really interesting.

1:58:14.600 --> 1:58:22.600
 It's not like this novel theory of everything type thing but to understand what's going on there really requires digging in in depth to certain ideas.

1:58:22.600 --> 1:58:28.600
 And if you let yourself think past what the video tells you about what does circularly polarized light mean and things like that.

1:58:28.600 --> 1:58:33.600
 It actually would get you to a pretty good appreciation of like two state states and quantum systems.

1:58:33.600 --> 1:58:43.600
 In a way that just trying to read about like what's the what are the hard parts about resolving quantum field theories with general relativity is never going to get you.

1:58:43.600 --> 1:58:47.600
 So as far as popularizing science is concerned like.

1:58:47.600 --> 1:58:52.600
 The audience should be less interested than they are in theories of everything.

1:58:52.600 --> 1:58:59.600
 The popularizers should be less emphatic than they are about that for like actual practicing physicists.

1:58:59.600 --> 1:59:03.600
 I might be the case maybe more people should think about fundamental questions but.

1:59:03.600 --> 1:59:08.600
 It's difficult to create like a three blue one brown video on theory of everything.

1:59:08.600 --> 1:59:17.600
 So basically we should really try to find the beauty in mathematics or physics by looking at concepts that are like within reach.

1:59:17.600 --> 1:59:19.600
 Yeah I think that's super important.

1:59:19.600 --> 1:59:24.600
 I mean so you see this in math too with the big unsolved problems.

1:59:24.600 --> 1:59:27.600
 So like the clay millennium problems Riemann hypothesis.

1:59:27.600 --> 1:59:29.600
 Have you ever done a video on Fermat's last year.

1:59:29.600 --> 1:59:31.600
 No I have not yet.

1:59:31.600 --> 1:59:33.600
 No but if I did do you know what I would do.

1:59:33.600 --> 1:59:39.600
 I would talk about proving Fermat's last theorem in the specific case of n equals three.

1:59:39.600 --> 1:59:41.600
 Is that still accessible though.

1:59:41.600 --> 1:59:43.600
 Yes actually barely.

1:59:43.600 --> 1:59:45.600
 Mathologer might be able to do like a great job on this.

1:59:45.600 --> 1:59:48.600
 He says good job of taking stuff that's barely accessible and making it.

1:59:48.600 --> 1:59:53.600
 But the the core ideas of proving it for n equals three are hard.

1:59:53.600 --> 1:59:56.600
 But they do get you real ideas about algebraic number theory.

1:59:56.600 --> 2:00:00.600
 It involves looking at a number field that's it lives in the complex plane.

2:00:00.600 --> 2:00:05.600
 It looks like a hexagonal lattice and you start asking questions about factoring numbers in this hexagonal lattice.

2:00:05.600 --> 2:00:10.600
 So it takes a while but I've talked about this sort of like lattice arithmetic in other contexts.

2:00:10.600 --> 2:00:14.600
 And you can get to a okay understanding of that.

2:00:14.600 --> 2:00:18.600
 And the things that make Fermat's last theorem hard are actually quite deep.

2:00:18.600 --> 2:00:28.600
 And so the cases that we can solve it for it's like you can get these broad sweeps based on some hard but like accessible bits of number theory.

2:00:28.600 --> 2:00:33.600
 But before you can even understand why the general cases as hard as it is you have to walk through those.

2:00:33.600 --> 2:00:39.600
 And so any other attempt to describe it would just end up being like shallow and not really productive for the viewer's time.

2:00:39.600 --> 2:00:49.600
 I think the same goes for most like unsolved problem type things where I think you know as a kid I was actually very inspired by the twin prime conjecture.

2:00:49.600 --> 2:00:55.600
 That like totally sucked me in is this thing that was understandable I kind of had this dream like oh maybe I'll be the one to prove the twin prime conjecture.

2:00:55.600 --> 2:01:01.600
 And new method I would learn would be like viewed through this lens of like oh maybe I can apply it to that in some way.

2:01:01.600 --> 2:01:10.600
 But you sort of mature to a point where you realize that you should spend your brain cycles on problems that you will see resolved.

2:01:10.600 --> 2:01:19.600
 Because then you're going to grow to see what it feels like for these things to be resolved rather than spending your brain cycles on something where it's not it's not going to pan out.

2:01:19.600 --> 2:01:30.600
 And the people who do make progress towards these things like James Maynard is a great example here of like young creative mathematician who like pushes in the direction of things like the twin prime conjecture.

2:01:30.600 --> 2:01:38.600
 Rather than hitting that head on just see all the interesting questions that are hard for similar reasons but become more tractable and let themselves really engage with those.

2:01:38.600 --> 2:01:49.600
 So I think people should get in that habit I think the popularization of physics should encourage that habit through things like the physics of simple everyday phenomena because it can get quite deep.

2:01:49.600 --> 2:02:03.600
 And yeah I think you know I've heard a lot of the interest that you know people send me messages asking to explain Einstein's thing or asking to explain Wolfram's thing one I don't understand them but more importantly.

2:02:03.600 --> 2:02:08.600
 You shouldn't be interested in those right.

2:02:08.600 --> 2:02:17.600
 The giant sort of ball of interesting ideas there's probably a million of interesting ideas in there that individually could be explored effectively.

2:02:17.600 --> 2:02:22.600
 And to be clear you should be interested in fundamental questions I think that's a good habit to ask like what the fundamentals of things are.

2:02:22.600 --> 2:02:32.600
 But I think it takes a lot of steps to like certainly you shouldn't be trying to answer that unless you actually understand quantum field theory and you actually understand general relativity.

2:02:32.600 --> 2:02:36.600
 That's the cool thing about like your videos people haven't done mathematics.

2:02:36.600 --> 2:02:44.600
 Like if you really give it time watch it a couple of times and like try to try to reason about it you can actually understand the concept that's being explained.

2:02:44.600 --> 2:03:01.600
 And it's not a coincidence that the things I'm describing aren't like the most up to date progress on the Riemann hypothesis cousins or like there's context in which the analog of the Riemann hypothesis has been solved in like more discrete feeling finite settings that are more well behaved.

2:03:01.600 --> 2:03:05.600
 I'm not describing that because it just takes a ton to get there.

2:03:05.600 --> 2:03:12.600
 And instead I think it'll be like productive to have an actual understanding of something that can you can pack into 20 minutes.

2:03:12.600 --> 2:03:14.600
 I think that's beautifully put.

2:03:14.600 --> 2:03:18.600
 Ultimately that's where like the most satisfying thing is when you really understand.

2:03:18.600 --> 2:03:20.600
 Yeah, really understand.

2:03:20.600 --> 2:03:25.600
 Build a habit of feeling what it's like to actually come to resolution.

2:03:25.600 --> 2:03:32.600
 Yeah, as opposed to which it can also be enjoyable but just being in awe of the fact that you don't understand anything.

2:03:32.600 --> 2:03:36.600
 Yeah, that's not like I don't know maybe people get entertainment out of that.

2:03:36.600 --> 2:03:41.600
 But it's not as fulfilling as understanding you won't grow.

2:03:41.600 --> 2:03:42.600
 Yeah.

2:03:42.600 --> 2:03:48.600
 And but also just the fulfilling it really does feel good when you first don't understand something and then you do.

2:03:48.600 --> 2:03:50.600
 That's a beautiful feeling.

2:03:50.600 --> 2:03:58.600
 Let me ask you one last time we got awkward and weird about fear of mortality which you made fun of me of.

2:03:58.600 --> 2:04:07.600
 But let me ask you on the other absurd question is what do you think is the meaning of our life, of meaning of life?

2:04:07.600 --> 2:04:09.600
 I'm sorry if I made fun of you about what you said.

2:04:09.600 --> 2:04:10.600
 No, you didn't.

2:04:10.600 --> 2:04:11.600
 I'm just joking.

2:04:11.600 --> 2:04:12.600
 It was great.

2:04:12.600 --> 2:04:14.600
 I don't think life has a meaning.

2:04:14.600 --> 2:04:17.600
 I think like meaning, I don't understand the question.

2:04:17.600 --> 2:04:21.600
 I think meaning is something that's described to stuff that's created with purpose.

2:04:21.600 --> 2:04:27.600
 There's a meaning to like this water bottle label in that someone created it with a purpose of conveying meaning.

2:04:27.600 --> 2:04:32.600
 And there was like one consciousness that wanted to get its ideas into another consciousness.

2:04:32.600 --> 2:04:34.600
 Most things don't have that property.

2:04:34.600 --> 2:04:39.600
 It's a little bit like if I ask you like what is the height?

2:04:39.600 --> 2:04:40.600
 All right.

2:04:40.600 --> 2:04:41.600
 So it's all relative.

2:04:41.600 --> 2:04:43.600
 Yeah, you'd be like the height of what?

2:04:43.600 --> 2:04:46.600
 You can't ask what is the height without an object.

2:04:46.600 --> 2:04:51.600
 You can't ask what is the meaning of life without like an intentful consciousness putting it...

2:04:51.600 --> 2:04:54.600
 I guess I'm revealing I'm not very religious.

2:04:54.600 --> 2:04:58.600
 But the mathematics of everything seems kind of beautiful.

2:04:58.600 --> 2:05:07.600
 It seems like there's some kind of structure relative to which I mean you could calculate the height.

2:05:07.600 --> 2:05:13.600
 What I'm saying is I don't understand the question what is the meaning of life in that I think people might be asking something very real.

2:05:13.600 --> 2:05:14.600
 I don't understand what they're asking.

2:05:14.600 --> 2:05:16.600
 Are they asking like why does life exist?

2:05:16.600 --> 2:05:17.600
 Like how did it come about?

2:05:17.600 --> 2:05:18.600
 What are the natural laws?

2:05:18.600 --> 2:05:22.600
 Are they asking as I'm making decisions day by day for what should I do?

2:05:22.600 --> 2:05:25.600
 What is the guiding light that inspires like what should I do?

2:05:25.600 --> 2:05:27.600
 I think that's what people are kind of asking.

2:05:27.600 --> 2:05:37.600
 But also like why the thing that gives you joy about education, about mathematics, what the hell is that?

2:05:37.600 --> 2:05:39.600
 Interactions with other people.

2:05:39.600 --> 2:05:43.600
 Interactions with like minded people I think is the meaning of in that sense.

2:05:43.600 --> 2:05:45.600
 It's bringing others joy essentially.

2:05:45.600 --> 2:05:52.600
 Like in something you've created it connects with others somehow and the same in the vice versa.

2:05:52.600 --> 2:06:00.600
 I think that that is what when we use the word meaning to mean like you sort of filled with a sense of happiness and energy to create more things.

2:06:00.600 --> 2:06:03.600
 Like I have so much meaning taken from this like that.

2:06:03.600 --> 2:06:06.600
 Yeah, that's what fuels my pump at least.

2:06:06.600 --> 2:06:10.600
 So life alone on a deserted island will be kind of meaningless.

2:06:10.600 --> 2:06:13.600
 You want to be alone together with someone?

2:06:13.600 --> 2:06:15.600
 I think we're all alone together.

2:06:15.600 --> 2:06:17.600
 I think there's no better way to end it.

2:06:17.600 --> 2:06:19.600
 Grant, you've been first time with talks.

2:06:19.600 --> 2:06:20.600
 It's amazing.

2:06:20.600 --> 2:06:22.600
 Again, it's a huge honor that you make time for me.

2:06:22.600 --> 2:06:24.600
 I appreciate talking with you.

2:06:24.600 --> 2:06:25.600
 Thanks, man.

2:06:25.600 --> 2:06:26.600
 Awesome.

2:06:26.600 --> 2:06:34.600
 Thanks for listening to this conversation with Grant Sanderson and thank you to our sponsors, Dollar Shave Club, DoorDash and Cash App.

2:06:34.600 --> 2:06:39.600
 Click the sponsor links in the description to get a discount and to support this podcast.

2:06:39.600 --> 2:06:46.600
 If you enjoy this thing, subscribe on YouTube, review it with five stars and up a podcast, follow on Spotify, support on Patreon.

2:06:46.600 --> 2:06:50.600
 I'll connect with me on Twitter at Lex Freedman.

2:06:50.600 --> 2:06:53.600
 And now let me leave you with some words from Richard Feynman.

2:06:53.600 --> 2:06:59.600
 I have a friend who's an artist and is sometimes taken a view which I don't agree with very well.

2:06:59.600 --> 2:07:02.600
 He'll hold up a flower and say, look how beautiful it is.

2:07:02.600 --> 2:07:04.600
 And I'll agree.

2:07:04.600 --> 2:07:13.600
 Then he says, I as an artist can see how beautiful this is, but you as a scientist take this all apart and it becomes a dull thing.

2:07:13.600 --> 2:07:15.600
 And I think he's kind of nutty.

2:07:15.600 --> 2:07:20.600
 First of all, the beauty that he sees is available to other people and to me too, I believe.

2:07:20.600 --> 2:07:27.600
 Although I may not be quite as refined aesthetically as he is, I can appreciate the beauty of a flower.

2:07:27.600 --> 2:07:30.600
 At the same time, I see much more about the flower than he sees.

2:07:30.600 --> 2:07:36.600
 I can imagine the cells in there, the complicated actions inside which also have a beauty.

2:07:36.600 --> 2:07:39.600
 I mean, it's not just beauty at this dimension at one centimeter.

2:07:39.600 --> 2:07:45.600
 There's also beauty at smaller dimensions, the inner structure, also the processes.

2:07:45.600 --> 2:07:51.600
 The fact that the colors in the flower evolved in order to attract insects to pollinate it is interesting.

2:07:51.600 --> 2:07:54.600
 It means that insects can see the color.

2:07:54.600 --> 2:07:55.600
 It adds a question.

2:07:55.600 --> 2:07:59.600
 Does this aesthetic sense also exist in the lower forms?

2:07:59.600 --> 2:08:00.600
 Why is it aesthetic?

2:08:00.600 --> 2:08:08.600
 All kinds of interesting questions which the science knowledge only adds to the excitement, the mystery, and the awe of a flower.

2:08:08.600 --> 2:08:09.600
 It only adds.

2:08:09.600 --> 2:08:12.600
 I don't understand how it subtracts.

2:08:12.600 --> 2:08:30.600
 Thank you for listening and hope to see you next time.

