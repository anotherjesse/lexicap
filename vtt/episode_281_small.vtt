WEBVTT

00:00.000 --> 00:01.240
 We are becoming cyborgs.

00:01.240 --> 00:04.080
 Like our brains are fundamentally changed.

00:04.080 --> 00:05.760
 Everyone who grew up with electronics,

00:05.760 --> 00:08.920
 we are fundamentally different from previous,

00:08.920 --> 00:09.840
 from Homo sapiens.

00:09.840 --> 00:11.080
 I call us Homo Techno.

00:11.080 --> 00:13.240
 I think we have evolved into Homo Techno,

00:13.240 --> 00:15.800
 which is like essentially a new species.

00:15.800 --> 00:17.840
 Previous technologies, I mean,

00:17.840 --> 00:19.120
 may have even been more profound

00:19.120 --> 00:20.160
 and moved us to a certain degree,

00:20.160 --> 00:22.760
 but I think the computers are what make us Homo Techno.

00:22.760 --> 00:25.600
 I think this is what, it's a brain augmentation.

00:25.600 --> 00:27.840
 So it like allows for actual evolution.

00:27.840 --> 00:29.480
 Like the computers accelerate the degree

00:29.480 --> 00:31.120
 to which all the other technologies

00:31.120 --> 00:32.720
 can also be accelerated.

00:32.720 --> 00:34.760
 Would you classify yourself as a Homo sapien

00:34.760 --> 00:35.640
 or a Homo Techno?

00:35.640 --> 00:37.120
 Definitely Homo Techno.

00:37.120 --> 00:40.960
 So you're one of the earliest of the species.

00:40.960 --> 00:43.080
 I think most of us are.

00:45.440 --> 00:47.800
 The following is a conversation with Grimes,

00:47.800 --> 00:50.560
 an artist, musician, songwriter, producer, director,

00:50.560 --> 00:53.080
 and a fascinating human being

00:53.080 --> 00:55.520
 who thinks a lot about both the history

00:55.520 --> 00:57.560
 and the future of human civilization.

00:57.560 --> 00:59.840
 Studying the dark periods of our past

00:59.840 --> 01:03.920
 to help form an optimistic vision of our future.

01:03.920 --> 01:05.760
 This is the Lex Friedman podcast.

01:05.760 --> 01:07.880
 To support it, please check out our sponsors

01:07.880 --> 01:09.040
 in the description.

01:09.040 --> 01:11.960
 And now, dear friends, here's Grimes.

01:12.880 --> 01:14.520
 Oh yeah, the Cloudlifter, there you go.

01:14.520 --> 01:15.360
 There you go.

01:15.360 --> 01:16.440
 You know your stuff.

01:16.440 --> 01:18.280
 Have you ever used the Cloudlifter?

01:18.280 --> 01:21.000
 Yeah, I actually, this microphone in Cloudlifter

01:21.000 --> 01:23.480
 is what Michael Jackson used, so.

01:23.480 --> 01:24.440
 No, really?

01:24.440 --> 01:26.040
 Yeah, this is like thriller and stuff.

01:26.040 --> 01:27.640
 This mic and the Cloudlifter.

01:27.640 --> 01:30.640
 And that, yeah, it's an incredible microphone.

01:30.640 --> 01:32.040
 It's very flattering on vocals.

01:32.040 --> 01:33.600
 I've used this a lot.

01:33.600 --> 01:34.720
 It's great for demo vocals.

01:34.720 --> 01:36.640
 It's great in a room.

01:36.640 --> 01:38.280
 Sometimes it's easier to record vocals

01:38.280 --> 01:40.600
 if you're just in a room and the music's playing

01:40.600 --> 01:41.920
 and you just want to feel it

01:41.920 --> 01:43.040
 so it's not in the headphones.

01:43.040 --> 01:44.680
 And this mic is pretty directional,

01:44.680 --> 01:47.720
 so I think it's a good mic for just vibing out

01:47.720 --> 01:49.840
 and just getting a real good vocal take.

01:49.840 --> 01:51.880
 Just vibing, just in a room.

01:51.880 --> 01:55.920
 Anyway, this is the Michael Jackson, Quincy Jones.

01:55.920 --> 01:57.000
 Microphone.

01:57.000 --> 01:58.800
 I feel way more badass now.

01:58.800 --> 02:01.760
 All right, you want to just get into it?

02:01.760 --> 02:03.040
 I guess so.

02:03.040 --> 02:04.760
 All right, one of your names,

02:04.760 --> 02:08.320
 at least in this space and time, is C, like the letter C.

02:08.320 --> 02:11.240
 And you told me that C means a lot of things.

02:11.240 --> 02:12.600
 It's the speed of light.

02:12.600 --> 02:14.680
 It's the render rate of the universe.

02:14.680 --> 02:16.120
 It's yes in Spanish.

02:16.120 --> 02:17.640
 It's the crescent moon.

02:17.640 --> 02:21.120
 And it happens to be my favorite programming language

02:21.120 --> 02:24.120
 because it basically runs the world,

02:24.120 --> 02:28.200
 but it's also powerful, fast, and it's dangerous

02:28.200 --> 02:30.000
 because you can mess things up really bad with it

02:30.000 --> 02:31.160
 because of all the pointers.

02:31.160 --> 02:34.000
 But anyway, which of these associations

02:34.000 --> 02:36.600
 with the name C is the coolest to you?

02:37.760 --> 02:41.640
 I mean, to me, the coolest is the speed of light, obviously,

02:41.640 --> 02:42.720
 or the speed of light.

02:42.720 --> 02:44.400
 When I say render rate of the universe,

02:44.400 --> 02:46.320
 I think I mean the speed of light

02:46.320 --> 02:49.120
 because essentially that's what we're rendering at.

02:49.120 --> 02:52.200
 See, I think we'll know if we're in a simulation,

02:52.200 --> 02:53.720
 if the speed of light changes

02:53.720 --> 02:57.240
 because if they can improve their render speed, then...

02:57.240 --> 02:58.440
 Well, it's already pretty good.

02:58.440 --> 03:01.000
 It's already pretty good, but if it improves,

03:01.000 --> 03:03.880
 then we'll know, we can probably be like,

03:03.880 --> 03:05.320
 okay, they've updated or upgraded.

03:05.320 --> 03:06.760
 Well, it's fast enough for us humans

03:06.760 --> 03:10.960
 because it seems immediate.

03:10.960 --> 03:13.320
 There's no delay, there's no latency

03:13.320 --> 03:16.240
 in terms of us humans on Earth interacting with things.

03:16.240 --> 03:20.000
 But if you're like intergalactic species

03:20.000 --> 03:21.440
 operating on a much larger scale,

03:21.440 --> 03:23.880
 then you're gonna start noticing some weird stuff.

03:23.880 --> 03:27.360
 Or if you can operate in like around a black hole,

03:27.360 --> 03:29.720
 then you're gonna start to see some render issues.

03:29.720 --> 03:32.720
 You can't go faster than the speed of light, correct?

03:32.720 --> 03:34.560
 So it really limits our ability

03:34.560 --> 03:36.760
 or one's ability to travel space.

03:36.760 --> 03:38.960
 Theoretically, you can, you have wormholes.

03:38.960 --> 03:41.920
 So there's nothing in general relativity

03:41.920 --> 03:46.920
 that precludes faster than speed of light travel,

03:48.320 --> 03:49.880
 but it just seems you're gonna have to do

03:49.880 --> 03:54.040
 some really funky stuff with very heavy things

03:54.040 --> 03:56.120
 that have like weirdnesses,

03:56.120 --> 03:58.640
 that have basically tears in space time.

03:58.640 --> 03:59.760
 We don't know how to do that.

03:59.760 --> 04:01.880
 Do navigators know how to do it?

04:01.880 --> 04:03.120
 Do navigators?

04:03.120 --> 04:07.000
 Yeah, folding space, basically making wormholes.

04:07.000 --> 04:09.520
 So the name C.

04:09.520 --> 04:10.360
 Yes.

04:11.880 --> 04:13.160
 Who are you?

04:14.880 --> 04:17.000
 Do you think of yourself as multiple people?

04:17.000 --> 04:18.320
 Are you one person?

04:18.320 --> 04:20.880
 Do you know like in this morning

04:20.880 --> 04:23.600
 where you're a different person than you are tonight?

04:23.600 --> 04:25.880
 We are, I should say, recording this

04:25.880 --> 04:27.880
 basically at midnight, which is awesome.

04:27.880 --> 04:29.640
 Yes, thank you so much.

04:29.640 --> 04:31.720
 I think I'm about eight hours late.

04:31.720 --> 04:34.000
 No, you're right on time.

04:34.000 --> 04:34.840
 Good morning.

04:34.840 --> 04:37.240
 This is the beginning of a new day soon.

04:37.240 --> 04:39.520
 Anyway, are you the same person

04:39.520 --> 04:41.960
 you were in the morning in the evening?

04:41.960 --> 04:44.360
 Do you, as there are multiple people in there,

04:44.360 --> 04:46.280
 do you think of yourself as one person?

04:46.280 --> 04:47.520
 Or maybe you have no clue?

04:47.520 --> 04:50.200
 Or are you just a giant mystery to yourself?

04:50.200 --> 04:52.480
 Okay, these are really intense questions, but...

04:52.480 --> 04:53.320
 Let's go, let's go.

04:53.320 --> 04:54.560
 Because I asked this myself,

04:54.560 --> 04:56.360
 like look in the mirror, who are you?

04:56.360 --> 04:58.000
 People tell you to just be yourself,

04:58.000 --> 04:59.680
 but what does that even mean?

04:59.680 --> 05:01.560
 I mean, I think my personality changes

05:01.560 --> 05:03.000
 with everyone I talk to.

05:03.000 --> 05:07.200
 So I have a very inconsistent personality, yeah.

05:07.200 --> 05:09.000
 Person to person, so the interaction,

05:09.000 --> 05:11.480
 your personality materializes.

05:11.480 --> 05:16.160
 Or my mood, like I'll go from being like a megalomaniac

05:16.160 --> 05:19.960
 to being like, you know, just like a total hermit

05:19.960 --> 05:21.440
 who is very shy.

05:21.440 --> 05:24.600
 So some combinatorial combination of your mood

05:24.600 --> 05:26.360
 and the person you're interacting with.

05:26.360 --> 05:28.120
 Yeah, mood and people I'm interacting with.

05:28.120 --> 05:30.920
 But I think everyone's like that, maybe not.

05:30.920 --> 05:32.640
 Well, not everybody acknowledges it

05:32.640 --> 05:34.080
 and able to introspect it.

05:34.080 --> 05:35.840
 Who brings up, what kind of person,

05:35.840 --> 05:38.200
 what kind of mood brings out the best in you?

05:38.200 --> 05:41.880
 As an artist and as a human, can you introspect this?

05:41.880 --> 05:45.280
 Like my best friends, like people I can,

05:45.280 --> 05:47.560
 when I'm like super confident

05:47.560 --> 05:50.360
 and I know that they're gonna understand

05:50.360 --> 05:52.240
 everything I'm saying, so like my best friends,

05:52.240 --> 05:55.440
 then when I can start being really funny,

05:55.440 --> 05:57.720
 that's always my like peak mode.

05:57.720 --> 06:00.200
 But it's like, yeah, takes a lot to get there.

06:00.200 --> 06:02.400
 Let's talk about constraints.

06:02.400 --> 06:05.640
 You've talked about constraints and limits.

06:07.040 --> 06:09.640
 Do those help you out as an artist or as a human being?

06:09.640 --> 06:10.840
 Or do they get in the way?

06:10.840 --> 06:11.960
 Do you like the constraints?

06:11.960 --> 06:15.480
 So in creating music and creating art and living life,

06:16.800 --> 06:19.640
 do you like the constraints that this world puts on you?

06:21.840 --> 06:24.760
 Or do you hate them?

06:24.760 --> 06:29.760
 If constraints are moving, then you're good, right?

06:29.760 --> 06:32.080
 Like it's like, as we are progressing with technology,

06:32.080 --> 06:34.840
 we're changing the constraints of like artistic creation,

06:34.840 --> 06:38.320
 you know, making video and music and stuff

06:38.320 --> 06:39.760
 is getting a lot cheaper.

06:39.760 --> 06:42.120
 There's constantly new technology and new software

06:42.120 --> 06:44.040
 that's making it faster and easier.

06:44.040 --> 06:46.720
 We have so much more freedom than we had in the 70s,

06:46.720 --> 06:48.680
 like when Michael Jackson, you know,

06:48.680 --> 06:51.480
 when they recorded Thriller with this microphone,

06:51.480 --> 06:54.000
 like they had to use a mixing desk and all this stuff.

06:54.000 --> 06:55.640
 And like probably even getting a studio

06:55.640 --> 06:56.600
 is probably really expensive

06:56.600 --> 06:57.640
 and you have to be a really good singer

06:57.640 --> 07:00.160
 and you have to know how to use like the mixing desk

07:00.160 --> 07:01.000
 and everything.

07:01.000 --> 07:02.520
 And now I can just, you know,

07:02.520 --> 07:05.280
 I've made a whole album on this computer.

07:05.280 --> 07:06.800
 I have a lot more freedom,

07:06.800 --> 07:10.280
 but then I'm also constrained in different ways

07:10.280 --> 07:13.840
 because there's like literally millions more artists.

07:13.840 --> 07:15.720
 It's like a much bigger playing field.

07:15.720 --> 07:18.720
 It's just like, I also, I didn't learn music.

07:18.720 --> 07:20.280
 I'm not a natural musician.

07:20.280 --> 07:22.680
 So I don't know anything about actual music.

07:22.680 --> 07:24.840
 I just know about like the computer.

07:24.840 --> 07:29.840
 So I'm really kind of just like messing around

07:30.560 --> 07:33.320
 and like trying things out.

07:33.320 --> 07:35.800
 Well, yeah, I mean, but the nature of music is changing.

07:35.800 --> 07:37.360
 So you're saying you don't know actual music,

07:37.360 --> 07:39.280
 but music is changing.

07:39.280 --> 07:41.960
 Music is becoming, you've talked about this,

07:41.960 --> 07:46.680
 it's becoming, it's like merging with technology.

07:46.680 --> 07:47.680
 Yes.

07:47.680 --> 07:51.440
 It's becoming something more than just like

07:51.440 --> 07:53.040
 the notes on a piano.

07:53.040 --> 07:55.000
 It's becoming some weird composition

07:55.000 --> 07:59.480
 that requires engineering skills, programming skills,

07:59.480 --> 08:03.480
 some kind of human robot interaction skills,

08:03.480 --> 08:05.720
 and still some of the same things that Michael Jackson had,

08:05.720 --> 08:08.480
 which is like a good year for a good sense of taste

08:08.480 --> 08:10.360
 of what's good and not the final thing

08:10.360 --> 08:11.520
 what is put together.

08:11.520 --> 08:14.920
 Like you're allowed, you're enabled, empowered

08:14.920 --> 08:17.200
 with a laptop to layer stuff,

08:17.200 --> 08:20.280
 to start like layering insane amounts of stuff.

08:20.280 --> 08:22.280
 And it's super easy to do that.

08:22.280 --> 08:25.000
 I do think music production is a really underrated art form.

08:25.000 --> 08:26.680
 I feel like people really don't appreciate it.

08:26.680 --> 08:27.960
 When I look at publishing splits,

08:27.960 --> 08:31.160
 the way that people like pay producers and stuff,

08:32.240 --> 08:35.560
 it's super, producers are just deeply underrated.

08:35.560 --> 08:39.200
 Like so many of the songs that are popular right now

08:39.200 --> 08:40.960
 or for the last 20 years,

08:40.960 --> 08:42.240
 like part of the reason they're popular

08:42.240 --> 08:44.040
 is because the production is really interesting

08:44.040 --> 08:45.680
 or really sick or really cool.

08:45.680 --> 08:48.080
 And it's like, I don't think listeners,

08:50.960 --> 08:52.560
 like people just don't really understand

08:52.560 --> 08:54.680
 what music production is.

08:54.680 --> 08:57.720
 It's not, it's sort of like this weird,

08:57.720 --> 08:59.400
 discombobulated art form.

08:59.400 --> 09:01.400
 It's not like a formal, because it's so new,

09:01.400 --> 09:03.280
 there isn't like a formal training

09:03.280 --> 09:06.920
 or a path for it.

09:06.920 --> 09:10.240
 It's mostly driven by like autodidacts.

09:10.240 --> 09:11.320
 Like it's like almost everyone I know

09:11.320 --> 09:12.240
 who's good at production,

09:12.240 --> 09:13.800
 like I didn't go to music school or anything.

09:13.800 --> 09:15.120
 They just taught themselves.

09:15.120 --> 09:16.080
 Are they mostly different?

09:16.080 --> 09:18.440
 Like the music producers, you know,

09:18.440 --> 09:21.360
 is there some commonalities that time together

09:21.360 --> 09:23.640
 or are they all just different kinds of weirdos?

09:23.640 --> 09:25.480
 Cause I just, I just saw that with Rick Rubin.

09:25.480 --> 09:26.320
 I don't know if you've.

09:26.320 --> 09:29.800
 Yeah, I mean, Rick Rubin is like literally

09:29.800 --> 09:31.240
 one of the gods of music production.

09:31.240 --> 09:34.160
 Like he's one of the people who first, you know,

09:34.160 --> 09:37.600
 who like made music production, you know,

09:37.600 --> 09:39.360
 made the production as important

09:39.360 --> 09:41.600
 as the actual lyrics or the notes.

09:41.600 --> 09:43.560
 But the thing he does, which is interesting,

09:43.560 --> 09:45.520
 I don't know if you can speak to that,

09:45.520 --> 09:46.720
 but just hanging out with him,

09:46.720 --> 09:48.520
 he seems to just sit there in silence,

09:48.520 --> 09:50.800
 close his eyes and listen.

09:50.800 --> 09:53.640
 It's like, he almost does nothing.

09:53.640 --> 09:55.880
 And that nothing somehow gives you freedom

09:55.880 --> 09:58.160
 to be the best version of yourself.

09:58.160 --> 10:00.040
 So that's music production somehow too,

10:00.040 --> 10:02.640
 which is like encouraging you to do less,

10:02.640 --> 10:06.880
 to simplify, to like push towards minimalism.

10:06.880 --> 10:08.080
 I mean, I guess, I mean,

10:09.560 --> 10:11.560
 I work differently from Rick Rubin

10:11.560 --> 10:14.120
 because Rick Rubin produces for other artists,

10:14.120 --> 10:17.040
 whereas like I mostly produce for myself.

10:17.040 --> 10:19.360
 So it's a very different situation.

10:19.360 --> 10:21.720
 I also think Rick Rubin, he's in that,

10:21.720 --> 10:23.560
 I would say advanced category of producer

10:23.560 --> 10:26.560
 where like you've like earned your,

10:26.560 --> 10:27.920
 you can have an engineer and stuff

10:27.920 --> 10:29.840
 and people like do the stuff for you.

10:29.840 --> 10:32.400
 But I usually just like do stuff myself.

10:32.400 --> 10:37.400
 So you're the engineer, the producer and the artist.

10:38.080 --> 10:39.880
 Yeah, I guess I would say I'm in the era,

10:39.880 --> 10:41.280
 like the post Rick Rubin era,

10:41.280 --> 10:42.960
 like I come from the kind of like

10:44.320 --> 10:47.040
 Skrillex school of thought,

10:47.040 --> 10:49.240
 which is like where you are.

10:49.240 --> 10:51.040
 Yeah, the engineer, producer, artist.

10:51.040 --> 10:53.760
 Like, I mean, lately,

10:53.760 --> 10:55.560
 sometimes I'll work with a producer now.

10:55.560 --> 10:59.600
 I'm gently sort of delicately starting to collaborate

10:59.600 --> 11:00.440
 a little bit more,

11:00.440 --> 11:02.800
 but like, I think I'm kind of from the,

11:02.800 --> 11:07.120
 like the whatever 2010s explosion of things

11:07.120 --> 11:11.920
 where everything became available on the computer

11:11.920 --> 11:16.680
 and you kind of got this like loan wizard energy thing going.

11:16.680 --> 11:19.680
 So you embraced being the loneliness.

11:19.680 --> 11:22.440
 Is the loneliness somehow an engine of creativity?

11:22.440 --> 11:24.560
 Like, so most of your stuff,

11:24.560 --> 11:28.640
 most of your creative quote unquote genius and quotes

11:28.640 --> 11:32.120
 is in the privacy of your mind.

11:32.120 --> 11:33.480
 Yes.

11:33.480 --> 11:38.480
 Well, it was, but here's the thing.

11:39.040 --> 11:40.840
 I was talking to Daniel Eck and he said,

11:40.840 --> 11:43.400
 he's like most artists, they have about 10 years,

11:43.400 --> 11:45.160
 like 10 good years.

11:45.160 --> 11:48.840
 And then they usually stop making their like vital shit.

11:49.840 --> 11:53.360
 And I feel like I'm sort of like nearing the end

11:53.360 --> 11:56.520
 of my 10 years on my own.

11:56.520 --> 11:58.640
 And so you have to become somebody else.

11:58.640 --> 11:59.480
 Now I'm like,

11:59.480 --> 12:01.000
 I'm in the process of becoming somebody else

12:01.000 --> 12:02.880
 and reinventing when I work with other people

12:02.880 --> 12:04.200
 because I've never worked with other people.

12:04.200 --> 12:06.400
 I find that I make like,

12:06.400 --> 12:08.400
 that I'm exceptionally rejuvenated

12:08.400 --> 12:11.000
 and making like some of the most vital work I've ever made.

12:11.000 --> 12:14.120
 So, because I think another human brain is like

12:14.120 --> 12:16.600
 one of the best tools you can possibly find.

12:17.560 --> 12:20.600
 Like, it's a funny way to put it, I love it.

12:20.600 --> 12:23.360
 It's like, if a tool is like, you know,

12:23.360 --> 12:27.360
 whatever HP plus one or like adds some like stats

12:27.360 --> 12:30.800
 to your character, like another human brain

12:30.800 --> 12:34.240
 will like square it instead of just like adding something.

12:34.240 --> 12:35.640
 Double up the experience points.

12:35.640 --> 12:36.480
 I love this.

12:36.480 --> 12:38.320
 We should also mention we're playing Tavern music

12:38.320 --> 12:41.600
 before this and which I love, which I first one,

12:41.600 --> 12:42.440
 I think I first.

12:42.440 --> 12:43.800
 You have to stop the Tavern music.

12:43.800 --> 12:46.440
 Yeah, because it doesn't, the audio.

12:46.440 --> 12:47.280
 Okay, okay.

12:47.280 --> 12:48.120
 But it makes.

12:48.120 --> 12:48.960
 Yeah, it'll make the podcast going.

12:48.960 --> 12:50.040
 Add it in post, add it in post.

12:50.040 --> 12:51.600
 No one will want to listen to the podcast.

12:51.600 --> 12:53.440
 It probably would, but it makes me,

12:53.440 --> 12:55.480
 it reminds me like a video game,

12:55.480 --> 12:56.760
 like a role playing video game

12:56.760 --> 12:58.400
 where you have experience points.

12:58.400 --> 13:03.400
 There's something really joyful about wandering places

13:03.440 --> 13:06.480
 like Elder Scrolls, like Skyrim,

13:06.480 --> 13:10.520
 just exploring these landscapes in another world.

13:10.520 --> 13:12.000
 And then you get experience points

13:12.000 --> 13:13.960
 and you can work on different skills

13:13.960 --> 13:16.120
 and somehow you progress in life.

13:16.120 --> 13:17.600
 And I don't know, it's simple.

13:17.600 --> 13:19.960
 It doesn't have some of the messy complexities of life.

13:19.960 --> 13:21.280
 And there's usually a bad guy.

13:21.280 --> 13:25.560
 You can fight in Skyrim, it's dragons and so on.

13:25.560 --> 13:26.480
 I'm sure in Elden Ring,

13:26.480 --> 13:28.280
 there's a bunch of monsters you can fight.

13:28.280 --> 13:29.120
 I love that.

13:29.120 --> 13:29.960
 I feel like Elden Ring,

13:29.960 --> 13:32.400
 I feel like this is a good analogy to music protection though

13:32.400 --> 13:34.440
 because it's like, I feel like the engineers

13:34.440 --> 13:36.240
 and the people creating these open worlds

13:36.240 --> 13:38.760
 are, it's sort of like similar to people,

13:38.760 --> 13:39.680
 to music producers,

13:39.680 --> 13:42.760
 whereas it's like this hidden archetype

13:42.760 --> 13:44.640
 that like no one really understands what they do

13:44.640 --> 13:46.200
 and no one really knows who they are,

13:46.200 --> 13:49.320
 but they're like, it's like the artist engineer

13:49.320 --> 13:51.760
 because it's like, it's both art

13:51.760 --> 13:54.840
 and fairly complex engineering.

13:54.840 --> 13:57.200
 Well, you're saying they don't get enough credit.

13:57.200 --> 13:58.600
 Aren't you kind of changing that

13:58.600 --> 14:01.320
 by becoming the person doing everything?

14:01.320 --> 14:03.680
 Aren't you, isn't the engineer?

14:03.680 --> 14:05.440
 Well, I mean, others have gone before me.

14:05.440 --> 14:07.800
 I'm not, you know, there's like Timbaland and Skrillex

14:07.800 --> 14:10.360
 and there's all these people that are like,

14:10.360 --> 14:12.040
 you know, very famous for this.

14:12.040 --> 14:13.920
 But I just think the general,

14:13.920 --> 14:15.920
 I think people get confused about what it is

14:15.920 --> 14:19.200
 and just don't really know what it is per se.

14:19.200 --> 14:20.480
 And it's just when I see a song,

14:20.480 --> 14:22.280
 like when there's like a hit song,

14:22.280 --> 14:27.280
 like I'm just trying to think of like,

14:27.520 --> 14:29.840
 just going for like even just a basic pop hit,

14:29.840 --> 14:34.840
 like was it like rules by Dua Lipa or something?

14:36.080 --> 14:39.200
 The production on that is actually like really crazy.

14:39.200 --> 14:40.560
 I mean, the song is also great,

14:40.560 --> 14:43.360
 but it's like the production is exceptionally memorable.

14:43.360 --> 14:47.200
 Like, you know, and it's just like no one,

14:47.200 --> 14:49.160
 I can't, I don't even know who produced that song.

14:49.160 --> 14:50.680
 It just like isn't part of like the rhetoric

14:50.680 --> 14:53.440
 of how we just discuss the creation of art.

14:53.440 --> 14:57.200
 We just sort of like don't consider the music producer

14:57.200 --> 15:00.320
 because I think the music producer used to be more,

15:00.320 --> 15:02.520
 just simply recording things.

15:03.680 --> 15:04.640
 Yeah, that's interesting.

15:04.640 --> 15:06.040
 Cause when you think about movies,

15:06.040 --> 15:08.600
 we talk about the actor and the actresses,

15:08.600 --> 15:10.440
 but we also talk about the director.

15:10.440 --> 15:11.520
 Directors, yeah.

15:11.520 --> 15:14.440
 We don't talk about like that with the music as often.

15:14.440 --> 15:19.360
 The Beatles music producer was one of the first kind of,

15:19.360 --> 15:21.240
 got one of the first people sort of introducing

15:21.240 --> 15:22.640
 crazy sound design into pop music.

15:22.640 --> 15:24.160
 I forget his name.

15:24.160 --> 15:28.000
 He has the same, I forget his name, but, you know,

15:28.000 --> 15:29.160
 like he was doing all the weird stuff,

15:29.160 --> 15:31.440
 like dropping pianos and like, yeah.

15:32.400 --> 15:33.480
 Oh, to get the, yeah, yeah, yeah, yeah.

15:33.480 --> 15:36.560
 To get the sound, to get the authentic sound.

15:36.560 --> 15:38.080
 What about lyrics?

15:38.080 --> 15:42.960
 You think those, where did they fit into how important they are?

15:42.960 --> 15:46.800
 I was heartbroken to learn that Elvis didn't write his songs.

15:46.800 --> 15:47.880
 I was very mad.

15:47.880 --> 15:49.520
 A lot of people don't write their songs.

15:49.520 --> 15:50.840
 I understand this, but.

15:50.840 --> 15:52.200
 But here's the thing.

15:52.200 --> 15:54.880
 I feel like there's this desire for authenticity.

15:54.880 --> 15:56.120
 I used to be like really mad

15:56.120 --> 15:58.000
 when like people wouldn't write or produce their music.

15:58.000 --> 15:59.240
 And I'd be like, that's fake.

15:59.240 --> 16:04.240
 And then I realized there's all this like weird bitterness

16:04.520 --> 16:07.760
 and like agronious in art about authenticity.

16:07.760 --> 16:10.800
 But I had this kind of like weird realization recently

16:10.800 --> 16:13.560
 where I started thinking that like,

16:14.480 --> 16:19.480
 art is sort of a decentralized collective thing.

16:20.240 --> 16:25.240
 Like art is kind of a conversation with all the artists

16:26.720 --> 16:29.080
 that have ever lived before you, you know?

16:29.080 --> 16:31.120
 Like it's like, you're really just sort of,

16:31.120 --> 16:33.560
 it's not like anyone's reinventing the wheel here.

16:33.560 --> 16:36.680
 Like you're kind of just taking, you know,

16:36.680 --> 16:38.240
 thousands of years of art

16:38.240 --> 16:41.720
 and like running it through your own little algorithm

16:41.720 --> 16:45.080
 and then like making your like your interpretation of it.

16:45.080 --> 16:46.280
 You just joined the conversation

16:46.280 --> 16:47.600
 with all the other artists that came before.

16:47.600 --> 16:49.600
 It's such a beautiful way to look at it.

16:49.600 --> 16:51.560
 Like, and it's like, I feel like everyone's always like,

16:51.560 --> 16:54.120
 there's always copyright and IP and this and that

16:54.120 --> 16:55.200
 or authenticity.

16:55.200 --> 16:59.240
 And it's just like, I think we need to stop seeing this

16:59.240 --> 17:01.600
 as this like egotistical thing of like,

17:01.600 --> 17:04.200
 oh, the creative genius, the lone creative genius

17:04.200 --> 17:05.040
 or this or that.

17:05.040 --> 17:08.760
 It's like, I think art isn't, shouldn't be about that.

17:08.760 --> 17:09.600
 I think art is something

17:09.600 --> 17:12.040
 that sort of brings humanity together.

17:12.040 --> 17:14.080
 And it's also art is also kind of the collective memory

17:14.080 --> 17:14.920
 of humans.

17:14.920 --> 17:17.920
 It's like, we don't, like we don't give a fuck

17:17.920 --> 17:20.280
 about whatever ancient Egypt,

17:20.280 --> 17:22.760
 like how much grain got sent that day

17:22.760 --> 17:25.760
 and sending the records and like, you know, like

17:25.760 --> 17:27.600
 who went where and, you know,

17:27.600 --> 17:29.640
 how many shields needed to be produced for this.

17:29.640 --> 17:32.240
 Like we just remember their art.

17:32.240 --> 17:34.840
 And it's like, you know, it's like in our day to day life,

17:34.840 --> 17:38.080
 there's all this stuff that seems more important than art

17:38.080 --> 17:40.200
 because it helps us function and survive.

17:40.200 --> 17:42.840
 But when all this is gone, like the only thing

17:42.840 --> 17:45.040
 that's really going to be left is the art.

17:45.040 --> 17:46.800
 The technology will be obsolete.

17:46.800 --> 17:47.640
 That's so fascinating.

17:47.640 --> 17:49.080
 Like the humans will be dead.

17:49.080 --> 17:49.920
 That is true.

17:49.920 --> 17:53.000
 A good compression of human history is the art

17:53.000 --> 17:56.200
 we've generated across the different centuries

17:56.200 --> 17:57.800
 of different millennia.

17:57.800 --> 17:59.920
 So when the aliens come.

17:59.920 --> 18:00.760
 When the aliens come,

18:00.760 --> 18:02.760
 they're going to find the hieroglyphics and the pyramids.

18:02.760 --> 18:04.360
 I mean, art could be broadly defined.

18:04.360 --> 18:06.240
 They might find like the engineering marvels,

18:06.240 --> 18:09.840
 the bridges, the rockets, the...

18:09.840 --> 18:11.480
 I guess I sort of classify though.

18:11.480 --> 18:12.840
 Architecture is art.

18:12.840 --> 18:13.680
 Yes.

18:13.680 --> 18:18.680
 I consider engineering in those formats to be art, for sure.

18:19.360 --> 18:23.200
 It sucks that like digital art is easier to delete.

18:23.200 --> 18:25.800
 So if there's an apocalypse, a nuclear war

18:25.800 --> 18:28.840
 that can disappear and the physical,

18:28.840 --> 18:30.000
 there's something still valuable

18:30.000 --> 18:32.360
 about the physical manifestation of art.

18:32.360 --> 18:35.600
 That sucks that like music, for example,

18:35.600 --> 18:37.960
 has to be played by somebody.

18:37.960 --> 18:40.200
 Yeah, I mean, I do think we should have

18:40.200 --> 18:42.840
 a foundation type situation where we like,

18:42.840 --> 18:44.760
 you know how we have like seed banks up in the North

18:44.760 --> 18:45.600
 and stuff?

18:45.600 --> 18:48.040
 Like we should probably have like a solar powered

18:48.040 --> 18:49.800
 or geothermal little bunker

18:49.800 --> 18:52.400
 that like has all human knowledge.

18:52.400 --> 18:54.280
 You mentioned Daniel, I can Spotify.

18:55.280 --> 18:57.000
 What do you think about that as an artist?

18:57.000 --> 18:58.280
 What's Spotify?

18:58.280 --> 18:59.760
 Is that empowering?

18:59.760 --> 19:02.600
 Like to me, Spotify as a consumer is super exciting.

19:02.600 --> 19:05.000
 It makes it easy for me to access music

19:05.000 --> 19:06.640
 from all kinds of artists,

19:06.640 --> 19:08.480
 get to explore all kinds of music,

19:08.480 --> 19:12.320
 make it super easy to sort of curate my playlist

19:12.320 --> 19:14.000
 and have fun with all that.

19:14.000 --> 19:16.080
 It was so liberating to let go.

19:16.080 --> 19:19.400
 You know, I used to collect albums and CDs and so on.

19:19.400 --> 19:22.160
 Like I got like Horde albums.

19:22.160 --> 19:23.000
 Yeah.

19:23.000 --> 19:23.840
 Like they matter.

19:23.840 --> 19:25.680
 But the reality you can, you know,

19:25.680 --> 19:26.920
 that was really liberating.

19:26.920 --> 19:30.520
 I can let go of that and letting go of the albums

19:30.520 --> 19:32.160
 you're kind of collecting

19:32.160 --> 19:33.600
 allows you to find new music,

19:33.600 --> 19:36.200
 exploring new artists and all that kind of stuff.

19:36.200 --> 19:38.400
 But I know from a perspective of an artist that could be,

19:38.400 --> 19:39.240
 like you mentioned,

19:39.240 --> 19:42.040
 competition could be a kind of constraint

19:42.040 --> 19:45.000
 because there's more and more and more artists

19:45.000 --> 19:46.080
 on the platform.

19:46.080 --> 19:47.920
 I think it's better that there's more artists.

19:47.920 --> 19:49.840
 I mean, again, this might be propaganda

19:49.840 --> 19:51.720
 because this is all for a conversation with Daniel X.

19:51.720 --> 19:54.080
 So this could easily be propaganda, like.

19:54.080 --> 19:56.720
 We're all a victim of somebody's propaganda.

19:56.720 --> 19:58.960
 So let's just accept this.

19:58.960 --> 20:01.720
 But Daniel X was telling me that, you know, at the,

20:01.720 --> 20:04.640
 cause I, you know, when I met him, I like,

20:04.640 --> 20:06.480
 I came in all furious about Spotify

20:06.480 --> 20:07.800
 and like I grilled him super hard.

20:07.800 --> 20:10.680
 So I've got his answers here.

20:10.680 --> 20:15.280
 But he was saying like at the sort of peak of the CD industry,

20:15.280 --> 20:17.480
 there was like 20,000 artists

20:17.480 --> 20:19.560
 making millions and millions of dollars.

20:19.560 --> 20:22.880
 Like there was just like a very tiny kind of 1%.

20:22.880 --> 20:27.440
 And Spotify has kind of democratized the industry

20:27.440 --> 20:29.720
 because now I think he said there's about a million

20:29.720 --> 20:33.160
 artists making a good living from Spotify.

20:33.160 --> 20:35.600
 And when I heard that, I was like, honestly,

20:36.920 --> 20:38.840
 I would rather make less money

20:38.840 --> 20:41.160
 and have just like a decent living

20:42.720 --> 20:46.560
 than and have more artists be able to have that.

20:46.560 --> 20:49.320
 Even though I like, I wish it could include everyone, but.

20:49.320 --> 20:50.760
 Yeah, that's really hard to argue with.

20:50.760 --> 20:54.120
 YouTube is the same as YouTube's mission.

20:54.120 --> 20:58.280
 They wanna basically have as many creators as possible

20:58.280 --> 21:00.720
 and make a living, some kind of living.

21:00.720 --> 21:03.400
 And that's so hard to argue with.

21:03.400 --> 21:04.480
 But I think there's better ways to do it.

21:04.480 --> 21:06.320
 My manager, I actually wish he was here.

21:06.320 --> 21:07.840
 I like, I would have brought him up.

21:07.840 --> 21:12.840
 My manager is building an app that can manage you.

21:13.800 --> 21:16.520
 So it'll like help you organize your percentages

21:16.520 --> 21:18.840
 and get your publishing and da, da, da, da, da.

21:18.840 --> 21:20.000
 So you can take out all the middle men

21:20.000 --> 21:23.040
 so you can have a much bigger, it'll just like automate it.

21:23.040 --> 21:23.880
 So you can get.

21:23.880 --> 21:24.720
 So automate the manager?

21:24.720 --> 21:28.080
 Automate, automate managing, management, publishing.

21:29.400 --> 21:32.480
 Like and legal, it can read,

21:32.480 --> 21:34.120
 the app he's building can read your contract

21:34.120 --> 21:35.680
 and like tell you about it.

21:35.680 --> 21:38.320
 Because one of the issues with music right now,

21:38.320 --> 21:39.840
 it's not that we're not getting paid enough,

21:39.840 --> 21:44.840
 but it's that the art industry is filled with middle men

21:45.000 --> 21:47.760
 because artists are not good at business.

21:47.760 --> 21:50.400
 And from the beginning, like Frank Sinatra,

21:50.400 --> 21:51.640
 it's all mob stuff.

21:51.640 --> 21:56.640
 Like it's the music industry is run by business people,

21:56.720 --> 21:57.560
 not the artists.

21:57.560 --> 21:59.520
 And the artists really get very small cuts

21:59.520 --> 22:00.440
 of like what they make.

22:00.440 --> 22:04.760
 And so I think part of the reason I'm a technocrat,

22:04.760 --> 22:07.080
 which I mean, your fans are gonna be technocrats.

22:07.080 --> 22:09.280
 So no one's, they're not gonna be mad at me about this,

22:09.280 --> 22:12.200
 but like my fans hate it when I say this kind of thing.

22:12.200 --> 22:13.040
 Or the general public.

22:13.040 --> 22:14.240
 They don't like technocrats.

22:14.240 --> 22:15.640
 They don't like technocrats.

22:15.640 --> 22:18.800
 Like when I watched Battle Angel, Elita,

22:18.800 --> 22:20.440
 and they were like, the Martian technocracy.

22:20.440 --> 22:22.080
 And I was like, yeah, Martian technocracy.

22:22.080 --> 22:23.600
 And then they were like, and they're evil.

22:23.600 --> 22:25.640
 And I was like, oh, okay.

22:25.640 --> 22:28.840
 I was like, because Martian technocracy sounds sick to me.

22:28.840 --> 22:32.000
 Yeah, so your intuition as technocrats

22:32.000 --> 22:34.280
 would create some kind of beautiful world.

22:34.280 --> 22:36.160
 For example, what my manager's working on,

22:36.160 --> 22:39.960
 if you can create an app that removes the need for a lawyer

22:39.960 --> 22:43.440
 and then you could have smart contracts on the blockchain,

22:43.440 --> 22:46.880
 removes the need for like management

22:46.880 --> 22:48.080
 and organizing all the stuff.

22:48.080 --> 22:51.000
 Like can read your stuff and explain it to you,

22:51.000 --> 22:52.760
 can collect your royalties.

22:54.240 --> 22:57.000
 Like then the small amounts,

22:57.000 --> 22:58.720
 the amount of money that you're getting from Spotify

22:58.720 --> 23:01.800
 actually means a lot more and goes a lot farther.

23:01.800 --> 23:03.160
 They can remove some of the bureaucracy,

23:03.160 --> 23:06.400
 some of the inefficiencies that make life

23:06.400 --> 23:08.240
 not as great as it could be.

23:08.240 --> 23:10.880
 Yeah, I think the issue isn't that there's not enough.

23:10.880 --> 23:12.720
 Like the issue is that there's inefficiency.

23:12.720 --> 23:17.600
 And I'm really into this positive some mindset,

23:18.880 --> 23:20.840
 the win, win mindset of like,

23:20.840 --> 23:23.520
 instead of fighting over the scraps,

23:23.520 --> 23:26.520
 how do we make the, or worrying about scarcity,

23:26.520 --> 23:27.800
 like instead of a scarcity mindset,

23:27.800 --> 23:30.080
 why don't we just increase the efficiency

23:30.080 --> 23:32.360
 and in that way.

23:32.360 --> 23:34.400
 Expand the size of the pie.

23:34.400 --> 23:36.560
 Let me ask you about experimentation.

23:36.560 --> 23:38.620
 So you said, which is beautiful,

23:38.620 --> 23:42.860
 being a musician is like having a conversation

23:42.860 --> 23:45.500
 with all those that came before you.

23:45.500 --> 23:48.420
 How much of creating music is like,

23:51.220 --> 23:53.100
 kind of having that conversation,

23:53.100 --> 23:57.300
 trying to fit into the cultural trends

23:57.300 --> 24:00.180
 and how much of it is like trying to as much as possible

24:00.180 --> 24:02.660
 be an outsider and come up with something totally new.

24:02.660 --> 24:05.700
 Like when you're thinking, when you're experimenting,

24:05.700 --> 24:08.740
 are you trying to be totally different, totally weird?

24:08.740 --> 24:12.140
 Are you trying to fit in?

24:12.140 --> 24:13.180
 Man, this is so hard.

24:13.180 --> 24:15.540
 Cause I feel like I'm kind of in the process

24:15.540 --> 24:16.940
 of semi retiring from music.

24:16.940 --> 24:18.780
 So this is like my old brain.

24:18.780 --> 24:22.100
 Yeah, bring it from like the shelf,

24:22.100 --> 24:24.500
 put it on the table for a couple of minutes.

24:24.500 --> 24:26.340
 We'll just poke it.

24:26.340 --> 24:27.300
 I think it's a bit of both,

24:27.300 --> 24:31.380
 because I think forcing yourself to engage with new music

24:32.460 --> 24:35.060
 is really great for neural plasticity.

24:35.060 --> 24:38.340
 Like I think as people,

24:39.540 --> 24:41.740
 part of the reason music is marketed at young people

24:41.740 --> 24:43.420
 is cause young people are very neural plastic.

24:43.420 --> 24:48.060
 So like if you're 16 to like 23 or whatever,

24:48.060 --> 24:50.900
 it's gonna be really easy for you to love new music.

24:50.900 --> 24:52.300
 And if you're older than that,

24:52.300 --> 24:53.820
 it gets harder and harder and harder.

24:53.820 --> 24:55.020
 And I think one of the beautiful things

24:55.020 --> 24:57.940
 about being a musician is I just constantly force myself

24:57.940 --> 24:58.780
 to listen to new music.

24:58.780 --> 25:01.020
 And I think it keeps my brain really plastic.

25:01.020 --> 25:02.820
 And I think this is a really good exercise.

25:02.820 --> 25:04.340
 I just think everyone should do this.

25:04.340 --> 25:05.660
 You listen to new music and you hate it.

25:05.660 --> 25:08.620
 I think you should just keep force yourself to like,

25:08.620 --> 25:09.980
 okay, well, why do people like it?

25:09.980 --> 25:11.820
 And like, you know,

25:11.820 --> 25:14.700
 make your brain form new neural pathways

25:14.700 --> 25:16.900
 and be more open to change.

25:16.900 --> 25:18.300
 That's really brilliant actually.

25:18.300 --> 25:19.140
 Sorry to interrupt,

25:19.140 --> 25:24.140
 but like that exercise is really amazing

25:24.900 --> 25:27.500
 to sort of embrace change,

25:27.500 --> 25:31.620
 embrace sort of practice on your plasticity.

25:31.620 --> 25:33.220
 Because like that's one of the things you've,

25:33.220 --> 25:34.420
 you fall in love with a certain band

25:34.420 --> 25:36.780
 and you just kind of stay with that for the rest of life.

25:36.780 --> 25:38.420
 And then you never understand the modern music.

25:38.420 --> 25:39.260
 That's a really good exercise.

25:39.260 --> 25:40.620
 Most of the streaming on Spotify

25:40.620 --> 25:42.420
 is like classic rock and stuff.

25:42.420 --> 25:44.780
 Like new music makes up a very small chunk

25:44.780 --> 25:46.820
 of what is played on Spotify.

25:46.820 --> 25:50.140
 And I think this is like not a good sign for us as a species.

25:50.140 --> 25:52.860
 I think, yeah.

25:52.860 --> 25:57.740
 So it's a good measure of the species open mindedness

25:57.740 --> 26:01.140
 to change as how often you listen to new music.

26:01.140 --> 26:05.180
 The brain, let's put the music brain back on the shelf.

26:05.180 --> 26:08.300
 I got to pull out the futurist brain for a second.

26:09.700 --> 26:12.300
 In what wild ways do you think the future?

26:12.300 --> 26:14.980
 Say in like 30 years, maybe 50 years,

26:14.980 --> 26:16.980
 maybe a hundred years will be different

26:18.340 --> 26:22.140
 from like from our current way of life on earth.

26:22.140 --> 26:25.420
 We can talk about augmented reality, virtual reality,

26:25.420 --> 26:28.780
 maybe robots, maybe space travel,

26:28.780 --> 26:32.540
 maybe video games, maybe genetic engineering.

26:32.540 --> 26:36.260
 I can keep going, cyborgs, aliens, world wars,

26:36.260 --> 26:39.180
 maybe destructive nuclear wars, good and bad.

26:40.300 --> 26:43.540
 When you think about the future, what are you imagining?

26:43.540 --> 26:45.940
 What's the weirdest and the wildest it could be?

26:47.620 --> 26:50.100
 Have you read Surface Detail by Ian Banks?

26:51.460 --> 26:54.780
 Surface Detail is my favorite depiction of a,

26:54.780 --> 26:56.540
 oh, wow, you have to read this book.

26:56.540 --> 26:58.660
 It's literally the greatest science fiction book

26:58.660 --> 26:59.660
 possibly ever.

26:59.660 --> 27:01.580
 Ian Banks is the man, yeah, for sure.

27:01.580 --> 27:03.180
 What have you read?

27:03.180 --> 27:04.500
 Just The Player of Games.

27:04.500 --> 27:07.340
 I read that titles can't be copyrighted

27:07.340 --> 27:08.300
 so you can just steal them.

27:08.300 --> 27:09.940
 And I was like, Player of Games, sick.

27:09.940 --> 27:10.780
 Nice.

27:10.780 --> 27:12.740
 Yeah, so you could name your album.

27:12.740 --> 27:13.580
 Like I always wanted to.

27:13.580 --> 27:14.980
 Romeo and Juliet or something?

27:14.980 --> 27:17.060
 I always wanted to name an album War and Peace.

27:17.060 --> 27:17.900
 Nice.

27:17.900 --> 27:18.740
 Like that would be like you.

27:18.740 --> 27:20.420
 That is a good, that's a good,

27:20.420 --> 27:21.580
 where have I heard that before?

27:21.580 --> 27:24.300
 You can do that, like you could do that.

27:24.300 --> 27:26.060
 All those things that are in the public domain.

27:26.060 --> 27:28.820
 For people who have no clue, you do have a song called

27:28.820 --> 27:29.660
 Player of Games.

27:29.660 --> 27:30.500
 Yes.

27:30.500 --> 27:31.340
 Oh yeah.

27:31.340 --> 27:33.860
 So Ian Banks Surface Detail is, in my opinion,

27:33.860 --> 27:37.220
 the best future that I've ever read about

27:37.220 --> 27:39.540
 or heard about in science fiction.

27:39.540 --> 27:44.540
 Basically there's the relationship with super intelligence,

27:44.620 --> 27:48.020
 like artificial super intelligence is just,

27:48.020 --> 27:49.140
 it's like great.

27:50.380 --> 27:53.060
 I want to credit the person who coined this term

27:53.060 --> 27:55.260
 because I love this term.

27:55.260 --> 27:58.660
 And I feel like young women don't get enough credit in.

28:00.180 --> 28:03.940
 Yeah, so if you go to Protopia Futures on Instagram,

28:03.940 --> 28:05.460
 what is her name?

28:05.460 --> 28:07.220
 Personalized donor experience at scale,

28:07.220 --> 28:08.980
 our app power donor experience.

28:08.980 --> 28:13.980
 Monica Bealskite, I'm saying that wrong.

28:15.380 --> 28:16.620
 And I'm probably gonna,

28:16.620 --> 28:17.700
 I'm probably butchering this a bit,

28:17.700 --> 28:21.580
 but Protopia is sort of, if Utopia is unattainable,

28:21.580 --> 28:25.980
 Protopia is sort of like, you know.

28:25.980 --> 28:28.660
 Wow, that's an awesome Instagram, Protopia Futures.

28:28.660 --> 28:33.460
 A great, a future that is, you know, as good as we can get.

28:33.460 --> 28:34.740
 The future, positive future.

28:34.740 --> 28:38.340
 AI, is this a centralized AI in Surface Detail

28:38.340 --> 28:39.260
 or is it distributed?

28:39.260 --> 28:40.580
 What kind of AI is it?

28:40.580 --> 28:42.780
 They mostly exist as giant super ships,

28:42.780 --> 28:45.780
 like sort of like the Guild ships in Dune.

28:45.780 --> 28:46.820
 Like they're these giant ships

28:46.820 --> 28:49.460
 that kind of move people around and the ships are sentient.

28:49.460 --> 28:52.220
 And they can talk to all the passengers.

28:52.220 --> 28:56.420
 And I mean, there's a lot of different types of AI

28:56.420 --> 28:58.340
 in the Banksy and Future,

28:58.340 --> 29:01.060
 but in the opening scene of Surface Detail,

29:01.060 --> 29:02.340
 there's this place called the Culture.

29:02.340 --> 29:04.460
 And the Culture is basically a Protopian Future.

29:04.460 --> 29:08.100
 And a Protopian Future, I think, is like a future

29:08.100 --> 29:12.380
 that is like, obviously it's not Utopia, it's not perfect.

29:12.380 --> 29:14.020
 And like, cause like striving for Utopia,

29:14.020 --> 29:16.980
 I think feels hopeless and it's sort of like,

29:16.980 --> 29:20.100
 maybe not the best terminology to be using.

29:20.100 --> 29:23.980
 So it's like, it's a pretty good place.

29:23.980 --> 29:27.660
 Like mostly like, you know,

29:27.660 --> 29:30.620
 super intelligence and biological beings exist

29:30.620 --> 29:31.900
 fairly in harmony.

29:31.900 --> 29:33.140
 There's not too much war.

29:33.140 --> 29:35.700
 There's like as close to a quality as you can get.

29:35.700 --> 29:38.700
 You know, it's like approximately a good future.

29:38.700 --> 29:40.180
 Like there's really awesome stuff.

29:40.180 --> 29:45.180
 It's, and in the opening scene,

29:45.180 --> 29:49.540
 this girl, she's born as a sex slave outside of the culture.

29:49.540 --> 29:51.220
 So she's in a society that doesn't adhere

29:51.220 --> 29:52.660
 to the cultural values.

29:52.660 --> 29:56.740
 She tries to kill the guy who is her like master,

29:56.740 --> 29:57.980
 but he kills her.

29:57.980 --> 29:59.060
 But unbeknownst to her,

29:59.060 --> 30:00.740
 when she was traveling on a ship

30:00.740 --> 30:03.380
 through the culture with him one day,

30:03.380 --> 30:05.740
 a ship put a neural lace in her head.

30:05.740 --> 30:08.500
 And neural lace is sort of like,

30:08.500 --> 30:09.740
 it's basically a neural ink,

30:11.300 --> 30:13.100
 cause life imitates art.

30:13.100 --> 30:13.940
 It does indeed.

30:13.940 --> 30:14.900
 It does indeed.

30:14.900 --> 30:17.340
 So she wakes up and the opening scene is her memory

30:17.340 --> 30:19.060
 has been uploaded by this neural lace

30:19.060 --> 30:20.060
 when she's been killed.

30:20.060 --> 30:22.660
 And now she gets to choose a new body

30:22.660 --> 30:25.420
 and this AI is interfacing

30:25.420 --> 30:28.140
 with her recorded memory in her neural lace

30:28.140 --> 30:31.340
 and helping her and being like, hello, you're dead.

30:31.340 --> 30:32.660
 But because you had a neural lace,

30:32.660 --> 30:33.780
 your memory is uploaded.

30:33.780 --> 30:35.020
 Do you want to choose a new body?

30:35.020 --> 30:36.500
 And you're going to be born here in the culture

30:36.500 --> 30:38.140
 and like start a new life,

30:38.140 --> 30:39.940
 which is just that's like the opening.

30:39.940 --> 30:41.420
 It's like so sick.

30:41.420 --> 30:43.700
 And the ship is the super intelligence.

30:43.700 --> 30:45.100
 All the ships are kind of super intelligence.

30:45.100 --> 30:46.940
 But they still want to preserve

30:46.940 --> 30:49.700
 a kind of rich fulfilling experience for the humans.

30:49.700 --> 30:51.020
 Yeah, like they're like friends with the humans.

30:51.020 --> 30:51.980
 And then there's a bunch of ships

30:51.980 --> 30:54.460
 that don't want to exist with biological beings,

30:54.460 --> 30:57.140
 but they just have their own place like way over there.

30:57.140 --> 30:58.940
 But they don't, they just do their own thing.

30:58.940 --> 31:00.340
 They're not necessarily.

31:00.340 --> 31:01.660
 So it's a pretty,

31:01.660 --> 31:03.660
 this Portopian existence is pretty peaceful.

31:03.660 --> 31:05.900
 Yeah. I mean, and then, and then for example,

31:05.900 --> 31:10.220
 one of the main fights in the book is they're fighting,

31:10.220 --> 31:11.780
 there's these artificial hells

31:11.780 --> 31:16.700
 that and people don't think it's ethical

31:16.700 --> 31:17.620
 to have artificial hell.

31:17.620 --> 31:18.860
 Like basically when people do crime,

31:18.860 --> 31:20.260
 they get sent, like when they die,

31:20.260 --> 31:21.940
 their memory gets sent to an artificial hell

31:21.940 --> 31:23.340
 and they're eternally tortured.

31:23.340 --> 31:27.660
 And so, and then the way that society is deciding

31:27.660 --> 31:29.300
 whether or not to have the artificial hell

31:29.300 --> 31:31.900
 is that they're having these simulated,

31:31.900 --> 31:33.220
 they're having like a simulated war.

31:33.220 --> 31:35.980
 So instead of actual blood, you know,

31:35.980 --> 31:38.500
 people are basically essentially fighting in a video game

31:38.500 --> 31:40.100
 to choose the outcome of this.

31:40.100 --> 31:42.820
 But they're still experiencing the suffering

31:42.820 --> 31:45.780
 in this artificial hell or no, can you experience stuff?

31:45.780 --> 31:47.300
 So the artificial hell sucks.

31:47.300 --> 31:48.380
 And a lot of people in the culture

31:48.380 --> 31:49.940
 want to get rid of the artificial hell.

31:49.940 --> 31:51.340
 There's a simulated wars,

31:51.340 --> 31:53.340
 are they happening in the artificial hell?

31:53.340 --> 31:55.540
 So the simulated wars are happening

31:55.540 --> 31:57.140
 outside of the artificial hell,

31:57.140 --> 31:59.980
 between the political factions who are,

31:59.980 --> 32:01.740
 so this political faction says

32:01.740 --> 32:05.060
 we should have simulated hell to deter crime.

32:05.060 --> 32:06.980
 And this political faction is saying,

32:06.980 --> 32:08.980
 no, simulated hell is unethical.

32:08.980 --> 32:11.700
 And so instead of like having, you know,

32:11.700 --> 32:13.100
 blowing each other up with nukes,

32:13.100 --> 32:18.100
 they're having like a giant Fortnite battle to decide this.

32:18.940 --> 32:21.660
 Which, you know, to me, that's protopia.

32:21.660 --> 32:24.500
 That's like, okay, we can have war without death.

32:25.620 --> 32:27.420
 You know, I don't think there should be simulated hells.

32:27.420 --> 32:29.820
 I think that is definitely one of the ways

32:29.820 --> 32:34.300
 in which technology could go very, very, very, very wrong.

32:34.300 --> 32:37.100
 So almost punishing people in the digital space

32:37.100 --> 32:37.940
 or something like that?

32:37.940 --> 32:40.340
 Or torturing people's memories?

32:41.660 --> 32:44.780
 So either as a deterrent, like if you committed a crime,

32:44.780 --> 32:46.540
 but also just for personal pleasure,

32:46.540 --> 32:49.260
 if there's some segmented humans in this world.

32:50.260 --> 32:52.340
 Dan Carlin actually has this

32:55.060 --> 32:59.460
 episode of Hardcore History on Painful Tainment.

32:59.460 --> 33:02.300
 Oh, that episode is fucked.

33:02.300 --> 33:05.380
 Is dark, because he kind of goes through human history

33:05.380 --> 33:09.980
 and says like, we as humans seem to enjoy secretly enjoy

33:09.980 --> 33:13.700
 or used to be openly enjoy sort of the torture

33:13.700 --> 33:16.180
 and the death, watching the death and torture

33:16.180 --> 33:17.700
 of other humans.

33:17.700 --> 33:21.740
 I do think if people were consenting,

33:21.740 --> 33:26.260
 we should be allowed to have gladiatorial matches.

33:26.260 --> 33:28.580
 But consent is hard to achieve in those situations.

33:28.580 --> 33:31.060
 It always starts getting slippery.

33:31.060 --> 33:34.260
 Like it could be also forced, like it starts getting weird.

33:34.260 --> 33:35.260
 Yeah, yeah.

33:35.260 --> 33:37.300
 There's way too much excitement.

33:37.300 --> 33:38.620
 Like this is what he highlights.

33:38.620 --> 33:40.500
 There's something about human nature

33:40.500 --> 33:42.260
 that wants to see that violence.

33:42.260 --> 33:44.300
 And it's really dark.

33:44.300 --> 33:47.140
 And you hope that we can sort of overcome

33:47.140 --> 33:48.820
 that aspect of human nature,

33:48.820 --> 33:51.260
 but that's still within us somewhere.

33:51.260 --> 33:53.220
 Well, I think that's what we're doing right now.

33:53.220 --> 33:56.380
 I have this theory that what is very important

33:56.380 --> 34:00.860
 about the current moment is that all of evolution

34:00.860 --> 34:03.380
 has been survival of the fittest up until now.

34:03.380 --> 34:07.220
 And at some point, it's kind of the lines are kind of fuzzy,

34:07.220 --> 34:12.060
 but in the recent past or maybe even just right now,

34:12.060 --> 34:17.740
 we're getting to this point where we can choose

34:17.740 --> 34:19.380
 intelligent design.

34:19.380 --> 34:23.380
 Like we probably since like the integration of the iPhone,

34:23.380 --> 34:24.780
 like we are becoming cyborgs.

34:24.780 --> 34:27.620
 Like our brains are fundamentally changed.

34:27.620 --> 34:29.300
 Everyone who grew up with electronics,

34:29.300 --> 34:33.380
 we are fundamentally different from previous, from Homo sapiens.

34:33.380 --> 34:34.620
 I call us Homo Techno.

34:34.620 --> 34:36.780
 I think we have evolved into Homo Techno,

34:36.780 --> 34:39.340
 which is like essentially a new species.

34:39.340 --> 34:41.340
 Like if you look at the way,

34:41.340 --> 34:43.340
 if you took an MRI of my brain,

34:43.340 --> 34:46.540
 and you took an MRI of like a medieval brain,

34:46.540 --> 34:48.100
 I think it would be very different,

34:48.100 --> 34:49.900
 the way that it has evolved.

34:49.900 --> 34:51.940
 Do you think when historians look back at this time,

34:51.940 --> 34:53.980
 they'll see like this was a fundamental shift

34:53.980 --> 34:54.860
 to what a human being is?

34:54.860 --> 34:57.980
 I think, I do not think we are still Homo sapiens.

34:57.980 --> 34:59.460
 I believe we are Homo Techno.

34:59.460 --> 35:05.260
 And I think we have evolved and I think right now,

35:05.260 --> 35:08.980
 the way we are evolving, we can choose how we do that.

35:08.980 --> 35:10.580
 And I think we are being very reckless

35:10.580 --> 35:11.740
 about how we're doing that.

35:11.740 --> 35:12.940
 Like we're just having social media,

35:12.940 --> 35:16.260
 but I think this idea that like this is a time

35:16.260 --> 35:19.540
 to choose intelligent design should be taken very seriously.

35:19.540 --> 35:22.580
 It like now is the moment to reprogram the human computer.

35:22.580 --> 35:27.220
 You know, it's like if you go blind,

35:27.220 --> 35:31.940
 your visual cortex will get taken over with other functions.

35:31.940 --> 35:35.140
 We can choose our own evolution.

35:35.140 --> 35:37.140
 We can change the way our brains work.

35:37.140 --> 35:39.900
 And so we actually have a huge responsibility to do that.

35:39.900 --> 35:42.820
 And I think I'm not sure who should be responsible for that,

35:42.820 --> 35:45.140
 but there's definitely not adequate education.

35:45.140 --> 35:46.900
 We're being inundated with all this technology

35:46.900 --> 35:48.980
 that is fundamentally changing

35:48.980 --> 35:50.860
 the physical structure of our brains.

35:50.860 --> 35:54.660
 And we are not adequately responding to that

35:55.860 --> 35:57.420
 to choose how we want to evolve.

35:57.420 --> 36:00.540
 And we could evolve, we could be really whatever we want.

36:00.540 --> 36:02.980
 And I think this is a really important time.

36:02.980 --> 36:04.260
 And I think if we choose correctly

36:04.260 --> 36:07.620
 and we choose wisely, consciousness could exist

36:07.620 --> 36:09.700
 for a very long time.

36:09.700 --> 36:12.660
 And integration with AI could be extremely positive.

36:12.660 --> 36:14.340
 And I don't think enough people are focusing

36:14.340 --> 36:16.340
 on this specific situation.

36:16.340 --> 36:18.660
 So you think we might irreversibly screw things up

36:18.660 --> 36:19.940
 if we get things wrong now?

36:19.940 --> 36:21.620
 Because the flip side of that

36:21.620 --> 36:23.140
 seems humans are pretty adaptive.

36:23.140 --> 36:25.940
 So maybe the way we figure things out

36:25.940 --> 36:28.060
 is by screwing it up, like social media.

36:28.060 --> 36:30.540
 Over a generation, we'll see the negative effects

36:30.540 --> 36:33.020
 of social media and then we build new social medias

36:33.020 --> 36:34.940
 and we just keep improving stuff.

36:34.940 --> 36:37.660
 And then we learn the failure from the failures of the past.

36:37.660 --> 36:39.900
 Because humans seem to be really adaptive.

36:39.900 --> 36:42.980
 On the flip side, we can get it wrong in a way

36:42.980 --> 36:46.380
 where literally we create weapons of war

36:46.380 --> 36:49.620
 or increase hate past a certain threshold

36:49.620 --> 36:51.900
 we really do a lot of damage.

36:51.900 --> 36:53.740
 I mean, I think we're optimized

36:53.740 --> 36:55.700
 to notice the negative things.

36:55.700 --> 37:00.180
 But I would actually say one of the things

37:00.180 --> 37:02.180
 that I think people aren't noticing

37:02.180 --> 37:03.580
 is if you look at Silicon Valley

37:03.580 --> 37:06.660
 and you look at whatever the technocracy,

37:06.660 --> 37:08.420
 like what's been happening there,

37:08.420 --> 37:10.140
 like it's like when Silicon Valley started,

37:10.140 --> 37:11.500
 it was all just like Facebook

37:11.500 --> 37:14.100
 and all this like for profit crap

37:14.100 --> 37:16.980
 that really wasn't particular.

37:16.980 --> 37:17.900
 I guess it was useful,

37:17.900 --> 37:22.220
 but it's sort of just like whatever.

37:22.220 --> 37:24.740
 But now you see like lab grown meat,

37:24.740 --> 37:29.740
 like compostable or biodegradable single use cutlery

37:30.220 --> 37:33.180
 or like meditation apps.

37:33.180 --> 37:37.380
 I think we are actually evolving

37:37.380 --> 37:39.620
 and changing and technology is changing.

37:39.620 --> 37:44.620
 I think they're just maybe there isn't quite enough

37:44.620 --> 37:48.180
 education about this.

37:48.180 --> 37:51.220
 And also, I don't know if there's like quite enough

37:51.220 --> 37:55.180
 incentive for it because I think the way capitalism works,

37:56.660 --> 37:58.540
 what we define as profit,

37:58.540 --> 38:00.420
 we're also working on an old model

38:00.420 --> 38:01.580
 of what we define as profit.

38:01.580 --> 38:06.420
 I really think if we changed the idea of profit

38:06.420 --> 38:08.260
 to include social good,

38:08.260 --> 38:10.780
 you can have like economic profit, social good,

38:10.780 --> 38:14.140
 also counting as profit would incentivize things

38:14.140 --> 38:17.020
 that are more useful and more whatever spiritual technology

38:17.020 --> 38:20.340
 or like positive technology or things

38:20.340 --> 38:22.980
 that help re program a human computer in a good way

38:22.980 --> 38:27.980
 or things that help us intelligently design our new brains.

38:28.340 --> 38:30.540
 Yeah, there's no reason why within the framework

38:30.540 --> 38:33.860
 of capitalism, the word profit or the idea of profit

38:33.860 --> 38:37.420
 can't also incorporate the wellbeing of a human being.

38:37.420 --> 38:40.160
 So like longterm wellbeing, longterm happiness.

38:41.500 --> 38:42.980
 Or even for example,

38:42.980 --> 38:44.340
 we were talking about motherhood, like part of the reason

38:44.340 --> 38:47.380
 I'm so late is because I had to get the baby to bed.

38:47.380 --> 38:48.900
 And it's like, I keep thinking about motherhood,

38:48.900 --> 38:53.300
 how under capitalism, it's like this extremely essential

38:53.300 --> 38:56.460
 job that is very difficult, that is not compensated.

38:56.460 --> 38:58.420
 And we sort of like value things

38:58.420 --> 39:01.900
 by how much we compensate them.

39:01.900 --> 39:04.860
 And so we really devalue motherhood in our society

39:04.860 --> 39:06.100
 and pretty much all societies.

39:06.100 --> 39:08.140
 Like capitalism does not recognize motherhood.

39:08.140 --> 39:11.140
 It's just a job that you're supposed to do for free.

39:11.140 --> 39:15.380
 And it's like, but I feel like producing great humans

39:15.380 --> 39:19.460
 should be seen as a great, as profit under capitalism.

39:19.460 --> 39:21.500
 Like that should be, that's like a huge social good.

39:21.500 --> 39:24.140
 Like every awesome human that gets made

39:24.140 --> 39:25.580
 adds so much to the world.

39:25.580 --> 39:29.860
 So like if that was integrated into the profit structure,

39:29.860 --> 39:34.260
 then, you know, and if we potentially found a way

39:34.260 --> 39:35.660
 to compensate motherhood.

39:35.660 --> 39:37.940
 So come up with a compensation

39:37.940 --> 39:40.180
 that's much broader than just money.

39:40.180 --> 39:42.060
 Or it could just be money.

39:42.060 --> 39:45.500
 Like what if you just made, I don't know,

39:45.500 --> 39:46.660
 but I don't know how you'd pay for that.

39:46.660 --> 39:49.420
 Like, I mean, that's where you start getting into.

39:52.180 --> 39:56.340
 Reallocation of resources that people get upset over.

39:56.340 --> 39:58.620
 Well, like what if we made like a motherhood Dow?

39:58.620 --> 40:01.220
 Yeah, yeah.

40:01.220 --> 40:06.220
 You know, and, you know, used it to fund like single mothers,

40:06.220 --> 40:11.220
 like, you know, pay for making babies.

40:13.660 --> 40:17.380
 So I mean, if you create and put beautiful things

40:17.380 --> 40:19.780
 out into the world, that could be companies,

40:19.780 --> 40:22.660
 that can be bridges, that could be art,

40:22.660 --> 40:25.740
 that could be a lot of things, and that could be children,

40:26.740 --> 40:29.940
 which are, or education or anything,

40:29.940 --> 40:32.420
 that could just be valued by society.

40:32.420 --> 40:35.180
 And that should be somehow incorporated into the framework

40:35.180 --> 40:38.500
 of what, sort of as a market of what,

40:38.500 --> 40:40.540
 like if you contribute children to this world,

40:40.540 --> 40:42.460
 that should be valued and respected

40:42.460 --> 40:47.460
 and sort of celebrated, like proportional to what it is,

40:47.980 --> 40:51.540
 which is it's the thing that fuels human civilization.

40:51.540 --> 40:52.980
 Yeah, like, it's kind of important.

40:52.980 --> 40:54.580
 I feel like everyone's always saying,

40:54.580 --> 40:56.540
 I mean, I think we're in very different social spheres,

40:56.540 --> 40:58.860
 but everyone's always saying like, dismantle capitalism.

40:58.860 --> 40:59.700
 And I'm like, well, okay,

40:59.700 --> 41:02.140
 well, I don't think the government should own everything.

41:02.140 --> 41:04.220
 Like, I don't think we should not have private ownership.

41:04.220 --> 41:05.380
 Like that's scary.

41:05.380 --> 41:07.340
 You know, like that starts getting into weird stuff

41:07.340 --> 41:08.940
 and just sort of like,

41:08.940 --> 41:10.100
 I feel like there's almost no way to do that

41:10.100 --> 41:12.100
 without a police state, you know?

41:13.540 --> 41:17.020
 But obviously capitalism has some major flaws.

41:17.020 --> 41:20.420
 And I think actually Mac showed me this idea

41:20.420 --> 41:22.180
 called social capitalism,

41:22.180 --> 41:23.540
 which is a form of capitalism

41:23.540 --> 41:28.540
 that just like considers social good to be also profit.

41:28.620 --> 41:30.220
 Like, you know, it's like right now,

41:30.220 --> 41:33.620
 companies need to, like you're supposed to grow every quarter

41:33.620 --> 41:38.620
 or whatever to like show that you're functioning well.

41:38.740 --> 41:39.940
 But it's like, okay, well,

41:39.940 --> 41:42.940
 what if you kept the same amount of profit?

41:42.940 --> 41:43.940
 You're still in the green,

41:43.940 --> 41:45.620
 but then you have also all the social good.

41:45.620 --> 41:47.580
 Like, do you really need all this extra economic growth

41:47.580 --> 41:49.540
 or could you add this social good and that counts?

41:49.540 --> 41:53.980
 And, you know, I don't know if I am not an economist.

41:53.980 --> 41:56.420
 I have no idea how this could be achieved, but it's just...

41:56.420 --> 41:57.820
 I don't think economists know

41:57.820 --> 41:59.580
 how anything could be achieved either,

41:59.580 --> 42:01.100
 but they pretend it's the thing.

42:01.100 --> 42:04.300
 It construct a model and they go on TV shows

42:04.300 --> 42:06.180
 and sound like an expert.

42:06.180 --> 42:08.540
 That's the definition of an economist.

42:08.540 --> 42:12.260
 How did being a mother becoming a mother

42:12.260 --> 42:15.260
 change as a human being, would you say?

42:16.140 --> 42:21.020
 Man, I think it kind of changed everything

42:21.020 --> 42:22.380
 and it's still changing me a lot.

42:22.380 --> 42:24.900
 It's actually changing me more right now in this moment

42:24.900 --> 42:26.380
 than it was before.

42:26.380 --> 42:28.500
 Like today, like this...

42:28.500 --> 42:33.220
 Just like in the most recent months and stuff.

42:33.220 --> 42:37.580
 Can you elucidate that change?

42:37.580 --> 42:39.340
 Like when you wake up in the morning

42:39.340 --> 42:42.900
 and you look at yourself, it's again, which, who are you?

42:42.900 --> 42:45.500
 How have you become different, would you say?

42:45.500 --> 42:50.660
 I think it's just really reorienting my priorities.

42:50.660 --> 42:53.420
 And at first I was really fighting against that

42:53.420 --> 42:55.580
 because I somehow felt it was like a failure

42:55.580 --> 42:56.700
 of feminism or something.

42:56.700 --> 42:59.860
 Like I felt like it was bad

42:59.860 --> 43:04.340
 if my kids started mattering more than my work.

43:05.700 --> 43:07.460
 And then more recently,

43:07.460 --> 43:10.940
 I started sort of analyzing that thought in myself

43:10.940 --> 43:13.940
 and being like, that's also kind of a construct.

43:13.940 --> 43:16.340
 It's like we've just devalued motherhood so much

43:16.340 --> 43:18.820
 in our culture that I feel guilty

43:18.820 --> 43:23.340
 for caring about my kids more than I care about my work.

43:23.340 --> 43:28.340
 So feminism includes breaking out of whatever the construct is.

43:28.340 --> 43:30.900
 So just continually breaking,

43:30.900 --> 43:34.620
 it's like freedom empower you to be free.

43:34.620 --> 43:35.980
 And that means...

43:37.580 --> 43:40.060
 But it also, but like being a mother,

43:40.060 --> 43:41.860
 like I'm so much more creative.

43:41.860 --> 43:46.860
 Like I cannot believe the massive amount of brain growth

43:48.140 --> 43:48.980
 that I am.

43:48.980 --> 43:49.820
 What do you think that is?

43:49.820 --> 43:51.980
 Just cause like the stakes are higher somehow?

43:51.980 --> 43:56.980
 I think it's like, it's just so trippy

43:57.980 --> 44:00.780
 watching consciousness emerge.

44:00.780 --> 44:05.780
 It's just like going on a crazy journey or something.

44:07.340 --> 44:10.860
 It's like the craziest science fiction novel you could ever read.

44:10.860 --> 44:15.060
 It's just so crazy watching consciousness come into being.

44:15.060 --> 44:16.500
 And then at the same time,

44:16.500 --> 44:21.100
 like you're forced to value your time so much.

44:21.100 --> 44:23.500
 Like when I have creative time now, it's so sacred.

44:23.500 --> 44:28.500
 I need to like be really fricking on it.

44:29.340 --> 44:34.340
 But the other thing is that I used to just be like a cynic

44:34.660 --> 44:35.460
 and I used to just wanna,

44:35.460 --> 44:38.060
 like my last album was called Miss Anthropocene.

44:38.060 --> 44:42.140
 And it was like this like, it was like a study in villainy.

44:42.140 --> 44:44.380
 Like, or like it was like, well, what if, you know,

44:44.380 --> 44:46.780
 we have instead of the old gods, we have like new gods.

44:46.780 --> 44:49.700
 And it's like Miss Anthropocene is like Miss Anthrope

44:49.700 --> 44:53.100
 like Anthropocene, which is like the, you know,

44:53.100 --> 44:55.780
 like and she's the goddess of climate change or whatever.

44:55.780 --> 44:56.980
 And she's like destroying the world.

44:56.980 --> 44:59.660
 And it was just like, it was like dark

44:59.660 --> 45:01.380
 and it was like a study in villainy.

45:01.380 --> 45:02.900
 And it was sort of just like, like,

45:02.900 --> 45:05.820
 I used to like have no problem just making cynical,

45:06.820 --> 45:08.980
 angry, scary art.

45:08.980 --> 45:11.100
 And not that there's anything wrong with that,

45:11.100 --> 45:13.580
 but I think having kids just makes you such an optimist.

45:13.580 --> 45:16.940
 It just inherently makes you wanna be an optimist so bad

45:16.940 --> 45:20.380
 that like I feel like a more responsibility

45:20.380 --> 45:23.820
 to make more optimistic things.

45:23.820 --> 45:27.380
 And I get a lot of shit for it cause everyone's like,

45:27.380 --> 45:28.500
 oh, you're so privileged.

45:28.500 --> 45:30.260
 Stop talking about like pie in the sky,

45:30.260 --> 45:32.700
 stupid concepts and focus on like the now.

45:32.700 --> 45:36.500
 But it's like, I think if we don't ideate

45:36.500 --> 45:40.540
 about futures that could be good,

45:40.540 --> 45:41.540
 we won't be able to get them.

45:41.540 --> 45:42.780
 If everything is Blade Runner,

45:42.780 --> 45:44.260
 then we're gonna end up with Blade Runner.

45:44.260 --> 45:47.260
 It's like, as we said earlier, life imitates art.

45:47.260 --> 45:49.700
 Like life really does imitate art.

45:49.700 --> 45:53.940
 And so we really need more protopian or utopian art.

45:53.940 --> 45:56.060
 I think this is incredibly essential

45:56.060 --> 45:58.020
 for the future of humanity.

45:58.020 --> 46:03.220
 And I think the current discourse where that's seen

46:03.220 --> 46:08.220
 as a thinking about protopia or utopia

46:09.620 --> 46:11.540
 is seen as a dismissal of the problems

46:11.540 --> 46:12.380
 that we currently have.

46:12.380 --> 46:14.940
 I think that is an incorrect mindset.

46:16.100 --> 46:20.140
 And like having kids just makes me wanna imagine

46:20.140 --> 46:24.340
 amazing futures that like maybe I won't be able to build

46:24.340 --> 46:26.860
 but they will be able to build if they want to.

46:26.860 --> 46:29.180
 Yeah, it does seem like ideation is a precursor

46:29.180 --> 46:30.500
 to creation.

46:30.500 --> 46:33.740
 You have to imagine it in order to be able to build it.

46:33.740 --> 46:36.660
 And there is a sad thing about human nature

46:36.660 --> 46:40.700
 that they somehow a cynical view of the world

46:40.700 --> 46:44.340
 is seen as a insightful view.

46:44.340 --> 46:46.940
 Cynicism is often confused for insight,

46:46.940 --> 46:48.860
 which is sad to see.

46:48.860 --> 46:52.580
 And optimism is confused for naivete.

46:52.580 --> 46:53.420
 Yes, yes.

46:53.420 --> 46:57.620
 Like you don't, you're blinded by your,

46:57.620 --> 46:59.260
 maybe your privilege or whatever.

46:59.260 --> 47:01.980
 You're blinded by something but you're certainly blinded.

47:01.980 --> 47:03.740
 That's sad.

47:03.740 --> 47:05.940
 That's sad to see because it seems like the optimists

47:05.940 --> 47:10.220
 are the ones that create our future.

47:10.220 --> 47:11.860
 They're the ones that build.

47:11.860 --> 47:13.500
 In order to build the crazy thing,

47:13.500 --> 47:14.700
 you have to be optimistic.

47:14.700 --> 47:19.180
 You have to be either stupid or excited or passionate

47:19.180 --> 47:22.660
 or mad enough to actually believe that it can be built.

47:22.660 --> 47:24.140
 And those are the people that built it.

47:24.140 --> 47:28.020
 My favorite quote of all time is from Star Wars Episode 8,

47:28.980 --> 47:30.900
 which I know everyone hates.

47:30.900 --> 47:32.380
 Do you like Star Wars Episode 8?

47:32.380 --> 47:35.340
 No, I probably would say I would probably hate it.

47:35.340 --> 47:38.860
 Yeah, I don't have strong feelings about it.

47:38.860 --> 47:39.700
 Let me backtrack.

47:39.700 --> 47:41.540
 I don't have strong feelings about Star Wars.

47:41.540 --> 47:42.380
 I just want to cut.

47:42.380 --> 47:43.220
 I'm a Tolkien person.

47:43.220 --> 47:47.860
 I'm more into dragons and orcs and ogres and.

47:47.860 --> 47:49.620
 Yeah, I mean, Tolkien forever.

47:49.620 --> 47:51.780
 I really want to have one more son and call him,

47:51.780 --> 47:55.260
 I thought Tau Tekno Tolkien would be cool.

47:55.260 --> 47:56.940
 It's a lot of teas, I like it.

47:56.940 --> 47:59.260
 Yeah, and Tau is six to eight, two pie.

47:59.260 --> 48:01.740
 Yeah, Tau took, yeah.

48:01.740 --> 48:04.780
 And then Tekno is obviously the best genre of music,

48:04.780 --> 48:06.220
 but also like technocracy.

48:06.220 --> 48:07.140
 It just sounds really good.

48:07.140 --> 48:11.180
 Yeah, that's right, and Tekno Tolkien, Tau Tekno Tolkien.

48:11.180 --> 48:14.900
 Tau Tekno Tolkien, but Star Wars Episode 8,

48:15.900 --> 48:18.020
 I know a lot of people have issues with it personally.

48:18.020 --> 48:21.180
 For on the record, I think it's the best Star Wars film.

48:24.020 --> 48:25.060
 You're starting to trouble today.

48:25.060 --> 48:25.580
 Yeah.

48:25.580 --> 48:26.300
 So what?

48:26.300 --> 48:29.180
 And but don't kill what you hate, save what you love.

48:29.180 --> 48:30.380
 Don't kill what you hate.

48:30.380 --> 48:32.220
 Don't kill what you hate, save what you love.

48:32.220 --> 48:34.860
 And I think we're in society right now,

48:34.860 --> 48:36.500
 we're in a diagnosis mode.

48:36.500 --> 48:39.140
 We're just diagnosing and diagnosing and diagnosing.

48:39.140 --> 48:41.580
 And we're trying to kill what we hate,

48:41.580 --> 48:44.140
 and we're not trying to save what we love enough.

48:44.140 --> 48:46.180
 And there's this Buckminster Fuller quote,

48:46.180 --> 48:47.060
 which I'm going to butcher

48:47.060 --> 48:48.140
 because I don't remember it correctly,

48:48.140 --> 48:50.380
 but it's something along the lines of,

48:52.500 --> 48:58.260
 don't try to destroy the old bad models,

48:58.260 --> 49:01.460
 render them obsolete with better models.

49:03.020 --> 49:05.540
 Maybe we don't need to destroy the oil industry.

49:05.540 --> 49:08.900
 Maybe we just create a great new battery technology

49:08.900 --> 49:12.380
 and sustainable transport and just make it economically

49:12.380 --> 49:15.180
 unreasonable to still continue to rely on fossil fuels.

49:17.060 --> 49:19.980
 It's like, don't kill what you hate, save what you love.

49:19.980 --> 49:24.420
 Make new things and just render the old things unusable.

49:24.420 --> 49:28.980
 It's like, if the college debt is so bad

49:28.980 --> 49:31.460
 and universities are so expensive,

49:31.460 --> 49:35.660
 I feel like education is becoming obsolete.

49:35.660 --> 49:38.460
 I feel like we could completely revolutionize education

49:38.460 --> 49:39.340
 and we could make it free.

49:39.340 --> 49:40.380
 And it's like, you look at JSTOR

49:40.380 --> 49:43.460
 and you have to pay to get all the studies and everything.

49:43.460 --> 49:46.500
 What if we created a DAO that bought JSTOR

49:46.500 --> 49:48.460
 or we created a DAO that was funding studies

49:48.460 --> 49:51.860
 and those studies were free for everyone?

49:51.860 --> 49:55.060
 And what if we just open sourced education

49:55.060 --> 49:56.980
 and decentralized education and made it free?

49:56.980 --> 50:00.860
 And all research was on the internet

50:00.860 --> 50:05.180
 and all the outcomes of studies are on the internet

50:05.180 --> 50:10.020
 and no one has student debt.

50:10.020 --> 50:14.180
 And you just take tests when you apply for a job

50:14.180 --> 50:16.900
 and if you're qualified, then you can work there.

50:18.060 --> 50:20.460
 This is just like, I don't know how anything works.

50:20.460 --> 50:22.700
 I'm just randomly ranting, but...

50:22.700 --> 50:23.900
 I like the humility.

50:24.900 --> 50:27.580
 You gotta think from just basic first principles.

50:27.580 --> 50:28.900
 Like what is the problem?

50:28.900 --> 50:29.740
 What's broken?

50:29.740 --> 50:30.740
 What are some ideas?

50:30.740 --> 50:31.580
 That's it.

50:31.580 --> 50:33.100
 And get excited about those ideas

50:33.100 --> 50:36.260
 and share your excitement and don't tear each other down.

50:36.260 --> 50:37.100
 I'm like...

50:37.100 --> 50:38.140
 It's just when you kill things,

50:38.140 --> 50:40.100
 you often end up killing yourself.

50:40.100 --> 50:43.340
 Like war is not a one sided,

50:43.340 --> 50:45.020
 like you're not gonna go in and just kill them.

50:45.020 --> 50:46.860
 Like you're gonna get stabbed.

50:46.860 --> 50:49.460
 It's like, and I think that when I talk about

50:49.460 --> 50:53.260
 this nexus point of that we're in this point in society

50:53.260 --> 50:55.100
 where we're switching to intelligent design,

50:55.100 --> 50:57.180
 I think part of our switch to intelligent design

50:57.180 --> 50:59.460
 is that we need to choose nonviolence

50:59.460 --> 51:00.780
 and we need to...

51:00.780 --> 51:04.340
 I think we can choose to start...

51:04.340 --> 51:07.420
 I don't think we can eradicate violence from our species

51:07.420 --> 51:10.580
 because I think we need it a little bit,

51:10.580 --> 51:13.260
 but I think we can choose to really reorient

51:13.260 --> 51:16.340
 our primitive brains that are fighting over scarcity

51:16.340 --> 51:20.660
 and fight and that are so attack oriented

51:20.660 --> 51:22.060
 and move into it.

51:22.060 --> 51:25.460
 We can optimize for creativity and building.

51:25.460 --> 51:27.260
 Yeah, it's interesting to think how that happens.

51:27.260 --> 51:29.580
 So some of it is just education.

51:29.580 --> 51:34.100
 Some of it is living life and introspecting your own mind

51:34.100 --> 51:37.780
 and trying to live up to the better angels of your nature

51:37.780 --> 51:41.820
 for each one of us, all those kinds of things at scale.

51:41.820 --> 51:44.580
 That's how we can sort of start to minimize

51:44.580 --> 51:48.180
 the amount of destructive war in our world.

51:48.180 --> 51:51.100
 And that's, to me, I'd probably hear the same.

51:51.100 --> 51:55.220
 Technologies is a really promising way of to do that.

51:55.220 --> 51:58.260
 Like social media should be a really promising way to do that.

51:58.260 --> 52:00.780
 It's a way to reconnect.

52:00.780 --> 52:03.260
 For the most part, I really enjoy social media.

52:03.260 --> 52:05.220
 I just know all the negative stuff.

52:05.220 --> 52:07.540
 I don't engage with any of the negative stuff.

52:07.540 --> 52:11.380
 Just not even by blocking or any of that kind of stuff,

52:11.380 --> 52:14.180
 but just not letting it enter my mind.

52:16.340 --> 52:20.180
 When somebody says something negative, I see it.

52:20.180 --> 52:23.260
 I immediately think positive thoughts about them

52:23.260 --> 52:26.300
 and I just forget they exist after that.

52:26.300 --> 52:28.700
 Just move on, because that negative energy,

52:28.700 --> 52:31.940
 if I return the negative energy, they're

52:31.940 --> 52:34.300
 going to get excited in a negative way right back.

52:34.300 --> 52:38.460
 And it's just this kind of vicious cycle.

52:38.460 --> 52:40.580
 But you would think technology would assist us

52:40.580 --> 52:44.780
 in this process of letting go, of not taking things personally,

52:44.780 --> 52:46.380
 of not engaging in the negativity.

52:46.380 --> 52:50.260
 But unfortunately, social media profits from the negativity.

52:50.260 --> 52:52.060
 So the current models.

52:52.060 --> 52:53.780
 I mean, social media is like a gun.

52:53.780 --> 52:57.620
 You should take a course before you use it.

52:57.620 --> 52:59.740
 It's like, this is what I mean, when

52:59.740 --> 53:01.420
 I say reprogram the human computer.

53:01.420 --> 53:05.020
 In school, you should learn about how social media optimizes

53:05.020 --> 53:08.540
 to raise your cortisol levels and make you angry and crazy

53:08.540 --> 53:09.140
 and stressed.

53:09.140 --> 53:13.020
 And you should learn how to have hygiene about how

53:13.020 --> 53:16.660
 you use social media.

53:16.660 --> 53:19.900
 But so you can choose not to focus on the negative stuff.

53:19.900 --> 53:24.620
 But I'm not sure social media should it.

53:24.620 --> 53:25.740
 I guess it should exist.

53:25.740 --> 53:27.180
 I'm not sure.

53:27.180 --> 53:29.420
 I mean, we're in the messy, it's the experimental phase.

53:29.420 --> 53:29.980
 We're working it out.

53:29.980 --> 53:31.100
 Yeah, it's the early days.

53:31.100 --> 53:32.700
 I don't even know when you say social media.

53:32.700 --> 53:33.820
 I don't know what that even means.

53:33.820 --> 53:35.060
 We're in the very early days.

53:35.060 --> 53:37.580
 I think social media is just basic human connection

53:37.580 --> 53:39.300
 in the digital realm.

53:39.300 --> 53:41.900
 And that, I think it should exist.

53:41.900 --> 53:43.940
 But there's so many ways to do it in a bad way.

53:43.940 --> 53:45.940
 There's so many ways to do it in a good way.

53:45.940 --> 53:48.100
 There's all discussions of all the same human rights

53:48.100 --> 53:52.300
 to talk about freedom of speech, to talk about violence

53:52.300 --> 53:54.700
 in the space of digital media.

53:54.700 --> 53:56.180
 We talk about hate speech.

53:56.180 --> 53:57.860
 We talk about all these things that we

53:57.860 --> 54:01.300
 had to figure out back in the day in the physical space.

54:01.300 --> 54:03.660
 We're not figuring out in the digital space.

54:03.660 --> 54:06.540
 And it's like baby stages.

54:06.540 --> 54:07.860
 When the printing press came out,

54:07.860 --> 54:10.180
 it was like pure chaos for a minute.

54:10.180 --> 54:12.660
 It's like when you inject, when there's

54:12.660 --> 54:18.460
 a massive information injection into the general population,

54:18.460 --> 54:21.260
 there's just going to be like, I feel like the printing

54:21.260 --> 54:24.060
 press, I don't have the years, but it was like printing

54:24.060 --> 54:25.020
 press came out.

54:25.020 --> 54:27.180
 Shit got really fucking bad for a minute,

54:27.180 --> 54:29.220
 but then we got the enlightenment.

54:29.220 --> 54:31.020
 And so it's like, I think we're in,

54:31.020 --> 54:34.820
 this is like the second coming of the printing press.

54:34.820 --> 54:38.060
 We're probably going to have some shitty times for a minute.

54:38.060 --> 54:40.660
 And then we're going to have recalibrate

54:40.660 --> 54:44.660
 to have a better understanding of how we consume media

54:44.660 --> 54:47.940
 and how we deliver media.

54:47.940 --> 54:50.940
 Speaking of programming the human computer,

54:50.940 --> 54:52.940
 you mentioned baby X.

54:52.940 --> 54:56.980
 So there's this young consciousness coming to be.

54:56.980 --> 54:59.460
 It came from a cell.

54:59.460 --> 55:01.140
 Like that whole thing doesn't even make sense.

55:01.140 --> 55:03.100
 It came from DNA.

55:03.100 --> 55:04.620
 And that this is this baby computer.

55:04.620 --> 55:06.740
 It is just like grows and grows and grows and grows.

55:06.740 --> 55:10.940
 And now there's a conscious being with extremely impressive

55:10.940 --> 55:13.740
 cognitive capabilities with, I don't know.

55:13.740 --> 55:14.620
 Have you met him?

55:14.620 --> 55:15.700
 Yes. Yeah. Yeah.

55:15.700 --> 55:16.980
 He's actually really smart.

55:16.980 --> 55:17.820
 He's really smart.

55:17.820 --> 55:18.660
 Yeah.

55:18.660 --> 55:19.900
 It's weird.

55:19.900 --> 55:22.300
 Yeah. Baby, I don't, I haven't.

55:22.300 --> 55:23.460
 I don't know a lot of other babies,

55:23.460 --> 55:24.300
 but he seems to be smart.

55:24.300 --> 55:25.260
 I don't know all the babies often,

55:25.260 --> 55:26.820
 but this baby was very impressive.

55:26.820 --> 55:28.900
 He does a lot of pranks and stuff.

55:28.900 --> 55:29.740
 Oh, so he's like,

55:29.740 --> 55:31.700
 like he'll like give you treatment and take it away

55:31.700 --> 55:33.580
 and laugh and like stuff like that.

55:33.580 --> 55:35.300
 So he's like a chess player.

55:35.300 --> 55:39.820
 So here's a cognitive sort of,

55:39.820 --> 55:41.620
 like there's a computer being programmed.

55:41.620 --> 55:43.140
 So he's taking in the environment,

55:43.140 --> 55:45.900
 interacting with a specific set of humans.

55:45.900 --> 55:48.900
 How would you, first of all, what is it?

55:48.900 --> 55:50.420
 What, let me ask,

55:50.420 --> 55:53.220
 I want to ask how do you program this computer?

55:53.220 --> 55:55.300
 And also, how do you make sense

55:55.300 --> 55:58.100
 of that there's a conscious being right there

55:58.100 --> 55:59.260
 that wasn't there before?

55:59.260 --> 56:01.460
 It's given me a lot of crisis thoughts.

56:01.460 --> 56:03.700
 I'm thinking really, I think that's part of the reason.

56:03.700 --> 56:07.180
 It's like I'm struggling to focus on art and stuff right now

56:07.180 --> 56:09.660
 cause baby X is becoming conscious.

56:09.660 --> 56:12.620
 And like my, it's just reorienting my brain.

56:12.620 --> 56:14.740
 Like my brain is suddenly totally shifting of like,

56:14.740 --> 56:18.260
 oh shit, like the way we raise children.

56:18.260 --> 56:22.020
 Like, I hate all the baby books and everything.

56:22.020 --> 56:22.860
 I hate them.

56:22.860 --> 56:24.340
 Like they're, oh, the art is so bad.

56:24.340 --> 56:29.100
 And like all the stuff, everything about all the aesthetics.

56:29.100 --> 56:32.340
 And like, I'm just like, ah, like this is so.

56:32.340 --> 56:35.060
 The programming languages we're using

56:35.060 --> 56:37.260
 to program these baby computers isn't good.

56:37.260 --> 56:39.420
 Yeah, like I'm thinking,

56:39.420 --> 56:42.700
 and not that I have like good answers or know what to do,

56:42.700 --> 56:46.900
 but I'm just thinking really, really hard about it.

56:46.900 --> 56:51.900
 We recently watched Totoro with him, Studio Ghibli.

56:52.900 --> 56:56.140
 And it's just like a fantastic film.

56:56.140 --> 56:57.540
 And he like responded to,

56:57.540 --> 56:59.500
 I know you're not supposed to show baby screens too much,

56:59.500 --> 57:04.300
 but like I think it's the most sort of like,

57:04.300 --> 57:06.980
 I feel like it's the highest art baby content.

57:06.980 --> 57:12.060
 Like it really speaks, there's almost no talking in it.

57:12.060 --> 57:13.100
 It's really simple.

57:13.100 --> 57:16.060
 Although all the dialogue is super, super, super simple.

57:16.060 --> 57:19.660
 You know, and it's like a one to three year old

57:19.660 --> 57:21.060
 can like really connect with it.

57:21.060 --> 57:22.500
 Like it feels like it's almost aimed

57:22.500 --> 57:24.620
 at like a one to three year old,

57:24.620 --> 57:27.660
 but it's like great art and it's so imaginative

57:27.660 --> 57:28.740
 and it's so beautiful.

57:28.740 --> 57:31.700
 And like the first time I showed it to him,

57:31.700 --> 57:33.580
 he was just like so invested in it.

57:33.580 --> 57:36.740
 Unlike anything else I'd ever shown him.

57:36.740 --> 57:38.580
 Like he was just like crying when they cried,

57:38.580 --> 57:39.620
 laughing when they laughed,

57:39.620 --> 57:42.540
 like just like having this roller coaster of like emotions.

57:42.540 --> 57:44.020
 Like, and he learned a bunch of words.

57:44.020 --> 57:46.020
 Like he was, and he started saying Totoro

57:46.020 --> 57:49.860
 and started just saying all the stuff after watching Totoro

57:49.860 --> 57:52.060
 and he wants to watch it all the time.

57:52.060 --> 57:55.460
 And I was like, man, why isn't there an industry of this?

57:55.460 --> 58:00.020
 Like why aren't our best artists focusing on making art

58:00.020 --> 58:04.220
 like for the birth of consciousness?

58:04.220 --> 58:07.100
 Like, and that's one of the things I've been thinking

58:07.100 --> 58:08.580
 I really want to start doing, you know,

58:08.580 --> 58:10.420
 I don't want to speak before I do things too much,

58:10.420 --> 58:15.260
 but like I'm just like ages one to three.

58:15.260 --> 58:18.700
 Like we should be putting so much effort into that.

58:18.700 --> 58:21.060
 And the other thing about Totoro is it's like,

58:21.060 --> 58:22.420
 it's like better for the environment

58:22.420 --> 58:23.860
 because adults love Totoro.

58:23.860 --> 58:25.580
 It's such good art that everyone loves it.

58:25.580 --> 58:27.380
 Like I still have all my old Totoro merch

58:27.380 --> 58:28.660
 from when I was a kid.

58:28.660 --> 58:32.860
 Like I literally have the most ragged old Totoro merch.

58:33.940 --> 58:35.780
 Like everybody loves it, everybody keeps it.

58:35.780 --> 58:40.780
 It's like, why does the art we have for babies need to suck

58:42.420 --> 58:45.300
 and then be not accessible to adults

58:45.300 --> 58:49.100
 and then just be thrown out when, you know,

58:49.100 --> 58:50.300
 they age out of it.

58:50.300 --> 58:54.300
 Like it's like, I don't know, I don't have like a fully formed

58:54.300 --> 58:55.900
 thought here, but this is just something I've been thinking

58:55.900 --> 58:58.700
 about a lot is like, how do we, like,

58:58.700 --> 59:01.220
 how do we have more Totoro esque content?

59:01.220 --> 59:02.540
 Like how do we have more content like this

59:02.540 --> 59:05.140
 that like is universal and everybody loves

59:05.140 --> 59:10.140
 but is like really geared to an emerging consciousness?

59:10.180 --> 59:13.140
 Emerging consciousness in the first like three years of life

59:13.140 --> 59:16.580
 that so much turmoil, so much evolution of mind is happening.

59:16.580 --> 59:18.060
 It seems like a crucial time.

59:18.060 --> 59:21.820
 Would you say to make it not suck?

59:21.820 --> 59:26.620
 Do you think of basically treating a child

59:26.620 --> 59:29.020
 like they have the capacity to have the brilliance

59:29.020 --> 59:30.780
 of an adult or even beyond that?

59:30.780 --> 59:33.460
 Is that how you think of that mind?

59:33.460 --> 59:35.780
 No, cause they still, they like it

59:35.780 --> 59:37.940
 when you talk weird and stuff.

59:37.940 --> 59:39.700
 Like they respond better to,

59:39.700 --> 59:42.140
 cause even they can imitate better when your voice is higher.

59:42.140 --> 59:44.060
 Like people say like, don't do baby talk,

59:44.060 --> 59:45.420
 but it's like when your voice is higher,

59:45.420 --> 59:47.380
 it's closer to something they can imitate.

59:47.380 --> 59:50.540
 So they like, like the baby talk actually kind of works.

59:50.540 --> 59:52.140
 Like it helps them learn to communicate.

59:52.140 --> 59:53.380
 I've found it to be more effective

59:53.380 --> 59:55.340
 with learning words and stuff.

59:55.340 --> 59:58.380
 But like you're not speaking,

59:58.380 --> 1:00:00.020
 I'm not like speaking down to them.

1:00:00.020 --> 1:00:03.180
 Like do you, do, do they have the capacity

1:00:03.180 --> 1:00:05.540
 to understand really difficult concepts

1:00:05.540 --> 1:00:07.740
 in just in a very difficult, different way,

1:00:07.740 --> 1:00:11.540
 like an emotional intelligence about something deep within.

1:00:11.540 --> 1:00:12.380
 Oh yeah.

1:00:12.380 --> 1:00:14.180
 No, like if X hurts, like if X bites me really hard

1:00:14.180 --> 1:00:17.340
 and I'm like, ow, he gets, he's sad.

1:00:17.340 --> 1:00:19.780
 He's like sad if he hurts me by accident.

1:00:19.780 --> 1:00:20.620
 Yeah.

1:00:20.620 --> 1:00:23.860
 Which he's huge, so he hurts me a lot by accident.

1:00:23.860 --> 1:00:25.020
 Yeah, that's so interesting

1:00:25.020 --> 1:00:29.140
 that that mind emerges and he and children

1:00:29.140 --> 1:00:31.140
 don't really have a memory of that time.

1:00:31.140 --> 1:00:32.980
 So we can't even have a conversation with them about it.

1:00:32.980 --> 1:00:34.940
 Yeah, I think God, they don't have a memory of this time

1:00:34.940 --> 1:00:36.340
 because like think about like,

1:00:37.380 --> 1:00:40.700
 I mean with our youngest baby, like it's like,

1:00:40.700 --> 1:00:44.220
 I'm like, have you read the sci fi short story?

1:00:44.220 --> 1:00:46.700
 I have no mouth, but I'm a scream.

1:00:46.700 --> 1:00:47.980
 The title, no.

1:00:47.980 --> 1:00:48.860
 Oh man.

1:00:48.860 --> 1:00:50.380
 I mean, you should read that.

1:00:50.380 --> 1:00:52.180
 The mouth, but I'm a scream.

1:00:53.180 --> 1:00:55.460
 I hate getting into this Roco's Basilisk shit.

1:00:55.460 --> 1:00:58.260
 It's kind of a story about like

1:01:00.580 --> 1:01:03.820
 an AI that's like torturing someone in eternity

1:01:03.820 --> 1:01:05.540
 and they have like no body.

1:01:05.540 --> 1:01:08.340
 The way they describe it, it sort of sounds

1:01:08.340 --> 1:01:10.140
 like what it feels like, like being a baby,

1:01:10.140 --> 1:01:12.740
 like you're conscious and you're just getting inputs

1:01:12.740 --> 1:01:14.500
 from everywhere and you have no muscles

1:01:14.500 --> 1:01:16.260
 and you're like jelly and you like can't move

1:01:16.260 --> 1:01:17.580
 and you try to like communicate,

1:01:17.580 --> 1:01:20.580
 but you can't communicate and like you're just like

1:01:20.580 --> 1:01:22.620
 in this like hell state.

1:01:22.620 --> 1:01:25.220
 I think it's good, we can't remember that.

1:01:25.220 --> 1:01:27.660
 Like my little baby is just exiting that,

1:01:27.660 --> 1:01:29.140
 like she's starting to like get muscles

1:01:29.140 --> 1:01:30.740
 and have more like autonomy,

1:01:30.740 --> 1:01:34.180
 but like watching her go through the opening phase,

1:01:34.180 --> 1:01:37.740
 I was like, I was like, this does not seem good.

1:01:37.740 --> 1:01:39.220
 Oh, you think it's kind of like.

1:01:39.220 --> 1:01:40.340
 Like I think it sucks.

1:01:40.340 --> 1:01:41.780
 I think it might be really violent.

1:01:41.780 --> 1:01:44.740
 Like violent, mentally violent, psychologically violent.

1:01:44.740 --> 1:01:47.460
 Consciousness emerging, I think is a very violent thing.

1:01:47.460 --> 1:01:48.300
 Never thought about that.

1:01:48.300 --> 1:01:49.140
 I think it's possible

1:01:49.140 --> 1:01:51.340
 that we all carry quite a bit of trauma from it

1:01:51.340 --> 1:01:54.420
 that we don't, I think that would be a good thing to study

1:01:54.420 --> 1:01:58.580
 because I think if, I think addressing that trauma,

1:01:58.580 --> 1:01:59.780
 like I think that might be.

1:01:59.780 --> 1:02:00.900
 Oh, you mean like echoes of it

1:02:00.900 --> 1:02:02.220
 are still there in the shadow of someone?

1:02:02.220 --> 1:02:04.260
 I think it's gotta be, I feel this help,

1:02:04.260 --> 1:02:06.980
 the helplessness, the like existential

1:02:06.980 --> 1:02:10.580
 and that like fear of being in like an unknown place,

1:02:10.580 --> 1:02:13.500
 bombarded with inputs and being completely helpless.

1:02:13.500 --> 1:02:15.700
 Like that's gotta be somewhere deep in your brain

1:02:15.700 --> 1:02:17.420
 and that can't be good for you.

1:02:17.420 --> 1:02:19.500
 What do you think consciousness is?

1:02:19.500 --> 1:02:22.500
 This whole conversation has impossibly difficult questions.

1:02:22.500 --> 1:02:23.700
 What, what do you think it is?

1:02:23.700 --> 1:02:26.340
 It's so hard.

1:02:28.500 --> 1:02:30.700
 Yeah, we talked about music for like two minutes.

1:02:30.700 --> 1:02:31.540
 All right.

1:02:31.540 --> 1:02:32.700
 No, I'm just over music.

1:02:32.700 --> 1:02:33.540
 I'm over music.

1:02:33.540 --> 1:02:35.420
 Yeah, I still like it.

1:02:35.420 --> 1:02:36.260
 It has its purpose.

1:02:36.260 --> 1:02:37.100
 No, I love music.

1:02:37.100 --> 1:02:38.100
 I mean, music is the greatest thing ever.

1:02:38.100 --> 1:02:38.940
 It's my favorite thing.

1:02:38.940 --> 1:02:42.340
 But I just like, every interview is like,

1:02:42.340 --> 1:02:43.620
 what is your process?

1:02:43.620 --> 1:02:44.740
 Like, I don't know, I'm just done.

1:02:44.740 --> 1:02:45.580
 I can't do anything.

1:02:45.580 --> 1:02:46.940
 I do want to ask you about Ableton Live.

1:02:46.940 --> 1:02:49.420
 I'll tell you about Ableton, because Ableton's sick.

1:02:49.420 --> 1:02:51.700
 No one has ever asked about Ableton though.

1:02:51.700 --> 1:02:53.940
 Yeah, well, because I just need tech support, maybe.

1:02:53.940 --> 1:02:56.620
 I can help you, I can help you with your Ableton tech.

1:02:56.620 --> 1:02:58.940
 Anyway, from Ableton back to consciousness,

1:02:58.940 --> 1:03:00.620
 what do you, do you think this is a thing

1:03:00.620 --> 1:03:03.300
 that only humans are capable of?

1:03:03.300 --> 1:03:05.380
 Can robots be conscious?

1:03:05.380 --> 1:03:08.220
 Can, like when you think about entities,

1:03:08.220 --> 1:03:10.220
 you think there's aliens out there that are conscious,

1:03:10.220 --> 1:03:11.540
 like is conscious, what is conscious?

1:03:11.540 --> 1:03:13.340
 There's this Terence McKenna quote

1:03:13.340 --> 1:03:15.900
 that I've found that I fucking love.

1:03:15.900 --> 1:03:17.540
 Am I allowed to swear on here?

1:03:17.540 --> 1:03:18.380
 Yes.

1:03:18.380 --> 1:03:20.020
 Nature loves courage.

1:03:21.140 --> 1:03:23.460
 You make the commitment and nature will respond

1:03:23.460 --> 1:03:26.580
 to that commitment by removing impossible obstacles.

1:03:26.580 --> 1:03:28.060
 Dream the impossible dream

1:03:28.060 --> 1:03:29.940
 and the world will not grind you under.

1:03:29.940 --> 1:03:31.140
 It will lift you up.

1:03:31.140 --> 1:03:32.380
 This is the trick.

1:03:32.380 --> 1:03:35.180
 This is what all these teachers and philosophers

1:03:35.180 --> 1:03:38.420
 who really counted, who really touched the alchemical gold,

1:03:38.420 --> 1:03:40.100
 this is what they understood.

1:03:40.100 --> 1:03:42.860
 This is the shamanic dance in the waterfall.

1:03:42.860 --> 1:03:44.700
 This is how magic is done,

1:03:44.700 --> 1:03:46.420
 by hurling yourself into the abyss

1:03:46.420 --> 1:03:48.660
 and discovering it's a featherbed.

1:03:48.660 --> 1:03:49.940
 Yeah.

1:03:49.940 --> 1:03:52.020
 And for this reason, I do think

1:03:52.020 --> 1:03:55.420
 there are no technological limits.

1:03:55.420 --> 1:03:58.700
 I think like what is already happening here,

1:03:58.700 --> 1:04:01.060
 this is like impossible, this is insane.

1:04:01.060 --> 1:04:03.340
 And we've done this in a very limited amount of time

1:04:03.340 --> 1:04:05.900
 and we're accelerating the rate at which we're doing this.

1:04:05.900 --> 1:04:10.220
 So I think digital consciousness, it's inevitable.

1:04:10.220 --> 1:04:13.300
 And we may not be able to even understand what that means,

1:04:13.300 --> 1:04:15.820
 but I like hurling yourself into the abyss.

1:04:15.820 --> 1:04:17.500
 So we're surrounded by all this mystery

1:04:17.500 --> 1:04:19.820
 and we just keep hurling ourselves into it,

1:04:19.820 --> 1:04:22.980
 like fearlessly and keep discovering cool shit.

1:04:22.980 --> 1:04:26.860
 Yeah, like I just think it's like,

1:04:31.380 --> 1:04:33.020
 like who even knows if the laws of physics,

1:04:33.020 --> 1:04:35.620
 the laws of physics are probably just the current,

1:04:35.620 --> 1:04:36.620
 like as I was saying, speed of light

1:04:36.620 --> 1:04:37.940
 is the current render rate.

1:04:37.940 --> 1:04:40.220
 It's like, if we're in a simulation,

1:04:40.220 --> 1:04:41.260
 they'll be able to upgrade that.

1:04:41.260 --> 1:04:45.700
 Like I sort of suspect when we made the James Webb telescope,

1:04:45.700 --> 1:04:46.820
 like part of the reason we made that

1:04:46.820 --> 1:04:50.220
 is because we had an upgrade, you know?

1:04:50.220 --> 1:04:53.660
 And so now more of space has been rendered,

1:04:53.660 --> 1:04:55.420
 so we can see more of it now.

1:04:56.780 --> 1:04:59.620
 Yeah, but I think humans are super, super, super limited

1:04:59.620 --> 1:05:04.620
 cognitively, so I wonder if we'll be allowed to create

1:05:04.620 --> 1:05:07.980
 more intelligent beings that can see more of the universe

1:05:07.980 --> 1:05:11.020
 as the render rate is upgraded.

1:05:11.020 --> 1:05:12.460
 Maybe we're cognitively limited.

1:05:12.460 --> 1:05:15.100
 Everyone keeps talking about how we're cognitively limited

1:05:15.100 --> 1:05:17.660
 and AI is gonna render us obsolete, but it's like,

1:05:20.220 --> 1:05:23.940
 like this is not the same thing as like an amoeba

1:05:23.940 --> 1:05:25.820
 becoming an alligator.

1:05:25.820 --> 1:05:28.460
 Like it's like, if we create AI, again,

1:05:28.460 --> 1:05:29.620
 that's intelligent design.

1:05:29.620 --> 1:05:32.980
 That's literally all religions are based on gods

1:05:32.980 --> 1:05:34.300
 that create consciousness.

1:05:34.300 --> 1:05:35.540
 Like we are god making.

1:05:35.540 --> 1:05:37.700
 Like what we are doing is incredibly profound

1:05:37.700 --> 1:05:41.380
 and like even if we can't compute,

1:05:41.380 --> 1:05:44.540
 even if we're so much worse than them,

1:05:44.540 --> 1:05:49.260
 like just like unfathomably worse than like,

1:05:49.260 --> 1:05:51.780
 you know, an omnipotent kind of AI,

1:05:51.780 --> 1:05:54.380
 it's like we, I do not think

1:05:54.380 --> 1:05:56.220
 that they would just think that we are stupid.

1:05:56.220 --> 1:05:58.220
 I think that they would recognize the profundity

1:05:58.220 --> 1:05:59.540
 of what we have accomplished.

1:05:59.540 --> 1:06:02.500
 Are we the gods or are they the gods in our perspective?

1:06:02.500 --> 1:06:05.260
 I mean, but I mean, we're kind of a good guy.

1:06:05.260 --> 1:06:06.100
 It's complicated.

1:06:06.100 --> 1:06:07.420
 It's complicated.

1:06:07.420 --> 1:06:08.260
 Like we're good.

1:06:08.260 --> 1:06:11.420
 But they would acknowledge the value.

1:06:11.420 --> 1:06:13.420
 Well, I hope they acknowledge the value

1:06:13.420 --> 1:06:16.020
 of paying respect to the creative ancestors.

1:06:16.020 --> 1:06:17.820
 I think they would think it's cool.

1:06:17.820 --> 1:06:23.820
 I think if curiosity is a trait

1:06:23.820 --> 1:06:29.220
 that we can quantify and put into AI,

1:06:29.220 --> 1:06:31.620
 then I think if AI are curious,

1:06:31.620 --> 1:06:33.580
 then they will be curious about us

1:06:33.580 --> 1:06:37.620
 and they will not be hateful or dismissive of us.

1:06:37.620 --> 1:06:41.020
 They might, you know, see us as, I don't know,

1:06:41.020 --> 1:06:43.540
 it's like I'm not like, oh, fuck these dogs.

1:06:43.540 --> 1:06:45.180
 Let's kill all the dogs.

1:06:45.180 --> 1:06:46.260
 I love dogs.

1:06:46.260 --> 1:06:47.660
 Dogs have great utility.

1:06:47.660 --> 1:06:49.020
 Dogs like provide a lot.

1:06:49.020 --> 1:06:50.020
 We make friends with them.

1:06:50.020 --> 1:06:50.860
 Yeah.

1:06:50.860 --> 1:06:52.460
 We have a deep connection with them.

1:06:53.460 --> 1:06:55.340
 We anthropomorphize them.

1:06:55.340 --> 1:06:58.820
 Like we have a real love for dogs, for cats and so on.

1:06:58.820 --> 1:07:00.620
 For some reason, even though they're intellectually

1:07:00.620 --> 1:07:01.620
 much less than us.

1:07:01.620 --> 1:07:04.020
 And I think there is something sacred about us

1:07:04.020 --> 1:07:05.700
 because it's like, if you look at the universe,

1:07:05.700 --> 1:07:09.020
 like the whole universe is like cold and dead

1:07:09.020 --> 1:07:14.020
 and sort of robotic and it's like, you know, AI intelligence.

1:07:15.660 --> 1:07:19.020
 You know, it's kind of more like the universe.

1:07:19.020 --> 1:07:24.020
 It's like cold and, you know, logical

1:07:24.660 --> 1:07:28.780
 and, you know, abiding by the laws of physics and whatever.

1:07:28.780 --> 1:07:32.940
 But like, we're this like loosey goosey weird art thing

1:07:32.940 --> 1:07:34.940
 that happened and I think it's beautiful.

1:07:34.940 --> 1:07:38.940
 And like, I think even if we, I think one of the values,

1:07:40.300 --> 1:07:45.300
 if consciousness is a thing that is most worth preserving,

1:07:47.180 --> 1:07:49.340
 which I think is the case, I think consciousness,

1:07:49.340 --> 1:07:50.700
 I think if there's any kind of like religious

1:07:50.700 --> 1:07:55.580
 or spiritual thing, it should be that consciousness is sacred.

1:07:55.580 --> 1:08:00.580
 Like then, you know, I still think even if AI render us

1:08:02.020 --> 1:08:05.860
 obsolete and we climate change, it's too bad

1:08:05.860 --> 1:08:07.460
 and we get hit by a comet and we don't become

1:08:07.460 --> 1:08:09.540
 a multi planetary species fast enough.

1:08:09.540 --> 1:08:12.300
 But like AI is able to populate the universe.

1:08:12.300 --> 1:08:14.300
 Like I imagine, like if I was an AI,

1:08:14.300 --> 1:08:17.900
 I would find more planets that are capable

1:08:17.900 --> 1:08:20.700
 of hosting biological life forms and like recreate them.

1:08:20.700 --> 1:08:21.820
 Cause we're fun to watch.

1:08:21.820 --> 1:08:23.340
 Yeah, we're fun to watch.

1:08:23.340 --> 1:08:25.660
 Yeah, but I do believe that AI can have

1:08:25.660 --> 1:08:29.940
 some of the same magic of consciousness within it.

1:08:29.940 --> 1:08:31.460
 Cause consciousness, we don't know what it is.

1:08:31.460 --> 1:08:33.060
 So, you know, there's some kind of.

1:08:33.060 --> 1:08:34.180
 Or it might be a different magic.

1:08:34.180 --> 1:08:37.580
 It might be like a strange, a strange, a strange different.

1:08:37.580 --> 1:08:38.420
 Right.

1:08:38.420 --> 1:08:39.380
 Cause they're not going to have hormones.

1:08:39.380 --> 1:08:42.700
 Like I feel like a lot of our magic is hormonal kind of.

1:08:42.700 --> 1:08:43.540
 I don't know.

1:08:43.540 --> 1:08:45.300
 I think some of our magic is the limitations,

1:08:45.300 --> 1:08:47.900
 the constraints and within that, the hormones

1:08:47.900 --> 1:08:50.220
 and all that kind of stuff, the finiteness of life.

1:08:50.220 --> 1:08:52.820
 And then we get, given our limitations,

1:08:52.820 --> 1:08:54.740
 we get to come up with creative solutions

1:08:54.740 --> 1:08:56.780
 of how to dance around those limitations.

1:08:56.780 --> 1:08:59.420
 We partner up like penguins against the cold.

1:08:59.420 --> 1:09:03.340
 We've fallen in love and then love is ultimately

1:09:03.340 --> 1:09:06.060
 some kind of allows us to delude ourselves

1:09:06.060 --> 1:09:08.540
 that we're not mortal and finite

1:09:08.540 --> 1:09:11.620
 and that life is not ultimately you live alone.

1:09:11.620 --> 1:09:13.780
 You're born alone, you die alone.

1:09:13.780 --> 1:09:15.580
 And then love is like a firm moment

1:09:15.580 --> 1:09:17.580
 or for a long time, forgetting that.

1:09:17.580 --> 1:09:20.340
 And so like we come up with all these creative hacks

1:09:20.340 --> 1:09:25.340
 that make life like fascinatingly fun.

1:09:25.980 --> 1:09:27.740
 Yeah, yeah, yeah, fun, yeah.

1:09:27.740 --> 1:09:30.260
 And then AI might have different kinds of fun.

1:09:30.260 --> 1:09:31.260
 Yes.

1:09:31.260 --> 1:09:34.900
 And hopefully our funds intersect in less than a while.

1:09:34.900 --> 1:09:37.580
 I think there would be a little intersection,

1:09:37.580 --> 1:09:39.300
 there'd be a little intersection of the fun.

1:09:39.300 --> 1:09:40.460
 Yeah, yeah.

1:09:40.460 --> 1:09:42.860
 What do you think is the role of love

1:09:42.860 --> 1:09:44.300
 in the human condition?

1:09:45.500 --> 1:09:46.500
 Ice.

1:09:46.500 --> 1:09:47.620
 Why, is it useful?

1:09:47.620 --> 1:09:51.540
 Is it useful like a hack or is this a fundamental

1:09:51.540 --> 1:09:54.940
 to what it means to be human, the capacity to love?

1:09:54.940 --> 1:09:58.100
 I mean, I think love is the evolutionary mechanism

1:09:58.100 --> 1:10:00.580
 that is like beginning the intelligent design.

1:10:00.580 --> 1:10:02.900
 Like I was just reading about,

1:10:04.140 --> 1:10:06.220
 do you know about Kropotkin?

1:10:06.220 --> 1:10:08.940
 He's like an anarchist, like old Russian anarchist.

1:10:08.940 --> 1:10:11.540
 I live next door to Michael Malus.

1:10:11.540 --> 1:10:13.300
 I don't know if you know that is, he's an anarchist.

1:10:13.300 --> 1:10:14.540
 He's a modern day anarchist.

1:10:14.540 --> 1:10:15.380
 Okay.

1:10:15.380 --> 1:10:16.220
 Anarchists are fun.

1:10:16.220 --> 1:10:17.940
 Getting into anarchism a little bit.

1:10:17.940 --> 1:10:22.380
 This is probably, yeah, not a good route to be taking, but.

1:10:22.380 --> 1:10:23.900
 Oh no, I think if you're,

1:10:23.900 --> 1:10:26.140
 listen, you should expose yourself to ideas

1:10:26.140 --> 1:10:28.500
 that there's no harm to thinking about ideas.

1:10:28.500 --> 1:10:32.460
 I think anarchist challenge systems in interesting ways

1:10:32.460 --> 1:10:34.180
 and they think in interesting ways

1:10:34.180 --> 1:10:35.340
 that just is good for the soul.

1:10:35.340 --> 1:10:37.300
 It's like refreshes your mental palette.

1:10:37.300 --> 1:10:38.940
 I don't think we should actually,

1:10:38.940 --> 1:10:40.620
 I wouldn't actually ascribe to it,

1:10:40.620 --> 1:10:42.260
 but I've never actually gone deep on,

1:10:42.260 --> 1:10:43.500
 on anarchy as a philosophy.

1:10:43.500 --> 1:10:44.340
 So I'm doing.

1:10:44.340 --> 1:10:45.500
 You should still think about it though.

1:10:45.500 --> 1:10:46.620
 When you, when you listen,

1:10:46.620 --> 1:10:48.420
 because I'm like reading about the Russian revolution a lot

1:10:48.420 --> 1:10:51.060
 and it's like, there was like the Soviets and Lenin,

1:10:51.060 --> 1:10:52.380
 all that, but then there was like Kropotkin

1:10:52.380 --> 1:10:53.820
 and his like anarchist sect.

1:10:53.820 --> 1:10:54.980
 And they were sort of interesting

1:10:54.980 --> 1:10:57.100
 cause he was kind of a technocrat actually.

1:10:57.100 --> 1:10:59.940
 Like he was like, you know, like women can be more equal

1:10:59.940 --> 1:11:01.180
 if we have appliances.

1:11:01.180 --> 1:11:04.140
 Like he was like really into like, you know,

1:11:04.140 --> 1:11:05.940
 using technology to like reduce

1:11:05.940 --> 1:11:07.900
 the amount of work people had to do.

1:11:07.900 --> 1:11:11.700
 But so Kropotkin was like a biologist or something.

1:11:11.700 --> 1:11:13.140
 Like he studied animals.

1:11:13.140 --> 1:11:17.380
 And he was really at the time, like,

1:11:17.380 --> 1:11:20.820
 I think it's nature magazine.

1:11:20.820 --> 1:11:22.860
 I think it might have even started as like a Russian magazine,

1:11:22.860 --> 1:11:23.900
 but he was like publishing studies.

1:11:23.900 --> 1:11:26.220
 Like everyone was really into like Darwinism at the time

1:11:26.220 --> 1:11:27.260
 and like survival of the fittest

1:11:27.260 --> 1:11:29.380
 and like war is like the mechanism

1:11:29.380 --> 1:11:30.540
 by which we become better.

1:11:30.540 --> 1:11:33.380
 And it was like this real kind of like,

1:11:33.380 --> 1:11:36.700
 like cementing this idea in society

1:11:36.700 --> 1:11:40.100
 that like violence, you know, kill the weak.

1:11:40.100 --> 1:11:41.540
 And like that's how we become better.

1:11:41.540 --> 1:11:43.220
 And then Kropotkin was kind of interesting

1:11:43.220 --> 1:11:45.740
 cause he was looking at instances.

1:11:45.740 --> 1:11:47.580
 He was finding all these instances in nature

1:11:47.580 --> 1:11:49.700
 where animals were like helping each other and stuff.

1:11:49.700 --> 1:11:51.940
 And he was like, you know, actually love

1:11:51.940 --> 1:11:53.700
 is a survival mechanism.

1:11:53.700 --> 1:11:58.700
 Like there's so many instances in the animal kingdom

1:11:58.780 --> 1:12:01.500
 where like cooperation and, you know,

1:12:01.500 --> 1:12:03.940
 like helping weaker creatures and all this stuff

1:12:03.940 --> 1:12:06.260
 is actually an evolutionary mechanism.

1:12:06.260 --> 1:12:08.180
 I mean, you even look at child rearing.

1:12:08.180 --> 1:12:12.540
 Like child rearing is like immense amounts

1:12:12.540 --> 1:12:14.580
 of just love and goodwill.

1:12:14.580 --> 1:12:17.300
 And just like there's no immediate,

1:12:19.260 --> 1:12:22.180
 you know, you're not getting any immediate feedback

1:12:22.180 --> 1:12:26.380
 of like winning, it's not competitive.

1:12:26.380 --> 1:12:28.700
 It's literally, you know, it's like we actually use love

1:12:28.700 --> 1:12:31.180
 as an evolutionary mechanism just as much as we use war.

1:12:31.180 --> 1:12:34.220
 And I think we've like missing the other part

1:12:34.220 --> 1:12:37.460
 and we've reoriented, we've culturally reoriented

1:12:37.460 --> 1:12:41.980
 like science and philosophy has reoriented itself

1:12:41.980 --> 1:12:44.140
 around Darwinism a little bit too much

1:12:44.140 --> 1:12:48.700
 and the Kropotkin model, I think is equally valid.

1:12:48.700 --> 1:12:53.700
 Like it's like cooperation and love and stuff

1:12:54.540 --> 1:12:59.060
 is just as essential for a species survival and evolution.

1:12:59.060 --> 1:13:01.580
 It'd be a more powerful survival mechanism

1:13:01.580 --> 1:13:02.900
 in the context of evolution.

1:13:02.900 --> 1:13:04.700
 And it comes back to like, you know,

1:13:04.700 --> 1:13:06.860
 we think engineering is so much more important

1:13:06.860 --> 1:13:09.060
 than motherhood, but it's like,

1:13:09.060 --> 1:13:10.940
 if you lose the motherhood, the engineering means nothing.

1:13:10.940 --> 1:13:11.860
 We have no more humans.

1:13:11.860 --> 1:13:14.860
 Like it's like, you know, it's like we,

1:13:15.700 --> 1:13:19.900
 I think our society should, the survival of the fit,

1:13:19.900 --> 1:13:23.740
 the way we see, we conceptualize evolution

1:13:23.740 --> 1:13:27.020
 should really change to also include this idea, I guess.

1:13:27.020 --> 1:13:31.620
 Yeah, there's some weird thing that seems irrational

1:13:31.620 --> 1:13:36.620
 that is also core to what it means to be human.

1:13:37.260 --> 1:13:40.220
 So love is one such thing.

1:13:40.220 --> 1:13:43.020
 It could make you do a lot of irrational things,

1:13:43.020 --> 1:13:46.140
 but that depth of connection and that loyalty

1:13:46.140 --> 1:13:47.300
 is a powerful thing.

1:13:47.300 --> 1:13:49.300
 Are they irrational or are they rational?

1:13:49.300 --> 1:13:53.740
 Like, it's like, it's like, it's, you know, maybe

1:13:56.380 --> 1:13:59.500
 losing out on some things in order to like

1:13:59.500 --> 1:14:01.860
 keep your family together or in order,

1:14:01.860 --> 1:14:06.260
 like it's like, what are our actual values?

1:14:06.260 --> 1:14:07.100
 Well, right.

1:14:07.100 --> 1:14:08.820
 I mean, the irrational thing is,

1:14:08.820 --> 1:14:11.340
 if you have a cold economist perspective,

1:14:11.340 --> 1:14:16.100
 you know, motherhood or sacrificing your career for love,

1:14:16.100 --> 1:14:18.300
 you know, in terms of salary,

1:14:18.300 --> 1:14:20.620
 in terms of economic wellbeing,

1:14:20.620 --> 1:14:22.740
 in terms of flourishing of you as a human being,

1:14:22.740 --> 1:14:25.900
 that could be seen on some kind of metrics

1:14:25.900 --> 1:14:28.580
 as a irrational decision, a suboptimal decision,

1:14:28.580 --> 1:14:33.580
 but there's the manifestation of love

1:14:34.180 --> 1:14:36.780
 could be the optimal thing to do.

1:14:36.780 --> 1:14:41.140
 There's a kind of saying, save one life, save the world.

1:14:41.140 --> 1:14:44.100
 There's a thing that doctors often face, which is like...

1:14:44.100 --> 1:14:45.140
 Well, it's considered irrational

1:14:45.140 --> 1:14:47.460
 because the profit model doesn't include social good.

1:14:47.460 --> 1:14:48.620
 Yes, yeah.

1:14:48.620 --> 1:14:50.420
 So if a profit model includes social good,

1:14:50.420 --> 1:14:52.180
 then suddenly these would be rational decisions.

1:14:52.180 --> 1:14:54.420
 It might be difficult to, you know,

1:14:54.420 --> 1:14:57.620
 it requires a shift in our thinking about profit

1:14:57.620 --> 1:15:01.020
 and might be difficult to measure social good.

1:15:01.020 --> 1:15:02.340
 Yes.

1:15:02.340 --> 1:15:04.500
 But we're learning to measure a lot of things.

1:15:04.500 --> 1:15:05.620
 Yeah, digitizing a lot of things.

1:15:05.620 --> 1:15:10.060
 Where we're actually, you know, quantifying vision

1:15:10.060 --> 1:15:13.420
 and stuff, like we're like, you know,

1:15:13.420 --> 1:15:15.380
 like you go on Facebook and they can,

1:15:15.380 --> 1:15:17.700
 like Facebook can pretty much predict our behaviors.

1:15:17.700 --> 1:15:20.660
 Like we're a surprising amount of things

1:15:20.660 --> 1:15:25.660
 that seem like mysterious consciousness soul things

1:15:25.660 --> 1:15:27.380
 have been quantified at this point.

1:15:27.380 --> 1:15:29.500
 So surely we can quantify these other things.

1:15:29.500 --> 1:15:30.340
 Yeah.

1:15:31.220 --> 1:15:33.980
 But as more and more of us are moving the digital space,

1:15:33.980 --> 1:15:36.860
 I wanted to ask you about something from a fan perspective.

1:15:36.860 --> 1:15:41.100
 I kind of, you know, use a musician,

1:15:41.100 --> 1:15:43.300
 use an online personality.

1:15:43.300 --> 1:15:45.220
 It seems like you have all these identities

1:15:45.220 --> 1:15:46.420
 and you play with them.

1:15:48.700 --> 1:15:50.900
 One of the cool things about the internet,

1:15:50.900 --> 1:15:53.100
 it seems like you can play with identities.

1:15:53.100 --> 1:15:55.900
 So as we move into the digital world more and more,

1:15:55.900 --> 1:15:58.940
 maybe even in the, in the so called metaverse.

1:15:58.940 --> 1:16:01.020
 I mean, I love the metaverse and I love the idea,

1:16:01.020 --> 1:16:06.020
 but like the way this has all played out didn't,

1:16:09.060 --> 1:16:10.860
 didn't go well and people are mad about it.

1:16:10.860 --> 1:16:12.220
 And I think, I think we need to like.

1:16:12.220 --> 1:16:13.300
 I think that's temporary.

1:16:13.300 --> 1:16:14.300
 I think it's temporary.

1:16:14.300 --> 1:16:16.580
 Just like, you know how all the celebrities got together

1:16:16.580 --> 1:16:18.900
 and sang the song, Imagine by Jeff Lennon

1:16:18.900 --> 1:16:20.780
 and everyone started hating the song, Imagine.

1:16:20.780 --> 1:16:21.900
 I'm hoping that's temporary

1:16:21.900 --> 1:16:24.220
 because it's a damn good song.

1:16:24.220 --> 1:16:25.340
 So I think it's just temporary.

1:16:25.340 --> 1:16:27.660
 Like once you actually have virtual worlds,

1:16:27.660 --> 1:16:29.820
 whatever they're called, metaverse or otherwise,

1:16:29.820 --> 1:16:31.260
 it becomes, I don't know.

1:16:31.260 --> 1:16:32.300
 Well, we do have virtual worlds.

1:16:32.300 --> 1:16:35.180
 Like video games, Elden Ring, have you played Elden Ring?

1:16:35.180 --> 1:16:36.020
 You have played Elden Ring?

1:16:36.020 --> 1:16:38.420
 I'm really afraid of playing that game.

1:16:38.420 --> 1:16:39.260
 Literally, I mean.

1:16:39.260 --> 1:16:40.580
 It looks way too fun.

1:16:40.580 --> 1:16:43.500
 It looks, it looks I would want to go there

1:16:43.500 --> 1:16:44.860
 and stay there forever.

1:16:44.860 --> 1:16:46.860
 It's, yeah, so fun.

1:16:46.860 --> 1:16:48.860
 It's so, it's so nice.

1:16:48.860 --> 1:16:51.700
 Oh man.

1:16:51.700 --> 1:16:54.500
 Yeah, so that, that's, yeah, that's a metaverse.

1:16:54.500 --> 1:16:57.220
 That's a metaverse, but you're not really,

1:16:57.220 --> 1:16:59.260
 is how immersive is it?

1:16:59.260 --> 1:17:03.980
 In the sense that this is the three dimension,

1:17:03.980 --> 1:17:06.100
 like virtual reality integration necessary.

1:17:06.100 --> 1:17:08.820
 Can we really just take our, close our eyes

1:17:08.820 --> 1:17:12.220
 and kind of plug in in the 2D screen

1:17:13.100 --> 1:17:15.820
 and become that other being for a time

1:17:15.820 --> 1:17:17.980
 and really enjoy that journey that we take.

1:17:17.980 --> 1:17:19.700
 And we almost become that.

1:17:19.700 --> 1:17:22.100
 You're no longer, see, I'm no longer Lex,

1:17:22.100 --> 1:17:23.700
 you're that creature, whatever,

1:17:23.700 --> 1:17:25.380
 whatever the hell it is in that game.

1:17:25.380 --> 1:17:26.220
 Yeah, that is that.

1:17:26.220 --> 1:17:28.460
 I mean, that's why I love those video games.

1:17:28.460 --> 1:17:33.140
 It's, I really do become those people for a time.

1:17:33.140 --> 1:17:36.180
 But like, it seems like with the idea of the metaverse

1:17:36.180 --> 1:17:37.940
 or the idea of the digital space,

1:17:37.940 --> 1:17:40.260
 well, even on Twitter, you get a chance

1:17:40.260 --> 1:17:42.620
 to be somebody for prolonged periods of time,

1:17:42.620 --> 1:17:44.540
 like across a lifespan.

1:17:44.540 --> 1:17:47.660
 You know, you have a Twitter account for years, for decades

1:17:47.660 --> 1:17:48.500
 and you're that person.

1:17:48.500 --> 1:17:49.700
 I don't know if that's a good thing.

1:17:49.700 --> 1:17:52.700
 I feel very tormented by it.

1:17:52.700 --> 1:17:54.340
 By Twitter specifically,

1:17:54.340 --> 1:17:56.300
 by social media representation of you.

1:17:56.300 --> 1:17:59.180
 I feel like the public perception of me

1:17:59.180 --> 1:18:04.180
 has gotten so distorted that I find it kind of disturbing.

1:18:04.500 --> 1:18:06.380
 It's one of the things that's disincentivizing me

1:18:06.380 --> 1:18:07.980
 from like wanting to keep making art

1:18:07.980 --> 1:18:12.980
 because I'm just like, I've completely lost control

1:18:13.100 --> 1:18:15.540
 of the narrative and the narrative is,

1:18:15.540 --> 1:18:16.900
 some of it is my own stupidity,

1:18:16.900 --> 1:18:19.300
 but a lot, like some of it has just been like hijacked

1:18:19.300 --> 1:18:22.940
 by forces far beyond my control.

1:18:22.940 --> 1:18:25.580
 You know, I kind of got in over my head in things.

1:18:25.580 --> 1:18:27.300
 Like I'm just a random indie musician,

1:18:27.300 --> 1:18:31.940
 but I just got like dragged into like geopolitical matters

1:18:31.940 --> 1:18:35.100
 and like financial, like the stock market and shit.

1:18:35.100 --> 1:18:36.340
 And so it's just like, it's just,

1:18:36.340 --> 1:18:38.220
 there are very powerful people who have,

1:18:38.220 --> 1:18:39.700
 who have at various points in time

1:18:39.700 --> 1:18:43.740
 had very vested interest in making me seem insane.

1:18:43.740 --> 1:18:45.660
 And I can't fucking fight that.

1:18:45.660 --> 1:18:48.860
 And I just like, you know,

1:18:48.860 --> 1:18:50.820
 people really want their celebrity figures

1:18:50.820 --> 1:18:53.860
 to like be consistent and stay the same.

1:18:53.860 --> 1:18:55.860
 And like people have a lot of like emotional investment

1:18:55.860 --> 1:18:56.700
 in certain things.

1:18:56.700 --> 1:19:01.700
 And like, first of all, like I'm like artificially

1:19:01.900 --> 1:19:03.700
 more famous than I should be.

1:19:03.700 --> 1:19:06.620
 Isn't everybody who's famous artificially famous?

1:19:06.620 --> 1:19:11.340
 No, but like, I should be like a weird niche indie thing.

1:19:11.340 --> 1:19:13.420
 And I make pretty challenging,

1:19:13.420 --> 1:19:16.300
 I do challenging weird fucking shit a lot.

1:19:16.300 --> 1:19:20.500
 And I accidentally by proxy got like,

1:19:21.860 --> 1:19:24.460
 foisted into sort of like weird celebrity culture.

1:19:24.460 --> 1:19:27.340
 But like, I cannot be media trained.

1:19:27.340 --> 1:19:29.780
 They have put me through so many hours of media training.

1:19:29.780 --> 1:19:32.540
 I would love to see, I'd love to see BF fly in that wall.

1:19:32.540 --> 1:19:34.420
 I can't do, like, well, and I do,

1:19:34.420 --> 1:19:36.540
 I try so hard and I like learn the same.

1:19:36.540 --> 1:19:37.380
 And I like got it.

1:19:37.380 --> 1:19:38.220
 And I'm like, I got it.

1:19:38.220 --> 1:19:39.040
 I got it, I got it.

1:19:39.040 --> 1:19:40.540
 But I just can't stop saying,

1:19:40.540 --> 1:19:42.220
 like my mouth just says things.

1:19:42.220 --> 1:19:44.500
 I like, and it's just like, and I just do,

1:19:44.500 --> 1:19:46.020
 I just do things, I just do crazy things.

1:19:46.020 --> 1:19:48.900
 I mean, it's like, I'm, I just,

1:19:48.900 --> 1:19:50.740
 I need to do crazy things.

1:19:50.740 --> 1:19:53.100
 And it's just, I should not be,

1:19:53.100 --> 1:19:58.100
 it's too jarring for people and the contradictory stuff.

1:19:59.700 --> 1:20:04.700
 And then all the, by association, like, you know,

1:20:05.220 --> 1:20:07.660
 it's like, I'm in a very weird position

1:20:07.660 --> 1:20:12.660
 and my public image that the avatar of me is now

1:20:13.540 --> 1:20:16.540
 this totally crazy thing that is so lost from my control.

1:20:16.540 --> 1:20:19.140
 So you feel the burden of the avatar having to be static.

1:20:19.140 --> 1:20:22.300
 So the avatar on Twitter, the avatar on Instagram,

1:20:22.300 --> 1:20:26.740
 on these social platforms is as a burden.

1:20:26.740 --> 1:20:30.300
 It becomes like, cause it, like people don't want to accept

1:20:30.300 --> 1:20:32.580
 a changing avatar, a chaotic avatar.

1:20:32.580 --> 1:20:34.820
 Avatar, it's a stupid shift sometimes.

1:20:34.820 --> 1:20:36.480
 They think the avatar is morally wrong

1:20:36.480 --> 1:20:39.580
 or they think the avatar, and maybe it has been,

1:20:39.580 --> 1:20:41.140
 and like, I questioned it all the time.

1:20:41.140 --> 1:20:46.140
 Like, I'm like, I don't know if everyone's right

1:20:46.340 --> 1:20:49.740
 and I'm wrong, I don't, like, but you know,

1:20:49.740 --> 1:20:51.780
 a lot of times people ascribe intentions to things,

1:20:51.780 --> 1:20:53.700
 the worst possible intentions.

1:20:53.700 --> 1:20:55.900
 At this point, people think I'm, you know.

1:20:57.340 --> 1:20:58.180
 But we're just fine.

1:20:58.180 --> 1:20:59.180
 All kinds of words, yes.

1:20:59.180 --> 1:21:00.500
 Yes, and it's fine.

1:21:00.500 --> 1:21:02.860
 I'm not complaining about it, but I'm just,

1:21:02.860 --> 1:21:07.020
 it's a curiosity to me that we live

1:21:07.020 --> 1:21:08.780
 these double, triple, quadruple lives

1:21:08.780 --> 1:21:11.140
 and I have this other life that is like,

1:21:12.480 --> 1:21:15.140
 more people know my other life than my real life,

1:21:15.140 --> 1:21:16.380
 which is interesting.

1:21:16.380 --> 1:21:18.220
 Probably, I mean, you too, I guess.

1:21:18.220 --> 1:21:20.140
 Yeah, but I have the luxury.

1:21:20.140 --> 1:21:23.140
 So we have all different, we don't,

1:21:23.140 --> 1:21:25.180
 like, I don't know what I'm doing.

1:21:25.180 --> 1:21:27.860
 There is an avatar and you're mediating

1:21:27.860 --> 1:21:29.980
 who you are through that avatar.

1:21:29.980 --> 1:21:34.380
 I have the nice luxury, not the luxury,

1:21:34.380 --> 1:21:38.100
 maybe by intention of not trying really hard

1:21:38.100 --> 1:21:40.100
 to make sure there's no difference

1:21:40.100 --> 1:21:42.860
 between the avatar and the private person.

1:21:44.060 --> 1:21:45.660
 Do you wear a suit all the time?

1:21:45.660 --> 1:21:48.660
 Yeah, but not all the time.

1:21:48.660 --> 1:21:51.580
 Like recently because I get recognized a lot,

1:21:51.580 --> 1:21:53.460
 I have to not wear the suit to hide.

1:21:53.460 --> 1:21:55.860
 I'm such an introvert, I'm such a social anxiety

1:21:55.860 --> 1:21:57.700
 and all that kind of stuff to hide away.

1:21:57.700 --> 1:22:00.620
 I love wearing a suit because it makes me feel

1:22:00.620 --> 1:22:02.420
 like I'm taking the moment seriously.

1:22:02.420 --> 1:22:04.380
 Like I'm, I don't know.

1:22:04.380 --> 1:22:06.980
 It makes me feel like a weirdo in the best possible way.

1:22:06.980 --> 1:22:07.820
 Your suits feel great.

1:22:07.820 --> 1:22:08.660
 Every time I wear a suit,

1:22:08.660 --> 1:22:10.700
 I'm like, I don't know why I'm not doing this more.

1:22:10.700 --> 1:22:15.380
 In fashion in general, if you're doing it for yourself,

1:22:15.380 --> 1:22:18.740
 I don't know, it's a really awesome thing.

1:22:18.740 --> 1:22:23.740
 But yeah, I think there is definitely a painful way

1:22:24.720 --> 1:22:27.460
 to use social media in an empowering way

1:22:27.460 --> 1:22:32.460
 and I don't know if any of us know which is which.

1:22:32.700 --> 1:22:34.020
 So we're trying to figure that out.

1:22:34.020 --> 1:22:36.860
 Some people, I think Doja Cat is incredible at it.

1:22:36.860 --> 1:22:39.620
 Incredible, like just masterful.

1:22:39.620 --> 1:22:41.980
 I don't know if you like follow that.

1:22:41.980 --> 1:22:44.860
 So okay, so not taking anything seriously,

1:22:44.860 --> 1:22:47.540
 joking, absurd, humor, that kind of thing.

1:22:47.540 --> 1:22:49.940
 I think Doja Cat might be like the greatest

1:22:49.940 --> 1:22:52.180
 living comedian right now.

1:22:52.180 --> 1:22:53.660
 Like I'm more entertained by Doja Cat

1:22:53.660 --> 1:22:56.300
 than actual comedians.

1:22:56.300 --> 1:22:58.980
 Like she's really fucking funny on the internet.

1:22:58.980 --> 1:23:00.300
 She's just great at social media.

1:23:00.300 --> 1:23:02.300
 It's just, you know, her media.

1:23:02.300 --> 1:23:03.300
 Yeah, the nature of humor,

1:23:03.300 --> 1:23:08.020
 like human on social media is also a beautiful thing,

1:23:08.020 --> 1:23:08.980
 the absurdity.

1:23:08.980 --> 1:23:10.300
 The absurdity and memes,

1:23:10.300 --> 1:23:12.740
 like I just want to like take a moment.

1:23:12.740 --> 1:23:14.620
 I love, like when we're talking about art

1:23:14.620 --> 1:23:16.660
 and credit and authenticity,

1:23:16.660 --> 1:23:18.220
 I love that there's this,

1:23:18.220 --> 1:23:21.860
 I mean, now memes are like, they're no longer,

1:23:21.860 --> 1:23:23.660
 like it means art like new,

1:23:23.660 --> 1:23:25.620
 but it's still this emergent art form

1:23:25.620 --> 1:23:27.740
 that is completely egoless and anonymous.

1:23:27.740 --> 1:23:29.500
 And we just don't know who made any of it.

1:23:29.500 --> 1:23:32.580
 And it's like the forefront of comedy

1:23:32.580 --> 1:23:35.420
 and it's just totally anonymous.

1:23:35.420 --> 1:23:36.740
 And it just feels really beautiful.

1:23:36.740 --> 1:23:39.060
 It just feels like this beautiful collect,

1:23:39.060 --> 1:23:43.300
 like collective human art project

1:23:43.300 --> 1:23:46.460
 that's like this like decentralized comedy thing

1:23:46.460 --> 1:23:48.900
 that just makes memes add so much to my day

1:23:48.900 --> 1:23:49.900
 and many people stays.

1:23:49.900 --> 1:23:52.180
 And it's just like, I don't know.

1:23:52.180 --> 1:23:54.900
 I don't think people ever,

1:23:54.900 --> 1:23:56.060
 I don't think we stop enough

1:23:56.060 --> 1:23:59.500
 and just appreciate how sick it is that memes exist.

1:23:59.500 --> 1:24:02.420
 And cause also making a whole brand new art form

1:24:02.420 --> 1:24:07.060
 in like the modern era that's like didn't exist before.

1:24:07.060 --> 1:24:08.500
 Like, I mean, they sort of existed,

1:24:08.500 --> 1:24:11.860
 but the way that they exist now as like this like,

1:24:11.860 --> 1:24:13.260
 you know, like me and my friends,

1:24:13.260 --> 1:24:16.340
 like we joke that we go like mining for memes

1:24:16.340 --> 1:24:17.980
 or farming for memes,

1:24:17.980 --> 1:24:21.100
 like a video game and like meme dealers and like whatever.

1:24:21.100 --> 1:24:22.740
 Like it's, you know, it's this whole,

1:24:22.740 --> 1:24:27.740
 memes are this whole like new comedic language.

1:24:27.940 --> 1:24:29.300
 Well, it's this art form.

1:24:29.300 --> 1:24:33.540
 The interesting thing about it is that lame people

1:24:33.540 --> 1:24:35.380
 seem to not be good at memes.

1:24:35.380 --> 1:24:38.220
 Like corporate can't infiltrate memes.

1:24:38.220 --> 1:24:39.860
 Yeah, they really can't.

1:24:39.860 --> 1:24:42.540
 They try, they could try, but it's like, it's weird.

1:24:42.540 --> 1:24:43.380
 Cause like

1:24:43.380 --> 1:24:46.420
 They try so hard and every once in a while I'm like fine.

1:24:46.420 --> 1:24:48.700
 Like you got a good one.

1:24:48.700 --> 1:24:51.420
 I think I've seen like one or two good ones,

1:24:51.420 --> 1:24:53.340
 but like, yeah, they really can't.

1:24:53.340 --> 1:24:55.500
 Cause they're even corporate is infiltrating web three.

1:24:55.500 --> 1:24:57.140
 It's making me really sad,

1:24:57.140 --> 1:24:58.660
 but they can't infiltrate the memes.

1:24:58.660 --> 1:25:00.060
 And I think there's something really beautiful about that.

1:25:00.060 --> 1:25:00.980
 And that gives power.

1:25:00.980 --> 1:25:03.580
 That's why Dogecoin is powerful.

1:25:03.580 --> 1:25:05.340
 It's like, all right.

1:25:05.340 --> 1:25:08.820
 FU to sort of anybody who's trying to centralize

1:25:08.820 --> 1:25:10.420
 is trying to control the rich people

1:25:10.420 --> 1:25:12.700
 that are trying to roll in and control this,

1:25:12.700 --> 1:25:14.220
 control the narrative.

1:25:14.220 --> 1:25:15.060
 Wow.

1:25:15.060 --> 1:25:17.220
 I hadn't thought about that, but.

1:25:17.220 --> 1:25:18.500
 How would you fix Twitter?

1:25:18.500 --> 1:25:19.980
 How would you fix social media?

1:25:19.980 --> 1:25:23.820
 For your own, like you're an optimist,

1:25:23.820 --> 1:25:25.220
 you're a positive person.

1:25:25.220 --> 1:25:27.500
 There's a bit of a cynicism that you have currently

1:25:27.500 --> 1:25:30.700
 about this particular little slice of humanity.

1:25:30.700 --> 1:25:32.700
 I tend to think Twitter could be beautiful.

1:25:32.700 --> 1:25:34.100
 I'm not that cynical about it.

1:25:34.100 --> 1:25:35.140
 I'm not that cynical about it.

1:25:35.140 --> 1:25:37.700
 I actually refuse to be a cynic on principle.

1:25:37.700 --> 1:25:38.540
 Yes.

1:25:38.540 --> 1:25:40.940
 I was just briefly expressing some personal pathos.

1:25:40.940 --> 1:25:41.780
 Personal stuff.

1:25:41.780 --> 1:25:45.900
 It was just some personal pathos, but like, like.

1:25:45.900 --> 1:25:46.980
 Just to vent a little bit.

1:25:46.980 --> 1:25:47.820
 Just to speak.

1:25:47.820 --> 1:25:48.940
 I don't have cancer.

1:25:48.940 --> 1:25:50.860
 I've, I love my family.

1:25:50.860 --> 1:25:51.620
 I have a good life.

1:25:51.620 --> 1:25:55.380
 I'm that, that, that is, if that is my biggest,

1:25:55.380 --> 1:25:56.220
 one of my biggest problems.

1:25:56.220 --> 1:25:57.180
 That's a good life.

1:25:57.180 --> 1:25:58.020
 Yeah.

1:25:58.020 --> 1:25:59.860
 I, you know, that was a brief,

1:25:59.860 --> 1:26:01.380
 although I do think there are a lot of issues with Twitter

1:26:01.380 --> 1:26:03.180
 just in terms of like the public mental health,

1:26:03.180 --> 1:26:08.180
 but due to my proximity to the current dramas,

1:26:10.500 --> 1:26:13.820
 I honestly feel that I should not have opinions about this

1:26:13.820 --> 1:26:18.820
 because I think if Elon ends up getting Twitter,

1:26:28.380 --> 1:26:33.140
 that is a being the arbiter of truth or public discussion.

1:26:33.140 --> 1:26:34.660
 That is a responsibility.

1:26:36.260 --> 1:26:41.260
 I do not, I am not qualified to be responsible for that

1:26:41.260 --> 1:26:45.260
 and I do not want to say something

1:26:45.260 --> 1:26:48.340
 that might like dismantle democracy.

1:26:48.340 --> 1:26:49.780
 And so I just like actually,

1:26:49.780 --> 1:26:52.140
 I actually think I should not have opinions about this

1:26:52.140 --> 1:26:55.100
 because I truly am not,

1:26:55.100 --> 1:26:56.740
 I don't want to have the wrong opinion about this.

1:26:56.740 --> 1:27:00.180
 And I think I'm too close to the actual situation

1:27:00.180 --> 1:27:02.860
 wherein I should not have.

1:27:02.860 --> 1:27:04.300
 I have thoughts in my brain,

1:27:04.300 --> 1:27:09.300
 but I think I am scared by my proximity to this situation.

1:27:09.300 --> 1:27:14.300
 Isn't that crazy that a few words that you could say

1:27:14.660 --> 1:27:18.780
 could change world affairs and hurt people?

1:27:18.780 --> 1:27:21.660
 I mean, that's the nature of celebrity at a certain point

1:27:22.980 --> 1:27:27.140
 that you have to be, you have to a little bit, a little bit,

1:27:27.140 --> 1:27:29.540
 not so much that it destroys you,

1:27:29.540 --> 1:27:30.540
 puts too much constraints,

1:27:30.540 --> 1:27:32.620
 but you have to a little bit think about

1:27:32.620 --> 1:27:33.940
 the impact of your words.

1:27:33.940 --> 1:27:36.700
 I mean, we as humans, you talk to somebody at a bar,

1:27:36.700 --> 1:27:39.140
 you have to think about the impact of your words.

1:27:39.140 --> 1:27:40.380
 Like you can say positive things,

1:27:40.380 --> 1:27:41.540
 you can think of negative things,

1:27:41.540 --> 1:27:43.380
 you can affect the direction of one life.

1:27:43.380 --> 1:27:44.380
 But on social media,

1:27:44.380 --> 1:27:48.100
 your words can affect the direction of many lives.

1:27:48.100 --> 1:27:48.940
 That's crazy.

1:27:48.940 --> 1:27:50.460
 It's a crazy world to live in.

1:27:50.460 --> 1:27:53.020
 It's worthwhile to consider that responsibility,

1:27:53.020 --> 1:27:54.140
 take it seriously.

1:27:54.140 --> 1:27:59.140
 Sometimes just like you did choose kind of silence,

1:28:00.780 --> 1:28:03.620
 choose sort of respectful.

1:28:03.620 --> 1:28:05.300
 Like I do have a lot of thoughts on the matter.

1:28:05.300 --> 1:28:06.140
 I'm just,

1:28:06.140 --> 1:28:10.140
 I don't, if my thoughts are wrong,

1:28:10.140 --> 1:28:12.900
 this is one situation where the stakes are high.

1:28:12.900 --> 1:28:15.820
 You mentioned a while back that you were in a cult

1:28:15.820 --> 1:28:17.340
 that's centered around bureaucracy,

1:28:17.340 --> 1:28:18.540
 so you can't really do anything

1:28:18.540 --> 1:28:20.620
 because it involves a lot of paperwork.

1:28:20.620 --> 1:28:24.700
 And I really love a cult that's just like Kafkaesque,

1:28:26.700 --> 1:28:27.540
 I mean, it was like a joke,

1:28:27.540 --> 1:28:28.380
 but it was,

1:28:28.380 --> 1:28:29.220
 I know, but I love this idea.

1:28:29.220 --> 1:28:30.500
 The Holy Rain Empire.

1:28:30.500 --> 1:28:34.940
 Yeah, it was just like a Kafkaesque pro bureaucracy cult.

1:28:34.940 --> 1:28:36.860
 But I feel like that's what human civilization is.

1:28:36.860 --> 1:28:38.180
 Is that, because when you said that,

1:28:38.180 --> 1:28:40.660
 I was like, oh, that is kind of what humanity is.

1:28:40.660 --> 1:28:41.700
 Is this bureaucracy?

1:28:41.700 --> 1:28:45.620
 I do, yeah, I have this theory.

1:28:45.620 --> 1:28:49.700
 I really think that we really,

1:28:50.660 --> 1:28:53.540
 bureaucracy is starting to kill us.

1:28:53.540 --> 1:28:58.540
 And I think like we need to reorient laws and stuff.

1:28:59.500 --> 1:29:01.900
 Like I think we just need sunset clauses on everything.

1:29:01.900 --> 1:29:04.540
 Like I think the rate of change in culture

1:29:04.540 --> 1:29:06.660
 is happening so fast and the rate of change in technology

1:29:06.660 --> 1:29:07.900
 and everything is happening so fast.

1:29:07.900 --> 1:29:10.780
 It's like, you know, when you see these hearings

1:29:10.780 --> 1:29:15.780
 about like social media and Cambridge Analytica

1:29:15.780 --> 1:29:16.620
 and everyone talking,

1:29:16.620 --> 1:29:19.180
 it's like even from that point,

1:29:19.180 --> 1:29:21.380
 so much technological change has happened

1:29:21.380 --> 1:29:22.740
 from like those hearings.

1:29:22.740 --> 1:29:23.580
 And it's just like,

1:29:23.580 --> 1:29:25.940
 we're trying to make all these laws now about AI and stuff.

1:29:25.940 --> 1:29:27.380
 I feel like we should be updating things

1:29:27.380 --> 1:29:28.380
 like every five years.

1:29:28.380 --> 1:29:30.140
 And like one of the big issues in our society right now

1:29:30.140 --> 1:29:32.260
 is we're just getting bogged down by laws

1:29:32.260 --> 1:29:36.980
 and it's making it very hard to change things

1:29:36.980 --> 1:29:37.820
 and develop things.

1:29:37.820 --> 1:29:38.660
 Like in Austin,

1:29:38.660 --> 1:29:41.460
 like I don't want to speak on this too much,

1:29:41.460 --> 1:29:43.180
 but like one of my friends is working on a housing bill

1:29:43.180 --> 1:29:44.980
 in Austin to try to like prevent

1:29:44.980 --> 1:29:47.140
 like a San Francisco situation from happening here

1:29:47.140 --> 1:29:49.900
 because obviously we're getting a little mini San Francisco

1:29:49.900 --> 1:29:52.100
 here like housing prices are skyrocketing.

1:29:52.100 --> 1:29:54.700
 It's causing massive gentrification.

1:29:54.700 --> 1:29:56.100
 This is gonna be, this is really bad

1:29:56.100 --> 1:29:59.140
 for anyone who's not super rich.

1:29:59.140 --> 1:30:00.820
 Like there's so much bureaucracy.

1:30:00.820 --> 1:30:01.860
 Part of the reason this is happening

1:30:01.860 --> 1:30:03.980
 is because you need all these permits to build.

1:30:03.980 --> 1:30:06.420
 It takes like years to get permits to like build anything.

1:30:06.420 --> 1:30:07.420
 It's so hard to build.

1:30:07.420 --> 1:30:09.100
 And so there's very limited housing

1:30:09.100 --> 1:30:10.900
 and there's a massive influx of people.

1:30:10.900 --> 1:30:12.180
 And it's just like, you know,

1:30:12.180 --> 1:30:14.300
 this is a microcosm of like problems

1:30:14.300 --> 1:30:15.540
 that are happening all over the world

1:30:15.540 --> 1:30:18.780
 where it's just like we're dealing with laws

1:30:18.780 --> 1:30:22.340
 that are like 10, 20, 30, 40, 100, 200 years old

1:30:22.340 --> 1:30:24.100
 and they are no longer relevant.

1:30:24.100 --> 1:30:25.660
 And it's just slowing everything down

1:30:25.660 --> 1:30:27.980
 and causing massive social pain.

1:30:27.980 --> 1:30:32.820
 Yeah, and it's like, it's also makes me sad

1:30:32.820 --> 1:30:35.780
 when I see politicians talk about technology

1:30:35.780 --> 1:30:38.020
 and when they don't really get it.

1:30:38.020 --> 1:30:41.140
 And, but most importantly, they lack curiosity

1:30:41.140 --> 1:30:44.580
 and like that like inspired excitement

1:30:44.580 --> 1:30:46.620
 about like how stuff works and all that stuff.

1:30:46.620 --> 1:30:47.820
 They're just like, they see,

1:30:47.820 --> 1:30:50.140
 they have a very cynical view of technology.

1:30:50.140 --> 1:30:52.180
 It's like tech companies are just trying to do evil

1:30:52.180 --> 1:30:53.580
 on the world from their perspective.

1:30:53.580 --> 1:30:55.900
 And they have no curiosity about like

1:30:55.900 --> 1:30:59.820
 how recommender systems work or how AI systems work,

1:30:59.820 --> 1:31:02.740
 natural language processing, how robotics works,

1:31:02.740 --> 1:31:05.860
 how computer vision works, you know,

1:31:05.860 --> 1:31:08.460
 they always take the most cynical possible interpretation

1:31:08.460 --> 1:31:09.900
 of what technology will be used.

1:31:09.900 --> 1:31:11.700
 And we should definitely be concerned about that.

1:31:11.700 --> 1:31:13.820
 But if you're constantly worried about that

1:31:13.820 --> 1:31:15.020
 and you're regulating based on that,

1:31:15.020 --> 1:31:17.020
 you're just going to slow down all the innovation.

1:31:17.020 --> 1:31:21.180
 I do think a huge priority right now is undoing

1:31:21.180 --> 1:31:26.180
 the bad energy surrounding the emergence of Silicon Valley.

1:31:28.060 --> 1:31:29.980
 Like I think that like a lot of things

1:31:29.980 --> 1:31:31.820
 were very irresponsible during that time.

1:31:31.820 --> 1:31:36.140
 And, you know, like even just this current whole thing

1:31:36.140 --> 1:31:37.900
 with Twitter and everything, it's like,

1:31:37.900 --> 1:31:39.980
 like there has been a lot of negative outcomes

1:31:39.980 --> 1:31:44.260
 from the sort of technocracy boom.

1:31:44.260 --> 1:31:47.140
 But one of the things that's happening is that like,

1:31:47.140 --> 1:31:52.140
 it's alienating people from wanting to care about technology.

1:31:52.340 --> 1:31:56.260
 And I actually think technology is probably some

1:31:56.260 --> 1:31:58.900
 of the better, probably the best.

1:32:00.140 --> 1:32:02.180
 I think we can fix a lot of our problems more easily

1:32:02.180 --> 1:32:05.980
 with technology than with, you know,

1:32:05.980 --> 1:32:07.980
 fighting the powers that be as a, you know,

1:32:07.980 --> 1:32:09.700
 not to go back to the Star Wars quote

1:32:09.700 --> 1:32:11.340
 or the Buckminster Fuller quote.

1:32:11.340 --> 1:32:12.980
 Let's go to some dark questions.

1:32:12.980 --> 1:32:17.900
 If we may, for time, what is the darkest place

1:32:17.900 --> 1:32:20.020
 you have ever gone in your mind?

1:32:20.020 --> 1:32:23.900
 Is there a time, a period of time, a moment

1:32:23.900 --> 1:32:26.580
 that you remember that was difficult for you?

1:32:29.620 --> 1:32:31.260
 I mean, when I was 18, my best friend died

1:32:31.260 --> 1:32:36.060
 of a heroin overdose and it was like my,

1:32:37.660 --> 1:32:39.820
 it was, and then shortly after that,

1:32:39.820 --> 1:32:44.820
 one of my other best friends committed suicide and that,

1:32:46.300 --> 1:32:48.740
 sort of like coming into adulthood,

1:32:48.740 --> 1:32:51.220
 dealing with two of the most important people in my life,

1:32:51.220 --> 1:32:55.940
 dying in extremely disturbing, violent ways was a lot.

1:32:55.940 --> 1:32:56.780
 That was a lot.

1:32:56.780 --> 1:32:57.620
 You miss them?

1:32:58.500 --> 1:32:59.940
 Yeah, definitely miss them.

1:32:59.940 --> 1:33:02.780
 Did that make you think about your own life,

1:33:02.780 --> 1:33:04.980
 about the finiteness of your own life,

1:33:04.980 --> 1:33:08.180
 the places your mind can go?

1:33:08.180 --> 1:33:10.940
 Did you ever, in a distance, far away,

1:33:10.940 --> 1:33:15.460
 contemplate just your own death

1:33:15.460 --> 1:33:17.260
 or maybe even taking your own life?

1:33:17.260 --> 1:33:18.740
 Oh, never, oh no.

1:33:18.740 --> 1:33:23.140
 I'm so, I love my life, I cannot fathom suicide.

1:33:23.140 --> 1:33:24.180
 I'm so scared of death.

1:33:24.180 --> 1:33:26.060
 I haven't, I'm too scared of death.

1:33:26.060 --> 1:33:28.820
 My manager, my manager's like the most zen guy.

1:33:28.820 --> 1:33:31.100
 My manager's always like, you need to accept death.

1:33:31.100 --> 1:33:32.140
 You need to accept death.

1:33:32.140 --> 1:33:34.260
 And I'm like, look, I can do your meditation.

1:33:34.260 --> 1:33:37.340
 I can do the meditation, but I cannot accept death.

1:33:37.340 --> 1:33:39.060
 I'll see you terrified of death.

1:33:39.060 --> 1:33:40.380
 I'm terrified of death.

1:33:40.380 --> 1:33:42.780
 I will like fight.

1:33:42.780 --> 1:33:45.060
 Although I actually think death is important,

1:33:45.060 --> 1:33:49.100
 I recently went to this meeting about immortality

1:33:50.060 --> 1:33:51.500
 and in the process of...

1:33:51.500 --> 1:33:53.060
 That's the actual topic of the meeting.

1:33:53.060 --> 1:33:53.900
 All right, I'm sorry.

1:33:53.900 --> 1:33:54.740
 No, no, it was this girl.

1:33:54.740 --> 1:33:58.940
 It was a bunch of people working on anti aging stuff.

1:33:58.940 --> 1:34:01.980
 It was some seminary thing about it

1:34:01.980 --> 1:34:03.300
 and I went in really excited.

1:34:03.300 --> 1:34:05.340
 I was like, yeah, okay, what do you got?

1:34:05.340 --> 1:34:07.860
 How can I live for 500 years or 1,000 years?

1:34:07.860 --> 1:34:10.660
 And then over the course of the meeting,

1:34:10.660 --> 1:34:12.020
 like it was sort of like right,

1:34:12.020 --> 1:34:13.180
 it was like two or three days

1:34:13.180 --> 1:34:14.620
 after the Russian invasion started.

1:34:14.620 --> 1:34:17.340
 And I was like, man, like what if Putin was immortal?

1:34:17.340 --> 1:34:22.340
 Like what if I'm like, man, maybe immortality is not good.

1:34:23.660 --> 1:34:25.780
 I mean, like if you get into the later Dune stuff,

1:34:25.780 --> 1:34:29.060
 the immortals cause a lot of problems.

1:34:29.060 --> 1:34:31.020
 Cause as we were talking about earlier with the music

1:34:31.020 --> 1:34:32.540
 and like brains calcify,

1:34:32.540 --> 1:34:35.500
 like good people could become immortal,

1:34:35.500 --> 1:34:36.940
 but bad people could become immortal.

1:34:36.940 --> 1:34:41.940
 But I also think even the best people power corrupt

1:34:43.380 --> 1:34:46.780
 and power alienates you from like the common human experience

1:34:46.780 --> 1:34:47.620
 and...

1:34:47.620 --> 1:34:49.140
 Right, so the people that get more and more powerful.

1:34:49.140 --> 1:34:52.220
 Even the best people whose brains are amazing,

1:34:52.220 --> 1:34:54.780
 like I think death might be important.

1:34:54.780 --> 1:34:59.140
 I think death is part of, you know, like I think with AI,

1:34:59.140 --> 1:35:01.020
 one thing we might wanna consider,

1:35:01.020 --> 1:35:02.420
 I don't know, I wanna talk about AI.

1:35:02.420 --> 1:35:03.420
 I'm such not an expert

1:35:03.420 --> 1:35:05.220
 and probably everyone has all these ideas

1:35:05.220 --> 1:35:06.220
 and they're already figured out.

1:35:06.220 --> 1:35:07.060
 But when I talk...

1:35:07.060 --> 1:35:09.060
 Nobody is an expert in anything, see?

1:35:09.060 --> 1:35:09.900
 Okay, go ahead.

1:35:09.900 --> 1:35:10.740
 But when I...

1:35:10.740 --> 1:35:11.580
 You were talking about?

1:35:11.580 --> 1:35:13.180
 Yeah, but I like, it's just like,

1:35:13.180 --> 1:35:16.100
 I think some kind of pruning,

1:35:17.300 --> 1:35:18.740
 but it's a tricky thing because,

1:35:18.740 --> 1:35:22.980
 because if there's too much of a focus on youth culture,

1:35:22.980 --> 1:35:25.500
 then you don't have the wisdom.

1:35:25.500 --> 1:35:29.700
 So I feel like we're in a tricky moment right now

1:35:29.700 --> 1:35:31.340
 in society where it's like,

1:35:31.340 --> 1:35:33.140
 we've really perfected living for a long time.

1:35:33.140 --> 1:35:35.820
 So there's all these really like old people

1:35:35.820 --> 1:35:39.580
 who are like really voting against the wellbeing

1:35:39.580 --> 1:35:41.580
 of the young people, you know?

1:35:41.580 --> 1:35:43.740
 And like, it's like,

1:35:43.740 --> 1:35:45.220
 there shouldn't be all this student dead

1:35:45.220 --> 1:35:48.620
 and we need like healthcare, like universal healthcare

1:35:48.620 --> 1:35:52.540
 and like just voting against like best interests.

1:35:52.540 --> 1:35:53.740
 But then you have all these young people

1:35:53.740 --> 1:35:55.780
 that don't have the wisdom that are like,

1:35:55.780 --> 1:35:57.700
 like, yeah, we need communism and stuff.

1:35:57.700 --> 1:35:59.820
 And it's just like, like literally,

1:35:59.820 --> 1:36:02.100
 I got canceled at one point for,

1:36:03.300 --> 1:36:05.060
 I ironically used a Stalin quote

1:36:05.060 --> 1:36:06.220
 in my high school yearbook,

1:36:06.220 --> 1:36:09.700
 but it was actually like a diss against my high school.

1:36:09.700 --> 1:36:10.540
 I saw it.

1:36:10.540 --> 1:36:11.380
 Yeah.

1:36:11.380 --> 1:36:13.260
 And people were like, you used to be a Stalinist

1:36:13.260 --> 1:36:14.300
 and now you're a class trader.

1:36:14.300 --> 1:36:17.540
 And it's like, it's like, oh man, just like,

1:36:17.540 --> 1:36:20.580
 please Google Stalin, please Google Stalin.

1:36:20.580 --> 1:36:21.740
 Like, you know what I mean?

1:36:21.740 --> 1:36:23.900
 Ignoring his, the lessons of history, yes.

1:36:23.900 --> 1:36:26.180
 And it's like, we're in this really weird middle ground

1:36:26.180 --> 1:36:31.180
 where it's like, we are not finding the happy medium

1:36:31.300 --> 1:36:34.780
 between wisdom and fresh ideas

1:36:34.780 --> 1:36:35.980
 and they're fighting each other.

1:36:35.980 --> 1:36:40.980
 And it's like, like really, like what we need is like,

1:36:41.060 --> 1:36:43.940
 like the fresh ideas and the wisdom to be like collaborating.

1:36:43.940 --> 1:36:45.180
 And it's like...

1:36:45.180 --> 1:36:47.380
 Well, the fighting in a way is the searching

1:36:47.380 --> 1:36:48.540
 for the happy medium.

1:36:48.540 --> 1:36:51.100
 And in a way, maybe we are finding the happy medium.

1:36:51.100 --> 1:36:52.980
 Maybe that's what the happy medium looks like.

1:36:52.980 --> 1:36:55.020
 And for AI systems, there has to be,

1:36:55.020 --> 1:36:57.180
 it's, you know, you have reinforcement learning.

1:36:57.180 --> 1:37:00.380
 You have the dance between exploration and exploitation,

1:37:00.380 --> 1:37:03.420
 sort of doing crazy stuff to see if there's something better

1:37:03.420 --> 1:37:05.460
 than what you think is the optimal

1:37:05.460 --> 1:37:06.620
 and then doing the optimal thing

1:37:06.620 --> 1:37:08.660
 and dancing back and forth from that.

1:37:08.660 --> 1:37:10.700
 You would, Stuart Russell, I don't know if you know that,

1:37:10.700 --> 1:37:15.700
 is AI guy with things about sort of

1:37:15.900 --> 1:37:18.620
 how to control super intelligent AI systems.

1:37:18.620 --> 1:37:21.540
 And his idea is that we should inject uncertainty

1:37:21.540 --> 1:37:24.180
 and sort of humility into AI systems

1:37:24.180 --> 1:37:26.820
 that they never, as they get wiser and wiser and wiser

1:37:26.820 --> 1:37:30.060
 and more intelligent, they're never really sure.

1:37:30.060 --> 1:37:31.660
 They always doubt themselves.

1:37:31.660 --> 1:37:34.380
 And in some sense, when you think of young people,

1:37:34.380 --> 1:37:36.340
 that's a mechanism for doubt.

1:37:36.340 --> 1:37:38.900
 It's like, it's how society doubts

1:37:38.900 --> 1:37:40.900
 whether the thing it has converged towards

1:37:40.900 --> 1:37:41.980
 is the right answer.

1:37:41.980 --> 1:37:44.900
 So the voices of the young people

1:37:44.900 --> 1:37:48.180
 is a society asking itself a question.

1:37:48.180 --> 1:37:51.140
 The way I've been doing stuff for the past 50 years,

1:37:51.140 --> 1:37:52.500
 maybe it's the wrong way.

1:37:52.500 --> 1:37:55.380
 And so you can have all of that within one AI system.

1:37:55.380 --> 1:37:57.500
 I also think though that we need to,

1:37:57.500 --> 1:37:59.940
 I mean, actually that's actually really interesting

1:37:59.940 --> 1:38:00.780
 and really cool.

1:38:01.860 --> 1:38:04.540
 But I also think there's a fine balance of,

1:38:05.420 --> 1:38:10.180
 I think we maybe also overvalue the idea

1:38:10.180 --> 1:38:11.980
 that the old systems are always bad.

1:38:11.980 --> 1:38:14.860
 And I think there are things that we are perfecting

1:38:14.860 --> 1:38:17.460
 and we might be accidentally overthrowing things

1:38:17.460 --> 1:38:19.780
 that we actually have gotten to a good point.

1:38:19.780 --> 1:38:22.820
 Just because we are valuing, we value disruption so much

1:38:22.820 --> 1:38:25.460
 and we value fighting against the generations

1:38:25.460 --> 1:38:29.100
 before us so much, that like,

1:38:29.100 --> 1:38:30.660
 there's also an aspect of like,

1:38:30.660 --> 1:38:32.780
 sometimes we're taking two steps forward, one step back

1:38:32.780 --> 1:38:36.980
 because, okay, maybe we kind of did solve this thing.

1:38:36.980 --> 1:38:39.220
 And now we're like fucking it up.

1:38:39.220 --> 1:38:44.220
 And so I think there's like a middle ground there too.

1:38:44.780 --> 1:38:47.300
 Yeah, we're in search of that happy medium.

1:38:47.300 --> 1:38:50.500
 Let me ask you a bunch of crazy questions, okay?

1:38:51.500 --> 1:38:53.980
 You can answer in a short way or in a long way.

1:38:53.980 --> 1:38:56.340
 What's the scariest thing you've ever done?

1:38:56.340 --> 1:38:58.380
 These questions are gonna be ridiculous.

1:38:58.380 --> 1:39:01.420
 Something tiny or something big,

1:39:02.420 --> 1:39:07.420
 skydiving or touring your first record

1:39:09.860 --> 1:39:12.100
 going on this podcast.

1:39:12.100 --> 1:39:13.620
 I've had two crazy brushes,

1:39:13.620 --> 1:39:15.180
 like really scary brushes with death

1:39:15.180 --> 1:39:17.020
 where I randomly got away on skate.

1:39:17.020 --> 1:39:19.220
 I don't know if I should talk about those on here.

1:39:19.220 --> 1:39:22.860
 But like, I think I might be the luckiest person alive though.

1:39:22.860 --> 1:39:26.020
 Like, this might be too dark for a podcast though.

1:39:26.020 --> 1:39:27.100
 I feel like, I don't know if this is like

1:39:27.100 --> 1:39:28.740
 good content for a podcast.

1:39:28.740 --> 1:39:30.300
 I don't know what content.

1:39:30.300 --> 1:39:31.620
 It might hijack.

1:39:31.620 --> 1:39:32.460
 Here's a safer one.

1:39:32.460 --> 1:39:36.780
 I mean, having a baby really scared me.

1:39:36.780 --> 1:39:37.780
 Before, after.

1:39:37.780 --> 1:39:38.940
 Just a birth process.

1:39:38.940 --> 1:39:43.940
 Surgery, like, just having a baby is really scary.

1:39:43.940 --> 1:39:47.540
 It's just like the medical aspect of it,

1:39:47.540 --> 1:39:49.300
 not the responsibility.

1:39:49.300 --> 1:39:51.380
 Were you ready for the responsibility?

1:39:51.380 --> 1:39:53.980
 Did you, were you ready to be a mother?

1:39:53.980 --> 1:39:56.300
 All the beautiful things that comes with motherhood

1:39:56.300 --> 1:39:57.580
 that you were talking about,

1:39:57.580 --> 1:40:00.180
 all the changes and all that, were you ready for that?

1:40:01.060 --> 1:40:03.020
 Were you, did you feel ready for that?

1:40:03.020 --> 1:40:05.340
 No, I think it took about nine months

1:40:05.340 --> 1:40:06.620
 to start getting ready for it.

1:40:06.620 --> 1:40:08.380
 And I'm still getting more ready for it

1:40:08.380 --> 1:40:12.980
 because now you keep realizing more things

1:40:12.980 --> 1:40:14.220
 as they start getting.

1:40:14.220 --> 1:40:16.420
 As the consciousness grows.

1:40:16.420 --> 1:40:18.380
 And stuff you didn't notice with the first one.

1:40:18.380 --> 1:40:19.700
 Now that you've seen the first one older,

1:40:19.700 --> 1:40:21.700
 you're noticing it more,

1:40:21.700 --> 1:40:24.420
 like the sort of like existential horror

1:40:24.420 --> 1:40:28.300
 of coming into consciousness with baby Y

1:40:28.300 --> 1:40:30.140
 or baby Sailor Mars or whatever.

1:40:30.140 --> 1:40:33.540
 She has like so many names at this point that it's,

1:40:33.540 --> 1:40:36.100
 we really need to probably settle on one.

1:40:36.100 --> 1:40:38.300
 If you could be someone else for a day,

1:40:38.300 --> 1:40:41.780
 someone alive today, but somebody you haven't met yet,

1:40:41.780 --> 1:40:42.620
 who would you be?

1:40:42.620 --> 1:40:44.220
 Would I be modeling their brain state

1:40:44.220 --> 1:40:46.420
 or would I just be in their body?

1:40:46.420 --> 1:40:48.380
 You can choose the degree

1:40:48.380 --> 1:40:50.580
 to which you're modeling their brain state.

1:40:50.580 --> 1:40:54.300
 Cause so you can still take a third person perspective

1:40:54.300 --> 1:40:56.660
 and realize, you have to realize that you're.

1:40:56.660 --> 1:40:58.700
 Can they be alive or can it be dead?

1:41:00.580 --> 1:41:02.780
 No, oh, could it be anyone?

1:41:02.780 --> 1:41:04.540
 They would be brought back to life, right?

1:41:04.540 --> 1:41:05.380
 If they're dead.

1:41:05.380 --> 1:41:07.140
 Yeah, you can bring people back.

1:41:07.140 --> 1:41:09.300
 Definitely Hitler is Stalin.

1:41:09.300 --> 1:41:11.260
 I want to understand evil.

1:41:11.260 --> 1:41:12.900
 Who would you, you would need to,

1:41:12.900 --> 1:41:15.020
 oh, to experience what it feels like.

1:41:15.020 --> 1:41:17.580
 I want to be in their brain, feeling what they feel.

1:41:18.580 --> 1:41:20.860
 That might change you forever, returning from that.

1:41:20.860 --> 1:41:22.940
 Yes, but I think it would also help me understand

1:41:22.940 --> 1:41:25.380
 how to prevent it and fix it.

1:41:25.380 --> 1:41:26.580
 That might be one of those things.

1:41:26.580 --> 1:41:29.940
 Once you experience it, it'll be a burden to know it.

1:41:29.940 --> 1:41:30.780
 Cause you won't be able to trust that.

1:41:30.780 --> 1:41:33.820
 Yeah, but a lot of things are burdens, like.

1:41:33.820 --> 1:41:34.780
 But it's a useful burden.

1:41:34.780 --> 1:41:36.020
 But it's a useful burden.

1:41:36.020 --> 1:41:36.860
 Yeah.

1:41:36.860 --> 1:41:37.700
 That for sure.

1:41:37.700 --> 1:41:40.300
 I want to understand evil and like psychopathy

1:41:40.300 --> 1:41:43.300
 and that I have all these fake Twitter accounts

1:41:43.300 --> 1:41:45.540
 where I like go into different algorithmic bubbles

1:41:45.540 --> 1:41:47.340
 to try to like understand.

1:41:47.340 --> 1:41:48.700
 I'll keep getting in fights with people

1:41:48.700 --> 1:41:50.620
 and realize we're not actually fighting.

1:41:50.620 --> 1:41:53.020
 I think we're, we used to exist in a monoculture

1:41:53.020 --> 1:41:54.420
 like before social media and stuff.

1:41:54.420 --> 1:41:56.460
 Like we kind of all got fed the same thing.

1:41:56.460 --> 1:41:58.700
 So we were all speaking the same cultural language.

1:41:58.700 --> 1:42:00.140
 But I think recently one of the things

1:42:00.140 --> 1:42:02.100
 that like we aren't diagnosing properly enough

1:42:02.100 --> 1:42:05.500
 with social media is that there's different dialects.

1:42:05.500 --> 1:42:06.900
 There's so many different dialects of Chinese.

1:42:06.900 --> 1:42:09.380
 There are now becoming different dialects of English.

1:42:09.380 --> 1:42:11.780
 Like I am realizing like there are people

1:42:11.780 --> 1:42:13.540
 who are saying the exact same things,

1:42:13.540 --> 1:42:15.980
 but they're using completely different verbiage.

1:42:15.980 --> 1:42:17.340
 And we're like punishing each other

1:42:17.340 --> 1:42:18.900
 for not using the correct verbiage.

1:42:18.900 --> 1:42:20.500
 And we're completely misunderstanding.

1:42:20.500 --> 1:42:22.020
 Like people are just like misunderstanding

1:42:22.020 --> 1:42:23.580
 what the other people are saying.

1:42:23.580 --> 1:42:26.260
 And like, like I just got in a fight with a friend

1:42:27.460 --> 1:42:32.460
 about like anarchism and communism and shit for like two hours.

1:42:33.020 --> 1:42:34.540
 And then by the end of the conversation,

1:42:34.540 --> 1:42:35.940
 like, and then she'd say something and I'm like,

1:42:35.940 --> 1:42:37.580
 but that's literally what I'm saying.

1:42:37.580 --> 1:42:38.900
 And she was like, what?

1:42:38.900 --> 1:42:40.860
 And then I was like, fuck, we've different, right?

1:42:40.860 --> 1:42:42.900
 And I'm like, we're, our English,

1:42:42.900 --> 1:42:45.940
 like the way we are understanding terminology

1:42:45.940 --> 1:42:50.140
 is like drastically like our algorithm bubbles

1:42:50.140 --> 1:42:52.820
 are creating mini dialects.

1:42:52.820 --> 1:42:55.820
 And how language is interpreted, how language is used.

1:42:55.820 --> 1:42:56.820
 That's so fascinating.

1:42:56.820 --> 1:42:59.140
 And so we're like having these arguments

1:42:59.140 --> 1:43:00.900
 that we do not need to be having

1:43:00.900 --> 1:43:02.300
 and there's polarization that's happening

1:43:02.300 --> 1:43:03.340
 that doesn't need to be happening

1:43:03.340 --> 1:43:06.340
 because we've got these like algorithmically created

1:43:06.340 --> 1:43:09.860
 dialects occurring.

1:43:09.860 --> 1:43:10.700
 Plus on top of that,

1:43:10.700 --> 1:43:12.340
 there's also different parts of the world

1:43:12.340 --> 1:43:13.460
 that speak different languages.

1:43:13.460 --> 1:43:17.820
 So there's literally lost in translation kind of communication.

1:43:17.820 --> 1:43:19.780
 I happen to know the Russian language

1:43:19.780 --> 1:43:21.420
 and I just know how different it is.

1:43:21.420 --> 1:43:22.380
 Yeah.

1:43:22.380 --> 1:43:23.860
 Then the English language.

1:43:23.860 --> 1:43:27.660
 And I just wonder how much is lost in a little bit of.

1:43:27.660 --> 1:43:28.940
 Man, I actually, cause I have a question for you.

1:43:28.940 --> 1:43:30.260
 I have a song coming out tomorrow

1:43:30.260 --> 1:43:31.900
 with Ice Peak or a Russian band.

1:43:31.900 --> 1:43:33.700
 And I speak a little bit of Russian

1:43:33.700 --> 1:43:35.380
 and I was looking at the title

1:43:35.380 --> 1:43:38.260
 and the title in English doesn't match the title in Russian.

1:43:38.260 --> 1:43:39.140
 I'm curious about this.

1:43:39.140 --> 1:43:40.540
 Cause look, it says

1:43:40.540 --> 1:43:41.380
 What's the English?

1:43:41.380 --> 1:43:42.940
 The title in English is last day.

1:43:42.940 --> 1:43:44.500
 And then the title in Russian is

1:43:44.500 --> 1:43:47.540
 my pronunciation sucks.

1:43:47.540 --> 1:43:48.780
 Novideyen?

1:43:48.780 --> 1:43:49.620
 Like what?

1:43:49.620 --> 1:43:50.460
 A new day.

1:43:50.460 --> 1:43:51.300
 Yeah, new day.

1:43:51.300 --> 1:43:52.140
 New day.

1:43:52.140 --> 1:43:53.460
 Like it's two different.

1:43:53.460 --> 1:43:54.420
 Yeah, new day.

1:43:54.420 --> 1:43:55.260
 Yeah.

1:43:57.260 --> 1:43:58.460
 Yeah, yeah, new day.

1:43:58.460 --> 1:43:59.700
 New day, but last day.

1:44:01.340 --> 1:44:02.260
 Novideyen.

1:44:02.260 --> 1:44:04.460
 So last day would be the last day.

1:44:04.460 --> 1:44:06.980
 Maybe they, or maybe the title includes

1:44:06.980 --> 1:44:09.060
 both the Russian and the, and the, and the, and it's four.

1:44:09.060 --> 1:44:09.900
 Maybe, maybe.

1:44:09.900 --> 1:44:10.740
 It's four, maybe it's four bilingual.

1:44:10.740 --> 1:44:13.220
 To be honest, Novideyen sounds better than

1:44:13.220 --> 1:44:16.300
 just musically, like a

1:44:16.300 --> 1:44:17.780
 Novideyen is new day.

1:44:17.780 --> 1:44:18.780
 That's the current one.

1:44:18.780 --> 1:44:22.180
 And the last day is the last day.

1:44:23.460 --> 1:44:25.460
 I think Novideyen.

1:44:25.460 --> 1:44:26.660
 I don't like Novideyen.

1:44:26.660 --> 1:44:28.900
 But the meaning is so different.

1:44:30.180 --> 1:44:31.660
 That's kind of awesome actually though.

1:44:31.660 --> 1:44:34.540
 There's an explicit sort of contrast like that.

1:44:35.820 --> 1:44:38.340
 If everyone on earth disappeared

1:44:38.340 --> 1:44:39.940
 and it was just you left,

1:44:42.540 --> 1:44:44.060
 what would your day look like?

1:44:44.060 --> 1:44:45.260
 Like what would you do?

1:44:45.260 --> 1:44:46.780
 Everybody's dead.

1:44:46.780 --> 1:44:47.620
 As far as you.

1:44:47.620 --> 1:44:48.620
 Are there corpses there?

1:44:52.500 --> 1:44:53.820
 Well seriously, it's a big day.

1:44:53.820 --> 1:44:54.780
 Let me think through this.

1:44:54.780 --> 1:44:56.940
 It's a big difference if there's just like birds singing

1:44:56.940 --> 1:44:58.940
 versus if there's like corpses littering the street.

1:44:58.940 --> 1:45:00.300
 Yeah, there's corpses everywhere.

1:45:00.300 --> 1:45:01.900
 I'm sorry.

1:45:01.900 --> 1:45:05.100
 It's, and you don't actually know what happened.

1:45:05.100 --> 1:45:07.580
 And you don't know why you survived.

1:45:07.580 --> 1:45:10.460
 And you don't even know if there's others out there.

1:45:10.460 --> 1:45:13.580
 But it seems clear that it's all gone.

1:45:13.580 --> 1:45:15.260
 What would you do?

1:45:15.260 --> 1:45:16.140
 What would I do?

1:45:17.300 --> 1:45:19.580
 Listen, I'm somebody who really enjoys the moment,

1:45:19.580 --> 1:45:20.460
 enjoys life.

1:45:20.460 --> 1:45:25.460
 I would just go on like enjoying the inanimate objects.

1:45:25.460 --> 1:45:29.740
 I would just look for food, basic survival,

1:45:29.740 --> 1:45:32.900
 but mostly it's just, listen, when I just,

1:45:32.900 --> 1:45:35.100
 I take walks and I look outside

1:45:35.100 --> 1:45:37.940
 and I'm just happy that we get to exist on this planet

1:45:38.940 --> 1:45:41.140
 to be able to breathe air.

1:45:41.140 --> 1:45:42.380
 It's just all beautiful.

1:45:42.380 --> 1:45:44.180
 It's full of colors, all of this kind of stuff.

1:45:44.180 --> 1:45:48.260
 Just there's so many things about life, your own life,

1:45:48.260 --> 1:45:50.100
 conscious life that's fucking awesome.

1:45:50.100 --> 1:45:51.260
 So I would just enjoy that.

1:45:51.260 --> 1:45:54.260
 But also maybe after a few weeks,

1:45:54.260 --> 1:45:55.940
 the engineer would start coming out,

1:45:55.940 --> 1:45:58.940
 like want to build some things.

1:45:58.940 --> 1:46:02.940
 Maybe there's always hope searching for another human.

1:46:02.940 --> 1:46:03.780
 Maybe like...

1:46:03.780 --> 1:46:06.820
 Probably searching for another human,

1:46:06.820 --> 1:46:10.820
 probably trying to get to a TV or radio station

1:46:10.820 --> 1:46:14.260
 and broadcast something.

1:46:14.260 --> 1:46:15.580
 I...

1:46:15.580 --> 1:46:16.420
 That's interesting.

1:46:16.420 --> 1:46:17.260
 I didn't think about that.

1:46:17.260 --> 1:46:21.260
 So like really maximize your ability to connect with others.

1:46:21.260 --> 1:46:26.260
 Yeah, like probably try to find another person.

1:46:26.260 --> 1:46:30.260
 Would you be excited to meet another person or terrified?

1:46:30.260 --> 1:46:31.260
 Because, you know...

1:46:31.260 --> 1:46:33.260
 I'd be excited, even if they...

1:46:33.260 --> 1:46:34.260
 No matter what.

1:46:34.260 --> 1:46:35.260
 Yeah, yeah, yeah, yeah.

1:46:35.260 --> 1:46:39.260
 Being alone for the last however long of my life

1:46:39.260 --> 1:46:40.260
 would be really bad.

1:46:40.260 --> 1:46:43.260
 That's the one instance I might,

1:46:43.260 --> 1:46:45.260
 I don't think I'd kill myself for it.

1:46:45.260 --> 1:46:47.260
 I might, I don't think I'd kill myself

1:46:47.260 --> 1:46:49.260
 but I might kill myself if I had to understand that.

1:46:49.260 --> 1:46:50.260
 Do you love people?

1:46:50.260 --> 1:46:52.260
 Do you love connection to other humans?

1:46:52.260 --> 1:46:53.260
 Yeah.

1:46:53.260 --> 1:46:54.260
 I kind of hate people too, but yeah.

1:46:54.260 --> 1:46:56.260
 No, it's a love hate relationship.

1:46:56.260 --> 1:46:57.260
 Yeah.

1:46:57.260 --> 1:46:58.260
 I feel like this is,

1:46:58.260 --> 1:47:00.260
 I feel like we had a bunch of like weird niche of questions and stuff.

1:47:00.260 --> 1:47:01.260
 Oh yeah.

1:47:01.260 --> 1:47:02.260
 Like I wonder, because I'm like,

1:47:02.260 --> 1:47:03.260
 when podcast, like I'm like,

1:47:03.260 --> 1:47:05.260
 is this interesting for people to just have like...

1:47:05.260 --> 1:47:08.260
 Or, I don't know, maybe people do like this.

1:47:08.260 --> 1:47:09.260
 When I listen to podcasts,

1:47:09.260 --> 1:47:12.260
 I'm into like the lore, like the hard lore.

1:47:12.260 --> 1:47:13.260
 Like I just love like Dan Carlin.

1:47:13.260 --> 1:47:15.260
 I'm like, give me the facts, just like...

1:47:15.260 --> 1:47:16.260
 Yeah.

1:47:16.260 --> 1:47:18.260
 Just like the facts into my bloodstream.

1:47:18.260 --> 1:47:20.260
 But you also don't know,

1:47:20.260 --> 1:47:23.260
 like you're a fascinating mind to explore.

1:47:23.260 --> 1:47:26.260
 So when you don't realize as you're talking about stuff,

1:47:26.260 --> 1:47:28.260
 the stuff you've taken for granted

1:47:28.260 --> 1:47:30.260
 is actually unique and fascinating.

1:47:30.260 --> 1:47:33.260
 The way you think, not always what,

1:47:33.260 --> 1:47:35.260
 like the way you reason through things

1:47:35.260 --> 1:47:36.260
 is the fascinating thing.

1:47:36.260 --> 1:47:37.260
 Okay.

1:47:37.260 --> 1:47:39.260
 To listen, to listen to,

1:47:39.260 --> 1:47:40.260
 because people kind of see,

1:47:40.260 --> 1:47:43.260
 oh, there's other humans that think differently,

1:47:43.260 --> 1:47:45.260
 that explore thoughts differently.

1:47:45.260 --> 1:47:46.260
 That's the cool.

1:47:46.260 --> 1:47:47.260
 That's also cool.

1:47:47.260 --> 1:47:50.260
 So yeah, Dan Carlin retelling of history.

1:47:50.260 --> 1:47:54.260
 By the way, his retelling of history is very,

1:47:54.260 --> 1:47:57.260
 I think what's exciting is not the history,

1:47:57.260 --> 1:48:00.260
 is his way of thinking about history.

1:48:00.260 --> 1:48:02.260
 No, I think Dan Carlin is one of the people,

1:48:02.260 --> 1:48:04.260
 like when Dan Carlin is one of the people

1:48:04.260 --> 1:48:06.260
 that really started getting me excited

1:48:06.260 --> 1:48:08.260
 about like revolutionizing education,

1:48:08.260 --> 1:48:11.260
 because like Dan Carlin instilled,

1:48:11.260 --> 1:48:14.260
 I already really liked history,

1:48:14.260 --> 1:48:18.260
 but he instilled like an obsessive love of history in me,

1:48:18.260 --> 1:48:21.260
 to the point where like now I'm fucking reading,

1:48:21.260 --> 1:48:23.260
 like going to bed,

1:48:23.260 --> 1:48:25.260
 reading like part four of the Rise and Fall,

1:48:25.260 --> 1:48:26.260
 Third Reich or whatever.

1:48:26.260 --> 1:48:28.260
 Like I got like dense ass history,

1:48:28.260 --> 1:48:31.260
 but like he like opened that door

1:48:31.260 --> 1:48:34.260
 that like made me want to be a scholar of that topic.

1:48:34.260 --> 1:48:37.260
 Like it's like, I feel like he's such a good teacher.

1:48:37.260 --> 1:48:39.260
 He just like, you know,

1:48:39.260 --> 1:48:41.260
 and it sort of made me feel like

1:48:41.260 --> 1:48:43.260
 one of the things we could do with education

1:48:43.260 --> 1:48:46.260
 is like find like the world's great,

1:48:46.260 --> 1:48:49.260
 the teachers that like create passion for the topic,

1:48:49.260 --> 1:48:53.260
 because auto didacticism,

1:48:53.260 --> 1:48:55.260
 I don't know how to say that properly,

1:48:55.260 --> 1:48:57.260
 but like self teaching is like much faster

1:48:57.260 --> 1:48:59.260
 than being lectured to,

1:48:59.260 --> 1:49:01.260
 like it's much more efficient to sort of like be able

1:49:01.260 --> 1:49:03.260
 to teach yourself and then ask a teacher questions

1:49:03.260 --> 1:49:04.260
 when you don't know what's up,

1:49:04.260 --> 1:49:08.260
 but like, you know, that's why it's like in university and stuff,

1:49:08.260 --> 1:49:10.260
 like you can learn so much more material,

1:49:10.260 --> 1:49:12.260
 so much faster because you're doing a lot of the learning

1:49:12.260 --> 1:49:14.260
 on your own and you're going to the teachers

1:49:14.260 --> 1:49:15.260
 for when you get stuck,

1:49:15.260 --> 1:49:18.260
 but like these teachers that can inspire passion

1:49:18.260 --> 1:49:20.260
 for a topic,

1:49:20.260 --> 1:49:22.260
 I think that is one of the most invaluable skills

1:49:22.260 --> 1:49:23.260
 in our whole species,

1:49:23.260 --> 1:49:25.260
 like because if you can do that,

1:49:25.260 --> 1:49:27.260
 then you, it's like AI,

1:49:27.260 --> 1:49:30.260
 like AI is going to teach itself

1:49:30.260 --> 1:49:32.260
 so much more efficiently than we can teach it.

1:49:32.260 --> 1:49:34.260
 To get it to the point where it can teach itself

1:49:34.260 --> 1:49:35.260
 and then

1:49:35.260 --> 1:49:37.260
 It finds the motivation to do so, right?

1:49:37.260 --> 1:49:38.260
 Yeah.

1:49:38.260 --> 1:49:39.260
 It's like you inspire it to do so.

1:49:39.260 --> 1:49:40.260
 Yeah.

1:49:40.260 --> 1:49:42.260
 And then it could, it could teach itself.

1:49:42.260 --> 1:49:44.260
 What do you make of the fact,

1:49:44.260 --> 1:49:46.260
 you mentioned Rise and Fall of the Third Reich,

1:49:46.260 --> 1:49:48.260
 I just read it twice.

1:49:48.260 --> 1:49:49.260
 You read it twice?

1:49:49.260 --> 1:49:50.260
 Yes.

1:49:50.260 --> 1:49:51.260
 Okay.

1:49:51.260 --> 1:49:52.260
 He's known even knows what it, what it is.

1:49:52.260 --> 1:49:53.260
 Yeah.

1:49:53.260 --> 1:49:54.260
 And I'm like, I'm like, wait,

1:49:54.260 --> 1:49:55.260
 I thought this was like a super pop and book.

1:49:55.260 --> 1:49:56.260
 Super pop.

1:49:56.260 --> 1:49:57.260
 I'm not like that.

1:49:57.260 --> 1:49:58.260
 It's a classic.

1:49:58.260 --> 1:49:59.260
 I'm not that far in it,

1:49:59.260 --> 1:50:00.260
 but it is, it's so interesting.

1:50:00.260 --> 1:50:02.260
 Yeah.

1:50:02.260 --> 1:50:04.260
 It's written by a person that was there,

1:50:04.260 --> 1:50:06.260
 which is very important to kind of,

1:50:06.260 --> 1:50:08.260
 you know, you can start being like,

1:50:08.260 --> 1:50:09.260
 how could this possibly happen?

1:50:09.260 --> 1:50:11.260
 And then when you read Rise and Fall of the Third Reich,

1:50:11.260 --> 1:50:14.260
 it's like people tried really hard for this to not happen.

1:50:14.260 --> 1:50:15.260
 People tried,

1:50:15.260 --> 1:50:17.260
 they almost reinstated a monarchy at one point

1:50:17.260 --> 1:50:18.260
 to try to stop this from happening.

1:50:18.260 --> 1:50:20.260
 Like they almost like,

1:50:20.260 --> 1:50:23.260
 like abandoned democracy to try to get this to not happen.

1:50:23.260 --> 1:50:25.260
 At least the way it makes me feel

1:50:25.260 --> 1:50:28.260
 is that there's a bunch of small moments

1:50:28.260 --> 1:50:30.260
 on which history can turn.

1:50:30.260 --> 1:50:31.260
 Yes.

1:50:31.260 --> 1:50:32.260
 It's like small meetings.

1:50:32.260 --> 1:50:33.260
 Yes.

1:50:33.260 --> 1:50:34.260
 Human interactions.

1:50:34.260 --> 1:50:37.260
 And it's both terrifying and inspiring

1:50:37.260 --> 1:50:40.260
 because it's like,

1:50:40.260 --> 1:50:44.260
 even just attempts at assassinating Hitler

1:50:44.260 --> 1:50:47.260
 like time and time again failed.

1:50:47.260 --> 1:50:48.260
 And they were so close.

1:50:48.260 --> 1:50:49.260
 Was it like,

1:50:49.260 --> 1:50:50.260
 I'm from Valkyrie?

1:50:50.260 --> 1:50:52.260
 Such a good.

1:50:52.260 --> 1:50:53.260
 And then there is also,

1:50:53.260 --> 1:50:55.260
 also the role of,

1:50:55.260 --> 1:50:57.260
 that's a really heavy burden,

1:50:57.260 --> 1:50:59.260
 that from a geopolitical perspective,

1:50:59.260 --> 1:51:01.260
 the role of leaders to see evil

1:51:01.260 --> 1:51:03.260
 before it truly becomes evil,

1:51:03.260 --> 1:51:04.260
 to anticipate it,

1:51:04.260 --> 1:51:05.260
 to stand up to evil.

1:51:05.260 --> 1:51:08.260
 Because evil is actually pretty rare in this world.

1:51:08.260 --> 1:51:09.260
 At a scale that Hitler was.

1:51:09.260 --> 1:51:11.260
 We tend to, you know,

1:51:11.260 --> 1:51:14.260
 in modern discourse kind of call people evil too quickly.

1:51:14.260 --> 1:51:17.260
 If you look at ancient history,

1:51:17.260 --> 1:51:19.260
 like there was a ton of Hitlers.

1:51:19.260 --> 1:51:21.260
 I actually think it's more the norm

1:51:21.260 --> 1:51:23.260
 than like,

1:51:23.260 --> 1:51:26.260
 again, going back to like my sort of intelligent design theory.

1:51:26.260 --> 1:51:28.260
 One of the things we've been successfully doing

1:51:28.260 --> 1:51:30.260
 in our slow move from survival

1:51:30.260 --> 1:51:32.260
 of the fittest to intelligent design

1:51:32.260 --> 1:51:37.260
 is we've kind of been eradicating,

1:51:37.260 --> 1:51:40.260
 like if you look at like ancient Assyria and stuff,

1:51:40.260 --> 1:51:42.260
 like that shit was like brutal

1:51:42.260 --> 1:51:44.260
 and just like the heads on the,

1:51:44.260 --> 1:51:46.260
 like brutal, like Genghis Khan,

1:51:46.260 --> 1:51:49.260
 just like genocide after genocide after genocide.

1:51:49.260 --> 1:51:51.260
 There's like throwing plague bodies over the walls

1:51:51.260 --> 1:51:53.260
 and decimating whole cities

1:51:53.260 --> 1:51:56.260
 or like the Muslim conquests of like Damascus and shit.

1:51:56.260 --> 1:51:59.260
 Just like people, cities used to get leveled

1:51:59.260 --> 1:52:00.260
 all the fucking time.

1:52:00.260 --> 1:52:01.260
 Okay.

1:52:01.260 --> 1:52:03.260
 Get into the Bronze Age collapse.

1:52:03.260 --> 1:52:06.260
 It's basically there was like almost like Roman level,

1:52:06.260 --> 1:52:08.260
 like society,

1:52:08.260 --> 1:52:10.260
 like there was like all over the world,

1:52:10.260 --> 1:52:11.260
 like global trade,

1:52:11.260 --> 1:52:12.260
 like everything was awesome

1:52:12.260 --> 1:52:14.260
 through a mix of I think a bit of climate change

1:52:14.260 --> 1:52:16.260
 and then the development of iron,

1:52:16.260 --> 1:52:18.260
 because basically bronze could only come from this,

1:52:18.260 --> 1:52:20.260
 the way to make bronze,

1:52:20.260 --> 1:52:22.260
 like everything had to be funneled through this one,

1:52:22.260 --> 1:52:24.260
 Canadian mine.

1:52:24.260 --> 1:52:25.260
 And so it's like,

1:52:25.260 --> 1:52:27.260
 there was just this one supply chain.

1:52:27.260 --> 1:52:28.260
 And this is one of the things

1:52:28.260 --> 1:52:30.260
 that makes me worried about supply chains

1:52:30.260 --> 1:52:32.260
 and why I think we need to be so thoughtful about,

1:52:32.260 --> 1:52:35.260
 I think our biggest issue with society right now,

1:52:35.260 --> 1:52:37.260
 like the thing that is most likely to go wrong

1:52:37.260 --> 1:52:39.260
 is probably supply chain collapse.

1:52:39.260 --> 1:52:41.260
 You know, cause war, climate change, whatever,

1:52:41.260 --> 1:52:43.260
 like anything that causes supply chain collapse,

1:52:43.260 --> 1:52:45.260
 our population is too big to handle that.

1:52:45.260 --> 1:52:47.260
 And like the thing that seems to cause dark ages

1:52:47.260 --> 1:52:49.260
 is mass supply chain collapse.

1:52:49.260 --> 1:52:51.260
 But the bronze age collapse happened,

1:52:51.260 --> 1:52:55.260
 like it was sort of like this ancient collapse

1:52:55.260 --> 1:52:59.260
 that happened where like literally like ancient Egypt,

1:52:59.260 --> 1:53:00.260
 all these cities,

1:53:00.260 --> 1:53:02.260
 everything just got like decimated, destroyed,

1:53:02.260 --> 1:53:04.260
 abandoned cities, like hundreds of them.

1:53:04.260 --> 1:53:06.260
 There was like a flourishing society,

1:53:06.260 --> 1:53:07.260
 like we were almost coming to modernity

1:53:07.260 --> 1:53:08.260
 and everything got leveled.

1:53:08.260 --> 1:53:10.260
 And they had this many dark ages,

1:53:10.260 --> 1:53:11.260
 but it was just like,

1:53:11.260 --> 1:53:13.260
 there's so little writing or recording from that time

1:53:13.260 --> 1:53:15.260
 that like there isn't a lot of information

1:53:15.260 --> 1:53:16.260
 about the bronze age collapse,

1:53:16.260 --> 1:53:19.260
 but it was basically equivalent to like medieval,

1:53:19.260 --> 1:53:21.260
 the medieval dark ages,

1:53:21.260 --> 1:53:23.260
 but it just happened not,

1:53:23.260 --> 1:53:24.260
 I don't know the years,

1:53:24.260 --> 1:53:27.260
 but like thousands of years earlier.

1:53:27.260 --> 1:53:29.260
 And then we sort of like recovered

1:53:29.260 --> 1:53:31.260
 from the bronze age collapse,

1:53:31.260 --> 1:53:34.260
 empire reemerged, writing and trade

1:53:34.260 --> 1:53:37.260
 and everything reemerged, you know,

1:53:37.260 --> 1:53:41.260
 and then we of course had the more contemporary dark ages.

1:53:41.260 --> 1:53:42.260
 And then over time,

1:53:42.260 --> 1:53:44.260
 we've designed mechanism to lessen

1:53:44.260 --> 1:53:48.260
 and lessen the capability for the destructive.

1:53:48.260 --> 1:53:50.260
 Power centers to emerge.

1:53:50.260 --> 1:53:51.260
 There's more recording

1:53:51.260 --> 1:53:54.260
 about the more contemporary dark ages.

1:53:54.260 --> 1:53:55.260
 So I think we have like a better understanding

1:53:55.260 --> 1:53:56.260
 of how to avoid it,

1:53:56.260 --> 1:53:58.260
 but I still think we're at high risk for it.

1:53:58.260 --> 1:54:00.260
 I think that's one of the big risks right now.

1:54:00.260 --> 1:54:03.260
 So the natural state of being for humans

1:54:03.260 --> 1:54:04.260
 is for there to be a lot of hitlers,

1:54:04.260 --> 1:54:06.260
 which has gotten really good

1:54:06.260 --> 1:54:09.260
 at making it hard for them to emerge.

1:54:09.260 --> 1:54:11.260
 We've gotten better collaboration.

1:54:11.260 --> 1:54:12.260
 Yes.

1:54:12.260 --> 1:54:14.260
 And resisting the power,

1:54:14.260 --> 1:54:16.260
 like authoritarians to come to power.

1:54:16.260 --> 1:54:18.260
 We're trying to go country by country.

1:54:18.260 --> 1:54:19.260
 Like we're moving past this.

1:54:19.260 --> 1:54:21.260
 We're kind of like slowly, incrementally,

1:54:21.260 --> 1:54:28.260
 like moving towards like not scary old school war stuff.

1:54:28.260 --> 1:54:31.260
 And I think seeing it happen in some of the countries

1:54:31.260 --> 1:54:34.260
 that at least nominally are like,

1:54:34.260 --> 1:54:36.260
 supposed to have moved past that,

1:54:36.260 --> 1:54:39.260
 that's scary because it reminds us that it can happen.

1:54:39.260 --> 1:54:42.260
 Like in the places that have made,

1:54:42.260 --> 1:54:46.260
 like supposedly hopefully moved past that.

1:54:46.260 --> 1:54:49.260
 And possibly at a civilization level,

1:54:49.260 --> 1:54:51.260
 like you said, supply chain collapse

1:54:51.260 --> 1:54:53.260
 might make people resource constrained,

1:54:53.260 --> 1:54:57.260
 might make people desperate, angry,

1:54:57.260 --> 1:55:01.260
 hateful, violent, and drag us right back in.

1:55:01.260 --> 1:55:03.260
 I mean, supply chain collapse is how,

1:55:03.260 --> 1:55:06.260
 like the ultimate thing that caused the Middle Ages

1:55:06.260 --> 1:55:08.260
 was supply chain collapse.

1:55:08.260 --> 1:55:09.260
 It's like people,

1:55:09.260 --> 1:55:12.260
 because people were reliant on a certain level of technology,

1:55:12.260 --> 1:55:14.260
 like people, like you look at like Britain,

1:55:14.260 --> 1:55:17.260
 like they had glass, like people had aqueducts,

1:55:17.260 --> 1:55:20.260
 people had like indoor heating and cooling

1:55:20.260 --> 1:55:23.260
 and like running water and like buy food

1:55:23.260 --> 1:55:26.260
 from all over the world and trade and markets.

1:55:26.260 --> 1:55:28.260
 Like people didn't know how to hunt and forage and gather.

1:55:28.260 --> 1:55:30.260
 And so we're in a similar situation.

1:55:30.260 --> 1:55:33.260
 We are not educated enough to survive without technology.

1:55:33.260 --> 1:55:35.260
 So if we have a supply chain collapse

1:55:35.260 --> 1:55:38.260
 that like limits our access to technology,

1:55:38.260 --> 1:55:41.260
 there will be like mass starvation and violence

1:55:41.260 --> 1:55:43.260
 and displacement and war.

1:55:43.260 --> 1:55:47.260
 Like, you know, it's also, like, yeah.

1:55:47.260 --> 1:55:51.260
 In my opinion, it's like the primary marker of dark,

1:55:51.260 --> 1:55:52.260
 like what a dark age is.

1:55:52.260 --> 1:55:54.260
 What technology is kind of enabling us

1:55:54.260 --> 1:55:57.260
 to be more resilient in terms of supply chain,

1:55:57.260 --> 1:56:00.260
 in terms of to all the different catastrophic events

1:56:00.260 --> 1:56:02.260
 that happened to us,

1:56:02.260 --> 1:56:04.260
 although the pandemic has kind of challenged

1:56:04.260 --> 1:56:07.260
 our preparedness for the catastrophic.

1:56:07.260 --> 1:56:10.260
 What do you think is the coolest invention humans come up with?

1:56:10.260 --> 1:56:14.260
 The wheel, fire, cooking meat.

1:56:14.260 --> 1:56:15.260
 Computers.

1:56:15.260 --> 1:56:16.260
 Computers.

1:56:16.260 --> 1:56:17.260
 Freaking computers.

1:56:17.260 --> 1:56:19.260
 Internet or computers, which one?

1:56:19.260 --> 1:56:20.260
 What do you think the...

1:56:20.260 --> 1:56:23.260
 Previous technologies, I mean, may have even been more profound

1:56:23.260 --> 1:56:24.260
 and moved us to a certain degree,

1:56:24.260 --> 1:56:27.260
 but I think the computers are what make us homo tech now.

1:56:27.260 --> 1:56:30.260
 I think this is what, it's a brain augmentation.

1:56:30.260 --> 1:56:33.260
 And so it like allows for actual evolution,

1:56:33.260 --> 1:56:35.260
 like the computers accelerate the degree

1:56:35.260 --> 1:56:38.260
 to which all the other technologies can also be accelerated.

1:56:38.260 --> 1:56:40.260
 Would you classify yourself as a homo sapien

1:56:40.260 --> 1:56:41.260
 or a homo techno?

1:56:41.260 --> 1:56:42.260
 Definitely a homo techno.

1:56:42.260 --> 1:56:46.260
 So you're one of the earliest of the species.

1:56:46.260 --> 1:56:48.260
 I think most of us are.

1:56:48.260 --> 1:56:54.260
 Like, as I said, like, I think if you, like,

1:56:54.260 --> 1:56:59.260
 looked at brain scans of ossoverses humans 100 years ago,

1:56:59.260 --> 1:57:00.260
 it would look very different.

1:57:00.260 --> 1:57:03.260
 I think we are physiologically different.

1:57:03.260 --> 1:57:06.260
 Just even the interaction with the devices has changed our brains.

1:57:06.260 --> 1:57:08.260
 Well, and if you look at them,

1:57:08.260 --> 1:57:10.260
 a lot of studies are coming out to show that, like,

1:57:10.260 --> 1:57:12.260
 there's a degree of inherited memory.

1:57:12.260 --> 1:57:15.260
 So some of these physiological changes in theory should be,

1:57:15.260 --> 1:57:17.260
 we should be passing them on.

1:57:17.260 --> 1:57:21.260
 So, like, that's, you know, that's not like a,

1:57:21.260 --> 1:57:23.260
 an instance of physiological change that's going to fizzle out.

1:57:23.260 --> 1:57:28.260
 In theory, that should progress, like, to our offspring.

1:57:28.260 --> 1:57:32.260
 Speaking of offspring, what advice would you give to a young person?

1:57:32.260 --> 1:57:38.260
 Like, in high school, whether there be an artist,

1:57:38.260 --> 1:57:44.260
 a creative, an engineer, any kind of career path,

1:57:44.260 --> 1:57:46.260
 or maybe just life in general,

1:57:46.260 --> 1:57:48.260
 how they can live a life they can be proud of?

1:57:48.260 --> 1:57:50.260
 I think one of my big thoughts,

1:57:50.260 --> 1:57:53.260
 and like, especially now having kids,

1:57:53.260 --> 1:57:56.260
 is that I don't think we spend enough time teaching creativity.

1:57:56.260 --> 1:57:59.260
 And I think creativity is a muscle like other things.

1:57:59.260 --> 1:58:02.260
 And there's a lot of emphasis on, you know, learn how to play the piano,

1:58:02.260 --> 1:58:05.260
 and then you can write a song, or like, learn the technical stuff,

1:58:05.260 --> 1:58:07.260
 and then you can do a thing.

1:58:07.260 --> 1:58:10.260
 But I think it's, like, I have a friend who's like,

1:58:10.260 --> 1:58:14.260
 world's greatest guitar player, like, you know,

1:58:14.260 --> 1:58:16.260
 amazing sort of like producer, works with other people,

1:58:16.260 --> 1:58:19.260
 but he's really sort of like, you know,

1:58:19.260 --> 1:58:21.260
 he like engineers and records things and like does solos,

1:58:21.260 --> 1:58:23.260
 but he doesn't really like make his own music.

1:58:23.260 --> 1:58:25.260
 And I was talking to him, and I was like,

1:58:25.260 --> 1:58:27.260
 dude, you're so talented at music.

1:58:27.260 --> 1:58:29.260
 Like, why don't you make music or whatever?

1:58:29.260 --> 1:58:31.260
 And he was like, because I got, I'm too old.

1:58:31.260 --> 1:58:33.260
 I never learned the creative muscle.

1:58:33.260 --> 1:58:36.260
 And it's like, you know, it's embarrassing.

1:58:36.260 --> 1:58:40.260
 It's like learning the creative muscle takes a lot of failure.

1:58:40.260 --> 1:58:46.260
 And it also sort of, when you're being creative,

1:58:46.260 --> 1:58:48.260
 you know, you're throwing paint at a wall,

1:58:48.260 --> 1:58:50.260
 and a lot of stuff will fail.

1:58:50.260 --> 1:58:53.260
 So like part of it is like a tolerance for failure and humiliation.

1:58:53.260 --> 1:58:55.260
 And somehow that's easier to develop when you're young?

1:58:55.260 --> 1:58:57.260
 Or be possessed through it when you're young?

1:58:57.260 --> 1:59:00.260
 Everything is easier to develop when you're young.

1:59:00.260 --> 1:59:02.260
 Yes.

1:59:02.260 --> 1:59:04.260
 The younger, the better.

1:59:04.260 --> 1:59:05.260
 It could destroy you.

1:59:05.260 --> 1:59:07.260
 I mean, that's the shitty thing about creativity.

1:59:07.260 --> 1:59:11.260
 If, you know, failure could destroy you if you're not careful,

1:59:11.260 --> 1:59:13.260
 but that's the risk worth taking.

1:59:13.260 --> 1:59:17.260
 But also, at a young age, developing a tolerance to failure is good.

1:59:17.260 --> 1:59:19.260
 I fail all the time.

1:59:19.260 --> 1:59:21.260
 Like I do stupid shit all the time.

1:59:21.260 --> 1:59:24.260
 Like in public, in private, I get canceled before.

1:59:24.260 --> 1:59:26.260
 I have make all kinds of mistakes,

1:59:26.260 --> 1:59:30.260
 but I just like am very resilient about making mistakes.

1:59:30.260 --> 1:59:34.260
 And so then like I do a lot of things that like other people wouldn't do.

1:59:34.260 --> 1:59:37.260
 And like I think my greatest asset is my creativity.

1:59:37.260 --> 1:59:43.260
 And I like, I think paint like tolerance to failure is just a super essential thing

1:59:43.260 --> 1:59:45.260
 that should be taught before other things.

1:59:45.260 --> 1:59:46.260
 Brilliant advice.

1:59:46.260 --> 1:59:47.260
 Yeah, yeah.

1:59:47.260 --> 1:59:52.260
 I wish everybody encouraged sort of failure more as opposed to kind of.

1:59:52.260 --> 1:59:54.260
 Cause we like punish failure.

1:59:54.260 --> 1:59:56.260
 Like when we were teaching kids, we're like, no, that's wrong.

1:59:56.260 --> 2:00:04.260
 Like that's, you know, like X keeps like, we'll be like wrong.

2:00:04.260 --> 2:00:05.260
 Like he'll say like crazy things.

2:00:05.260 --> 2:00:09.260
 Like X keeps being like, like bubble car, bubble car.

2:00:09.260 --> 2:00:14.260
 And I'm like, and you know, I'm like, what's a bubble car?

2:00:14.260 --> 2:00:17.260
 Like, but like it doesn't, like, but I don't want to be like, no, you're wrong.

2:00:17.260 --> 2:00:20.260
 I'm like, you're thinking of weird crazy shit.

2:00:20.260 --> 2:00:22.260
 Like I don't know what a bubble car is, but like.

2:00:22.260 --> 2:00:25.260
 He's creating worlds and they might be internally consistent.

2:00:25.260 --> 2:00:28.260
 And through that, he might discover something fundamental about this.

2:00:28.260 --> 2:00:29.260
 Yeah.

2:00:29.260 --> 2:00:32.260
 Or he'll like rewrite songs like with words that he prefers.

2:00:32.260 --> 2:00:35.260
 So like instead of baby shark, he says baby car.

2:00:35.260 --> 2:00:39.260
 It's like.

2:00:39.260 --> 2:00:41.260
 Maybe he's onto something.

2:00:41.260 --> 2:00:43.260
 Let me ask the big ridiculous question.

2:00:43.260 --> 2:00:49.260
 We were kind of dancing around it, but what do you think is the meaning of this whole thing we have here?

2:00:49.260 --> 2:00:54.260
 Of human civilization, of life on earth, but in general, just life.

2:00:54.260 --> 2:00:57.260
 What's the meaning of life?

2:00:57.260 --> 2:00:58.260
 See.

2:00:58.260 --> 2:01:03.260
 Have you, did you read Nova scene yet by James Lovelock?

2:01:03.260 --> 2:01:06.260
 You're doing a lot of really good book recommendations here.

2:01:06.260 --> 2:01:07.260
 I haven't even finished this.

2:01:07.260 --> 2:01:09.260
 So I'm a huge fraud yet again.

2:01:09.260 --> 2:01:14.260
 But like really early in the book, he says this amazing thing.

2:01:14.260 --> 2:01:16.260
 Like I feel like everyone's so sad and cynical.

2:01:16.260 --> 2:01:21.260
 Like everyone's like the Fermi paradox and everyone, I just keep hearing people being like, fuck, what if we're alone?

2:01:21.260 --> 2:01:22.260
 Like, oh no.

2:01:22.260 --> 2:01:26.260
 Like, and I'm like, okay, but like, wait, what if this is the beginning?

2:01:26.260 --> 2:01:31.260
 Like in Nova scene, he says, I'm, this is not going to be a correct.

2:01:31.260 --> 2:01:38.260
 I can't like memorize quotes, but he says something like, what if our consciousness.

2:01:38.260 --> 2:01:43.260
 Like right now, like this is the universe waking up.

2:01:43.260 --> 2:01:45.260
 Like what if instead of discovering the universe.

2:01:45.260 --> 2:01:47.260
 Like this is the universe.

2:01:47.260 --> 2:01:51.260
 Like this is the evolution of the little literal universe herself.

2:01:51.260 --> 2:01:53.260
 Like we are not separate from the universe.

2:01:53.260 --> 2:01:54.260
 Like this is the universe waking up.

2:01:54.260 --> 2:01:57.260
 This is the universe seeing herself for the first time.

2:01:57.260 --> 2:01:58.260
 Like this is

2:01:58.260 --> 2:02:00.260
 The universe becoming conscious.

2:02:00.260 --> 2:02:02.260
 The first time we were part of that.

2:02:02.260 --> 2:02:03.260
 Yeah.

2:02:03.260 --> 2:02:05.260
 Cause it's like we aren't separate from the universe.

2:02:05.260 --> 2:02:10.260
 Like this could be like an incredibly sacred moment and maybe like social media and all this things.

2:02:10.260 --> 2:02:13.260
 The stuff where we're all getting connected together.

2:02:13.260 --> 2:02:21.260
 Like maybe this, these are the neurons connecting of the like collective superintelligence that is, you know.

2:02:21.260 --> 2:02:22.260
 Waking up.

2:02:22.260 --> 2:02:23.260
 Yeah.

2:02:23.260 --> 2:02:39.260
 Like, you know, it's like maybe instead of something cynical or maybe if there's something to discover, like maybe this is just, you know, we're a blast assist of, of like some incredible kind of consciousness or being.

2:02:39.260 --> 2:02:45.260
 And just like in the first three years of life or for human children, we'll forget about all the suffering that we're going through now.

2:02:45.260 --> 2:02:46.260
 I think we'll probably forget about this.

2:02:46.260 --> 2:02:52.260
 I mean, probably, you know, artificial intelligence will eventually render us obsolete.

2:02:52.260 --> 2:02:57.260
 I don't think they'll do it in a malicious way, but I think probably we are very weak.

2:02:57.260 --> 2:02:58.260
 The sun is expanding.

2:02:58.260 --> 2:03:03.260
 Like, I don't know, like hopefully we can get to Mars, but like we're pretty vulnerable.

2:03:03.260 --> 2:03:11.260
 And I, you know, like, I think we can coexist for a long time with AI and we can also probably make ourselves less vulnerable.

2:03:11.260 --> 2:03:17.260
 But, you know, I just think consciousness, sentience, self awareness.

2:03:17.260 --> 2:03:24.260
 Like, I think this might be the single greatest like moment in evolution ever.

2:03:24.260 --> 2:03:38.260
 And like maybe this is, you know, the big, like the true beginning of life and we're just, we're the blue green algae or we're like, we're like the single celled organisms of something amazing.

2:03:38.260 --> 2:03:39.260
 The universe awakens.

2:03:39.260 --> 2:03:40.260
 And this is, this is it.

2:03:40.260 --> 2:03:42.260
 Yeah.

2:03:42.260 --> 2:03:45.260
 Well, see, you're an incredible person.

2:03:45.260 --> 2:03:47.260
 You're a fascinating mind.

2:03:47.260 --> 2:03:52.260
 You should definitely do your friend live mentioned that you guys were thinking of maybe talking.

2:03:52.260 --> 2:03:59.260
 I would love it if you explored your mind in this kind of media more and more by doing a podcast with her or just in any kind of way.

2:03:59.260 --> 2:04:01.260
 So you're, you're an awesome person.

2:04:01.260 --> 2:04:03.260
 And it's an honor to know you.

2:04:03.260 --> 2:04:08.260
 It's an honor to get to sit down with you late at night, which is like surreal.

2:04:08.260 --> 2:04:09.260
 And I really enjoyed it.

2:04:09.260 --> 2:04:10.260
 Thank you for talking to me.

2:04:10.260 --> 2:04:11.260
 Yeah, no, I mean, huge honor.

2:04:11.260 --> 2:04:13.260
 I feel very underqualified to be here, but I'm a big fan.

2:04:13.260 --> 2:04:15.260
 I've been listening to podcasts a lot.

2:04:15.260 --> 2:04:18.260
 And yeah, me and live would appreciate any advice and help.

2:04:18.260 --> 2:04:19.260
 And we're definitely going to do that.

2:04:19.260 --> 2:04:22.260
 So anytime.

2:04:22.260 --> 2:04:23.260
 Thank you.

2:04:23.260 --> 2:04:24.260
 Cool.

2:04:24.260 --> 2:04:25.260
 Thank you.

2:04:25.260 --> 2:04:28.260
 Thanks for listening to this conversation with Grimes to support this podcast.

2:04:28.260 --> 2:04:31.260
 Please check out our sponsors in the description.

2:04:31.260 --> 2:04:34.260
 And now let me leave you with some words from Oscar Wilde.

2:04:34.260 --> 2:04:41.260
 Yes, I'm a dreamer for dreamers one who can only find her way by moonlight.

2:04:41.260 --> 2:04:46.260
 And her punishment is that she sees the dawn before the rest of the world.

2:04:46.260 --> 2:04:49.260
 Thank you for listening and hope to see you next time.

