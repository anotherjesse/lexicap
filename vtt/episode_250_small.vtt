WEBVTT

00:00.000 --> 00:03.920
 The following is a conversation with Peter Wang, one of the most impactful leaders and

00:03.920 --> 00:09.920
 developers in the Python community, former physicist, current philosopher, and someone

00:09.920 --> 00:16.400
 who many people told me about and praised as a truly special mind that I absolutely should talk to.

00:16.400 --> 00:24.000
 Recommendations ranging from Travis Hallifant to Eric Weinstein. So, here we are. This is

00:24.000 --> 00:28.720
 the Lex Freeman podcast. To support it, please check out our sponsors in the description.

00:28.720 --> 00:32.160
 And now, here's my conversation with Peter Wang.

00:33.280 --> 00:39.360
 You're one of the most impactful humans in the Python ecosystem. So, you're an engineer,

00:39.360 --> 00:45.280
 leader of engineers, but you're also a philosopher. So, let's talk both in this conversation about

00:45.280 --> 00:52.240
 programming and philosophy. First, programming. What to you is the best or maybe the most beautiful

00:52.240 --> 00:58.960
 feature of Python? Or maybe the thing they made you fall in love or stay in love with Python?

00:58.960 --> 01:02.400
 Well, those are three different things. What I think is most beautiful, what made me fall in

01:02.400 --> 01:08.320
 love, what made me stay in love. When I first started using it was when I was a C++ computer

01:08.320 --> 01:13.520
 graphics performance nerd. In the 90s? Yeah, in late 90s. And that was my first job out of college.

01:15.040 --> 01:20.720
 And we kept trying to do more and more abstract and higher order programming in C++, which at

01:20.720 --> 01:26.480
 the time was quite difficult with templates. The compiler support wasn't great, et cetera.

01:26.480 --> 01:30.720
 So, when I started playing around with Python, that was my first time encountering really

01:30.720 --> 01:36.000
 first class support for types, for functions, and things like that. And it felt so incredibly

01:36.000 --> 01:40.080
 expressive. So, that was what kind of made me fall in love with it a little bit. And also,

01:40.720 --> 01:45.680
 once you spend a lot of time in a C++ dev environment, the ability to just whip something

01:45.680 --> 01:50.880
 together that basically runs and works the first time is amazing. So, really productive scripting

01:50.880 --> 01:57.520
 language. I knew Perl, I knew Bash, I was decent at both. But Python just made everything, it made

01:57.520 --> 02:01.760
 the whole world accessible. I could script this and that and the other network things,

02:02.800 --> 02:06.400
 little hard drive utilities, I could write all of these things in the space of an afternoon.

02:06.400 --> 02:08.480
 And that was really, really cool. So, that's what made me fall in love.

02:08.480 --> 02:13.120
 Is there something specific you could put your finger on that you're not programming in Perl

02:13.120 --> 02:20.560
 today? Like why Python for scripting? Oh, I think there's not a specific thing as much as the design

02:20.560 --> 02:25.920
 motif of both the creator of the language and the core group of people that built the standard

02:25.920 --> 02:33.520
 library around him. There was definitely, there was a taste to it. I mean, Steve Jobs used that

02:33.520 --> 02:38.560
 term in somewhat of an arrogant way, but I think it's a real thing that it was designed to fit.

02:39.120 --> 02:42.240
 A friend of mine actually expressed this really well. He said, Python just fits in my head.

02:42.240 --> 02:47.840
 And there's nothing better to say than that. Now, people might argue modern Python,

02:47.840 --> 02:52.640
 there's a lot more complexity, but certainly as version 152, I think was my first version,

02:53.200 --> 02:56.000
 that fit in my head very easily. So, that's what made me fall in love with it.

02:56.000 --> 03:04.160
 Okay. So, the most beautiful feature of Python that made you stay in love. It's like over the years,

03:04.800 --> 03:10.400
 what has like, you know, you do a double take and you return too often as a thing that just

03:10.400 --> 03:17.360
 brings you a smile. I really still like the ability to play with metaclasses and express

03:17.360 --> 03:23.280
 higher order things when I have to create some new object model to model something, right?

03:23.280 --> 03:28.720
 It's easy for me because I'm pretty expert as a Python programmer. I can easily put all sorts of

03:28.720 --> 03:32.800
 lovely things together and use properties and decorators and other kinds of things

03:32.800 --> 03:37.840
 and create something that feels very nice. So, that to me, I would say that's tied with the

03:37.840 --> 03:43.680
 numpy and vectorization capabilities. I love thinking in terms of the matrices and the vectors

03:43.680 --> 03:49.280
 and these kind of data structures. So, I would say those two are kind of tied for me.

03:49.280 --> 03:54.640
 So, the elegance of the numpy data structure, like slicing through the different multidimensional...

03:54.640 --> 03:59.120
 Yeah, there's just enough things there. It's like a very simple, comfortable tool.

04:00.480 --> 04:04.160
 It's easy to reason about what it does when you don't stray too far afield.

04:04.160 --> 04:11.200
 Can you put your finger on how to design a language such that it fits in your head?

04:11.840 --> 04:18.560
 Certain things like the colon or the certain notation aspects of Python that just kind of work.

04:18.560 --> 04:23.600
 Is it something you have to kind of write out on paper look and say,

04:23.600 --> 04:28.160
 it's just right? Is it a taste thing or is there a systematic process? What's your sense?

04:28.160 --> 04:33.840
 I think it's more of a taste thing. But one thing that should be said is that

04:34.640 --> 04:40.320
 you have to pick your audience. So, the better defined the user audience is or the users are,

04:40.320 --> 04:44.560
 the easier it is to build something that fits in their minds because their needs

04:45.120 --> 04:49.440
 will be more compact and coherent. It is possible to find a projection, a compact

04:49.440 --> 04:55.360
 projection for their needs. The more diverse the user base, the harder that is. And so,

04:55.360 --> 05:00.000
 as Python has grown in popularity, that's also naturally created more complexity

05:00.000 --> 05:03.520
 as people try to design any given thing. There will be multiple valid

05:03.520 --> 05:07.920
 opinions about a particular design approach. And so, I do think that's the

05:09.120 --> 05:12.960
 downside of popularity. It's almost an intrinsic aspect of the complexity of the problem.

05:12.960 --> 05:18.480
 Well, at the very beginning, aren't you an audience of one? Aren't all the greatest

05:18.480 --> 05:21.840
 projects in history were just solving a problem that you yourself had?

05:21.840 --> 05:27.440
 Well, so Clay Scherke in his book on crowdsourcing or in his kind of thoughts on crowdsourcing,

05:27.440 --> 05:31.360
 he identifies the first step of crowdsourcing is me first collaboration.

05:31.360 --> 05:35.600
 You first have to make something that works well for yourself. It's very telling that when you

05:35.600 --> 05:40.480
 look at all of the impactful big projects, well, their fundamental projects now in the

05:40.480 --> 05:47.280
 SciPy and PyData ecosystem, they all started with the people in the domain trying to scratch

05:47.280 --> 05:50.560
 their own itch. And the whole idea of scratching your own itch is something that

05:50.560 --> 05:53.120
 the open source or the free software world has known for a long time.

05:53.680 --> 05:58.400
 But in the scientific computing areas, these are assistant professors or

05:58.400 --> 06:02.960
 electrical engineering grad students. They didn't have really a lot of programming skill

06:02.960 --> 06:07.920
 necessarily, but Python was just good enough for them to put something together that fit in their

06:07.920 --> 06:14.880
 domain. So, it's almost like a necessity is a mother intervention aspect. And also, it was a

06:14.880 --> 06:22.240
 really harsh filter for utility and compactness and expressiveness. It was too hard to use,

06:22.240 --> 06:25.680
 then they wouldn't have built it because there was just too much trouble. It was a side project

06:25.680 --> 06:29.360
 for them. And also, necessity creates a kind of deadline. It seems like a lot of these projects

06:29.360 --> 06:34.160
 are quickly thrown together in the first step. And that even though it's flawed,

06:35.440 --> 06:38.800
 that just seems to work well for software projects.

06:38.800 --> 06:42.560
 Well, it does work well for software projects in general. And in this particular space,

06:42.560 --> 06:47.680
 but one of my colleagues, Stan Siebert, identified this, that all the projects in the

06:47.680 --> 06:53.360
 SciPy ecosystem, you know, if we just rattle them off, there's NumPy, there's SciPy, built by

06:53.360 --> 06:58.000
 different collaborations of people, although Travis is the heart of both of them. But NumPy

06:58.000 --> 07:01.760
 coming from numeric and numeric, these are different people. And then you've got Pandas,

07:01.760 --> 07:08.240
 you've got Jupyter or iPython, there's Matplotlib, there's just so many others I'm,

07:08.240 --> 07:11.520
 you know, not going to do justice if I try to name them all. But all of them are actually

07:11.520 --> 07:17.520
 different people. And as they rolled out their projects, the fact that they had limited resources

07:17.520 --> 07:24.240
 meant that they were humble about scope. A great famous hacker, Jamie Zewiski, once said that every

07:25.120 --> 07:31.120
 geek's dream is to build the ultimate middleware, right? And the thing is with these

07:31.120 --> 07:34.640
 scientist turn programmers, they had no such thing. They were just trying to write something

07:34.640 --> 07:38.080
 that was a little bit better for what they needed, the MATLAB. And they were going to

07:38.080 --> 07:42.160
 leverage what everyone else had built. So naturally, almost in kind of this annealing

07:42.160 --> 07:49.040
 process or whatever, we built a very modular cover of the basic needs of a scientific computing

07:49.040 --> 07:54.560
 library. If you look at the whole human story, how much of a leap is it? We've developed all

07:54.560 --> 07:59.040
 kinds of languages, all kinds of methodologies for communication, and just kind of like grew

07:59.040 --> 08:04.240
 this collective intelligence, the civilization grew, it expanded, we wrote a bunch of books,

08:04.240 --> 08:11.040
 and now we tweet. How big of a leap is programming if programming is yet another language? Is it

08:11.040 --> 08:18.400
 just a nice little trick that's temporary in our human history? Or is it like a big leap in the,

08:19.520 --> 08:26.080
 almost us becoming another organism at a higher level of abstraction, something else?

08:26.080 --> 08:34.240
 I think the act of programming or using grammatical constructions of some underlying primitives,

08:34.880 --> 08:39.440
 that is something that humans do learn, but every human learns this. Anyone who can speak

08:39.440 --> 08:43.760
 learns how to do this. What makes programming different has been that up to this point,

08:44.880 --> 08:50.800
 when we try to give instructions to computing systems, all of our computers, well, actually,

08:50.800 --> 08:54.800
 this is not quite true, but I'll first say it and then I'll tell you why it's not true.

08:54.800 --> 08:58.320
 But for the most part, we can think of computers as being these iterated systems.

08:58.880 --> 09:04.800
 So when we program, we're giving very precise instructions to iterated systems that then run at

09:05.600 --> 09:12.000
 incomprehensible speed and run those instructions. In my experience, some people are just better

09:12.000 --> 09:21.600
 equipped to model systematic iterated systems in their head. Some people are really good at that

09:21.600 --> 09:28.560
 and other people are not. For instance, sometimes people have tried to build systems that make

09:28.560 --> 09:32.880
 programming easier by making it visual drag and drop. And the issue is you can have a drag and

09:32.880 --> 09:36.640
 drop thing, but once you start having to iterate the system with conditional logic, handling case

09:36.640 --> 09:41.040
 statements and branch statements and all these other things, the visual drag and drop part doesn't

09:41.040 --> 09:45.200
 save you anything. You still have to reason about this giant iterated system with all these different

09:45.200 --> 09:52.160
 conditions around it. That's the hard part. So handling iterated logic, that's the hard part.

09:52.160 --> 09:56.560
 The languages we use then emerge to give us ability and capability over these things.

09:57.120 --> 10:00.320
 Now, the one exception to this rule, of course, is the most popular programming system in the

10:00.320 --> 10:06.160
 world, which is Excel, which is a data flow and a data driven, immediate mode, data transformation

10:06.160 --> 10:11.280
 oriented programming system. And this is actually not an accident that that system is the most

10:11.280 --> 10:16.240
 popular programming system because it's so accessible to a much broader group of people.

10:16.800 --> 10:22.800
 I do think as we build future computing systems, you're actually already seeing this a little bit,

10:22.800 --> 10:26.480
 it's much more about composition of modular blocks. They themselves

10:27.600 --> 10:32.000
 actually maintain all their internal state and the interfaces between them are well defined data

10:32.000 --> 10:37.680
 schemas. And so to stitch these things together using like IFTTT or Zapier or any of these kind of,

10:37.680 --> 10:43.040
 you know, I would say compositional scripting kinds of things. I mean, hypercard was also a

10:43.040 --> 10:49.840
 little bit in this vein. That's much more accessible to most people. It's really that implicit state

10:49.840 --> 10:54.000
 that's so hard for people to track. Yeah, okay. So that's modular stuff. But there's also an

10:54.000 --> 10:58.320
 aspect where you're standing on the shoulders of giants. You're building like higher and higher

10:58.320 --> 11:04.080
 levels of abstraction. You do that a little bit with language. So with language, you develop

11:04.080 --> 11:09.520
 sort of ideas, philosophies from Plato and so on. And then you kind of leverage those philosophies as

11:09.520 --> 11:14.640
 you try to have deeper and deeper conversations. But with programming, it seems like you can build

11:15.200 --> 11:19.920
 much more complicated systems. Like without knowing how everything works, you can build on top of the

11:19.920 --> 11:23.920
 work of others. And it seems like you're developing more and more sophisticated

11:23.920 --> 11:34.160
 expressions, ability to express ideas in a computational space. I think it's worth pondering

11:34.160 --> 11:42.640
 the difference here between complexity and complication. Back to Excel. Well, not quite

11:42.640 --> 11:48.240
 back to Excel, but the idea is, you know, when we have a human conversation, all languages

11:48.240 --> 11:56.720
 is for humans emerged to support human relational communications, which is that the person we're

11:56.720 --> 12:04.480
 communicating with is a person, and they would communicate back to us. And so we sort of hit a

12:04.480 --> 12:08.720
 resonance point, right, when we actually agree on some concepts. So there's a messiness to it,

12:08.720 --> 12:12.960
 and there's a fluidity to it. With computing systems, when we express something to the computer,

12:12.960 --> 12:18.240
 and it's wrong, we just try again. So we can basically live many virtual worlds of having failed at

12:18.240 --> 12:22.720
 expressing ourselves to the computer until the one time we expressed ourselves right.

12:22.720 --> 12:25.360
 Then we kind of put in production and then discover that it's still wrong,

12:25.360 --> 12:31.040
 you know, a few days down the road. So I think the sophistication of things that we build with

12:31.040 --> 12:37.280
 computing, one has to really pay attention to the difference between when an end user is expressing

12:37.280 --> 12:43.600
 something onto a system that exists versus when they're extending the system to increase the

12:43.600 --> 12:48.560
 system's capability for someone else to that interface with. We happen to use the same language

12:48.560 --> 12:52.880
 for both of those things in most cases, but it doesn't have to be that. And Excel is actually

12:52.880 --> 12:59.360
 a great example of this, of kind of a counterpoint to that. Okay. So what about the idea of, you

12:59.360 --> 13:09.360
 said messiness, wouldn't you put the software 2.0 idea, this idea of machine learning into the

13:10.480 --> 13:16.000
 further and further steps into the world of messiness. The same kind of beautiful messiness

13:16.000 --> 13:23.440
 of human communication, isn't that what machine learning is, is building on levels of abstraction

13:23.440 --> 13:28.160
 that don't have messiness in them, that at the operating system level, then there's Python,

13:28.160 --> 13:34.480
 the programming languages that have more and more power. But then finally, there's neural networks

13:34.480 --> 13:40.400
 that ultimately work with data. And so the programming is almost in the space of data,

13:40.400 --> 13:45.840
 and the data is allowed to be messy. Isn't that a kind of program? So the idea of software 2.0

13:45.840 --> 13:53.920
 is a lot of the programming happens in the space of data, all roads lead back to Excel,

13:53.920 --> 13:58.480
 in the space of data, and also the hyperparameters of the neural networks. And all of those allow

14:00.000 --> 14:03.440
 the same kind of messiness that human communication allows.

14:04.240 --> 14:09.840
 It does, but my background is a physics. I took like two CS courses in college.

14:09.840 --> 14:15.360
 So I don't have, now I did cram a bunch of CS in prep when I applied for grad school,

14:15.360 --> 14:20.880
 but still, I don't have a formal background in computer science. But what I have observed in

14:20.880 --> 14:25.600
 studying programming languages and programming systems and things like that is that there seems

14:25.600 --> 14:31.440
 to be this triangle. It's one of these beautiful little iron triangles that you find in life sometimes.

14:32.000 --> 14:37.360
 And it's the connection between the code correctness and kind of expressiveness of code,

14:37.360 --> 14:43.120
 the semantics of the data, and then the kind of correctness or parameters of the underlying

14:43.120 --> 14:50.160
 hardware compute system. So there's the algorithms that you want to apply. There's what the bits,

14:50.160 --> 14:55.920
 that are stored on whatever media actually represents, the semantics of the data within

14:55.920 --> 15:00.640
 their representation. And then there's what the computer can actually do. And every programming

15:00.640 --> 15:06.560
 system, every information system ultimately finds some spot in the middle of this little triangle.

15:07.360 --> 15:10.800
 Sometimes some systems collapse them into just one edge.

15:10.800 --> 15:13.440
 Are we including humans as a system in this?

15:13.440 --> 15:15.280
 No, no, I'm just thinking about computing systems here.

15:15.280 --> 15:19.920
 Okay. And the reason I bring this up is because I believe there's no free lunch around this stuff.

15:19.920 --> 15:26.080
 So if we build machine learning systems to sort of write the correct code that is at a certain

15:26.080 --> 15:31.440
 level of performance, so it'll sort of select with the hyperparameters, we can tune kind of how

15:31.440 --> 15:37.440
 we want the performance boundary in SLA to look like for transforming some set of inputs into

15:37.440 --> 15:44.000
 certain kinds of outputs. That training process itself is intrinsically sensitive to the kinds

15:44.000 --> 15:48.240
 of inputs we put into it. It's quite sensitive to the boundary conditions we put around the

15:48.240 --> 15:53.360
 performance. So I think even as we move to using automated systems to build this transformation,

15:53.360 --> 15:58.000
 as opposed to humans explicitly from a top down perspective, figuring out, well, this schema and

15:58.000 --> 16:02.320
 this database and these columns get selected for this algorithm. And here we put a, you know,

16:02.320 --> 16:08.000
 a Fibonacci heap for some other thing, human design or computer design. Ultimately, what we hit,

16:08.000 --> 16:13.040
 the boundaries that we hit with these information systems is when the representation of the data

16:13.040 --> 16:17.840
 hits the real world is where there's a lot of slop and a lot of interpretation. And that's where

16:17.840 --> 16:22.320
 actually I think a lot of the work will go in the future is actually understanding kind of how to

16:22.320 --> 16:28.560
 better, in the view of these live data systems, how to better encode the semantics of the world

16:29.200 --> 16:33.280
 for those things. There'll be less of the details of how we write a particular SQL query.

16:33.280 --> 16:36.720
 Okay. But given the semantics of the real world and the messiness of that,

16:36.720 --> 16:39.680
 what does the word correctness mean when you're talking about code?

16:40.720 --> 16:44.640
 There's a lot of dimensions to correctness. Historically, and this is one of the reasons

16:44.640 --> 16:49.760
 I say that we're coming to the end of the era of software, because for the last 40 years or so,

16:49.760 --> 16:55.360
 software correctness was really defined about functional correctness. I write a function,

16:55.360 --> 16:59.120
 it's got some inputs, does it produce the right outputs? If so, then I can turn it on,

16:59.120 --> 17:03.680
 hook it up to the live database and it goes. And more and more now, we have, I mean, in fact,

17:03.680 --> 17:07.680
 I think the bright line in the sand between machine learning systems or modern data driven

17:07.680 --> 17:15.920
 systems versus classical software systems is that the values of the input actually have to

17:15.920 --> 17:19.360
 be considered with the function together to say this whole thing is correct or not.

17:19.360 --> 17:23.680
 And usually there's a performance SLA as well. Like, did it actually finish making this SLA?

17:23.680 --> 17:28.480
 Sorry, service level agreement. So it has to return within some time. You have a 10 millisecond

17:28.480 --> 17:34.400
 time budget to return a prediction of this level of accuracy. So these are things that were not

17:34.400 --> 17:38.320
 traditionally in most business computing systems for the last 20 years at all. People didn't think

17:38.320 --> 17:43.680
 about it. But now we have value dependence on functional correctness. So that question of

17:43.680 --> 17:47.360
 correctness is becoming a bigger and bigger question. What is that map to the end of software?

17:48.080 --> 17:53.760
 We've thought about software as just this thing that you can do in isolation with some test trial

17:53.760 --> 18:00.880
 inputs and in a very sort of sandboxed environment. And we can quantify how does it scale? How does

18:00.880 --> 18:05.840
 it perform? How many nodes do we need to allocate if we want to scale this many inputs? When we start

18:05.840 --> 18:11.440
 turning this stuff into prediction systems, real cybernetic systems, you're going to find scenarios

18:11.440 --> 18:14.640
 where you get inputs that you don't want to spend a little more time thinking about. You're going to

18:14.640 --> 18:18.720
 find inputs that are not, it's not clear what you should do, right? So then the software has a varying

18:18.720 --> 18:23.440
 amount of runtime and correctness with regard to input. And that is a different kind of system

18:23.440 --> 18:27.680
 altogether. Now it's a full on cybernetic system. It's a next generation information system that

18:27.680 --> 18:33.040
 is not like traditional software systems. Can you maybe describe what is a cybernetic system?

18:33.040 --> 18:38.800
 Do you include humans in that picture? So is a human in the loop kind of complex mess

18:38.800 --> 18:44.000
 of the whole kind of interactivity of software with the real world or is it something more

18:44.000 --> 18:48.480
 concrete? Well, when I say cybernetic, I really do mean that the software itself is closing the

18:48.480 --> 18:54.560
 Observe Orient Decide Act loop by itself. So humans being out of the loop is the fact what,

18:54.560 --> 19:00.560
 for me, makes it a cybernetic system. Humans are out of that loop.

19:00.560 --> 19:05.360
 When humans are out of the loop, when the machine is actually sort of deciding on its own what it

19:05.360 --> 19:10.560
 should do next to get more information, that makes it a cybernetic system. So we're just at the dawn

19:10.560 --> 19:16.160
 of this, right? I think everyone talking about MLAI, it's great. But really the thing we should

19:16.160 --> 19:21.760
 be talking about is when we really enter the cybernetic era and all of the questions of ethics

19:21.760 --> 19:27.040
 and governance and correctness and all these things, they really are the most important questions.

19:27.040 --> 19:30.640
 Okay. Can we just linger on this? What does it mean for the human to be out of the loop in a

19:30.640 --> 19:36.800
 cybernetic system? Because isn't the cybernetic system that's ultimately accomplishing some kind

19:36.800 --> 19:43.120
 of purpose that at the bottom, the turtles all the way down at the bottom turtle is a human?

19:44.000 --> 19:47.840
 Well, the human may have set some criteria, but the human wasn't precise. So for instance,

19:47.840 --> 19:52.400
 I just read the other day that earlier this year, or maybe it was last year at some point,

19:52.400 --> 19:57.600
 the Libyan army, I think, sent out some automated killer drones with explosives.

19:58.400 --> 20:02.080
 And there was no human in the loop at that point. They basically put them in a geofenced area,

20:02.080 --> 20:05.360
 said find any moving target like a truck or vehicle that looks like this and boom,

20:06.880 --> 20:12.320
 that's not a human in the loop, right? So increasingly the less human there is in the

20:12.320 --> 20:17.280
 loop, the more concerned you are about these kinds of systems because there's unintended

20:17.280 --> 20:22.640
 consequences like less the original designer and engineer of the system is able to predict.

20:23.600 --> 20:27.200
 Even one with good intent is able to predict the consequences of such a system.

20:27.760 --> 20:32.000
 That's right. There are some software systems that run without humans in the loop that are

20:32.000 --> 20:35.760
 quite complex. And that's like the electronic markets. And we get flash crashes all the time.

20:35.760 --> 20:41.680
 We get in the heyday of high frequency trading, there's a lot of market microstructure,

20:41.680 --> 20:47.120
 people doing all sorts of weird stuff that the market designers had never really thought about,

20:47.120 --> 20:51.760
 contemplated or intended. So when we run these full on systems with these automated trading bots,

20:53.040 --> 20:56.720
 now they become automated killer drones and then all sorts of other stuff,

20:58.320 --> 21:01.760
 that's what I mean by we're at the dawn of the cybernetic era and the end of the era of just

21:01.760 --> 21:08.720
 pure software. Are you more concerned if you're thinking about cybernetic systems or even like

21:08.720 --> 21:14.000
 self replicating systems? So systems that aren't just doing a particular task, but are able to

21:14.000 --> 21:20.240
 sort of multiply and scale in some dimension in the digital or even the physical world.

21:20.240 --> 21:27.040
 Are you more concerned about like the lobster being boiled? So a gradual with us not noticing

21:29.040 --> 21:38.000
 collapse of civilization or a big explosion? Like oops, kind of a big thing where everyone

21:38.000 --> 21:44.720
 notices, but it's too late. I think that it will be a different experience for different people.

21:46.240 --> 21:53.680
 I do share a common point of view with some of the people who are concerned about climate change

21:53.680 --> 22:02.080
 and just the big existential risks that we have. But unlike a lot of people who share my level

22:02.080 --> 22:08.080
 of concern, I think the collapse will not be quite so dramatic as some of them think. And what I

22:08.080 --> 22:13.520
 mean is that I think that for certain tiers of let's say economic class or certain locations

22:13.520 --> 22:18.560
 in the world, people will experience dramatic collapse scenarios. But for a lot of people,

22:18.560 --> 22:24.640
 especially in the developed world, the realities of collapse will be managed. There will be narrative

22:24.640 --> 22:30.080
 management around it so that they essentially insulate, the middle class will be used to

22:30.080 --> 22:35.760
 insulate the upper class from the pitchforks and the flaming torches and everything.

22:35.760 --> 22:40.560
 It's interesting because my specific question wasn't as general as my question is more about

22:40.560 --> 22:45.680
 cybernetic systems or software. Okay. It's interesting, but it would nevertheless perhaps

22:45.680 --> 22:50.160
 be about class. So the effect of algorithms might affect certain classes more than others.

22:50.160 --> 22:55.760
 Absolutely. I was more thinking about whether it's social media algorithms or actual robots.

22:55.760 --> 23:03.920
 Is there going to be a gradual effect on us where we wake up one day and don't recognize the humans

23:03.920 --> 23:11.840
 we are? Or is it something truly dramatic where there's a Meltdown of a nuclear reactor kind of

23:11.840 --> 23:20.400
 thing, Chernobyl, catastrophic events that are almost bugs in a program that scaled itself too

23:20.400 --> 23:27.920
 quickly? Yeah, I'm not as concerned about the visible stuff. And the reason is because the big

23:27.920 --> 23:32.240
 visible explosions, I mean, this is something I said about social media is that, at least with

23:32.240 --> 23:36.720
 nuclear weapons, when a nuke goes off, you can see it and you're like, well, that's really, wow,

23:36.720 --> 23:41.040
 that's kind of bad. I mean, Oppenheimer was reciting the Bhagavad Gita when he saw one of

23:41.040 --> 23:46.640
 those things go off. So we can see nukes are really bad. He's not reciting anything about

23:46.640 --> 23:53.360
 Twitter. Well, right. But then when you have social media, when you have all these different things

23:53.360 --> 23:58.560
 that conspire to create a layer of virtual experience for people that alienates them from

23:59.360 --> 24:05.120
 reality and from each other, that's very pernicious. It's impossible to see, right? And it slowly

24:05.120 --> 24:11.840
 gets in there. You've written about this idea of virtuality on this topic, which you define as

24:11.840 --> 24:17.840
 the subjective phenomenon of knowingly engaging with virtual sensation and perception and

24:17.840 --> 24:26.720
 suspending or forgetting the context that it's some alakam. So let me ask, what is real? Is there

24:26.720 --> 24:32.560
 a hard line between reality and virtuality? Like perception drifts from some kind of physical

24:32.560 --> 24:37.680
 reality. We have to kind of have a sense of what is the line that's too, we've gone too far.

24:37.680 --> 24:45.360
 Right, right. For me, it's not about any hard line about physical reality as much as a simple

24:45.360 --> 24:52.960
 question of, does the particular technology help people connect in a more integral way

24:52.960 --> 24:58.400
 with other people, with their environment, with all of the full spectrum of things around them?

24:58.400 --> 25:02.880
 So it's less about, oh, this is a virtual thing and this is a hard real thing,

25:02.880 --> 25:08.800
 more about when we create virtual representations of the real things. Always,

25:08.800 --> 25:13.760
 some things are lost in translation. Usually, many, many dimensions are lost in translation,

25:13.760 --> 25:18.080
 right? We're now coming to almost two years of COVID, people on Zoom all the time. You know,

25:18.080 --> 25:21.280
 it's different when you meet somebody in person than when you see them on, I've seen you on YouTube

25:21.280 --> 25:28.320
 lots, right? But the senior person is very different. And so I think when we engage in virtual

25:28.320 --> 25:34.160
 experiences all the time, and we only do that, there is absolutely a level of embodiment,

25:34.160 --> 25:39.120
 there's a level of embodied experience and participatory interaction that is lost.

25:40.160 --> 25:43.280
 And it's very hard to put your finger on exactly what it is. It's hard to say, oh,

25:43.280 --> 25:49.360
 we're going to spend $100 million building a new system that captures this 5% better

25:49.360 --> 25:52.560
 higher fidelity human expression. No one's going to pay for that, right?

25:52.560 --> 25:58.560
 So when we rush madly into a world of simulacrum and virtuality,

26:00.160 --> 26:05.520
 you know, the things that are lost are, it's difficult. Once everyone moves there, it can

26:05.520 --> 26:11.360
 be hard to look back and see what we've lost. So is it irrecoverably lost? Or rather,

26:11.360 --> 26:16.960
 when you put it all on the table, is it possible for more to be gained than is lost?

26:16.960 --> 26:23.600
 If you look at video games, they create virtual experiences that are surreal and can bring joy

26:23.600 --> 26:28.640
 to a lot of people, connect a lot of people and can get people to talk a lot of trash.

26:29.760 --> 26:34.800
 So they can bring out the best and the worst in people. So is it possible to have a future world

26:35.600 --> 26:41.520
 where the pros outweigh the cons? It is. I mean, it's possible to have that in the current world.

26:41.520 --> 26:49.040
 But when literally trillions of dollars of capital are tied to using those things to

26:49.920 --> 26:55.920
 groom the worst of our inclinations and to attack our weaknesses in the limbic system

26:55.920 --> 26:58.560
 to create these things into id machines versus connection machines,

26:59.120 --> 27:03.040
 then those good things don't stand a chance.

27:03.040 --> 27:07.520
 Can you make a lot of money by building connection machines? Is it possible,

27:07.520 --> 27:12.960
 do you think, to bring out the best in human nature to create fulfilling connections and

27:12.960 --> 27:16.800
 relationships in the digital world and make a shit ton of money?

27:18.560 --> 27:20.000
 If I figured out, I'll let you know.

27:20.880 --> 27:24.560
 But what's your intuition without concretely knowing what's the solution?

27:24.560 --> 27:29.680
 My intuition is that a lot of our digital technologies give us the ability to have

27:29.680 --> 27:36.080
 synthetic connections or to experience virtuality. They have co evolved with

27:36.080 --> 27:41.920
 sort of the human expectations. It's sort of like sugary drinks. As people have more sugary

27:41.920 --> 27:46.960
 drinks, they need more sugary drinks to get that same hit. So with these virtual things

27:47.760 --> 27:52.720
 and with TV and fast cuts and TikToks and all these different kinds of things,

27:52.720 --> 27:57.200
 we're co creating essentially humanity that sort of asks and needs those things.

27:57.200 --> 28:01.600
 And now it becomes very difficult to get people to slow down. It gets difficult for people to

28:01.600 --> 28:07.120
 hold their attention on slow things and actually feel that embodied experience.

28:07.120 --> 28:12.960
 So mindfulness now more than ever is so important in schools and as a therapy technique

28:12.960 --> 28:16.960
 for people because our environment has been accelerated. And McLuhan actually talks about

28:16.960 --> 28:21.280
 this in the electric environment of the television. And that was before TikTok and before front

28:21.280 --> 28:27.040
 facing cameras. So I think for me, the concern is that it's not like we can ever switch to

28:27.040 --> 28:32.880
 doing something better, but more of the humans and technology, they're not independent of each

28:32.880 --> 28:38.960
 other. The technology that we use kind of molds what we need for the next generation of technology.

28:38.960 --> 28:44.400
 Yeah, but humans are intelligent and they're introspective and they can reflect on the

28:44.400 --> 28:49.120
 experiences of their life. So for example, there's been many years in my life where I ate an

28:49.120 --> 28:53.280
 excessive amount of sugar. And then a certain moment I woke up and said,

28:53.280 --> 28:59.360
 why do I keep doing this? This doesn't feel good. Like long term. And I think

29:00.240 --> 29:05.520
 so going through the TikTok process of realizing, okay, when I short my attention span,

29:06.240 --> 29:12.560
 actually that does not make me feel good longer term and realizing that and then going to platforms,

29:13.120 --> 29:21.120
 going to places that are away from the sugar. And so doing you can create platforms that can

29:21.120 --> 29:26.160
 make a lot of money when so to help people wake up to what actually makes them feel good long term

29:26.160 --> 29:31.200
 develop, grow as human beings. And it just feels like humans are more intelligent than

29:32.560 --> 29:38.240
 mice looking for cheese. They're able to sort of think, I mean, we can think we can contemplate

29:38.240 --> 29:46.000
 our mortality and contemplate things like long term love and we can have a long term fear of

29:46.000 --> 29:52.560
 certain things like mortality. We can contemplate whether the experience is the sort of the drugs

29:52.560 --> 29:58.880
 of daily life that we've been partaking in is making us happier, better people. And then

29:58.880 --> 30:04.720
 once we contemplate that we can make financial decisions in using services and paying for services

30:04.720 --> 30:11.920
 that are making us better people. So it just seems that we're in the very first stages of

30:11.920 --> 30:18.480
 social networks that just we're able to make a lot of money really quickly. But in bringing out

30:18.480 --> 30:24.880
 sometimes the bad parts of human nature, they didn't destroy humans. They just fed everybody

30:24.880 --> 30:29.920
 a lot of sugar. And now everyone's going to wake up and say, hey, we're going to start having

30:29.920 --> 30:35.680
 like sugar free social media. Right. Well, there's a lot to unpack there. I think some people

30:35.680 --> 30:39.520
 certainly have the capacity for that. And I certainly think, I mean, it's very interesting

30:39.520 --> 30:43.200
 even the way you said it. You woke up one day and you thought, well, this doesn't feel very good.

30:44.000 --> 30:46.480
 Well, that's still your limbic system saying this doesn't feel very good.

30:47.120 --> 30:51.920
 Right. You have a cat brain's worth of neurons around your gut. Right. And so maybe that

30:51.920 --> 30:57.760
 saturated and that was telling you, hey, this isn't good. Humans are more than just mice looking

30:57.760 --> 31:02.960
 for cheese or monkeys looking for sex and power. Right. So let's slow down. Now you're,

31:03.520 --> 31:07.280
 now a lot of people would argue with you on that one. But we're more than just that,

31:07.280 --> 31:14.800
 but we're at least that. And we're very, very seldom not that. So my, I don't actually disagree with

31:14.800 --> 31:18.560
 you that we could be better and that we can, that better platforms exist. And people are

31:18.560 --> 31:22.640
 voluntarily noping out of things like Facebook and noping out. That's an awesome verb.

31:22.640 --> 31:26.240
 It's a great term. Yeah, I love it. I use it all the time. You're welcome. I'm going to have to

31:26.240 --> 31:30.880
 nope out of that. I want to nope out of that. Right. It's going to be a hard pass. And that's,

31:30.880 --> 31:35.840
 and that's, that's great. But that's again, to your point, that's the first generation

31:35.840 --> 31:42.560
 of front facing cameras of social pressures and you as a, you know, self starter, self aware

31:42.560 --> 31:47.440
 adult have the capacity to say, yeah, I'm not going to do that. I'm going to go and spend time

31:47.440 --> 31:51.280
 on long form reads. I'm going to spend time managing my attention. I'm going to do some yoga.

31:52.000 --> 31:57.680
 If you're a 15 year old in high school and your entire social environment is everyone doing

31:57.680 --> 32:00.720
 these things, guess what you're going to do? You're going to kind of have to do that because

32:00.720 --> 32:04.640
 your limbic system says, hey, I need to get the guy or the girl or the whatever. And that's

32:04.640 --> 32:08.640
 what I'm going to do. And so one of the things that we have to reason about here is the social

32:08.640 --> 32:15.200
 media systems or, you know, social media, I think is a first, our first encounter with

32:16.000 --> 32:23.520
 a technological system that runs a bit of a loop around our own cognition and attention.

32:24.080 --> 32:30.000
 It's not the last. It's far from the last. And it gets to the heart of some of the

32:30.000 --> 32:34.960
 philosophical Achilles heel of the Western philosophical system, which is each person

32:34.960 --> 32:39.600
 gets to make their own determination. Each person is an individual that's sacrosanct

32:39.600 --> 32:44.160
 and their agency and their sovereignty and all these things. The problem with these systems is

32:44.160 --> 32:48.960
 they come down and they are able to manage everyone en masse. And so every person is making

32:48.960 --> 32:54.560
 their own decision, but together the bigger system is causing them to act with a group

32:54.560 --> 33:01.920
 dynamic that's very profitable for people. So this is the issue that we have is that our philosophies

33:01.920 --> 33:09.280
 are actually not geared to understand what is it for a person to have a high trust connection

33:10.160 --> 33:15.120
 as part of a collective and for that collective to have its right to coherency and agency.

33:16.160 --> 33:20.800
 That's something like when a social media app causes a family to break apart,

33:20.800 --> 33:26.880
 it's done harm to more than just individuals. So that concept is not something we really talk

33:26.880 --> 33:31.200
 about or think about very much, but that's actually the problem is that we're vaporizing

33:31.200 --> 33:35.440
 molecules into atomic units and then we're hitting all the atoms with certain things that's like,

33:35.440 --> 33:41.200
 yeah, well, that person chose to look at my app. So our understanding of human nature is at the

33:41.200 --> 33:46.320
 individual level. It emphasizes the individual too much because ultimately society operates at

33:46.320 --> 33:51.360
 the collective level. And these apps do as well. And the apps do as well. So for us to understand

33:51.360 --> 33:55.760
 the progression and development of this organism, we call human civilization,

33:55.760 --> 34:00.880
 we have to think of the collective level too. I would say multi tiered. Multi tiered. So individual

34:00.880 --> 34:07.760
 as well. Just individuals, family units, social collectives, and on the way up. Okay. So you've

34:07.760 --> 34:12.640
 said that individual humans are multi layered susceptible to signals and waves and multiple

34:12.640 --> 34:18.640
 strata, the physical, the biological, social, cultural, intellectual. So sort of going along

34:18.640 --> 34:26.720
 these lines, can you describe the layers of the cake that is a human being and maybe the human

34:26.720 --> 34:33.200
 collective human society? So I'm just stealing wholesale here from Robert Persig, who is the

34:33.200 --> 34:40.160
 author of Zen and the Auto Motorcycle Maintenance. And his follow on book has a sequel to it called

34:40.160 --> 34:46.800
 Lila. He goes into this in a little more detail. But it's a crude approach to thinking about people,

34:46.800 --> 34:51.120
 but I think it's still an advancement over traditional subject object metaphysics,

34:51.120 --> 34:57.040
 where we look at people as a dualist would say, well, is your mind, your consciousness,

34:57.040 --> 35:03.040
 is that just merely the matter that's in your brain? Or is there something kind of more beyond

35:03.040 --> 35:07.840
 that? And they would say, yes, there's a soul, sort of ineffable soul beyond just merely the

35:07.840 --> 35:13.680
 physical body. And I'm not one of those people. I think that we don't have to draw a line between

35:14.400 --> 35:19.600
 are things only this or only that, collectives of things can emerge structures and patterns

35:19.600 --> 35:24.800
 that are just as real as the underlying pieces. But they're transcendent, but they're still of

35:24.800 --> 35:30.480
 the underlying pieces. So your body is this way. I mean, we just know physically, you consist of

35:30.480 --> 35:36.240
 atoms and whatnot. And then the atoms are arranged into molecules, which then arrange into certain

35:36.240 --> 35:41.200
 kinds of structures that seem to have a homeostasis to them, we'll call them cells. And those cells

35:41.200 --> 35:48.000
 form biological structures. Those biological structures give your body its physical ability

35:48.000 --> 35:53.440
 and biological ability to consume energy and to maintain homeostasis. But humans are social

35:53.440 --> 35:59.440
 animals. I mean, human by themselves is not very long for the world. So we also part of our biology

35:59.440 --> 36:04.960
 is why are two connect to other people from the mirror neurons to our language centers and all

36:04.960 --> 36:10.640
 these other things. So we are intrinsically, there's a layer, there's a part of us that

36:10.640 --> 36:15.200
 wants to be part of a thing. If we're around other people, not saying a word, but they're just up

36:15.200 --> 36:19.920
 and down jumping and dancing, laughing, we're going to feel better, right? And there was no

36:19.920 --> 36:25.120
 exchange of physical anything. They didn't give us like five atoms of happiness, right? But there's

36:25.120 --> 36:30.640
 an induction in our own sense of self that is at that social level. And then beyond that,

36:30.640 --> 36:34.320
 person puts the intellectual level kind of one level higher than social. I think they're actually

36:34.320 --> 36:40.160
 more intertwined than that. But the intellectual level is the level of pure ideas that you are a

36:40.160 --> 36:45.760
 vessel for memes. You're a vessel for philosophies. You will conduct yourself in a particular way.

36:46.320 --> 36:50.400
 I mean, I think part of this is if we think about it from a physics perspective, you're not, you

36:50.400 --> 36:55.120
 know, there's the joke that physicists like to approximate things and we'll say, well, approximate

36:55.120 --> 36:58.800
 a spherical cow, right? You're not a spherical cow. You're not a spherical human. You're a messy

36:58.800 --> 37:04.640
 human. You're a messy human. And we can't even say what the dynamics of your emotion will be

37:04.640 --> 37:11.200
 unless we analyze all four of these layers, right? If you're a Muslim at a certain time of day,

37:11.200 --> 37:14.480
 guess what? You're going to be on the ground kneeling and praying, right? And that has nothing

37:14.480 --> 37:19.440
 to do with your biological need to get on the ground or physics of gravity. It is an intellectual

37:19.440 --> 37:24.000
 drive that you have. It's a cultural phenomenon and an intellectual belief that you carry. So

37:24.000 --> 37:30.160
 that's what the four layered stack is all about. It's that a person is not only one of these things.

37:30.160 --> 37:35.360
 They're all of these things at the same time. It's a superposition of dynamics that run through

37:35.360 --> 37:42.080
 us that make us who we are. So no layers special? Not so much no layers special. Each layer is

37:42.080 --> 37:49.440
 just different. But we are... Each layer gives the participation trophy. Each layer is a part

37:49.440 --> 37:54.640
 of what you are. You are a layer cake of all these things. And if we try to deny... So many

37:54.640 --> 37:59.520
 philosophies do try to deny the reality of some of these things. Some people will say,

37:59.520 --> 38:03.360
 well, we're only atoms. Well, we're not only atoms because there's a lot of other things that are

38:03.360 --> 38:08.320
 only atoms. I can reduce a human being to a bunch of soup and they're not the same thing,

38:08.320 --> 38:13.280
 even though it's the same atoms. So I think the order and the patterns that emerge within humans

38:14.240 --> 38:18.880
 to understand, to really think about what a next generation of philosophy would look like,

38:18.880 --> 38:23.600
 that would allow us to reason about extending humans into the digital realm or to interact

38:23.600 --> 38:28.960
 with autonomous intelligences that are not biological nature. We really need to appreciate

38:28.960 --> 38:34.000
 these... What human beings actually are is the superposition of these different layers.

38:34.640 --> 38:40.560
 You mentioned consciousness. Are each of these layers of cake conscious? Is consciousness a

38:40.560 --> 38:45.920
 particular quality of one of the layers? Is there like a spike if you have a consciousness

38:45.920 --> 38:50.800
 detector at these layers? Or is something that just permeates all of these layers and just takes

38:50.800 --> 38:56.480
 different form? I believe what humans experience as consciousness is something that sits on a gradient

38:56.480 --> 39:05.040
 scale of a general principle in the universe that seems to look for order and reach for order when

39:05.040 --> 39:10.160
 there's an excess of energy. It would be odd to say a proton is alive. It'd be odd to say this

39:10.160 --> 39:18.880
 particular atom or molecule of hydrogen gas is alive. But there's certainly something we can make

39:19.920 --> 39:25.360
 assemblages of these things that have auto poetic aspects to them, that will create structures,

39:25.360 --> 39:30.240
 that will... Crystalline solids will form very interesting and beautiful structures. This gets

39:30.240 --> 39:34.320
 kind of into weird mathematical territories. You start to think about Penrose and Game of

39:34.320 --> 39:39.360
 Life stuff about the generativity of math itself, like the hyperreal numbers, things like that.

39:39.360 --> 39:44.800
 But without going down that rabbit hole, I would say that there seems to be a tendency

39:45.520 --> 39:51.200
 in the world that when there is excess energy, things will structure and pattern themselves.

39:51.200 --> 39:56.480
 And they will then actually furthermore try to create an environment that furthers their continued

39:56.480 --> 40:02.400
 stability. It's the concept of externalized extended phenotype or niche construction. So

40:03.520 --> 40:09.040
 this is ultimately what leads to certain kinds of amino acids forming certain kinds of structures

40:09.040 --> 40:12.800
 and so on and so forth until you get the latter of life. So what we experience as consciousness,

40:12.800 --> 40:18.400
 no, I don't think cells are conscious of that level. But is there something beyond mere equilibrium

40:18.400 --> 40:26.000
 state biology and chemistry and biochemistry that drives what makes things work? I think there is.

40:27.440 --> 40:31.680
 So Adrian Bajon has his Constructo Law. There's other things you look at when you look at the

40:31.680 --> 40:36.800
 life sciences and you look at any kind of statistical physics and statistical mechanics.

40:36.800 --> 40:42.080
 When you look at things far out of equilibrium, when you have excess energy,

40:42.080 --> 40:46.720
 what happens then? Life doesn't just make a hotter soup. It starts making structure.

40:47.280 --> 40:48.240
 There's something there.

40:48.240 --> 40:52.480
 With the poetry of reaches for order when there's an excess of energy.

40:54.080 --> 40:55.680
 Because you brought up game of life.

40:57.120 --> 41:03.920
 You did it. Not me. I love cellular automata, so I have to sort of linger on that for a little bit.

41:03.920 --> 41:11.680
 So cellular automata, I guess, or game of life is a very simple example of reaching for order

41:11.680 --> 41:16.480
 when there's an excess of energy or reaching for order and somehow creating complexity.

41:18.480 --> 41:26.320
 It's explosion of just turmoil, somehow trying to construct structures and so doing

41:26.320 --> 41:34.080
 creates very elaborate organism looking type things. What intuition do you draw from the

41:34.080 --> 41:40.880
 simplest mechanism? Well, I like to turn that around its head and look at it as what if every

41:40.880 --> 41:46.880
 single one of the patterns created life or created, not life, but created interesting

41:46.880 --> 41:51.200
 patterns? Because some of them don't and sometimes you make cool gliders. And other times,

41:51.200 --> 41:54.800
 you start with certain things and you make gliders and other things that then construct

41:54.800 --> 41:59.920
 like and gates and not gates and you build computers on them. All of these rules that

41:59.920 --> 42:04.960
 create these patterns that we can see, those are just the patterns we can see. What if our

42:04.960 --> 42:11.120
 subjectivity is actually limiting our ability to perceive the order in all of it? What if some

42:11.120 --> 42:13.840
 of the things that we think are random are actually not that random? We're simply not

42:13.840 --> 42:19.520
 integrating at a final level across a broad enough time horizon. And this again, I said,

42:19.520 --> 42:25.840
 we go down the rabbit holes and the Penrose stuff or like Wolfram's explorations on these things.

42:25.840 --> 42:29.600
 There is something deep and beautiful in the mathematics of all this that is hopefully one

42:29.600 --> 42:33.600
 day I'll have enough money to work and retire and just ponder those questions. But there's

42:33.600 --> 42:37.200
 something there. But you're saying there's a ceiling to when you have enough money and you

42:37.200 --> 42:41.200
 retire and you ponder it, there's a ceiling to how much you can truly ponder because there's

42:41.200 --> 42:48.720
 cognitive limitations in what you're able to perceive as a pattern. Yeah. And maybe mathematics

42:48.720 --> 42:54.560
 extends your perception capabilities, but it's still finite. It's just like...

42:55.280 --> 42:58.240
 Yeah. The mathematics we use is the mathematics that can fit in our head.

42:58.880 --> 43:04.400
 Yeah. Did God really create the integers or did God create all of it? And we just happened

43:04.400 --> 43:06.240
 at this point in time to be able to perceive integers.

43:07.040 --> 43:09.360
 Well, he just did the positive in it.

43:09.360 --> 43:11.520
 I said, did she create all of it?

43:14.080 --> 43:17.600
 She just created the natural numbers and then we screwed all up with zero and then I guess.

43:17.600 --> 43:22.880
 Okay. But we did. We created mathematical operations so that we can have iterated

43:22.880 --> 43:29.280
 steps to approach bigger problems. I mean, the entire point of the Arabic neural system and

43:29.280 --> 43:34.000
 it's a rubric for mapping a certain set of operations, folding them into a simple little

43:34.000 --> 43:39.280
 expression, but that's just the operations that we can fit in our heads. There are many other

43:39.280 --> 43:46.640
 operations besides. The thing that worries me the most about aliens and humans is that

43:46.640 --> 43:51.520
 they're aliens. They're all around us and we're too dumb to see them.

43:51.520 --> 43:52.720
 Oh, certainly. Yeah.

43:52.720 --> 43:59.040
 Or life. Let's say just life. Life of all kinds of forms or organisms. You know what? Just even

43:59.040 --> 44:06.000
 the intelligence of organisms is imperceptible to us because we're too dumb and self centered.

44:06.880 --> 44:11.840
 Well, we're looking for a particular kind of thing. When I was at Cornell, I had a lovely

44:11.840 --> 44:18.160
 professor of Asian religions, Jamery Law, and she would tell this story about a musician,

44:18.160 --> 44:23.440
 a Western musician, who went to Japan and he taught classical music and could play all sorts

44:23.440 --> 44:28.480
 of instruments. He went to Japan and he would ask people, he would basically be looking for

44:28.480 --> 44:34.560
 things in the style of a Western chromatic scale and these kinds of things. And then

44:34.560 --> 44:37.920
 finding none of it, he would say, well, there's really no music in Japan, but they're using

44:37.920 --> 44:41.040
 a different scale. They're playing different kinds of instruments. The same thing she was

44:41.040 --> 44:45.680
 using as sort of a metaphor for religion as well. In the West, we center a lot of religion,

44:45.680 --> 44:50.880
 certainly the religions of Abraham, we center them around belief. And in the East, it's more

44:50.880 --> 44:55.760
 about practice, right? Spirituality and practice rather than belief. So anyway, the point is here,

44:55.760 --> 45:03.200
 to your point, life. I think so many people are so fixated on certain aspects of self replication

45:03.200 --> 45:09.200
 or homeostasis or whatever. But if we kind of broaden and generalize this thing of things

45:09.200 --> 45:14.240
 reaching for order, under which conditions can they then create an environment that sustains that

45:14.240 --> 45:20.960
 order that allows them, the invention of death is an interesting thing. There are some organisms

45:20.960 --> 45:25.360
 on earth that are thousands of years old. And it's not like they're incredibly complex,

45:25.360 --> 45:30.800
 they're actually simpler than the cells that comprise us, but they never die. So at some point,

45:31.680 --> 45:36.080
 death was invented somewhere along the eukaryotic scale, I mean, even the protists, right? There's

45:36.080 --> 45:42.960
 death. And why is that along with the sexual reproduction, right? There is something about

45:43.840 --> 45:47.520
 the renewal process, something about the ability to respond to a changing environment,

45:48.080 --> 45:52.480
 where it just become, you know, just killing off the old generation and letting new generations

45:53.280 --> 45:56.560
 try seems to be the best way to fit into the niche.

45:56.560 --> 46:01.520
 You know, human historian seems to write about wheels and fires, the greatest inventions,

46:01.520 --> 46:06.400
 but it seems like death and sex are pretty good. And they're kind of essential inventions

46:06.400 --> 46:09.680
 at the very beginning. At the very beginning, yeah. Well, we didn't invent them, right?

46:10.400 --> 46:17.200
 Well, broad, we, you didn't invent them. ICS is one, you particular Homo sapiens did not

46:17.200 --> 46:21.680
 invent them, but we together, it's a team project, just like you're saying.

46:21.680 --> 46:25.440
 I think the greatest Homo sapiens invention is collaboration.

46:25.440 --> 46:33.840
 So when you say collaboration, Peter, where do ideas come from? And how do they take hold in

46:33.840 --> 46:39.520
 society? What's, is that the nature of collaboration? Is that the basic atom of collaboration is ideas?

46:40.320 --> 46:44.560
 It's not not ideas, but it's not only ideas. There's a book I just started reading called

46:44.560 --> 46:46.880
 Death from a Distance. Have you heard of this? No.

46:46.880 --> 46:52.480
 It's a really fascinating thesis, which is that humans are the only conspecific,

46:52.480 --> 46:57.040
 the, the, the only species that can kill other members of the species from range.

46:58.160 --> 47:00.880
 And maybe there's a few exceptions, but if you look in the animal world,

47:00.880 --> 47:05.680
 you see like pronghorns, butting heads, right? You see the alpha lion and the beta lion,

47:05.680 --> 47:09.920
 and they take each other down. Humans, we develop the ability to chuck rocks at each other and,

47:09.920 --> 47:14.800
 well, at prey, but also at each other. And that means the beta male can chuck a rock

47:14.800 --> 47:19.920
 at the alpha male and take them down. And with very, and he can throw a lot of rocks actually,

47:19.920 --> 47:25.680
 miss a bunch of times, which is hit once and be good. So this ability to actually kill members

47:25.680 --> 47:30.960
 of our own species from range without a threat of harm to ourselves, create essentially mutually

47:30.960 --> 47:36.240
 assured destruction where we had to evolve cooperation. If we didn't, then if we just

47:36.240 --> 47:40.400
 continue to try to do like I'm the, the biggest monkey in the tribe, and I'm going to, you know,

47:40.960 --> 47:46.560
 own this tribe and you have to go, if we do it that way, then those tribes basically failed.

47:46.560 --> 47:51.360
 And the tribes that persisted and that have now given rise to the modern Homo sapiens

47:51.360 --> 47:55.200
 are the ones where respecting the fact that we can kill each other from range

47:56.080 --> 48:00.880
 without harm, like there's an asymmetric ability to, to snipe the leader from range.

48:00.880 --> 48:05.680
 That meant that we sort of had to learn how to cooperate with each other, right? Come back here,

48:05.680 --> 48:10.080
 don't throw that rock at me. Let's talk our, this is out. So violence is also part of collaboration.

48:10.080 --> 48:15.040
 The threat of violence, let's say. Well, the recognition, I would, maybe the better way to

48:15.040 --> 48:21.040
 put it is the recognition that we have more to gain by working together than the prisoner's dilemma

48:21.040 --> 48:27.040
 of both of us defecting. So mutually assured destruction in all its forms is part of this

48:27.040 --> 48:31.600
 idea of collaboration. Well, and Eric Weinstein talks about our nuclear peace, right? I mean,

48:31.600 --> 48:35.440
 it kind of sucks though if thousands of warheads aimed at each other, Russian and the US, but

48:35.440 --> 48:40.560
 it's like, on the other hand, you know, we only fought proxy wars, right? We did not have another

48:40.560 --> 48:45.120
 world war three of like hundreds of millions of people dying to like machine gun fire and,

48:45.120 --> 48:50.240
 and, you know, giant, you know, guided missiles. So the original nuclear weapon is, is a rock

48:50.240 --> 48:53.760
 that we learned how to throw essentially. The original, yeah. Well, the original scope of

48:53.760 --> 48:59.680
 the world for any human being was their little tribe. I would say it still is to the most,

48:59.680 --> 49:07.440
 for the most part. Eric Weinstein speaks very highly of you, which is very surprising to me

49:07.440 --> 49:13.680
 at first because I didn't know there's this depth to you because I knew you as a, as a, as an amazing

49:14.320 --> 49:19.680
 leader of engineers and an engineer yourself and so on. So it's fascinating. Maybe just as a comment,

49:20.320 --> 49:27.040
 a side tangent that we can take. What's your nature of your friendship with Eric Weinstein?

49:27.040 --> 49:32.880
 How did the two, how did such two interesting paths cross? Is it your origins in physics?

49:32.880 --> 49:37.600
 Is it your interest in philosophy and the ideas of how the world works? What is it?

49:37.600 --> 49:42.800
 It's actually, it's very random. It's Eric found me. He actually found Travis and I.

49:43.680 --> 49:48.400
 Travis Alffant. Yeah, we were both working at a company called Enthought back in the mid 2000s,

49:48.400 --> 49:53.520
 and we're doing a lot of consulting around scientific Python. And we'd made some,

49:53.520 --> 49:58.480
 some tools and Eric was trying to use some of these Python tools to visualize,

49:58.480 --> 50:03.840
 that he had a fiber bundle approach to modeling certain aspects of economics. He was doing this

50:03.840 --> 50:09.680
 and that's how he kind of got in touch with us. And so this was in the early mid 2000s.

50:12.000 --> 50:13.680
 Oh, seven time frame? Oh, six, oh, seven.

50:13.680 --> 50:19.760
 Eric Weinstein trying to use Python to visualize fiber bundles using some of the tools that we

50:19.760 --> 50:24.000
 had built in the open source. That's somehow entertaining to me, the thought of that.

50:24.000 --> 50:27.040
 It's really funny. But then, you know, we've met with him a couple of times,

50:27.040 --> 50:32.560
 really interesting guy. And then in the wake of the 0708 kind of financial collapse, he helped

50:32.560 --> 50:38.800
 organize with Lee Smolin a symposium at the Perimeter Institute about, okay, well, clearly,

50:39.520 --> 50:43.440
 you know, big finance can't be trusted, governments in its pockets with regulatory capture,

50:43.440 --> 50:49.040
 what the F do we do? And all sorts of people, Nassim Tlaib was there and Andy Lowe from MIT was

50:49.040 --> 50:54.640
 there and, you know, Bill Janeway, I mean, just a lot of, you know, top billing people were there.

50:54.640 --> 51:01.200
 And he invited me and Travis and another one of our coworkers, Robert Kern, who was a anyone in

51:01.200 --> 51:05.840
 the SciPy, NumPy community knows Robert, really great guy. So the three of us also got invited

51:05.840 --> 51:08.720
 to go to this thing. And that's where I met Brett Weinstein for the first time as well.

51:09.280 --> 51:15.360
 Yeah, I knew him before he got all famous for unfortunate reasons, I guess. But anyway, we,

51:16.320 --> 51:21.360
 so we met then and kind of had a friendship, you know, throughout since then.

51:21.360 --> 51:27.920
 You have a depth of thinking that kind of runs with Eric in terms of just thinking about the

51:27.920 --> 51:33.360
 world deeply and thinking philosophically. And then there's Eric's interest in programming.

51:33.360 --> 51:39.760
 Actually, never, you know, he'll bring up programming to me quite a bit as a metaphor

51:39.760 --> 51:43.280
 for stuff. Right. But I never kind of pushed the point of like,

51:44.320 --> 51:48.720
 what's the nature of your interest in programming? I think you saw it probably as a tool.

51:48.720 --> 51:53.600
 Yeah, absolutely. To visualize, to explore mathematics and explore physics. But

51:53.600 --> 51:58.400
 and I was wondering, like, what's the, his depth of interest and also his

52:00.640 --> 52:07.200
 vision for what programming would look like in the future? Have you had interaction with him,

52:07.200 --> 52:11.840
 like discussion in the space of Python programming? Well, in the sense of sometimes he asks me,

52:11.840 --> 52:20.000
 why is this stuff still so hard? Yeah, you know, everybody's a critic. But actually, no, Eric.

52:20.000 --> 52:23.200
 Programming, you mean like ingest? Yes. Yes. Well, not programming in general,

52:23.200 --> 52:29.440
 but certain things in the Python ecosystem. But he actually, I think what I find in listening

52:29.440 --> 52:33.600
 to some of his stuff is that he does use programming metaphors a lot, right? He'll

52:33.600 --> 52:37.360
 talk about APIs or object oriented and things like that. So I think that's a useful

52:37.360 --> 52:43.680
 set of frames for him to draw upon for discourse. I haven't pair programmed with him

52:43.680 --> 52:50.160
 in a very long time. You've previously... Well, I mean, try to help, like, put together some

52:50.160 --> 52:53.840
 of the visualizations around these things. But it's been a very, not really pair program,

52:53.840 --> 52:57.920
 but like, even looked at his code, right? I mean, how legendary would be is that, like,

52:58.800 --> 53:04.960
 get repo with Peter Wang and Eric Weinstein? Well, honestly, Robert Kern did all the heavy

53:04.960 --> 53:09.280
 lifting. So I have to give credit where credit is due. Robert is the silent, but incredibly deep,

53:10.160 --> 53:14.560
 quiet, not silent, but quiet, but incredibly deep individual at the heart of a lot of those things

53:14.560 --> 53:19.440
 that Eric was trying to do. But we did have, you know, in the... As Travis and I were starting

53:19.440 --> 53:26.000
 our company in 2012 timeframe, we went to New York. Eric was still in New York at the time.

53:26.000 --> 53:30.720
 He hadn't moved to... This is before he joined Teal Capital. We just had like a steak dinner

53:30.720 --> 53:35.120
 somewhere. Maybe it was Keynes, I don't know, somewhere in New York. So it's me, Travis, Eric,

53:35.120 --> 53:40.080
 and then Wes McKinney, the creative pandas, and then Wes's then business partner, Adam.

53:40.080 --> 53:46.080
 The five of us sat around having this just a hilarious time, amazing dinner. I forget what

53:46.080 --> 53:51.040
 all we talked about, but it was one of those conversations which I wish as soon as COVID is

53:51.040 --> 53:56.320
 over, maybe Eric and I can sit down. Recreate. Recreate in somewhere in LA or maybe he comes

53:56.320 --> 53:59.120
 here because a lot of cool people are here in Austin, right? Exactly. Yeah, we're all here.

53:59.120 --> 54:04.160
 He should come here. Eric, come here. Yeah. So he uses the metaphor source code sometimes to

54:04.160 --> 54:08.960
 talk about physics. We figure out our own source code. So you were the physics background

54:10.800 --> 54:15.520
 and somebody who's quite a bit of an expert in source code, do you think we'll ever figure out

54:15.520 --> 54:20.000
 our own source code in the way that Eric means? Do you think we'll figure out the nature we have?

54:20.000 --> 54:23.680
 Well, I think we're constantly working on that problem. I mean, I think we'll make more and more

54:23.680 --> 54:29.280
 progress. For me, there's some things I don't really doubt too much. I don't really doubt

54:29.280 --> 54:35.600
 that one day we will create a synthetic, maybe not fully in silicon, but a synthetic approach

54:36.240 --> 54:44.000
 to cognition that rivals the biological 20 watt computers in our heads.

54:44.640 --> 54:50.960
 What's cognition here? Cognition, perception, attention, memory, recall, asking better questions.

54:50.960 --> 54:55.200
 That, for me, is a measure of intelligence. Doesn't Roomba vacuum clean already do that?

54:55.200 --> 55:00.400
 Or do you mean, oh, it doesn't ask questions? I mean, no. So I mean, I have a Roomba, but it's

55:00.960 --> 55:05.440
 not even as smart as my cat, right? Yeah, but it asks questions about what is this wall.

55:05.440 --> 55:10.480
 It now, a new feature asks, is this poop or not, apparently? Yes. A lot of our current

55:10.480 --> 55:14.480
 cybernetic system, it's a cybernetic system. It will go and it will happily vacuum up some poop,

55:14.480 --> 55:19.280
 right? The older generations would. A new one, just released, does not vacuum up the poop.

55:19.280 --> 55:25.200
 Okay. I wonder if it still gets stuck under my first rung of my stare. In any case, these

55:25.200 --> 55:33.920
 cybernetic systems we have, they're designed to be sent off into a relatively static environment.

55:33.920 --> 55:37.600
 And whatever dynamic things happen in the environment, they have a very limited capacity

55:37.600 --> 55:44.880
 to respond to. A human baby, a human toddler of 18 months of age has more capacity to manage

55:44.880 --> 55:50.480
 its own attention and its own capacity to make better sense of the world than the most advanced

55:50.480 --> 55:55.600
 robots today. So again, my cat, I think, can do a better job of my two and they're both pretty

55:55.600 --> 56:01.040
 clever. So I do think though, back to my kind of original point, I think that it's not, for me,

56:01.040 --> 56:07.040
 it's not a question at all that we will be able to create synthetic systems that are able to do this

56:07.920 --> 56:12.480
 better than the human, at an equal level or better than the human mind. It's also for me,

56:12.480 --> 56:22.000
 not a question that we will be able to put them alongside humans so that they capture the full

56:22.000 --> 56:28.160
 broad spectrum of what we are seeing as well. And also looking at our responses, listening

56:28.160 --> 56:33.440
 to our responses, even maybe measuring certain vital signs about us. So in this kind of sidecar

56:33.440 --> 56:42.160
 mode, a greater intelligence could use us and our whatever, 80 years of life to train itself up and

56:42.160 --> 56:49.200
 then be a very good simulacrum of us moving forward. So who is in the sidecar in that picture

56:49.200 --> 56:56.080
 of the future exactly? The baby version of our immortal selves. Okay. So once the baby grows up,

56:56.080 --> 57:03.120
 is there any use for humans? I think so. I think that out of epistemic humility,

57:03.120 --> 57:07.920
 we need to keep humans around for a long time. And I would hope that anyone making those systems

57:07.920 --> 57:13.840
 would believe that to be true. Out of epistemic humility, what's the nature of the humility that...

57:13.840 --> 57:16.880
 We don't know what we don't know. So we don't...

57:18.880 --> 57:23.440
 Right? So we don't know... First we have to build systems that help us do the things that we do

57:23.440 --> 57:27.760
 know about, that can then probe the unknowns that we know about. But the unknown unknowns,

57:27.760 --> 57:34.560
 we don't know. Nature is the one thing that is infinitely able to surprise us. So we should

57:34.560 --> 57:39.600
 keep biological humans around for a very, very, very long time. Even after our immortal selves

57:39.600 --> 57:44.000
 have transcended and have gone off to explore other worlds, gone to go communicate with the

57:44.000 --> 57:51.520
 lifeforms living in the sun or whatever else. So I think that's... For me, these seem like

57:51.520 --> 57:55.600
 things that are going to happen. I don't really question that, that they're going to happen.

57:55.600 --> 57:58.160
 Assuming we don't completely destroy ourselves.

57:58.160 --> 58:06.000
 Is it possible to create an AI system that you fall in love with and it falls in love with you

58:06.000 --> 58:10.640
 and you have a romantic relationship with it or a deep friendship, let's say?

58:10.640 --> 58:13.360
 I would hope that that is the design criteria for any of these systems.

58:14.400 --> 58:20.240
 If we cannot have a meaningful relationship with it, then it's still just a chunk of silicon.

58:20.240 --> 58:23.600
 So then what is meaningful? Because back to sugar.

58:23.600 --> 58:27.360
 Well, sugar doesn't love you back, right? So the computer has to love you back. And what does love

58:27.360 --> 58:32.320
 mean? Well, in this context, for me, love... I'm going to take a page from Alain de Bouton. Love

58:32.320 --> 58:35.760
 means that it wants to help us become the best version of ourselves.

58:37.760 --> 58:44.560
 That's beautiful. That's a beautiful definition of love. So what role does love play in the human

58:44.560 --> 58:49.760
 condition at the individual level and at the group level? Because you were kind of saying that

58:50.880 --> 58:55.120
 we should really consider humans both at the individual and the group and the societal level.

58:55.120 --> 58:59.520
 What's the role of love in this whole thing? We talked about sex, we talked about death

58:59.520 --> 59:04.160
 thanks to the bacteria, they invented it. At which point did we invent love, by the way?

59:04.160 --> 59:10.560
 I mean, is that also... No, I think love is the start of it all and the feelings of... And this

59:10.560 --> 59:18.000
 gets sort of beyond just romantic, sensual, whatever kind of things, but actually genuine

59:18.000 --> 59:22.560
 love as we have for another person, love as it would be used in a religious text, right?

59:22.560 --> 59:28.240
 I think that capacity to feel love more than consciousness, that is the universal thing.

59:28.240 --> 59:32.880
 Our feeling of love is actually a sense of that generativity. When we can look at another person

59:32.880 --> 59:38.400
 and see that they can be something more than they are and more than just what we...

59:40.080 --> 59:44.400
 A pigeonhole, we might stick them in. I think in any religious text, you'll find

59:46.160 --> 59:50.240
 voiced some concept of this, that you should see the grace of God and the other person,

59:50.240 --> 59:56.800
 right? They're made in the spirit of the love that God feels for his creation or her creation.

59:57.840 --> 1:00:04.640
 I think this thing is actually the root of it. I don't think molecules of water

1:00:04.640 --> 1:00:10.720
 feel consciousness, have consciousness, but there is some proto micro quantum thing of love

1:00:10.720 --> 1:00:15.440
 that's the generativity when there's more energy than what they need to maintain equilibrium.

1:00:15.440 --> 1:00:22.800
 That, when you sum it all up, is something that leads to... I had my mind blown one day as an

1:00:22.800 --> 1:00:28.080
 undergrad at the physics computer lab. I logged in and when you log in to Bash for a long time,

1:00:28.080 --> 1:00:32.720
 there was a little fortune that would come out and it said, man was created by water to carry

1:00:32.720 --> 1:00:39.600
 itself uphill. I was logging in to work on some problem set and I logged in and I saw that and

1:00:39.600 --> 1:00:45.360
 I just said, son of a bitch, I logged out and I went to the coffee shop and I got a coffee and I sat

1:00:45.360 --> 1:00:54.720
 there on the quad and I'm like, it's not wrong and yet WTF, right? So when you look at it that way,

1:00:55.920 --> 1:01:01.440
 okay, non equilibrium physics is a thing. So when we think about love, when we think about

1:01:01.440 --> 1:01:07.040
 these kinds of things, I would say that in the modern day human condition,

1:01:07.040 --> 1:01:13.920
 there's a lot of talk about freedom and individual liberty and rights and all these things,

1:01:14.560 --> 1:01:19.200
 but that's very Hegelian. It's very kind of following from the Western philosophy

1:01:19.760 --> 1:01:26.480
 of the individual as sacrosanct, but it's not really couched, I think, the right way because

1:01:26.480 --> 1:01:31.840
 it should be how do we maximize people's ability to love each other, to love themselves first,

1:01:31.840 --> 1:01:37.120
 to love each other, their responsibilities to the previous generation, to the future generations.

1:01:37.760 --> 1:01:42.160
 Those are the kinds of things that should be our design criteria, right? Those should be

1:01:42.960 --> 1:01:49.040
 what we start with to then come up with the philosophies of self and of rights and responsibilities.

1:01:50.000 --> 1:01:55.280
 But that love being at the center of it, I think when we design systems for cognition,

1:01:56.480 --> 1:02:00.640
 it should absolutely be built that way. I think if we simply focus on efficiency

1:02:00.640 --> 1:02:07.440
 and productivity, these kind of very industrial era, all the things that Marx had issues with,

1:02:07.440 --> 1:02:12.960
 right? That's a way to go and really, I think, go off the deep end in the wrong way.

1:02:12.960 --> 1:02:20.320
 So one of the interesting consequences of thinking of life in this hierarchical way

1:02:20.880 --> 1:02:27.200
 of an individual human, and then there's groups and there are societies, is I believe that

1:02:27.200 --> 1:02:36.240
 that you believe that corporations are people. So this is a kind of a politically dense idea

1:02:36.240 --> 1:02:40.400
 and all those kinds of things. If we just throw politics aside, if we throw all of that aside,

1:02:41.200 --> 1:02:44.320
 in which sense do you believe that corporations are people?

1:02:46.080 --> 1:02:51.200
 And how does love connect to that? Right. So the belief is that groups of people

1:02:51.200 --> 1:02:58.320
 have some kind of higher level, I would say, mesoscopic claim to agency. So where do I,

1:02:59.520 --> 1:03:04.080
 let's start with this. Most people would say, okay, individuals have claims to agency and

1:03:04.080 --> 1:03:10.480
 sovereignty. Nations, we certainly act as if nations sort of very large, large scale. Nations have

1:03:10.480 --> 1:03:16.080
 rights to sovereignty and agency. Like everyone plays the game of modernity as if that's true.

1:03:16.080 --> 1:03:20.800
 We believe France is a thing. We believe the United States is a thing. But to say that groups of

1:03:20.800 --> 1:03:27.840
 people at a smaller level than that, like a family unit is a thing. Well, in our laws,

1:03:27.840 --> 1:03:34.720
 we actually do encode this concept. I believe that in a relationship and a marriage, one partner can

1:03:34.720 --> 1:03:40.720
 sue for loss of consortium if someone breaks up the marriage or whatever. So these are concepts

1:03:40.720 --> 1:03:46.000
 that even in law, we do respect that there is something about the union and about the family.

1:03:46.000 --> 1:03:52.720
 So for me, I don't think it's so weird to think that groups of people have a claim to rights

1:03:52.720 --> 1:04:00.320
 and sovereignty of some degree. And we look at our clubs, we look at churches. We talk about

1:04:00.320 --> 1:04:06.320
 these collectives of people as if they have a real agency to them. And then they do. But I think

1:04:06.320 --> 1:04:11.840
 if we take that one step further and say, okay, they can accrue resources. Well, yes, check. By

1:04:11.840 --> 1:04:17.680
 law, they can. They can own land. They can engage in contracts. They can do all these different

1:04:17.680 --> 1:04:24.320
 kinds of things. So we, in legal terms, support this idea that groups of people have rights.

1:04:26.080 --> 1:04:32.480
 Where we go wrong on this stuff is that the most popular version of this is the for profit

1:04:32.480 --> 1:04:39.520
 absentee owner corporation that then is able to amass larger resources than anyone else in the

1:04:39.520 --> 1:04:44.160
 landscape, anything else, any other entity of equivalent size. And they're able to essentially

1:04:44.160 --> 1:04:47.760
 bully around individuals, whether it's laborers, whether it's people whose resources they want

1:04:47.760 --> 1:04:53.440
 to capture. They're also able to bully around our system of representation, which is still tied

1:04:53.440 --> 1:05:01.440
 to individuals. So I don't believe that's correct. I don't think it's good that they're people,

1:05:01.440 --> 1:05:04.480
 but they're assholes. I don't think that corporations as people acting like assholes is a

1:05:04.480 --> 1:05:09.120
 good thing. But the idea that collectives and collections of people that we should treat

1:05:09.120 --> 1:05:16.800
 them philosophically as having some agency, some agency and some mass at a mesoscopic level,

1:05:16.800 --> 1:05:22.320
 I think that's an important thing. Because one thing I do think we under appreciate sometimes

1:05:22.320 --> 1:05:27.360
 is the fact that relationships have relationships. So it's not just individuals having

1:05:27.360 --> 1:05:31.760
 relationships with each other. But if you have eight people seated around a table,

1:05:31.760 --> 1:05:35.440
 right, each person has a relationship with each of the others. And that's obvious.

1:05:35.440 --> 1:05:40.640
 But then if it's four couples, each couple also has a relationship with each of the other couples,

1:05:41.280 --> 1:05:46.960
 right? The dyads do. And if it's couples, but one is the father, mother, older,

1:05:46.960 --> 1:05:53.920
 and then one of their children and their spouse, that family unit of four has a relationship with

1:05:53.920 --> 1:05:57.920
 the other family unit of four. So the idea that relationships have relationships is something

1:05:57.920 --> 1:06:02.720
 that we intuitively know in navigating the social landscape. But it's not something I

1:06:02.720 --> 1:06:07.520
 hear expressed like that. It's certainly not something that is, I think, taken into account

1:06:07.520 --> 1:06:13.360
 very well when we design these kinds of things. So I think the reason why I care a lot about this

1:06:13.920 --> 1:06:20.000
 is because I think the future of humanity requires us to form better sense, make collective

1:06:20.000 --> 1:06:29.600
 sense making units at something around Dunbar number, half to 5x Dunbar. And that's very different

1:06:29.600 --> 1:06:36.080
 than right now where we defer sense making to massive aging zombie institutions.

1:06:36.880 --> 1:06:41.040
 Or we just do it ourselves. We go it alone, go to the dark forest of the internet by ourselves.

1:06:41.040 --> 1:06:47.280
 So that's really interesting. So you've talked about agency, I think, maybe calling it a convenient

1:06:47.280 --> 1:06:52.960
 fiction at all these different levels. So even at the human individual level, it's kind of a fiction.

1:06:52.960 --> 1:06:56.720
 We all believe because we are, like you said, made of cells and cells are made of atoms.

1:06:56.720 --> 1:07:02.240
 So that's a useful fiction. And then there's nations. That seems to be a useful fiction.

1:07:02.800 --> 1:07:08.400
 But it seems like some fictions are better than others. There's a lot of people that argue the

1:07:08.400 --> 1:07:14.480
 fiction of nation is a bad idea. One of them lives two doors down from me. Michael Malis,

1:07:14.480 --> 1:07:20.240
 he's an anarchist. I'm sure there's a lot of people who are into meditation that believe

1:07:20.240 --> 1:07:26.960
 the idea this useful fiction of agency of an individual is troublesome as well. We need to

1:07:26.960 --> 1:07:33.440
 let go of that in order to truly like to transcend, I don't know, I don't know what words you want to

1:07:33.440 --> 1:07:40.960
 use, but suffering or to elevate the experience of life. So you're kind of arguing that, okay,

1:07:40.960 --> 1:07:48.320
 so we have some of these useful fictions of agency. We should add a stronger fiction that we tell

1:07:48.320 --> 1:07:56.640
 ourselves about the agency of groups in the hundreds of half a Dunbar's number or five X

1:07:56.640 --> 1:08:00.080
 Dunbar's number. Yeah, something in that order. And we call them fictions, but really they're

1:08:00.080 --> 1:08:05.520
 rules of the game, right? Rules that we feel are fair or rules that we consent to.

1:08:05.520 --> 1:08:09.680
 I always question the rules when I lose like a monopoly. That's when I usually question them.

1:08:09.680 --> 1:08:12.720
 When I'm winning, I don't question the rules. We should play a game of monopoly someday.

1:08:12.720 --> 1:08:18.480
 There's a trippy version of it that we could do. Contract monopoly is introduced by a friend of mine

1:08:18.480 --> 1:08:24.800
 to me where you can write contracts on future earnings or landing on various things and you

1:08:24.800 --> 1:08:28.960
 can hand out like, you know, you can land first three times, you land a park place is free or

1:08:28.960 --> 1:08:34.240
 whatever, just and then you can start trading those contracts for money. And then you create

1:08:34.240 --> 1:08:40.720
 human civilization and somehow Bitcoin comes into it. Okay, but some of these... Actually,

1:08:40.720 --> 1:08:45.280
 I bet if me and you and Eric sat down to play a game of monopoly and we were to make NFTs out

1:08:45.280 --> 1:08:48.960
 of the contracts we wrote, we could make a lot of money. Now, it's a terrible idea.

1:08:48.960 --> 1:08:52.800
 Yes. I would never do it, but I bet we could actually sell the NFTs around.

1:08:52.800 --> 1:08:58.080
 I have other ideas to make money that I could tell you and they're all terrible ideas,

1:08:59.840 --> 1:09:04.880
 including cat videos on the internet. Okay, but some of these rules of the game, some of these

1:09:04.880 --> 1:09:11.200
 fictions are, it seems like they're better than others. They have worked this far to

1:09:11.200 --> 1:09:16.400
 cohere human, to organize human collective action. But you're saying something about,

1:09:16.400 --> 1:09:24.160
 especially this technological age requires modified fictions, stories of agency. Why the

1:09:24.160 --> 1:09:28.320
 Dunbar number and also, you know, how do you select the group of people? You know,

1:09:28.320 --> 1:09:37.200
 Dunbar numbers, I think, I have this sense that it's overused as a kind of law that somehow

1:09:37.920 --> 1:09:44.480
 we can have deep human connection at this scale. Like some of it feels like an interface problem

1:09:44.480 --> 1:09:51.680
 too. It feels like if I have the right tools, I can deeply connect with a larger number of people.

1:09:51.680 --> 1:09:58.720
 It just feels like there's a huge value to interacting just in person, getting to share

1:09:59.360 --> 1:10:03.920
 traumatic experiences together or beautiful experiences together. There's other experiences

1:10:05.600 --> 1:10:09.680
 that in the digital space that you can share. It just feels like Dunbar's number can be

1:10:09.680 --> 1:10:15.280
 expanded significantly, perhaps not to the level of millions and billions, but it feels

1:10:15.280 --> 1:10:23.600
 like it could be expanded. How do we find the right interface, you think, for having a little

1:10:23.600 --> 1:10:28.320
 bit of a collective here that has agency? You're right, that there's many different ways that we

1:10:28.320 --> 1:10:34.080
 can build trust with each other. My friend Joe Edelman talks about a few different ways that

1:10:35.920 --> 1:10:41.840
 mutual appreciation, trustful conflict, just experiencing something. There's a variety of

1:10:41.840 --> 1:10:47.440
 different things that we can do, but all those things take time and you have to be present.

1:10:48.320 --> 1:10:51.760
 The less present you are, I mean, there's just, again, a no free lunch principle here. The less

1:10:51.760 --> 1:10:57.040
 present you are, the more of them you can do, but then the less connection you build. I think

1:10:57.040 --> 1:11:03.200
 there is a human capacity issue around some of these things. Now, that being said, if we can

1:11:03.200 --> 1:11:08.640
 use certain technologies. For instance, if I write a little monograph on my view of the world,

1:11:08.640 --> 1:11:12.080
 you read it asynchronously at some point and you're like, wow, Peter, this is great. Here's

1:11:12.080 --> 1:11:17.920
 mine. I read it. I'm like, wow, Lex, this is awesome. We can be friends without having to spend 10

1:11:17.920 --> 1:11:22.160
 years figuring all this stuff out together. We can just read each other's thing and be like, oh,

1:11:22.160 --> 1:11:30.320
 yeah, this guy's exactly in my wheelhouse and vice versa. We can then connect just a few times a year

1:11:30.320 --> 1:11:35.680
 and maintain a high trust relationship. It can be expanded a little bit, but it also requires,

1:11:35.680 --> 1:11:38.960
 these things are not all technological in nature. It requires the individual themselves

1:11:39.520 --> 1:11:44.960
 to have a certain level of capacity, to have a certain lack of neuroticism. If you want to

1:11:44.960 --> 1:11:50.480
 use the ocean big five sort of model, people have to be pretty centered. The less centered you are,

1:11:50.480 --> 1:11:55.120
 the fewer authentic connections you can really build for a particular unit of time. It just takes

1:11:55.120 --> 1:11:58.240
 more time. Other people have to put up with your crap. There's just a lot of the stuff that you

1:11:58.240 --> 1:12:04.960
 have to deal with if you are not so well balanced. Yes, we can help people get better to where they

1:12:04.960 --> 1:12:09.440
 can develop more relationships faster. Then you can maybe expand Dunbar number by quite a bit,

1:12:09.440 --> 1:12:12.800
 but you're not going to do it. I think it's going to be hard to get it beyond 10x,

1:12:12.800 --> 1:12:20.720
 kind of the rough swag of what it is. Well, don't you think that AI systems could be in addition

1:12:20.720 --> 1:12:25.520
 to the Dunbar's number? Do you count as one system or multiple AI systems?

1:12:25.520 --> 1:12:30.000
 Multiple AI systems. I do believe that AI systems, for them to integrate into human

1:12:30.000 --> 1:12:35.120
 society as it is now, have to have a sense of agency. There has to be an individual,

1:12:35.120 --> 1:12:40.560
 because otherwise we wouldn't relate to them. We could engage certain kinds of individuals to make

1:12:40.560 --> 1:12:46.320
 sense of them for us and be almost like, did you ever watch Star Trek? There's the Volta,

1:12:46.320 --> 1:12:53.120
 who are the interfaces, the ambassadors for the Dominion. We may have ambassadors that speak on

1:12:53.120 --> 1:12:57.040
 behalf of these systems. They're like the Mentats of Dune, maybe, or something like this.

1:12:57.040 --> 1:13:02.800
 I mean, we already have this to some extent. If you look at the biggest AI system, but the biggest

1:13:02.800 --> 1:13:06.800
 cybernetic system in the world is the financial markets. It runs outside of any individual's

1:13:06.800 --> 1:13:11.840
 control. You have an entire stack of people on Wall Street, Wall Street analysts, to CNBC,

1:13:11.840 --> 1:13:17.920
 reporters, whatever. They're all helping to communicate, what does this mean? Jim Cramer,

1:13:17.920 --> 1:13:22.960
 like Murrow Down, yelling and stuff. All of these people are part of that lowering of the

1:13:22.960 --> 1:13:29.920
 complexity there to help do sense making for people at whatever capacity they're at. I don't

1:13:29.920 --> 1:13:33.600
 see this changing with AI systems. I think you would have ringside commentators talking about

1:13:33.600 --> 1:13:37.600
 all this stuff that this AI system is trying to do over here, over here, because it's actually a

1:13:37.600 --> 1:13:41.440
 super intelligence. If you want to talk about humans interfacing, making first contact with

1:13:41.440 --> 1:13:45.520
 the super intelligence, we're already there. We do it pretty poorly. If you look at the gradient

1:13:45.520 --> 1:13:49.760
 of power and money, what happens is the people closest to it will absolutely exploit their

1:13:49.760 --> 1:13:56.720
 distance for personal financial gain. We should look at that and be like, oh, well, that's probably

1:13:56.720 --> 1:14:01.520
 what the future will look like as well. Nonetheless, we're already doing this kind of thing. In the

1:14:01.520 --> 1:14:06.400
 future, we can have AI systems, but you're still going to have to trust people to bridge the sense

1:14:06.400 --> 1:14:13.440
 making gap to them. I just feel like there could be millions of AI systems that have

1:14:13.440 --> 1:14:21.280
 agencies. When you say one super intelligence, super intelligence in that context means

1:14:22.160 --> 1:14:28.480
 it's able to solve particular problems extremely well, but there's some aspect of human like

1:14:28.480 --> 1:14:33.680
 intelligence that's necessary to be integrated into human society, so not financial markets,

1:14:33.680 --> 1:14:41.360
 not weather prediction systems or logistics optimization. I'm more referring to things

1:14:41.360 --> 1:14:48.720
 that you interact with on the intellectual level. I think there has to be a backstory,

1:14:48.720 --> 1:14:53.120
 there has to be a personality. I believe it has to fear its own mortality in a genuine way.

1:14:56.480 --> 1:15:01.760
 Many of the elements that we humans experience that are fundamental to the human condition,

1:15:01.760 --> 1:15:04.800
 because otherwise, we would not have a deep connection with it.

1:15:05.680 --> 1:15:09.440
 But I don't think having a deep connection with it is necessarily going to stop us from

1:15:09.440 --> 1:15:15.520
 building a thing that has quite an alien intelligence aspect. The other kind of alien

1:15:15.520 --> 1:15:19.200
 intelligence on this planet is octopuses or octopodes or whatever you want to call them.

1:15:21.280 --> 1:15:23.600
 There's a little controversy as to what the plural is, I guess.

1:15:23.600 --> 1:15:26.320
 I look forward to your letters.

1:15:27.840 --> 1:15:33.280
 An octopus, it really acts as a collective intelligence of eight intelligent arms.

1:15:33.280 --> 1:15:41.520
 Its arms have a tremendous amount of neural density to them. Let's go with what you're

1:15:41.520 --> 1:15:47.920
 saying. If we build a singular intelligence that interfaces with humans that has a sense of agency

1:15:47.920 --> 1:15:52.080
 so we can run the cybernetic loop and develop its own theory of mind as well as its theory of

1:15:52.080 --> 1:15:57.520
 action, I agree with you that that's the necessary components to build a real intelligence.

1:15:57.520 --> 1:16:00.640
 There's got to be something at stake, it's got to make a decision, it's got to then run the

1:16:00.640 --> 1:16:04.000
 OODA loop. Okay, so we build one of those. Well, if we can build one of those, we can probably

1:16:04.000 --> 1:16:08.720
 build five million of them. So we'll build five million of them and if their cognitive systems

1:16:08.720 --> 1:16:13.520
 are already digitized and are already kind of there, we stick our antenna on each of them,

1:16:13.520 --> 1:16:17.920
 bring it all back to a hive mind that maybe doesn't make all the individual decisions for them,

1:16:17.920 --> 1:16:23.680
 but treats each one as almost like a neuronal input of a much higher bandwidth and fidelity,

1:16:23.680 --> 1:16:30.320
 going back to a central system that is then able to perceive much broader dynamics that we

1:16:30.320 --> 1:16:33.680
 can't see. In the same way that a phased array radar, you think about how a phased array radar

1:16:33.680 --> 1:16:39.600
 works, it's just sensitivity, it's just radars and then it's hypersensitivity and really great

1:16:39.600 --> 1:16:43.840
 timing between all of them and with a flat array, it's as good as a curved radar dish.

1:16:44.640 --> 1:16:49.280
 So with these things, it's a phased array of cybernetic systems that'll give the centralized

1:16:49.280 --> 1:16:55.520
 intelligence much, much better, much higher fidelity understanding of what's actually

1:16:55.520 --> 1:16:59.280
 happening in the environment. But the more power, the more understanding the central

1:16:59.280 --> 1:17:07.680
 superintelligence has, the dumber the individual fingers of this intelligence are, I think.

1:17:07.680 --> 1:17:08.800
 Not necessarily.

1:17:08.800 --> 1:17:16.080
 In my sense, this argument, there has to be the experience of the individual agent has to have

1:17:16.080 --> 1:17:23.200
 the full richness of the human like experience. You have to be able to be driving the car in

1:17:23.200 --> 1:17:28.480
 the rain, listening to Bruce Springsteen and all of a sudden break out in tears because

1:17:28.480 --> 1:17:30.880
 remembering something that happened to you in high school.

1:17:30.880 --> 1:17:32.720
 We can implant those memories if that's really needed.

1:17:32.720 --> 1:17:39.520
 No, but the central agency, I guess I'm saying in my view, for intelligence to be born,

1:17:39.520 --> 1:17:47.200
 you have to have a decentralization. Each one has to struggle and reach,

1:17:47.200 --> 1:17:54.320
 so each one in excess of energy has to reach for order as opposed to a central place doing so.

1:17:54.320 --> 1:18:01.040
 Have you ever read some sci fi where there's hive minds? The Verner Vinge, I think, has one of these

1:18:01.040 --> 1:18:07.040
 and then some of the stuff from the Commonwealth saga, the idea that you're an individual, but

1:18:07.040 --> 1:18:11.600
 you're connected with a few other individuals telepathically as well. Together, you form a swarm.

1:18:12.800 --> 1:18:19.280
 If you are, ask you, what do you think is the experience of, well, a borg, right? If you are

1:18:19.280 --> 1:18:24.480
 one, if you're part of this hive mind, outside of all the aesthetics, forget the aesthetics,

1:18:25.360 --> 1:18:29.920
 internally, what is your experience like? Because I have a theory as to what that looks like.

1:18:30.560 --> 1:18:36.240
 The one question I have for you about that experience is, how much is there feeling of freedom,

1:18:36.800 --> 1:18:44.960
 of free will? Because I obviously, as a human, very biased, but also somebody who values freedom

1:18:44.960 --> 1:18:55.920
 and bias, it feels like the experience of freedom is essential for trying stuff out, to being creative

1:18:55.920 --> 1:19:00.160
 and doing something truly novel, which is at the core of... Yeah. Well, I don't think you have to

1:19:00.160 --> 1:19:03.920
 lose any freedom when you're in that mode, because I think what happens is we think,

1:19:04.480 --> 1:19:08.160
 we still think, and I mean, you're still thinking about this in a sense of a top down,

1:19:08.160 --> 1:19:13.360
 command and control hierarchy, which is not what it has to be at all. I think the experience,

1:19:13.360 --> 1:19:18.960
 so I'll just show my cards here. I think the experience of being a robot in that robot swarm,

1:19:19.520 --> 1:19:23.840
 a robot who has agency over their own local environment that's doing sense making and

1:19:23.840 --> 1:19:30.560
 reporting it back to the hive mind, I think that robot's experience would be when the hive mind

1:19:30.560 --> 1:19:36.720
 is working well, it would be an experience of talking to God, that you essentially are reporting

1:19:37.360 --> 1:19:41.040
 to, you're sort of saying, here's what I see. I think this is what's going to happen over here.

1:19:41.040 --> 1:19:44.800
 I'm going to go do this thing, because I think if I want to do this, this will make this change

1:19:44.800 --> 1:19:52.160
 happen in the environment. And then, God, she may tell you, that's great. And in fact, your

1:19:52.160 --> 1:19:56.160
 brothers and sisters will join you to help make this go better, right? And then she can let your

1:19:56.160 --> 1:20:00.560
 brothers and sisters know, hey, Peter's going to go do this thing. Would you like to help him?

1:20:00.560 --> 1:20:03.680
 Because we think that this will make this thing go better. And they'll say, yes, we'll help him.

1:20:03.680 --> 1:20:09.920
 So the whole thing could be actually very emergent, the sense of what does it feel like to be a cell

1:20:09.920 --> 1:20:15.360
 in a network that is alive, that is generative. And I think actually the feeling is serendipity,

1:20:16.080 --> 1:20:23.600
 that there's random order, not random disorder or chaos, but random order, just when you need it

1:20:23.600 --> 1:20:28.560
 to hear Bruce Springsteen, you turn on the radio and bam, it's Bruce Springsteen, right?

1:20:28.560 --> 1:20:33.840
 That feeling of serendipity, I feel like this is a bit of a flight of fancy, but every cell in your

1:20:33.840 --> 1:20:39.040
 body must have like, what does it feel like to be a cell in your body? When it needs sugar,

1:20:39.040 --> 1:20:43.680
 there's sugar. When it needs oxygen, there's just oxygen. Now, when it needs to go and do its work

1:20:43.680 --> 1:20:49.200
 and pull like as one of your muscle fibers, right? It does its work and it's great. It contributes

1:20:49.200 --> 1:20:54.400
 to the cause, right? So this is all, again, a flight of fancy, but I think as we extrapolate up,

1:20:54.400 --> 1:20:58.640
 what does it feel like to be an independent individual with some bounded sense of freedom?

1:20:58.640 --> 1:21:02.480
 All sense of freedom is actually bounded, but it was a bounded sense of freedom that still lives

1:21:02.480 --> 1:21:07.040
 within a network that has order to it. And I feel like it has to be a feeling of serendipity.

1:21:07.040 --> 1:21:10.400
 So the cell, there's a feeling of serendipity, even though...

1:21:11.120 --> 1:21:14.000
 It has no way of explaining why it's getting oxygen and sugar when it gets it.

1:21:14.000 --> 1:21:19.520
 So you have to, each individual component has to be too dumb to understand the big picture.

1:21:20.240 --> 1:21:22.800
 No, the big picture is bigger than what it can understand.

1:21:22.800 --> 1:21:28.720
 But isn't that an essential characteristic of the individual is to be too dumb to understand

1:21:28.720 --> 1:21:33.920
 the bigger picture? Like not dumb necessarily, but limited in its capacity to understand.

1:21:33.920 --> 1:21:39.920
 Because the moment you understand, I feel like that leads to, if you tell me now

1:21:40.960 --> 1:21:44.800
 that there are some bigger intelligence controlling everything I do,

1:21:45.600 --> 1:21:50.880
 intelligence broadly defined, meaning like even the Sam Harris thing, there's no free will.

1:21:51.440 --> 1:21:58.880
 If I'm smart enough to truly understand that that's the case, that's kind of, I don't know if I...

1:21:58.880 --> 1:22:02.960
 Well, you have philosophical breakdown, right? Because we're in the West and we're pumped full

1:22:02.960 --> 1:22:07.760
 of this stuff of like you are a golden, fully free individual with all your freedoms and all

1:22:07.760 --> 1:22:11.360
 your liberties and go grab a gun and shoot whatever you want to. No, it's actually...

1:22:11.360 --> 1:22:17.280
 You don't actually have a lot of these... You're not unconstrained, but the areas where you can

1:22:17.920 --> 1:22:23.120
 manifest agency, you're free to do those things. You can say whatever you want on this podcast.

1:22:23.120 --> 1:22:24.800
 You can create a podcast, right? Yeah.

1:22:24.800 --> 1:22:29.040
 You're not... I mean, you have a lot of this kind of freedom, but even as you're doing this,

1:22:29.040 --> 1:22:35.120
 you are actually, I guess with the denouement of this is that we are already intelligent agents

1:22:35.760 --> 1:22:41.520
 in such a system, right? In that one of these like robots of one to five million little

1:22:41.520 --> 1:22:45.280
 swarm robots or one of the Borg, they're just posting an internal bulletin board.

1:22:45.280 --> 1:22:48.480
 I mean, maybe the Borg Cube is just a giant Facebook machine floating in space

1:22:48.480 --> 1:22:52.480
 and everyone's just posting on there. They're just posting really fast and like...

1:22:52.480 --> 1:22:53.680
 It's called the metaverse now.

1:22:53.680 --> 1:22:55.920
 The nest called the metaverse. That's right. Here's the enterprise. Maybe we should all

1:22:55.920 --> 1:22:58.800
 go shoot it. Yeah, everyone upvotes and they're going to go shoot it, right?

1:22:58.800 --> 1:23:04.240
 But we already are part of a human online collaborative environment and collaborative

1:23:04.240 --> 1:23:09.680
 sense making system. It's not very good yet. It's got the overhangs of zombie sense making

1:23:09.680 --> 1:23:14.400
 institutions all over it. But as that washes away and as we get better at this,

1:23:15.440 --> 1:23:21.840
 we are going to see humanity improving at speeds that are unthinkable in the past.

1:23:21.840 --> 1:23:24.560
 And it's not because anyone's freedoms were limited. In fact, the open source...

1:23:24.560 --> 1:23:26.720
 And we started this with open source software, right?

1:23:26.720 --> 1:23:31.200
 The collaboration, what the internet surfaced was the ability for people all over the world

1:23:31.200 --> 1:23:35.600
 to collaborate and produce some of the most foundational software that's in use today,

1:23:35.600 --> 1:23:38.080
 right? That entire ecosystem was created by collaborators all over the place.

1:23:38.880 --> 1:23:45.920
 So these online kind of swarm kind of things are not novel. I'm just suggesting that

1:23:45.920 --> 1:23:51.360
 future AI systems, if you can build one smart system, you have no reason not to build multiple.

1:23:51.360 --> 1:23:57.040
 If you build multiple, there's no reason not to integrate them all into a collective sense making

1:23:57.040 --> 1:24:01.760
 substrate. And that thing will certainly have immersion intelligence that none of the individuals

1:24:01.760 --> 1:24:06.720
 and probably not any of the human designers will be able to really put a bow around and explain.

1:24:06.720 --> 1:24:14.480
 But in some sense, would that AI system still be able to go like rural Texas by ranch,

1:24:14.480 --> 1:24:21.520
 go off the grid, go full survivalist? Can you disconnect from the hive mind?

1:24:22.400 --> 1:24:23.280
 You may not want to.

1:24:25.120 --> 1:24:27.920
 So to be an effective, to be intelligent.

1:24:27.920 --> 1:24:31.040
 You have access to way more intelligence capability if you're plugged into five

1:24:31.040 --> 1:24:34.000
 million other really, really smart cyborgs. Why would you leave?

1:24:34.800 --> 1:24:40.480
 So like there's a word control that comes to mind. So it doesn't feel like control,

1:24:40.480 --> 1:24:45.200
 like overbearing control. It's just knowledge.

1:24:45.200 --> 1:24:49.280
 I think systems, well, this is to your point. I mean, look at how uncomfortable you are with

1:24:49.280 --> 1:24:54.800
 this concept, right? I think systems that feel like overbearing control will not evolutionarily

1:24:54.800 --> 1:25:00.080
 win out. I think systems that give their individual elements the feeling of serendipity and the

1:25:00.080 --> 1:25:06.400
 feeling of agency that those systems will win. But that's not to say that there will not be

1:25:06.400 --> 1:25:11.920
 emergent higher level order on top of it. And that's the thing, that's the philosophical breakdown

1:25:11.920 --> 1:25:16.800
 that we're staring right at, which is in the Western mind, I think there's a very sharp

1:25:16.800 --> 1:25:24.800
 delineation between explicit control. Cartesian, like what is the vector? Where is the position?

1:25:24.800 --> 1:25:31.360
 Where is it going? It's completely deterministic. And kind of this idea that things emerge,

1:25:31.360 --> 1:25:37.200
 everything we see is the emergent patterns of other things. And there is agency when there's

1:25:37.200 --> 1:25:44.560
 extra energy. So you have spoken about a kind of meaning crisis that we're going through.

1:25:45.840 --> 1:25:55.040
 But it feels like since we invented sex and death, we broadly speaking, we've been searching for a

1:25:55.040 --> 1:25:59.760
 kind of meaning. So it feels like human civilization has been going through a meaning crisis of

1:25:59.760 --> 1:26:07.360
 different flavors throughout its history. Why is how is this particular meaning crisis different?

1:26:07.360 --> 1:26:11.520
 Or is it really a crisis and it wasn't previously? What's your sense?

1:26:11.520 --> 1:26:16.000
 A lot of human history, there wasn't so much a meaning crisis. There was just a food and not

1:26:16.000 --> 1:26:21.040
 getting eaten by bears crisis. Once you get to a point where you can make food, there was the

1:26:21.040 --> 1:26:26.160
 not getting killed by other humans crisis. So sitting around wondering what is it all about,

1:26:26.160 --> 1:26:32.640
 it's actually a relatively recent luxury. And to some extent, the meaning crisis coming out of

1:26:32.640 --> 1:26:38.160
 that is precisely because... Well, it's not precisely because I believe that meaning is the

1:26:38.160 --> 1:26:46.160
 consequence of when we make consequential decisions. It's tied to agency. When we make

1:26:46.160 --> 1:26:51.040
 consequential decisions, that generates meaning. So if we make a lot of decisions,

1:26:51.040 --> 1:26:54.400
 but we don't see the consequences of them, then it feels like what was the point?

1:26:54.400 --> 1:26:58.240
 Right? But if there's all these big things happening, but words are long for the ride,

1:26:58.240 --> 1:27:02.320
 then it also does not feel very meaningful. Meaning, as far as I can tell, this is my

1:27:02.320 --> 1:27:09.200
 working definition of Serga 2021 is generally the result of a person making a consequential

1:27:09.200 --> 1:27:13.520
 decision, acting on it, and then seeing the consequences of it. So historically,

1:27:14.640 --> 1:27:18.400
 just when humans are in survival mode, you're making consequential decisions all the time.

1:27:19.360 --> 1:27:22.560
 So there's not a lack of meaning because you either got eaten or you didn't.

1:27:22.560 --> 1:27:27.440
 Right? You got some food and that's great. You feel good. These are all consequential decisions.

1:27:27.440 --> 1:27:35.600
 Only in the post fossil fuel and industrial revolution could we create a massive leisure

1:27:35.600 --> 1:27:44.320
 class. I could sit around not being threatened by bears, not starving to death, making decisions

1:27:44.320 --> 1:27:48.480
 somewhat, but a lot of times not seeing the consequences of any decisions they make.

1:27:48.480 --> 1:27:54.880
 The general sense of anomy, I think there's the French term for it, in the wake of the consumer

1:27:54.880 --> 1:28:02.240
 society, in the wake of mass media telling everyone, hey, choosing between Hermes and Chanel is a

1:28:02.240 --> 1:28:05.600
 meaningful decision. No, it's not. I don't know what either of those mean.

1:28:05.600 --> 1:28:13.360
 Oh, there's high end luxury purses and crap like that. But the point is that we give people the

1:28:13.360 --> 1:28:19.280
 idea that consumption is meaning, that making a choice of this team versus that team spectating has

1:28:19.280 --> 1:28:26.480
 meaning. So we produce all of these different things that are as if meaning, but really making

1:28:26.480 --> 1:28:31.040
 a decision that has no consequences for us. And so that creates the meaning crisis.

1:28:31.040 --> 1:28:35.120
 Well, you're saying choosing between Chanel and the other one has no consequence?

1:28:36.400 --> 1:28:39.520
 Why is one more meaningful than the other? It's not that it's more meaningful than the other.

1:28:39.520 --> 1:28:44.560
 It's that you make a decision between these two brands and you're told this brand will make me

1:28:44.560 --> 1:28:49.120
 look better in front of other people. If I buy this brand of car, if I wear that brand of apparel,

1:28:50.080 --> 1:28:55.360
 the idea, like a lot of decisions we make are around consumption, but consumption by itself

1:28:55.360 --> 1:29:01.600
 doesn't actually yield meaning. Gaining social status does provide meaning. So that's why in this

1:29:01.600 --> 1:29:08.480
 era of abundant production, so many things turn into status games. Then the NFT kind of explosion

1:29:08.480 --> 1:29:14.400
 is a similar kind of thing. Everywhere there are status games because we just have so much

1:29:14.400 --> 1:29:21.440
 excess production. But aren't those status games a source of meaning? Why do the games we play have

1:29:21.440 --> 1:29:26.080
 to be grounded in physical reality like they are when you're trying to run away from lions?

1:29:26.080 --> 1:29:31.840
 Why can't we in this virtuality world on social media, why can't we play the games on social

1:29:31.840 --> 1:29:37.680
 media, even the dark ones? Right, we can. But you're saying that's creating a meaning crisis.

1:29:37.680 --> 1:29:42.960
 Well, there's a meaning crisis in that there's two aspects of it. Number one, playing those kinds

1:29:42.960 --> 1:29:52.960
 of status games oftentimes requires destroying the planet because it ties to consumption, consuming

1:29:52.960 --> 1:29:57.440
 the latest and greatest version of a thing, buying the latest limited edition sneaker,

1:29:57.440 --> 1:30:01.040
 and throwing out all the old ones. Maybe it keeps in the old ones, but the amount of sneakers we

1:30:01.040 --> 1:30:05.760
 have to cut up and destroy every year to create artificial scarcity for the next generation.

1:30:05.760 --> 1:30:09.120
 Right? This is kind of stuff that's not great. It's not great at all.

1:30:10.560 --> 1:30:17.040
 So, can speakers consumption fueling status games is really bad for the planet, not sustainable?

1:30:17.040 --> 1:30:22.160
 The second thing is you can play these kinds of status games, but then what it does is it

1:30:22.160 --> 1:30:27.040
 renders you captured to the virtual environment. The status games that really wealthy people are

1:30:27.040 --> 1:30:31.280
 playing are all around the hard resources where they're going to build the factories,

1:30:31.280 --> 1:30:34.080
 they're going to have the fuel in the rare earths to make the next generation of robots.

1:30:34.080 --> 1:30:39.200
 They're then going to run circles around you and your children. So, that's another reason

1:30:39.200 --> 1:30:44.960
 not to play those virtual status games. So, you're saying ultimately the big picture game is one

1:30:45.840 --> 1:30:50.400
 by people who have access or control over actual hard resources. So, you can't,

1:30:51.200 --> 1:30:56.720
 you don't see a society where most of the games are played in the virtual space.

1:30:56.720 --> 1:31:00.560
 They'll be captured in the physical space. It all builds. It's just like the stack

1:31:00.560 --> 1:31:07.360
 of human being. If you only play the game at the cultural and intellectual level,

1:31:07.360 --> 1:31:12.160
 then the people with the hard resources and access to layer zero physical are going to own you.

1:31:12.800 --> 1:31:17.920
 But isn't money not connected to or less and less connected to hard resources and money still

1:31:17.920 --> 1:31:23.120
 seems to work? It's a virtual technology. There's different kinds of money. Part of the reason that

1:31:23.120 --> 1:31:32.880
 some of the stuff is able to go a little unhinged is because the big sovereignties where one spends

1:31:32.880 --> 1:31:38.320
 money and uses money and plays money games and inflates money, their ability to adjudicate

1:31:39.120 --> 1:31:42.960
 the physical resources and hard resources on land and things like that, those have not been

1:31:42.960 --> 1:31:49.200
 challenged in a very long time. So, we went off the gold standard. Most money is not connected

1:31:49.200 --> 1:31:57.520
 to physical resources. It's an idea. And that idea is very closely connected to status.

1:31:59.920 --> 1:32:04.880
 But it's also tied to, it's actually tied to law. It is tied to some physical hard things. So,

1:32:04.880 --> 1:32:11.440
 you have to pay your taxes. Yes. So, it's always at the end going to be connected to the blockchain

1:32:11.440 --> 1:32:18.640
 of physical reality. So, in the case of law and taxes, it's connected to government and government

1:32:18.640 --> 1:32:29.040
 is what? Violence is the, I'm playing a stack of devil's advocates here. And popping one devil

1:32:29.040 --> 1:32:33.120
 off the stack at a time. Isn't ultimately, of course, it'll be connected to physical reality,

1:32:33.120 --> 1:32:36.640
 but just because people control the physical reality, it doesn't mean the status,

1:32:37.680 --> 1:32:41.440
 LeBron James, in theory, could make more money than the owners of the teams

1:32:42.320 --> 1:32:47.360
 in theory. And to me, that's a virtual idea. So, somebody else constructed a game

1:32:47.360 --> 1:32:53.440
 and now you're playing in the virtual space of the game. And so, it just feels like there could

1:32:53.440 --> 1:33:01.280
 be games where status, we build realities that give us meaning in the virtual space. I can imagine

1:33:01.280 --> 1:33:06.240
 such things being possible. Oh, yeah. Okay. So, I think I see what you're saying there. With

1:33:06.240 --> 1:33:10.720
 the idea there, I mean, we'll take the LeBron James side and put in some YouTube influencer.

1:33:10.720 --> 1:33:16.480
 Yes, sure. Right. So, the YouTube influencer, it is status games, but at a certain level,

1:33:16.480 --> 1:33:22.560
 it precipitates into real dollars. Well, you look at Mr. Beast, right? He's setting off

1:33:22.560 --> 1:33:25.680
 half a million dollars worth of fireworks or something on a YouTube video.

1:33:25.680 --> 1:33:29.600
 And also, saving trees and so on. Sure, right. They're trying to plan a

1:33:29.600 --> 1:33:33.200
 million trees with Mark Rober or whatever it was. Yeah. It's not that those kinds of games can't

1:33:33.200 --> 1:33:39.840
 lead to real consequences. It's that for the vast majority of people in consumer culture,

1:33:39.840 --> 1:33:47.040
 they are incented by the... I would say mostly I'm thinking about middle class consumers.

1:33:47.680 --> 1:33:52.480
 They're incented by advertisements. They're incented by their memetic environment to treat

1:33:53.040 --> 1:33:58.240
 the purchasing of certain things, the need to buy the latest model, whatever, the need to appear,

1:33:58.240 --> 1:34:04.720
 however, the need to pursue status games as a driver of meaning. And my point would be that

1:34:04.720 --> 1:34:10.240
 it's a very hollow driver of meaning. And that is what creates a meaning crisis because at the

1:34:10.240 --> 1:34:14.480
 end of the day, it's like eating a lot of empty calories, right? Yeah, it tasted good going down.

1:34:14.480 --> 1:34:18.240
 It's a lot of sugar, but man, it was not enough protein to help build your muscles.

1:34:18.240 --> 1:34:22.640
 And you kind of feel that in your gut. And I think that's... I mean, all this stuff aside and

1:34:22.640 --> 1:34:27.360
 setting aside our discussion on currency, which I hope we get back to, that's what I mean about

1:34:27.360 --> 1:34:34.560
 the meaning crisis, part of it being created by the fact that we're not encouraged to have

1:34:34.560 --> 1:34:42.080
 more and more direct relationships. We're actually alienated from relating to even our family members

1:34:42.080 --> 1:34:48.000
 sometimes, right? We're encouraged to relate to brands. We're encouraged to relate to these kinds

1:34:48.000 --> 1:34:54.160
 of things that then tell us to do things that are really of low consequence. And that's where

1:34:54.160 --> 1:34:58.000
 the meaning crisis comes from. So the role of technology in this... So there's somebody you

1:34:58.000 --> 1:35:05.840
 mentioned who's Jacques Eliel. His view of technology, he warns about the towering piles

1:35:05.840 --> 1:35:12.240
 of technique, which I guess is a broad idea of technology. So I think, correct me if I'm wrong

1:35:12.240 --> 1:35:18.640
 for him, technology is bad at moving away from human nature and ultimately is destructive.

1:35:19.360 --> 1:35:24.160
 My question broadly speaking in this meaning crisis, what are the pros and cons of technology?

1:35:24.160 --> 1:35:28.800
 Can it be a good? Yeah, I think it can be. I certainly draw on some of Elul's

1:35:28.800 --> 1:35:34.560
 ideas and I think some of them are pretty good. But the way he defines technique is

1:35:35.760 --> 1:35:40.160
 well, also, Simonda as well. I mean, he speaks to the general mentality of efficiency,

1:35:40.800 --> 1:35:46.080
 homogenized processes, homogenized production, homogenized labor to produce homogenized artifacts

1:35:46.800 --> 1:35:53.440
 that then are not actually... They don't sit well in the environment. So it's essentially,

1:35:53.440 --> 1:36:01.200
 you can think of it as the antonym of craft. Whereas a craftsman will come to a problem,

1:36:01.760 --> 1:36:05.760
 maybe a piece of wood and they need to make into a chair. It may be a site to build a house or

1:36:05.760 --> 1:36:12.480
 build a stable or build whatever. And they will consider how to bring various things in to build

1:36:12.480 --> 1:36:19.200
 something well contextualized that's in right relationship with that environment.

1:36:19.200 --> 1:36:26.720
 But the way we have driven technology over the last 150 years is not that at all. It is how can we

1:36:27.520 --> 1:36:34.720
 make sure the input materials are homogenized, cut to the same size, diluted and doped to exactly

1:36:34.720 --> 1:36:38.880
 the right alloy concentrations. How do we create machines that then consume exactly the right kind

1:36:38.880 --> 1:36:43.440
 of energy to be able to run at this high speed to stamp out the same parts, which then go out the

1:36:43.440 --> 1:36:47.120
 door. Everyone gets the same tickle, Mielmo. And the reason why everyone wants it is because we

1:36:47.120 --> 1:36:52.880
 have broadcasts that tells everyone, this is the cool thing. So homogenized demand. And we're like

1:36:52.880 --> 1:36:58.320
 Baudrillard and the other critiques of modernity coming from that direction, the situationalist

1:36:58.320 --> 1:37:04.480
 as well. It's that their point is that at this point in time, consumption is the thing that drives

1:37:04.480 --> 1:37:08.720
 a lot of the economic stuff, not the need, but the need to consume and build status games on top.

1:37:09.360 --> 1:37:14.720
 So we have homogenized, when we discovered, I think this is really like Bernays and stuff,

1:37:14.720 --> 1:37:20.800
 in the early 20th century, we discovered we can create, we can create demand. We can create desire

1:37:20.800 --> 1:37:27.520
 in a way that was not possible before because of broadcast media. And not only do we create desire,

1:37:27.520 --> 1:37:31.680
 we don't create a desire for each person to connect to some bespoke thing to build a relationship

1:37:31.680 --> 1:37:35.920
 with their neighbor or their spouse. We are telling them, you need to consume this brand.

1:37:35.920 --> 1:37:39.200
 You need to drive this vehicle. You got to listen to this music. Have you heard this?

1:37:39.200 --> 1:37:45.680
 Have you seen this movie? So creating homogenized demand makes it really cheap to create homogenized

1:37:45.680 --> 1:37:50.400
 product. And now you have economics of scale. So we make the same tickle myelmo, give it to

1:37:50.400 --> 1:37:57.520
 all the kids. And all the kids are like, hey, I got a tickle myelmo. So this is ultimately where

1:37:57.520 --> 1:38:04.720
 this ties in then to runaway hyper capitalism is that capitalism is always looking for growth.

1:38:04.720 --> 1:38:08.880
 It's always looking for growth. And growth only happens at the margins. So you have to squeeze

1:38:08.880 --> 1:38:12.160
 more and more demand out. You got to make it cheaper and cheaper to make the same thing.

1:38:12.160 --> 1:38:17.120
 But tell everyone they're still getting meaning from it. This is still your tickle myelmo.

1:38:18.080 --> 1:38:23.120
 And we see little bits of this, critiques of this dripping in popular culture. You see it

1:38:23.120 --> 1:38:28.960
 sometimes. It's when Buzz Lightyear walks into the thing, he's like, oh my God, at the toy store,

1:38:28.960 --> 1:38:33.520
 I'm just a toy. There's millions of other, or there's hundreds of other Buzz Lightyears just

1:38:33.520 --> 1:38:40.080
 like me, right? That is, I think, a fun Pixar critique on this homogenization dynamic.

1:38:40.080 --> 1:38:44.560
 I agree with you on most of the things you're saying. So I'm playing devil's advocate here.

1:38:44.560 --> 1:38:54.400
 But this homogenized machine of capitalism is also the thing that is able to fund if

1:38:54.400 --> 1:39:01.200
 channeled correctly innovation, invention, and development of totally new things that

1:39:01.200 --> 1:39:05.200
 in the best possible world create all kinds of new experiences that can enrich lives,

1:39:06.560 --> 1:39:14.000
 the quality of lives for all kinds of people. So isn't this the machine that actually enables

1:39:14.000 --> 1:39:17.440
 the experiences and more and more experiences that would then give meaning?

1:39:18.560 --> 1:39:23.760
 It has done that to some extent. I mean, it's not all good or bad in my perspective.

1:39:24.560 --> 1:39:29.280
 We can always look backwards and offer a critique of the path we've taken to get

1:39:29.280 --> 1:39:34.800
 to this point in time. But that's somewhat different and informs the discussion,

1:39:35.760 --> 1:39:39.520
 but it's somewhat different than the question of where do we go in the future, right?

1:39:40.560 --> 1:39:44.000
 Is this still the same rocket we need to ride to get to the next point? We'll even get us to

1:39:44.000 --> 1:39:47.600
 the next point. Well, how does this, so you're predicting the future, how does it go wrong in

1:39:47.600 --> 1:39:54.960
 your view? We have the mechanisms we have now explored enough technologies to where we can

1:39:54.960 --> 1:40:02.000
 actually, I think, sustainably produce what most people in the world need to live.

1:40:03.360 --> 1:40:10.320
 We have also created the infrastructures to allow continued research and development

1:40:10.320 --> 1:40:14.160
 of additional science and medicine and various other kinds of things.

1:40:16.160 --> 1:40:19.840
 The organizing principles that we use to govern all these things today

1:40:19.840 --> 1:40:27.280
 have been, a lot of them have been just inherited from, honestly, medieval times.

1:40:28.400 --> 1:40:33.840
 Some of them have refactored a little bit in the industrial era, but a lot of these modes

1:40:33.840 --> 1:40:43.360
 of organizing people are deeply problematic. Furthermore, they're rooted in, I think, a

1:40:43.360 --> 1:40:49.600
 very industrial mode perspective on human labor. This is one of those things I'm going to go back

1:40:49.600 --> 1:40:55.280
 to the open source thing. There was a point in time when, well, let me ask you this. If you look

1:40:55.280 --> 1:41:01.600
 at the core SciPy collection of libraries, that's SciPy NumPy Mapplotlib. There's SciPython Notebook.

1:41:01.600 --> 1:41:08.640
 Let's throw pandas in there, scikit learn, a few of these things. How much value do you think,

1:41:08.640 --> 1:41:11.120
 economic value, would you say they drive in the world today?

1:41:13.040 --> 1:41:19.280
 That's one of the fascinating things about talking to you and Travis. It's a measure

1:41:19.280 --> 1:41:22.320
 with at least $1 billion a day, maybe?

1:41:22.320 --> 1:41:28.000
 $1 billion, sure. It's similar question of how much value does Wikipedia create.

1:41:31.520 --> 1:41:32.560
 All of it? I don't know.

1:41:32.560 --> 1:41:36.720
 Well, I mean, if you look at our systems, when you do a Google search, some of that stuff runs

1:41:36.720 --> 1:41:41.040
 through TensorFlow, but when you look at Siri, when you do credit card transaction,

1:41:42.480 --> 1:41:46.480
 just everything, every intelligence agency under the sun, they're using some aspect of

1:41:46.480 --> 1:41:51.440
 these kinds of tools. I would say that these create billions of dollars of value.

1:41:51.440 --> 1:41:53.840
 Oh, you mean like direct use of tools that leverage this?

1:41:53.840 --> 1:41:56.560
 Yeah, even that's billions a day, yeah.

1:41:56.560 --> 1:42:00.560
 Yeah, easily. I think the things they could not do if they didn't have these tools.

1:42:02.720 --> 1:42:05.840
 That's billions of dollars a day. Great. I think that's about right. Now,

1:42:05.840 --> 1:42:10.880
 if we take how many people did it take to make that? There was a point in time,

1:42:10.880 --> 1:42:13.680
 not anymore, but there was a point in time when they could fit in a van. I could have

1:42:13.680 --> 1:42:18.400
 fit them in my Mercedes printer. If you look at that, like holy crap,

1:42:19.120 --> 1:42:25.760
 literally a van of maybe a dozen people could create value to the tune of billions of dollars

1:42:27.200 --> 1:42:29.920
 a day. What lesson do you draw from that?

1:42:29.920 --> 1:42:36.560
 Well, here's the thing. What can we do to do more of that? That's open source. The way I've

1:42:36.560 --> 1:42:42.960
 talked about this in other environments is when we use generative participatory crowd

1:42:42.960 --> 1:42:50.480
 sourced approaches, we unlock human potential at a level that is better than what capitalism can do.

1:42:52.080 --> 1:42:57.200
 I would challenge anyone to go and try to hire the right 12 people in the world

1:42:58.160 --> 1:43:02.880
 to build that entire stack the way those 12 people did that. They would be very,

1:43:02.880 --> 1:43:06.560
 very hard to press to do that. If a hedge fund could just hire a dozen people

1:43:06.560 --> 1:43:10.640
 and create something that is worth billions of dollars a day, every single one of them

1:43:10.640 --> 1:43:15.040
 will be racing to do it. Finding the right people, fostering the right collaborations,

1:43:15.040 --> 1:43:19.600
 getting it adopted by the right other people to then refine it, that is a thing that was

1:43:19.600 --> 1:43:24.320
 organic in nature. That took crowdsourcing. That took a lot of the open source ethos and it took

1:43:24.320 --> 1:43:29.120
 the right kinds of people. None of those people who started that said, I need to have a part of a

1:43:29.120 --> 1:43:33.840
 multi billion dollar a day enterprise. They're like, I'm doing this cool thing to solve my

1:43:33.840 --> 1:43:39.840
 problem for my friends. The point of telling the story is to say that our way of thinking about

1:43:39.840 --> 1:43:44.480
 value, our way of thinking about allocation of resources, our ways of thinking about property

1:43:44.480 --> 1:43:49.920
 rights and all these kinds of things, they come from finite game, scarcity mentality,

1:43:49.920 --> 1:43:56.960
 medieval institutions. As we are now entering, to some extent, we're in a post scarcity era,

1:43:56.960 --> 1:44:01.200
 although some people are hoarding a whole lot of stuff. We are at a point where,

1:44:01.200 --> 1:44:06.400
 if not now soon, we'll be in a post scarcity era. The question of how we allocate resources

1:44:06.400 --> 1:44:10.880
 has to be revisited at a fundamental level, because the kind of software these people built,

1:44:10.880 --> 1:44:17.840
 the modalities that those human ecologies that built the software, it treats softwares unproperty.

1:44:17.840 --> 1:44:24.960
 Actually, sharing creates value. Restricting and forking reduces value. That's different than

1:44:24.960 --> 1:44:28.640
 any other physical resource that we've ever dealt with. It's different than how most corporations

1:44:28.640 --> 1:44:36.880
 treat software IP. If treating software in this way created this much value so efficiently,

1:44:36.880 --> 1:44:43.120
 so cheaply, because feeding a dozen people for 10 years is really cheap. That's the reason I care

1:44:43.120 --> 1:44:48.320
 about this right now is because looking forward when we can automate a lot of labor, where we can,

1:44:48.320 --> 1:44:54.080
 in fact, the programming for your robot in your neck of the woods and your part of the Amazon to

1:44:54.080 --> 1:44:58.960
 build something sustainable for you and your tribe to deliver the right medicines to take care of the

1:44:58.960 --> 1:45:06.240
 kids, that's just software. That's just code. That could be totally open sourced. We can actually

1:45:06.240 --> 1:45:11.680
 get to a mode where all of these additional generative things that humans are doing,

1:45:12.320 --> 1:45:18.240
 they don't have to be wrapped up in a container and then we charge for all the exponential dynamics

1:45:18.240 --> 1:45:23.040
 out of it. That's what Facebook did. That's what modern social media did, because the old internet

1:45:23.040 --> 1:45:26.720
 was connecting people just fine. Facebook came along and said, well, anyone can post a picture,

1:45:26.720 --> 1:45:30.880
 anyone can post some text, and we're going to amplify the crap out of it to everyone else,

1:45:30.880 --> 1:45:34.880
 and it exploded this generative network of human interaction, and then I said,

1:45:34.880 --> 1:45:38.960
 how do I make money off that? Oh yeah, I'm going to be a gatekeeper on everybody's attention,

1:45:39.680 --> 1:45:47.040
 and that's how we make money. How do we create more than one van? How do we have millions of vans

1:45:47.040 --> 1:45:54.720
 full of people that create NumPy, SciPy, that create Python? The story of those people is often

1:45:54.720 --> 1:45:59.440
 they have some kind of job outside of this. This is what they're doing for fun. Don't you need to

1:45:59.440 --> 1:46:09.040
 have a job? Don't you have to be connected, plugged in to the capitalist system? Isn't this consumerism,

1:46:09.040 --> 1:46:15.840
 the engine that results in the individuals that take a break from it every once in a while to

1:46:15.840 --> 1:46:22.560
 create something magical at the edges? The question of surplus, this is the question. If everyone

1:46:22.560 --> 1:46:26.240
 were to go and run their own farm, no one would have time to go and write NumPy, SciPy,

1:46:26.240 --> 1:46:32.720
 right? Maybe, but that's what I'm talking about when I say we're maybe at a post scarcity point

1:46:32.720 --> 1:46:38.800
 for a lot of people. The question that we're never encouraged to ask in a Super Bowl ad is,

1:46:38.800 --> 1:46:44.000
 how much do you need? How much is enough? Do you need to have a new car every two years,

1:46:44.000 --> 1:46:47.600
 every five? If you have a reliable car, can you drive one for 10 years? Is that all right?

1:46:48.400 --> 1:46:52.720
 I had a car for 10 years and it was fine. Your iPhone, do you have to upgrade every two years?

1:46:52.720 --> 1:46:56.560
 I mean, you're using the same apps you did four years ago, right?

1:46:56.560 --> 1:46:58.160
 This should be a Super Bowl ad.

1:46:58.160 --> 1:46:59.840
 This should be a Super Bowl ad. That's great. Maybe somebody...

1:46:59.840 --> 1:47:01.280
 Do you really need a new iPhone?

1:47:01.280 --> 1:47:05.600
 Maybe one of our listeners will fund something like this of like, no, but just actually

1:47:05.600 --> 1:47:12.560
 bring it back, bring it back to actually the question of what do you need? How do we create

1:47:12.560 --> 1:47:19.760
 the infrastructure for collectives of people to live on the basis of providing what we need,

1:47:19.760 --> 1:47:23.680
 meeting people's needs with a little bit of access to handle emergencies and things like that,

1:47:24.320 --> 1:47:29.280
 pulling our resources together to handle the really, really big emergencies, somebody with a

1:47:29.280 --> 1:47:34.800
 really rare cat form of cancer or some massive fire sweeps through half the village or whatever,

1:47:34.800 --> 1:47:43.360
 but can we actually unscale things and solve for people's needs and then give them the capacity

1:47:44.080 --> 1:47:46.560
 to explore how to be the best version of themselves?

1:47:47.120 --> 1:47:52.000
 And for Travis, that was throwing away his shot of tenure in order to write NumPy.

1:47:52.720 --> 1:47:58.640
 For others, there is a saying in the sci fi community that sci fi advance is one failed

1:47:58.640 --> 1:48:05.520
 postdoc at a time and we can do these things. We can actually do this kind of collaboration

1:48:05.520 --> 1:48:10.880
 because code, software information organization, that's cheap. Those bits are very cheap to

1:48:10.880 --> 1:48:11.840
 fling across the oceans.

1:48:12.800 --> 1:48:17.280
 So you mentioned Travis. We've been talking and we'll continue to talk about open source.

1:48:19.360 --> 1:48:23.280
 Maybe you can comment, how did you meet Travis? Who is Travis Alfon?

1:48:23.280 --> 1:48:30.000
 What's your relationship been like through the years? Where did you work together?

1:48:30.000 --> 1:48:34.960
 How did you meet? What's the present and the future look like?

1:48:34.960 --> 1:48:38.560
 Yeah. So the first time I met Travis was at a sci fi conference in Pasadena.

1:48:39.120 --> 1:48:40.080
 Do you remember the year?

1:48:40.720 --> 1:48:46.400
 2005. I was working at Nthought, working on scientific computing, consulting,

1:48:46.400 --> 1:48:53.680
 and a couple of years later, he joined us at Nthought, I think 2007.

1:48:55.120 --> 1:49:00.480
 And he came in as the president, one of the founders of Nthought was the CEO, Eric Jones.

1:49:01.760 --> 1:49:04.880
 And we were all very excited that Travis was joining us and that was great fun.

1:49:04.880 --> 1:49:09.600
 And so I worked with Travis on a number of consulting projects and we worked on

1:49:10.880 --> 1:49:14.480
 some open source stuff. I mean, it was just a really, it was a good time there.

1:49:14.480 --> 1:49:17.600
 It was primarily Python related?

1:49:17.600 --> 1:49:20.080
 Oh yeah, it was all Python, NumPy, sci fi consulting kind of stuff.

1:49:20.800 --> 1:49:26.560
 Towards the end of that time, we started getting called into more and more finance shops.

1:49:27.520 --> 1:49:31.840
 They were adopting Python pretty heavily. I did some work on like a high frequency

1:49:31.840 --> 1:49:35.440
 trading shop, working on some stuff, and then we worked together on some

1:49:36.640 --> 1:49:42.000
 a couple of investment banks in Manhattan. And so we started seeing that there was a

1:49:42.000 --> 1:49:45.600
 potential to take Python in the direction of business computing.

1:49:45.600 --> 1:49:49.680
 More than just being this niche like MATLAB replacement for big vector computing,

1:49:50.400 --> 1:49:54.000
 what we were seeing was, oh yeah, you could actually use Python as a Swiss army knife to do

1:49:54.000 --> 1:49:59.600
 a lot of shadow data transformation kind of stuff. So that's when we realized the potential

1:49:59.600 --> 1:50:04.560
 was much greater. And so we started Anaconda, I mean, it was called Continuum Analytics at the

1:50:04.560 --> 1:50:10.640
 time, but we started in January of 2012 with the vision of shoring up the parts of Python

1:50:10.640 --> 1:50:15.200
 that needed to get expanded to handle data at scale, to do web visualization, application

1:50:15.200 --> 1:50:22.560
 development, et cetera. And that was that, yeah. So he was CEO and I was president for the first

1:50:23.120 --> 1:50:28.800
 five years. And then we raised some money and then the board, it was sort of put in a new CEO.

1:50:28.800 --> 1:50:34.880
 They hired a kind of professional CEO. And then Travis, you laugh out that, I took over the CTO

1:50:34.880 --> 1:50:40.960
 role, Travis then left after a year to do his own thing, to do Quonsite, which was more oriented

1:50:40.960 --> 1:50:46.000
 around some of the bootstrap years that we did at Continuum, where it was open source and consulting.

1:50:46.000 --> 1:50:49.760
 It wasn't sort of like gung ho product development. And it wasn't focused on,

1:50:49.760 --> 1:50:52.560
 you know, we accidentally stumbled into the package management problem

1:50:53.680 --> 1:50:58.400
 at Anaconda. But we had a lot of other visions of other technology that we built in the open

1:50:58.400 --> 1:51:04.000
 source. And Travis was really trying to push, again, the frontiers of numerical computing,

1:51:04.000 --> 1:51:08.400
 vector computing, handling things like auto differentiation and stuff intrinsically in

1:51:08.400 --> 1:51:17.440
 the open ecosystem. So I think that's kind of the direction he's working on in some of his work.

1:51:18.080 --> 1:51:23.200
 We remain great friends and colleagues and collaborators, even though he's no longer

1:51:23.840 --> 1:51:28.320
 day to day working at Anaconda. But he gives me a lot of feedback about this and that and the other.

1:51:28.320 --> 1:51:34.800
 What's a big lesson you've learned from Travis about life or about programming or about leadership?

1:51:35.360 --> 1:51:38.880
 Wow, there's a lot. There's a lot. Travis is a really, really good guy.

1:51:40.240 --> 1:51:42.720
 His heart is really in it. He cares a lot.

1:51:44.480 --> 1:51:48.480
 I've gotten that sense having to interact with him. It's so interesting, such a good

1:51:48.480 --> 1:51:52.080
 he's a really good dude. And he and I, you know, it's so interesting. We come from very different

1:51:52.080 --> 1:52:00.720
 backgrounds. We're quite different as people. But I think we can not talk for a long time

1:52:00.720 --> 1:52:08.160
 and then be on a conversation and be eye to eye on 90% of things. And so he's someone who I believe,

1:52:08.160 --> 1:52:12.560
 no matter how much fog settles in over the ocean, his ship, my ship are pointed in the

1:52:12.560 --> 1:52:17.440
 same direction to the same star. Wow, that's a beautiful way to phrase it. No matter how much

1:52:17.440 --> 1:52:22.160
 fog there is or pointed at the same star. Yeah, and I hope he feels the same way. I mean, I hope

1:52:22.160 --> 1:52:27.760
 he knows that over the years now. We both care a lot about the community. For someone who cares so

1:52:27.760 --> 1:52:31.280
 deeply, I would say this about Travis, that's interesting. For someone who cares so deeply

1:52:31.280 --> 1:52:36.880
 about the nerd details of like type system design and vector computing and efficiency of

1:52:36.880 --> 1:52:41.840
 expressing this and that and the other, memory layouts and all that stuff, he cares even more

1:52:41.840 --> 1:52:50.240
 about the people in the ecosystem, the community. And I have a similar kind of alignment. I care a

1:52:50.240 --> 1:52:58.720
 lot about the tech. I really do. But for me, the beauty of what this human ecology has produced

1:52:59.280 --> 1:53:03.600
 is, I think, a touchstone. It's an early version. We should look at it and say,

1:53:03.600 --> 1:53:07.680
 how do we replicate this for humanity at scale? What this open source collaboration was able to

1:53:07.680 --> 1:53:12.800
 produce? How can we be generative in human collaboration moving forward and create that as

1:53:12.800 --> 1:53:18.320
 a civilizational kind of dynamic? Can we seize this moment to do that? Because a lot of the

1:53:18.320 --> 1:53:24.720
 other open source movements, it's all nerds nerding out on code for nerds. And this,

1:53:24.720 --> 1:53:29.280
 because it's scientists, because it's people working on data that all of it faces real human

1:53:29.280 --> 1:53:33.760
 problems, I think we have an opportunity to actually make a bigger impact.

1:53:33.760 --> 1:53:38.240
 Is there a way for this kind of open source vision to make money?

1:53:39.040 --> 1:53:40.080
 Absolutely.

1:53:40.080 --> 1:53:43.040
 To fund the people involved. Is that an essential part of it?

1:53:43.040 --> 1:53:49.440
 It's hard. But we're trying to do that in our own way at Anaconda because we know that business

1:53:49.440 --> 1:53:52.880
 users, as they use more of the stuff, they have needs that like business specific needs

1:53:52.880 --> 1:54:00.480
 around security, provenance. They really can't tell their VPs and their investors, hey, we're

1:54:00.480 --> 1:54:04.960
 having our data scientists are installing random packages from who knows where and running on

1:54:04.960 --> 1:54:07.760
 customer data. So they have to have someone to talk to you and that's what Anaconda does.

1:54:08.320 --> 1:54:13.040
 So we are a governed source of packages for them and that's great. That makes some money.

1:54:13.040 --> 1:54:18.080
 We take some of that and we just take that as a dividend. We take a percentage of our revenues

1:54:18.080 --> 1:54:23.840
 and write that as a dividend for the open source community. But beyond that, I really see the

1:54:23.840 --> 1:54:31.040
 development of a marketplace for people to create notebooks, models, data sets, curation of these

1:54:31.040 --> 1:54:36.880
 different kinds of things and to really have a long tail marketplace dynamic with that.

1:54:37.920 --> 1:54:42.400
 Can you speak about this problem that you stumbled into of package management,

1:54:42.400 --> 1:54:48.800
 Python package management? What is that? A lot of people speak very highly of Conda,

1:54:48.800 --> 1:54:52.480
 which is part of Anaconda, which is a package manager. There's a ton of packages.

1:54:52.480 --> 1:54:57.840
 So first, what are package managers? And second, what was there before? What is PIP?

1:54:58.560 --> 1:55:04.880
 And why is Conda more awesome? The package problem is this, which is that in order to do

1:55:08.080 --> 1:55:14.720
 numerical computing efficiently with Python, there are a lot of low level libraries that need

1:55:14.720 --> 1:55:20.320
 to be compiled, compiled with a C compiler or C++ compiler or Fortran compiler. They need to not

1:55:20.320 --> 1:55:24.240
 just be compiled, but they need to be compiled with all of the right settings. And oftentimes,

1:55:24.240 --> 1:55:29.200
 those settings are tuned for specific chip architectures. And when you add GPUs to the mix,

1:55:29.200 --> 1:55:35.120
 when you look at different operating systems, you may be on the same chip. But if you're running Mac

1:55:35.120 --> 1:55:39.920
 versus Linux versus Windows on the same X86 chip, you compile and link differently.

1:55:39.920 --> 1:55:46.960
 All of this complexity is beyond the capability of most data scientists to reason about. And it's

1:55:46.960 --> 1:55:52.320
 also beyond what most of the package developers want to deal with too. Because if you're a package

1:55:52.320 --> 1:55:56.720
 developer, you're like, I code on Linux, this works for me, I'm good. It is not my problem to

1:55:56.720 --> 1:56:00.720
 figure out how to build this on an ancient version of Windows, right? That's just simply not my

1:56:00.720 --> 1:56:07.360
 problem. So what we end up with is we have a creator or create a very creative crowdsourced

1:56:07.360 --> 1:56:13.120
 environment where people want to use this stuff, but they can't. And so we ended up creating

1:56:13.120 --> 1:56:19.120
 a new set of technologies like a build recipe system, a build system, and an installer system

1:56:19.120 --> 1:56:27.680
 that is able to, well, to put it simply, it's able to build these packages correctly on each of

1:56:27.680 --> 1:56:31.360
 these different kinds of platforms and operating systems and make it so when people want to install

1:56:31.360 --> 1:56:35.920
 something, they can. It's just one command. They don't have to, you know, set up a big compiler

1:56:35.920 --> 1:56:40.800
 system and do all these things. So when it works well, it works great. Now, the difficulty is

1:56:40.800 --> 1:56:45.520
 we have literally thousands of people writing code in the ecosystem, building all sorts of stuff,

1:56:45.520 --> 1:56:50.000
 and each person writing code, they may take a dependence on something else. And so all this

1:56:50.000 --> 1:56:57.040
 web, incredibly complex web of dependencies. So installing the correct package for any given

1:56:57.040 --> 1:57:02.960
 set of packages you want, getting that right subgraph is an incredibly hard problem. And

1:57:02.960 --> 1:57:06.480
 again, most data scientists don't want to think about this. They're like, I want to install NumPy

1:57:06.480 --> 1:57:13.600
 and Pandas. I want this version of some geospatial library. I want this other thing. Why is this

1:57:13.600 --> 1:57:19.360
 hard? These exist, right? And it is hard because it's, well, you're installing this on a version

1:57:19.360 --> 1:57:24.560
 of Windows, right? And half of these libraries are not built for Windows. Or the latest version

1:57:24.560 --> 1:57:27.440
 isn't available, but the old version was. If you go to the old version of this library,

1:57:27.440 --> 1:57:32.320
 that means you need to go to a different version of that library. And so the Python ecosystem,

1:57:32.320 --> 1:57:38.720
 by virtue of being crowdsourced, we were able to fill 100,000 different niches. But then we also

1:57:38.720 --> 1:57:44.160
 suffer this problem that because it's crowdsourced, and no one, it's like a tragedy to the comments,

1:57:44.160 --> 1:57:50.160
 right? No one really needs, wants to support their thousands of other dependencies. So we end up sort

1:57:50.160 --> 1:57:54.400
 of having to do a lot of this. And of course, the Kanda Forge community also steps up as an open

1:57:54.400 --> 1:57:58.960
 source community that, you know, maintains some of these recipes. That's what Kanda does. Now,

1:57:58.960 --> 1:58:04.720
 PIP is a tool that came along after Kanda to some extent. It came along as an easier way for the

1:58:06.320 --> 1:58:12.800
 Python developers writing Python code that didn't have as much compiled, you know, stuff,

1:58:12.800 --> 1:58:17.680
 they could then install different packages. And what ended up happening in the Python ecosystem

1:58:17.680 --> 1:58:22.320
 was that a lot of the core Python and web Python developers, they never ran into any of this

1:58:22.320 --> 1:58:29.280
 compilation stuff at all. So even we have, you know, on video, we have Guido van Rossum saying,

1:58:29.280 --> 1:58:32.400
 you know what, the scientific community's packaging problems are just too exotic and

1:58:32.400 --> 1:58:36.720
 different. I mean, you're talking about Fortran compilers, right? Like, you guys just need to

1:58:36.720 --> 1:58:42.160
 build your own solution, perhaps, right? So the Python core Python community went and built its

1:58:42.160 --> 1:58:48.400
 own sort of packaging technologies, not really contemplating the complexity of the stuff over

1:58:48.400 --> 1:58:53.520
 here. And so now we have the challenge where you can't PIP install some things. Some libraries,

1:58:53.520 --> 1:58:57.440
 if you just want to get started with them, you can PIP install TensorFlow and that works great.

1:58:57.440 --> 1:59:01.680
 The instant you want to also install some other packages that use different versions of

1:59:01.680 --> 1:59:06.640
 NumPy or some like graphics library or some OpenCV thing or some other thing,

1:59:06.640 --> 1:59:10.880
 you now run into dependency hell. Because you cannot, you know, OpenCV can have a different

1:59:10.880 --> 1:59:15.600
 version of libjpeg over here than PyTorch over here. Like they actually, they all have to use

1:59:15.600 --> 1:59:18.800
 the, if you want to use GPU acceleration, they have to all use the same underlying drivers and

1:59:18.800 --> 1:59:24.560
 same GPU CUDA things. So it's, it gets to be very gnarly. And it's a level of technology that

1:59:24.560 --> 1:59:27.520
 both the makers and the users don't really want to think too much about.

1:59:28.400 --> 1:59:33.120
 And that's where you step in and try to solve the sub graph problem. How much is that? And you

1:59:33.120 --> 1:59:36.720
 said that you don't want to think, they don't want to think about it, but how much is it a

1:59:36.720 --> 1:59:42.720
 little bit on the developer and providing them tools to, to be a little bit more clear of that

1:59:42.720 --> 1:59:47.040
 sub graph of dependency that's necessary? It is, it is getting to a point where we do have to think

1:59:47.040 --> 1:59:52.240
 about, look, can we pull some of the most popular packages together and get them to work on a

1:59:52.240 --> 1:59:56.560
 coordinated release timeline, get them to build against the same test matrix, et cetera, et cetera.

1:59:56.560 --> 2:00:01.520
 Right. And there is a little bit of dynamic around this, but again, it is a volunteer community.

2:00:02.560 --> 2:00:06.160
 You know, people working on these different projects have their own timelines and their own

2:00:06.160 --> 2:00:12.080
 things they're trying to meet. So we end up trying to pull these things together. And then it's,

2:00:12.080 --> 2:00:16.480
 it's just incredibly, and I would recommend just as a business tip, don't ever go into business

2:00:16.480 --> 2:00:21.120
 where when your hard work works, you're invisible. And when it breaks, because of someone else's

2:00:21.120 --> 2:00:25.920
 problem, you get flack for it. Because that's, that's a, in our situation, right? When something

2:00:25.920 --> 2:00:30.080
 doesn't condo install properly, usually it's some upstream issue, but it looks like condo is broken.

2:00:30.080 --> 2:00:34.000
 It looks like, you know, anaconda, screw something up. When things do work though, it's like, oh,

2:00:34.000 --> 2:00:38.080
 yeah, cool, it's worked. Assuming naturally, of course, that's very easy to make that work, right?

2:00:38.080 --> 2:00:44.240
 So we end up in this kind of problematic scenario. But, but it's okay, because I think we're still,

2:00:44.880 --> 2:00:48.720
 you know, our hearts in the right place. We're trying to move this forward as a community sort

2:00:48.720 --> 2:00:51.760
 of affair. I think most of the people in the community also appreciate the work we've done

2:00:51.760 --> 2:00:56.480
 over the years to try to move these things forward in a, in a collaborative fashion. So

2:00:57.280 --> 2:01:04.160
 one of the sub graphs of dependencies that became super complicated is the move from

2:01:04.160 --> 2:01:08.160
 Python two to Python three. So there's all these ways to mess with these kinds of

2:01:09.200 --> 2:01:13.600
 ecosystems of packages and so on. So I just want to ask you about that particular one.

2:01:13.600 --> 2:01:19.280
 What do you think about the move from Python two to three? Now, why did it take so long?

2:01:19.280 --> 2:01:24.320
 What were, from your perspective, just seeing the packages all struggle in the community,

2:01:24.320 --> 2:01:28.640
 all struggle through this process? What lessons do you take away from it? Why did it take so long?

2:01:28.640 --> 2:01:36.400
 Looking back, some people perhaps underestimated how much adoption Python two had.

2:01:38.000 --> 2:01:43.600
 I think some people also underestimated how much, or they overestimated how much value

2:01:44.320 --> 2:01:48.880
 some of the new features in Python three really provided. Like the things they really loved

2:01:48.880 --> 2:01:51.440
 about Python three just didn't matter to some of these people on Python two.

2:01:51.440 --> 2:01:58.240
 Yeah. Because this change was happening as Python scipy was starting to take off really like

2:01:58.240 --> 2:02:02.080
 past like a hockey stick of adoption in the early data science era in the early 2010s.

2:02:02.800 --> 2:02:07.120
 A lot of people were learning and onboarding in whatever just worked. And the teachers were like,

2:02:07.120 --> 2:02:10.480
 well, yeah, these libraries I need are not supporting Python three yet. I'm going to

2:02:10.480 --> 2:02:15.040
 teach you Python two. It took a lot of advocacy to get people to move over to Python three.

2:02:15.600 --> 2:02:20.240
 So I think it wasn't any particular single thing, but it was one of those death by,

2:02:20.240 --> 2:02:24.880
 you know, a dozen cuts, which just really made it hard to move off of Python two.

2:02:25.440 --> 2:02:29.200
 And also Python three itself, as they were kind of breaking things and changing these

2:02:29.200 --> 2:02:32.160
 around and reorganizing the standard library, there's a lot of stuff that was happening there

2:02:32.880 --> 2:02:36.880
 that kept giving people an excuse to say, I'll put off till the next version.

2:02:37.600 --> 2:02:41.440
 Two is working fine enough for me right now. So I think that's essentially what happened there.

2:02:41.440 --> 2:02:47.760
 And I will say this though, the strength of the Python data science movement,

2:02:47.760 --> 2:02:54.000
 I think, is what kept Python alive in that transition. Because a lot of languages have died

2:02:54.000 --> 2:03:00.160
 and left their user bases behind. If there wasn't the use of Python for data, there's a good chunk

2:03:00.160 --> 2:03:04.800
 of Python users that during that transition would have just left for Go and Rust and stayed.

2:03:04.800 --> 2:03:08.080
 In fact, some people did. They moved to Go and Rust and they just never look back.

2:03:08.720 --> 2:03:15.120
 The fact that we were able to grow by millions of users, the Python data community,

2:03:15.120 --> 2:03:19.760
 that is what kept the momentum for Python going. And now the usage of Python for data

2:03:19.760 --> 2:03:26.800
 is over 50% of the overall Python user base. So I will put, I will make, I'm happy to debate

2:03:26.800 --> 2:03:32.480
 that on stage somewhere. But from where I sit, I think that's true.

2:03:32.480 --> 2:03:36.720
 The statement there, the idea is that the switch from Python two to Python three

2:03:37.840 --> 2:03:44.560
 would have probably destroyed Python if it didn't also coincide with Python for whatever

2:03:44.560 --> 2:03:51.680
 reason, just overtaking the data science community, anything that processes data.

2:03:51.680 --> 2:03:58.560
 So the timing was perfect that this maybe imperfect decision was coupled with a great

2:03:58.560 --> 2:04:01.920
 timing on the value of data in our world.

2:04:01.920 --> 2:04:06.240
 I would say the troubled execution of a good decision. It was a decision that was necessary.

2:04:07.280 --> 2:04:10.240
 It's possible if we had more resources, we could have done it in a way that was a little bit

2:04:10.240 --> 2:04:16.640
 smoother. But ultimately, the arguments for Python three, I bought them at the time and I buy them

2:04:16.640 --> 2:04:22.080
 now. Having great text handling is like a nonnegotiable table stakes thing you need to have

2:04:22.080 --> 2:04:32.880
 in a language. So that's great. But the execution, Python is the, it's volunteer driven.

2:04:32.880 --> 2:04:36.560
 It's like now the most popular language on the planet, but it's all literally volunteers.

2:04:36.560 --> 2:04:42.000
 So the lack of resources meant that they had to really, they had to do things in a very

2:04:42.000 --> 2:04:47.600
 hamstrung way. And I think to carry the Python momentum in the language through that time,

2:04:47.600 --> 2:04:49.760
 the data movement was a critical part of that.

2:04:49.760 --> 2:04:56.480
 So some of it is carrot and stick. I actually have to shamefully admit that it took me a very

2:04:56.480 --> 2:05:00.160
 long time to switch from Python two and Python three because I'm a machine learning person.

2:05:00.160 --> 2:05:03.600
 It was just for the longest time, you could just do fine with Python two.

2:05:03.600 --> 2:05:11.440
 Right. But I think the moment where I switched everybody I worked with and switched myself

2:05:12.000 --> 2:05:18.880
 for small projects and big is when finally when NumPy announced that they're going to end support

2:05:20.320 --> 2:05:26.080
 like in 2020 or something like that. Right. So like when I realized, oh, this isn't going,

2:05:26.080 --> 2:05:30.800
 this is going to end. Right. So that's the stick. That's not a carrot. That's not so for the longest

2:05:30.800 --> 2:05:35.840
 time was carrots. It was like all of these packages were saying, okay, we have Python three support

2:05:35.840 --> 2:05:41.040
 now come join us with Python two and Python three. But when NumPy, one of the packages I

2:05:41.680 --> 2:05:50.240
 sort of love and depend on said like, nope, it's over. That's, that's when I decided to switch.

2:05:50.240 --> 2:05:54.640
 I wonder if you think it was possible much earlier for somebody like,

2:05:54.640 --> 2:06:04.800
 like NumPy or some major package to step into the cold. Well, it's a chicken and egg problem too.

2:06:04.800 --> 2:06:09.440
 Right. You don't want to cut off a lot of users unless you see the user momentum going too. So

2:06:09.440 --> 2:06:14.080
 the decisions for the scientific community, for each of the different projects, you know,

2:06:14.080 --> 2:06:18.000
 there's not a monolith. Some projects are like, we'll only be releasing new features on Python

2:06:18.000 --> 2:06:26.320
 three. And that was more of a sticky carrot or a firm carrot, if you will, a firm carrot, a

2:06:26.320 --> 2:06:31.600
 stick shaped carrot. But then for others, yeah, NumPy in particular, because it's at the base

2:06:31.600 --> 2:06:37.440
 of the dependency stack for so many things. That was the final stick. That was a stick shaped stick.

2:06:37.440 --> 2:06:41.520
 People were saying, look, if I have to keep maintaining my releases for Python two,

2:06:41.520 --> 2:06:46.880
 that's that much less energy that I can put into making things better for the Python three folks

2:06:46.880 --> 2:06:51.360
 or in my new version, which is of course going to be Python three. So people were also getting

2:06:51.360 --> 2:06:56.560
 kind of pulled by this tension. So the overall community sort of had a lot of input into when

2:06:56.560 --> 2:07:01.280
 the NumPy core folks decided that they would end of life on Python two.

2:07:01.280 --> 2:07:06.720
 So as these numbers are a little bit loose, but there are about 10 million Python programmers

2:07:06.720 --> 2:07:10.720
 in the world, you could argue that number, but let's say 10 million. That's actually

2:07:10.720 --> 2:07:18.400
 where I was looking said 27 million total programmers, developers in the world. You mentioned in a talk

2:07:18.400 --> 2:07:24.960
 that changes need to be made for there to be 100 million programmers. So first of all,

2:07:24.960 --> 2:07:29.440
 do you see a future where there's 100 million Python programmers? And second, what kind of

2:07:29.440 --> 2:07:34.080
 changes need to be made? So Anaconda, Miniconda get downloaded about a million times a week.

2:07:34.880 --> 2:07:40.240
 So I think the idea that there's only 10 million Python programmers in the world is a little bit

2:07:40.240 --> 2:07:46.640
 undercounting. There are a lot of people who escape traditional counting that are using Python and

2:07:46.640 --> 2:07:52.960
 data in their jobs. I do believe that the future world for it to, well, the world I would like to

2:07:52.960 --> 2:07:59.520
 see is one where people are data literate. So they are able to use tools that let them express

2:07:59.520 --> 2:08:06.320
 their questions and ideas fluidly. And the data variety and data complexity will not go down.

2:08:06.320 --> 2:08:13.280
 It will only keep increasing. So I think some level of code or code like things will continue to

2:08:14.080 --> 2:08:21.760
 be relevant. And so my hope is that we can build systems that allow people to more seamlessly

2:08:21.760 --> 2:08:28.080
 integrate Python kinds of expert sensitivity with data systems and operationalization methods

2:08:28.080 --> 2:08:34.000
 that are much more seamless. And what I mean by that is, right now, you can't punch Python code

2:08:34.000 --> 2:08:38.320
 into an Excel cell. I mean, there's some tools you can do to kind of do this. We didn't build

2:08:38.320 --> 2:08:44.560
 a thing for doing this back in the day. But I feel like the total addressable market for Python

2:08:44.560 --> 2:08:50.400
 users, if we do the things right, is on the order of the Excel users, which is a few hundred million.

2:08:51.200 --> 2:08:59.360
 So I think Python has to get better at being embedded, being a smaller thing that pulls

2:08:59.360 --> 2:09:06.240
 in just the right parts of the ecosystem to run numerics and do data exploration, meeting people

2:09:06.240 --> 2:09:10.560
 where they're already at with their data and their data tools. And then I think also,

2:09:11.840 --> 2:09:16.960
 it has to be easier to take some of those things they've written and flow those back into deployed

2:09:16.960 --> 2:09:21.520
 systems or little apps or visualizations. I think if we don't do those things, then we will always be

2:09:22.160 --> 2:09:27.040
 kept in a silo as sort of an expert user's tool and not a tool for the masses.

2:09:27.040 --> 2:09:34.400
 You know, I work with a bunch of folks in the Adobe creative suite, and I'm kind of forcing them

2:09:34.400 --> 2:09:39.120
 or inspired them to learn Python to do a bunch of stuff that helps them. And it's interesting

2:09:39.120 --> 2:09:42.880
 because they probably wouldn't call themselves a Python programmer, but they're all using Python.

2:09:43.680 --> 2:09:48.240
 I would love it if the tools like Photoshop and Premiere and all those kinds of tools that are

2:09:48.240 --> 2:09:53.600
 targeted towards creative people, I guess that's where Excel is targeted towards a certain kind

2:09:53.600 --> 2:09:59.680
 of audience that works with data, financial people, all that kind of stuff. If there would be easy

2:09:59.680 --> 2:10:06.640
 ways to leverage to use Python for quick scripting tasks. And you know, there's an exciting application

2:10:06.640 --> 2:10:13.600
 of artificial intelligence in the space that I'm hopeful about looking at open AI codex with

2:10:13.600 --> 2:10:22.880
 generating programs. So almost helping people bridge the gap from kind of visual interface

2:10:23.440 --> 2:10:29.680
 to generating programs to something formal. And then they can modify it and so on. But kind of

2:10:30.560 --> 2:10:34.720
 without having to read the manual, without having to do a Google search and stack overflow,

2:10:34.720 --> 2:10:38.000
 which is essentially what a neural network does when it's doing code generation,

2:10:38.000 --> 2:10:44.880
 is actually generating code and allowing a human to communicate with multiple programs. And then

2:10:44.880 --> 2:10:50.480
 maybe even programs to communicate with each other via Python. So that to me is a really exciting

2:10:50.480 --> 2:10:57.600
 possibility because I think there's a friction to kind of like, how do I learn how to use Python

2:10:57.600 --> 2:11:04.240
 in my life? Oftentimes, you kind of start a class, you start learning about types,

2:11:04.240 --> 2:11:09.680
 yes, I don't know, functions. Like this is, you know, Python is the first language with

2:11:09.680 --> 2:11:16.800
 which you start to learn to program. But I feel like that's going to take a long time for you

2:11:16.800 --> 2:11:22.160
 to understand why it's useful. You almost want to start with a script. Well, you do, in fact. I

2:11:22.160 --> 2:11:26.000
 think starting with the theory behind programming languages and types and all that, I mean,

2:11:26.000 --> 2:11:30.880
 types are there to make the compiler writer's jobs easier. Types are not, I mean,

2:11:30.880 --> 2:11:36.960
 heck, do you have an ontology of types or just the objects on this table? No. So types are there

2:11:36.960 --> 2:11:43.040
 because compiler writers are human and they're limited in what they can do. But I think that

2:11:43.040 --> 2:11:48.480
 the beauty of scripting, like there's a Python book that's called Automate the Boring Stuff,

2:11:49.040 --> 2:11:57.920
 which is exactly the right mentality. I grew up with computers in a time when Steve Jobs

2:11:57.920 --> 2:12:01.200
 was still pitching these things as bicycles for the mind. They were supposed to not be just

2:12:01.200 --> 2:12:06.400
 media consumption devices. But they were actually, you could write some code, you could write basic,

2:12:06.400 --> 2:12:12.560
 you could write some stuff to do some things. And that feeling of a computer as a thing that

2:12:12.560 --> 2:12:18.560
 we can use to extend ourselves has all but evaporated for a lot of people. So you see a

2:12:18.560 --> 2:12:23.520
 little bit in parts of the current, the generation of youth around Minecraft or Roblox, right?

2:12:23.520 --> 2:12:30.160
 And I think Python, circuit Python, these things could be a renaissance of that, of people actually

2:12:31.040 --> 2:12:36.480
 shaping and using their computers as computers, as an extension of their minds and the curiosity,

2:12:36.480 --> 2:12:42.800
 their creativity. So you talk about scripting the Adobe suite with Python in the 3D graphics world.

2:12:42.800 --> 2:12:49.280
 Python is a scripting language that some of these 3D graphics suites use. And I think it's great.

2:12:49.280 --> 2:12:54.080
 We should better support those kinds of things. But ultimately, the idea that I should be able

2:12:54.080 --> 2:12:58.800
 to have power over my computing environment, if I want these things to happen repeatedly all the

2:12:58.800 --> 2:13:05.520
 time, I should be able to say that somehow to the computer, right? Now, whether the operating systems

2:13:05.520 --> 2:13:09.680
 get there faster by having some, you know, Siri backed with open AI with whatever. So you can

2:13:09.680 --> 2:13:13.600
 just say, Siri, make this do this and this and every other Friday, right? We probably will get

2:13:13.600 --> 2:13:17.680
 there somewhere. And Apple's always had these ideas, you know, there's the Apple script in the menu

2:13:17.680 --> 2:13:22.640
 that no one ever uses. But you can do these kinds of things. But when you start doing that kind

2:13:22.640 --> 2:13:27.040
 of scripting, the challenge isn't learning the type system, or even the syntax of the language.

2:13:27.040 --> 2:13:31.520
 The challenge is all of the dictionaries and all the objects of all their properties and attributes

2:13:31.520 --> 2:13:37.440
 and parameters, like who's got time to learn all that stuff, right? So that's when then programming

2:13:37.440 --> 2:13:42.880
 by prototype, or by example, becomes the right way to get the user to express their desire.

2:13:43.600 --> 2:13:46.640
 So there's a lot of these different ways that we can approach programming. But I do think

2:13:46.640 --> 2:13:50.480
 when, as you were talking about the Adobe scripting thing, I was thinking about, you know,

2:13:51.280 --> 2:13:56.080
 when we do use something like NumPy, when we use things in the Python data and scientific,

2:13:57.520 --> 2:14:03.120
 they say expression system, there's a reason we use that, which is that it gives us mathematical

2:14:03.120 --> 2:14:08.960
 precision. It gives us actually quite a lot of precision over precisely what we mean about

2:14:08.960 --> 2:14:12.960
 this data set, that data set. And it's the fact that we can have that precision

2:14:12.960 --> 2:14:20.400
 that lets Python be powerful over as a duct tape for data. You know, you give me a TSV or a CSV,

2:14:21.120 --> 2:14:26.640
 and if you give me some massively expensive vendor tool for data transformation, I don't know,

2:14:26.640 --> 2:14:31.200
 I'm going to be able to solve your problem. But if you give me a Python prompt, you can throw

2:14:31.200 --> 2:14:36.480
 whatever data you want at me, I will be able to mash it into shape. So that ability to take it as

2:14:36.480 --> 2:14:43.680
 sort of this machete out into the data jungle is really powerful. And I think that's why at some

2:14:43.680 --> 2:14:50.240
 level, we're not going to get away from some of these expressions and APIs in libraries in Python

2:14:50.240 --> 2:14:58.320
 for data transformation. You've been at the center of the Python community for many years.

2:14:58.320 --> 2:15:05.440
 If you could change one thing about the community to help it grow, to help it improve,

2:15:05.440 --> 2:15:11.600
 to help it flourish and prosper, what would it be? I mean, that doesn't have to be one thing,

2:15:11.600 --> 2:15:14.720
 but what kind of comes to mind? What are the challenges?

2:15:15.280 --> 2:15:18.400
 Humility is one of the values that we have at Anaconda, the company, but it's also one of

2:15:18.400 --> 2:15:24.400
 the values in the community that it's been breached a little bit in the last few years,

2:15:24.400 --> 2:15:31.440
 but in general, people are quite decent and reasonable and nice. And that humility prevents

2:15:31.440 --> 2:15:40.160
 them from seeing the greatness that they could have. I don't know how many people in the core

2:15:40.160 --> 2:15:47.840
 Python community really understand that they stand perched at the edge of an opportunity

2:15:47.840 --> 2:15:53.440
 to transform how people use computers. And actually, PyCon, I think it was the last physical

2:15:53.440 --> 2:16:00.880
 PyCon I went to, Russell Keith McGee gave a great keynote about very much along the lines of the

2:16:00.880 --> 2:16:06.320
 challenges I have, which is Python, for a language that doesn't actually, that can't put an interface

2:16:06.320 --> 2:16:10.960
 up on the most popular computing devices, it's done really well as a language, hasn't it?

2:16:11.600 --> 2:16:14.880
 You can't write a web frontend with Python, really. I mean, everyone uses JavaScript.

2:16:14.880 --> 2:16:20.640
 You certainly can't write native apps. So for a language that you can't actually write apps in

2:16:20.640 --> 2:16:27.520
 any of the frontend runtime environments, Python's done exceedingly well. And so that wasn't to

2:16:27.520 --> 2:16:31.200
 pat ourselves in the back. That was to challenge ourselves as a community to say, we, through

2:16:31.200 --> 2:16:36.480
 our current volunteer dynamic, have gotten to this point, what comes next and how do we seize,

2:16:36.480 --> 2:16:40.320
 you know, we've caught the tiger by the tail, how do we make sure we keep up with it as it goes

2:16:40.320 --> 2:16:45.600
 forward? So that's one of the questions I have about sort of open source communities, is at

2:16:45.600 --> 2:16:53.040
 its best, there's a kind of humility. Is that humility prevent you to have a vision for creating

2:16:53.040 --> 2:16:57.680
 something like very new and powerful? And you've brought us back to consciousness again. The

2:16:57.680 --> 2:17:02.720
 collaboration is a swarm emergent dynamic. Humility lets these people work together without

2:17:02.720 --> 2:17:07.760
 anyone trouncing anyone else. How do they, you know, in consciousness, there's the question of

2:17:07.760 --> 2:17:12.400
 the binding problem. How does a singular, our attention, how does that emerge from, you know,

2:17:12.400 --> 2:17:19.040
 billions of neurons? So how can you have a swarm of people emerge a consensus that has a singular

2:17:19.040 --> 2:17:24.720
 vision to say, we will do this. And most importantly, we're not going to do these things. Emerging a

2:17:25.360 --> 2:17:31.920
 coherent, pointed, focused leadership dynamic from a collaboration, being able to do that kind of,

2:17:31.920 --> 2:17:37.040
 and then dissolve it so people can still do the swarm thing. That's a problem. That's a question.

2:17:37.040 --> 2:17:42.480
 So do you have to have a charismatic leader? For some reason, Linus Torvald comes to mind,

2:17:42.480 --> 2:17:46.880
 but you know, there's people who criticize the rules that iron fist, man. But there's

2:17:46.880 --> 2:17:52.080
 still charisma. There's charisma, right? There's charisma to that iron fist. There's a,

2:17:53.440 --> 2:17:59.040
 every leader is different, I would say, in their success. So he doesn't, I don't even know if you

2:17:59.040 --> 2:18:08.480
 can say he doesn't have humility. There's such a meritocracy of ideas that like, this is a good

2:18:08.480 --> 2:18:12.800
 idea and this is a bad idea. There's a step function to it. Once you clear a threshold,

2:18:12.800 --> 2:18:20.160
 he's open to your ideas, I think. The interesting thing is, obviously,

2:18:20.160 --> 2:18:26.320
 that will not stand in an open source community if that threshold that is defined by that one

2:18:26.320 --> 2:18:32.320
 particular person is not actually that good. So you actually have to be really excellent at what

2:18:32.320 --> 2:18:39.680
 you do. So he's very good at what he does. And so there's some aspect of leadership where

2:18:39.680 --> 2:18:44.960
 you can get thrown out. People can just leave. That's how it works with the open source of the

2:18:44.960 --> 2:18:52.160
 fork. But at the same time, you want to sometimes be a leader with a strong opinion because people,

2:18:52.160 --> 2:18:57.200
 I mean, there's some kind of balance here for this high of mind to get behind.

2:18:57.200 --> 2:19:00.960
 Leadership is a big topic. And I didn't, I'm not one of these guys that went to MBA school and said,

2:19:00.960 --> 2:19:04.400
 I'm going to be an entrepreneur and I'm going to be a leader. And I'm going to read all these

2:19:04.400 --> 2:19:09.520
 Harvard Business Review articles on leadership and all this other stuff. I was a physicist

2:19:09.520 --> 2:19:14.640
 turned into a software nerd who then really nerded out on Python. And now I am entrepreneurial. I

2:19:14.640 --> 2:19:19.840
 saw a business opportunity around the use of Python for data. But for me, what has been interesting

2:19:19.840 --> 2:19:27.840
 over this journey with the last 10 years is how much I started really enjoying the understanding,

2:19:27.840 --> 2:19:33.120
 thinking deeper about organizational dynamics and leadership. And leadership does come down to

2:19:33.120 --> 2:19:41.920
 a few core things. Number one, a leader has to create belief or at least has to dispel disbelief.

2:19:43.920 --> 2:19:48.640
 Leadership also, you have to have vision, loyalty and experience.

2:19:49.200 --> 2:19:53.600
 So can you say belief in a singular vision? What is belief?

2:19:53.600 --> 2:19:57.760
 Yeah, belief means a few things. Belief means here's what we need to do. And this is a valid thing

2:19:57.760 --> 2:20:07.600
 to do. And we can do it that you have to be able to drive that belief. And every step of leadership

2:20:07.600 --> 2:20:14.160
 along the way has to help you amplify that belief to more people. I mean, I think at a fundamental

2:20:14.160 --> 2:20:20.640
 level, that's what it is. You have to have a vision. You have to be able to show people that,

2:20:20.640 --> 2:20:25.360
 or you have to convince people to believe in the vision and to get behind you. And that's where

2:20:25.360 --> 2:20:29.520
 the loyalty part comes in and the experience part comes in. There's all different flavors of

2:20:29.520 --> 2:20:36.560
 leadership. So if we talk about Linus, we could talk about Elon Musk and Steve Jobs. There's

2:20:36.560 --> 2:20:42.320
 Sander Perchai. There's people that kind of put themselves at the center and are strongly opinionated.

2:20:42.320 --> 2:20:48.480
 And some people are more like consensus builders. What works well for open source? What works well

2:20:48.480 --> 2:20:53.600
 in the space of programmers? So you've been a programmer. You've led many programmers and now

2:20:53.600 --> 2:20:58.160
 sort of at the center of this ecosystem, what works well in the programming world, would you say?

2:20:58.800 --> 2:21:03.280
 It really depends on the people, what style of leadership is best. And it depends on the

2:21:03.280 --> 2:21:07.680
 programming community. I think for the Python community, servant leadership is one of the

2:21:07.680 --> 2:21:17.200
 values. At the end of the day, the leader has to also be the high priest of values. So any

2:21:17.200 --> 2:21:24.480
 collection of people has values of their living. And if you want to maintain certain values and

2:21:24.480 --> 2:21:29.600
 those values help you as an organization become more powerful, then the leader has to live those

2:21:29.600 --> 2:21:37.520
 values unequivocally and has to hold the values. So in our case, in this collaborative community

2:21:37.520 --> 2:21:43.760
 around Python, I think that the humility is one of those values. Servant leadership,

2:21:43.760 --> 2:21:47.200
 you actually have to kind of do the stuff. You have to walk the walk, not just talk the talk.

2:21:48.880 --> 2:21:53.680
 I don't feel like the Python community really demands that much from a vision standpoint.

2:21:53.680 --> 2:22:00.160
 And they should. And I think they should. This is the interesting thing is that so

2:22:00.160 --> 2:22:07.760
 many people use Python. From where comes the vision? You have an Elon Musk type character who

2:22:07.760 --> 2:22:15.120
 has bold statements about the vision for particular companies he's involved with. And it's like,

2:22:16.320 --> 2:22:23.120
 I think a lot of people that work at those companies kind of can only last if they believe

2:22:23.120 --> 2:22:29.120
 that vision. And some of it is super bold. So my question is, and by the way, those companies

2:22:29.120 --> 2:22:36.160
 often use Python, how do you establish a vision? Get to 100 million users, right?

2:22:36.160 --> 2:22:46.640
 Get to where the Python is at the center of the machine learning and was it data science,

2:22:46.640 --> 2:22:53.680
 machine learning, deep learning, artificial intelligence, revolution, right? In many ways,

2:22:53.680 --> 2:22:57.360
 perhaps the Python community is not thinking of it that way, but it's leading the way on this.

2:22:58.080 --> 2:23:03.120
 Like the tooling is like essential. Right. Well, for a while,

2:23:03.120 --> 2:23:09.120
 PyCon, people in the scientific Python and the PyData community, they would submit talks.

2:23:09.120 --> 2:23:15.680
 Those are early 2010s. They would submit talks to PyCon and the talks would all be rejected

2:23:15.680 --> 2:23:19.440
 because there was the separate sort of PyData conferences. And they're like, well, these

2:23:19.440 --> 2:23:24.000
 probably belong more to PyData. And instead, there'd be yet another talk about threads and

2:23:24.720 --> 2:23:30.800
 whatever, some web framework. And it's like, that was an interesting dynamic to see that there was,

2:23:30.800 --> 2:23:34.240
 I mean, at the time, it was a little annoying because we want to try to get more users and

2:23:34.240 --> 2:23:37.360
 get more people talking about these things. And PyCon is a huge venue, right? It's

2:23:38.000 --> 2:23:42.960
 thousands of Python programmers. But then also came to appreciate that, you know, parallel,

2:23:42.960 --> 2:23:47.680
 having an ecosystem that allows parallel innovation is not bad, right? There are people

2:23:47.680 --> 2:23:51.280
 doing embedded Python stuff. There's people doing web programming, people doing scripting,

2:23:51.280 --> 2:23:56.320
 there's cyber uses of Python. I think ultimately at some point, if your slide mode

2:23:56.320 --> 2:24:01.040
 covers so much stuff, you have to respect that different things are growing in different areas

2:24:01.040 --> 2:24:05.280
 and different niches. Now, at some point, that has to come together and the central body has to

2:24:06.080 --> 2:24:11.600
 provide resources. The principle here is subsidiarity. Give resources to the various groups

2:24:11.600 --> 2:24:16.560
 to then allocate as they see fit in their niches. That would be a really helpful dynamic. But again,

2:24:16.560 --> 2:24:19.440
 it's a volunteer community. It's not like they had that many resources to start with.

2:24:21.040 --> 2:24:25.600
 What was or is your favorite programming setup? What operating system, what keyboard,

2:24:25.600 --> 2:24:32.320
 how many screens are you listening to? What time of day? Are you drinking coffee? Tea?

2:24:32.960 --> 2:24:37.120
 Tea. Sometimes coffee, depending on how well I slept. I used to have...

2:24:37.120 --> 2:24:42.080
 How deep do you get? A night owl? I remember somebody asked you somewhere a question about

2:24:42.080 --> 2:24:49.280
 work life balance. Not just work life balance, but like a family. You lead a company and your

2:24:49.280 --> 2:24:53.440
 answer was basically like, I still haven't figured it out.

2:24:53.440 --> 2:24:57.840
 Yeah. I think I've gotten to a little bit better balance. I have a really great leadership team

2:24:57.840 --> 2:25:03.600
 now supporting me. That takes a lot of the day to day stuff off my plate. My kids are getting

2:25:03.600 --> 2:25:08.800
 a little older, so that helps. Of course, I have a wonderful wife who takes care of a lot of the

2:25:08.800 --> 2:25:13.520
 things that I'm not able to take care of and she's great. I try to get to sleep earlier now

2:25:13.520 --> 2:25:16.800
 because I have to get up every morning at six to take my kid down to the bus stop.

2:25:16.800 --> 2:25:21.920
 So there's a hard thing. For a while, I was doing polyphasic sleep, which is really interesting.

2:25:21.920 --> 2:25:26.560
 Like I go to bed at nine, wake up at like 2 a.m., work till five, sleep three hours,

2:25:26.560 --> 2:25:29.840
 wake up at eight. That was actually... It was interesting. It wasn't too bad.

2:25:29.840 --> 2:25:34.800
 How did it feel? It was good. I didn't keep it up for years, but once I have travel,

2:25:34.800 --> 2:25:38.480
 then it just... Everything goes out the window, right? Because then you're like time zones and

2:25:38.480 --> 2:25:43.360
 all these things. Socially, was it accepted? Were you able to live outside of how you felt?

2:25:43.360 --> 2:25:45.600
 Yes. Were you able to live normal society?

2:25:45.600 --> 2:25:48.800
 Oh yeah, because on the night that wasn't out, hanging out with people or whatever,

2:25:48.800 --> 2:25:53.120
 going to bed at nine, no one cares. I wake up at two, I'm still responding to their slacks, emails,

2:25:53.120 --> 2:25:57.920
 whatever, and shitposting on Twitter or whatever at two in the morning is great.

2:25:57.920 --> 2:25:58.800
 Yes, exactly.

2:25:58.800 --> 2:26:03.280
 Right? And then you go to bed for a few hours and you wake up. It's like you had an extra day in

2:26:03.280 --> 2:26:07.520
 the middle. And I'd read somewhere that humans naturally have biphasic sleep or something.

2:26:07.520 --> 2:26:13.200
 I don't know. I read basically everything somewhere. So every option of everything.

2:26:13.200 --> 2:26:16.640
 Every option of everything. I will say that that worked out for me for a while,

2:26:16.640 --> 2:26:21.760
 although I don't do it anymore. In terms of programming setup, I had a 27 inch high DPI

2:26:22.720 --> 2:26:27.840
 setup that I really liked. But then I moved to a curved monitor just because when I moved to the

2:26:27.840 --> 2:26:33.840
 new house, I want to have a bit more screen for Zoom plus communications plus various kinds of things.

2:26:33.840 --> 2:26:35.600
 It's like one large monitor.

2:26:35.600 --> 2:26:36.560
 One large curved monitor.

2:26:37.840 --> 2:26:39.040
 What operating system?

2:26:39.680 --> 2:26:40.480
 Mac.

2:26:40.480 --> 2:26:41.040
 Okay.

2:26:41.040 --> 2:26:41.520
 Yeah.

2:26:41.520 --> 2:26:46.080
 Is that what happens when you become important? Is you stop using Linux and Windows?

2:26:46.080 --> 2:26:49.280
 No, I actually have a Windows box as well on the next table over.

2:26:50.480 --> 2:26:54.000
 But I have three desks, right?

2:26:54.000 --> 2:26:54.240
 Yes.

2:26:54.240 --> 2:26:59.280
 So a main one is a standing desk so that I can whatever. I have a teleprompter set up and

2:26:59.280 --> 2:27:06.320
 everything else. And then I've got my iMac and then eGPU and then Windows PC.

2:27:06.320 --> 2:27:10.400
 The reason I moved to Mac was it's got a Linux prompt.

2:27:10.400 --> 2:27:14.080
 Or sorry, it's got a Unix prompt so I can do all my stuff.

2:27:14.080 --> 2:27:20.400
 But then I don't have to worry like when I'm presenting for clients or investors or whatever.

2:27:21.600 --> 2:27:27.040
 I don't have to worry about any like ACPI related FSIQ things in the middle of a presentation,

2:27:27.040 --> 2:27:29.280
 like none of that. It just, it will always wake from sleep.

2:27:30.800 --> 2:27:32.160
 And it won't kernel panic on me.

2:27:32.160 --> 2:27:38.240
 And this is not a dig against Linux except that I just, I feel really bad.

2:27:38.240 --> 2:27:40.080
 I feel like a traitor to my community saying this, right?

2:27:40.080 --> 2:27:43.920
 But in 2012, I was just like, okay, start my own company, what do I get?

2:27:43.920 --> 2:27:46.320
 And Linux laptops were just not quite there.

2:27:47.360 --> 2:27:48.400
 And so I've just stuck with Max.

2:27:48.400 --> 2:27:52.240
 Can I just defend something that nobody respectable seems to do?

2:27:52.240 --> 2:28:00.320
 Which is, I do a boot on Linux Windows, but in Windows, I have Windows subsystems for Linux

2:28:00.320 --> 2:28:01.600
 or whatever WSL.

2:28:01.600 --> 2:28:02.240
 Yes, WSL.

2:28:02.880 --> 2:28:08.240
 And I find myself being able to handle everything I need and almost everything I need in Linux

2:28:08.240 --> 2:28:12.800
 for basic sort of tasks, scripting tasks within WSL and it creates a really nice environment.

2:28:12.800 --> 2:28:16.560
 So I've been, but like whenever I hang out with like, especially important people,

2:28:17.760 --> 2:28:20.560
 like they're all on iPhone and a Mac.

2:28:20.560 --> 2:28:27.680
 And it's like, yeah, like what there, there is a messiness to Windows and a messiness to Linux

2:28:27.680 --> 2:28:30.960
 that makes me feel like you're still in it.

2:28:31.760 --> 2:28:35.760
 Well, the Linux stuff, Windows subsystem for Linux is very tempting,

2:28:35.760 --> 2:28:40.640
 but there's still the Windows on the outside where I don't know where, and I've been,

2:28:40.640 --> 2:28:45.440
 okay, I've been, I've used DOS since version 1.1.1 or 1.2.1 or something.

2:28:45.440 --> 2:28:48.240
 So I've been a long time Microsoft user.

2:28:48.240 --> 2:28:53.280
 And I will say that like, it's really hard for me to know where anything is,

2:28:53.280 --> 2:28:56.720
 how to get to the details behind something when something screws up as an invariably does.

2:28:57.440 --> 2:29:01.280
 And just things like changing group permissions on some shared folders and stuff,

2:29:01.280 --> 2:29:04.880
 just everything seems a little bit more awkward, more clicks than it needs to be.

2:29:06.320 --> 2:29:09.440
 Not to say that there aren't any weird things like hidden attributes and all this other happy

2:29:09.440 --> 2:29:16.000
 stuff on Mac, but for the most part, and well, actually, especially now with the new hardware

2:29:16.000 --> 2:29:20.880
 coming out on Mac, that'll be very interesting, with the new M1, there were some dark years

2:29:20.880 --> 2:29:24.560
 in the last few years when I was like, I think maybe I have to move off of Mac as a platform.

2:29:26.480 --> 2:29:30.560
 I mean, like my keyboard was just not working, like literally my keyboard just wasn't working,

2:29:30.560 --> 2:29:34.000
 right? I had this touch bar, didn't have a physical escape button like I needed to

2:29:34.000 --> 2:29:36.800
 because I used VIM, and now I think we're back.

2:29:36.800 --> 2:29:40.160
 So you use VIM, and you have what kind of keyboard?

2:29:40.160 --> 2:29:45.040
 So I use a RealForce 87U. It's a mechanical, it's a topra key switch.

2:29:45.040 --> 2:29:46.720
 It's a weird shape. There's a normal shape.

2:29:48.240 --> 2:29:53.040
 Oh, no, because I say that because I use a kinesis and I had, you said some dark, you said,

2:29:53.040 --> 2:29:58.720
 yeah, dark moments. I've recently had a dark moment was like, what am I doing with my life?

2:29:58.720 --> 2:30:04.960
 So I remember sort of flying in a very kind of tight space. And as I'm working,

2:30:04.960 --> 2:30:09.520
 this is what I do on an airplane. I pull out a laptop and on top of the laptop,

2:30:09.520 --> 2:30:11.920
 I'll put a kinesis keyboard. That's hardcore, man.

2:30:11.920 --> 2:30:14.960
 I was thinking, is this who I am? Is this what I'm becoming?

2:30:14.960 --> 2:30:19.680
 Will I be this person? Because I'm on Emacs with this kinesis keyboard sitting like

2:30:20.560 --> 2:30:22.800
 with everybody around. Emacs on Windows.

2:30:23.600 --> 2:30:27.280
 On the WSL, yeah. Yeah, Emacs on Linux on Windows.

2:30:27.280 --> 2:30:33.040
 Yeah, on Windows. And like everybody around me is using their iPhone to look at TikTok.

2:30:33.040 --> 2:30:38.400
 So I'm like in this land and I thought, you know what? Maybe I need to become an adult and

2:30:38.400 --> 2:30:44.880
 put the 90s behind me and use like a normal keyboard. And then I did some soul searching

2:30:44.880 --> 2:30:48.720
 and I decided like, this is who I am. This is me like coming out of the closet to saying,

2:30:48.720 --> 2:30:51.840
 I'm kinesis keyboard all the way. I'm going to use Emacs.

2:30:52.800 --> 2:30:56.400
 You know, also the kinesis fan, Wes McKinney, that created pandas.

2:30:57.440 --> 2:31:00.480
 He just, he banged out pandas on a kinesis keyboard, I believe. I don't know if he's still

2:31:00.480 --> 2:31:03.920
 using one maybe, but certainly 10 years ago, like he was.

2:31:03.920 --> 2:31:08.240
 If anyone's out there, maybe we need to have a kinesis support group. Please reach out.

2:31:08.240 --> 2:31:10.000
 Isn't there already one? Is there one?

2:31:10.000 --> 2:31:11.440
 I don't know. There's got to be an IRC channel, man.

2:31:14.320 --> 2:31:19.440
 Oh no. And you access it through Emacs. Okay. Do you still program these days?

2:31:19.440 --> 2:31:26.720
 I do a little bit. Honestly, the last thing I did was I had written, I was working with my son

2:31:26.720 --> 2:31:30.480
 to script some Minecraft stuff. So I was doing a little bit of that. That was the last, literally

2:31:30.480 --> 2:31:34.800
 the last code I wrote. Oh, you know what? Also, I wrote some code to do some

2:31:35.360 --> 2:31:37.680
 cap table evaluation, waterfall modeling kind of stuff.

2:31:39.120 --> 2:31:44.000
 What advice would you give to a young person? He said your son today in high school,

2:31:44.000 --> 2:31:47.040
 maybe even college, about career, about life.

2:31:48.400 --> 2:31:49.920
 This may be where I get into trouble a little bit.

2:31:51.040 --> 2:31:55.840
 We are coming to the end. We're rapidly entering a time between worlds.

2:31:55.840 --> 2:32:01.680
 So we have a world now that's starting to really crumble under the weight of aging institutions

2:32:01.680 --> 2:32:07.280
 that no longer even pretend to serve the purposes they were created for. We are creating technologies

2:32:07.280 --> 2:32:12.480
 that are hurtling billions of people headlong into philosophical crises, who they don't even know

2:32:12.480 --> 2:32:16.320
 the philosophical operating systems in their firmware, and they're heading into a time when

2:32:16.320 --> 2:32:21.760
 that gets vaporized. So for people in high school, and certainly I tell my son this as well, he's in

2:32:21.760 --> 2:32:30.000
 middle school, people in college, you are going to have to find your own way. You're going to

2:32:30.000 --> 2:32:36.080
 have to have a pioneer spirit, even if you live in the middle of the most dense urban environment.

2:32:37.520 --> 2:32:45.520
 All of human reality around you is the result of the last few generations of humans

2:32:45.520 --> 2:32:53.520
 agreeing to play certain kinds of games. A lot of those games no longer operate according to

2:32:53.520 --> 2:33:01.120
 the rules they used to. Collapse is nonlinear, but it will be managed. And so if you are in a

2:33:01.120 --> 2:33:10.000
 particular social caste or economic caste, and I think it's not kosher to say that about America,

2:33:10.000 --> 2:33:16.240
 but America is a very stratified and classist society, there's some mobility, but it's really

2:33:16.240 --> 2:33:22.000
 quite classist. And in America, unless you're in the upper middle class, you are head into very

2:33:22.000 --> 2:33:28.400
 choppy waters. So it is really, really good to think and understand the fundamentals of what you

2:33:28.400 --> 2:33:36.560
 need to build a meaningful life for you, your loved ones with your family. And almost all of the

2:33:36.560 --> 2:33:43.600
 technology being created that's consumer facing is designed to own people, to take the four stack

2:33:44.240 --> 2:33:50.880
 of people, to delaminate them and to own certain portions of that stack. And so if you want to

2:33:50.880 --> 2:33:56.240
 be an integral human being, if you want to have your agency and you want to find your own way in

2:33:56.240 --> 2:34:02.880
 the world, when you're young, would be a great time to spend time looking at some of the classics

2:34:02.880 --> 2:34:08.880
 around what it means to live a good life, what it means to build connection with people. And so

2:34:08.880 --> 2:34:15.840
 much of the status games, so much of the stuff, one of the things that I talk about as we create

2:34:16.640 --> 2:34:20.960
 more and more technology, there's a gradient of technology and a gradient of technology always

2:34:20.960 --> 2:34:25.040
 leads to a gradient of power. And this is Jacques Aloul's point to some extent as well.

2:34:25.040 --> 2:34:29.120
 That gradient of power is not going to go away. The technologies are going so fast

2:34:29.120 --> 2:34:33.600
 that even people like me, who helped create some of the stuff, I'm being left behind that's

2:34:33.600 --> 2:34:38.080
 cutting edge research. I don't know what's going on against today. I'll go read some proceedings.

2:34:38.640 --> 2:34:45.040
 So as the world gets more and more technological, it will create more and more gradients where people

2:34:45.040 --> 2:34:51.600
 will seize power, economic fortunes. And the way they make the people who are left behind okay

2:34:51.600 --> 2:34:59.840
 with their lot in life is they create lottery systems. They make you take part in the narrative

2:34:59.840 --> 2:35:07.200
 of your own being trapped in your own economic zone. So avoiding those kinds of things is really

2:35:07.200 --> 2:35:11.760
 important knowing when someone is running game on you basically. So these are things I would tell

2:35:11.760 --> 2:35:16.400
 young people. It's a dark message, but it's realism. I mean, that's what I see. So after you

2:35:16.400 --> 2:35:23.440
 gave some realism, you sit back with your son, you're looking out at the sunset. What to him

2:35:24.080 --> 2:35:31.360
 can you give as words of hope and to you from where do you derive hope for the future of our

2:35:31.360 --> 2:35:37.280
 world? So you said at the individual level, you have to have a pioneer mindset to go back to

2:35:37.280 --> 2:35:42.960
 the classics to understand what is in human nature you can find meaning. But at the societal level,

2:35:42.960 --> 2:35:46.720
 what trajectory, when you look at possible trajectories, what gives you hope?

2:35:47.280 --> 2:35:54.560
 What gives me hope is that we have little tremors now shaking people out of the reverie

2:35:54.560 --> 2:35:58.640
 of the fiction of modernity that they've been living in kind of a late 20th century style

2:35:58.640 --> 2:36:06.880
 modernity. That's good, I think, because and also to your point earlier, people are burning

2:36:06.880 --> 2:36:09.680
 out on some of the social media stuff. They're sort of seeing the ugly side, especially the

2:36:09.680 --> 2:36:15.760
 latest news with Facebook and the whistleblower. It's quite clear these things are not all

2:36:15.760 --> 2:36:21.680
 they're cracked up to be. I believe better social media can be built because they are burning out

2:36:21.680 --> 2:36:26.320
 and incentivize other competitors to be built. Do you think that's possible?

2:36:26.320 --> 2:36:34.560
 Well, the thing about it is that when you have extractive return on returns capital coming in

2:36:34.560 --> 2:36:38.320
 and saying, look, you own a network, give me some exponential dynamics out of this network.

2:36:38.320 --> 2:36:42.560
 What are you going to do? You're going to just basically put a toll keeper at every single node

2:36:42.560 --> 2:36:49.120
 and every single graph edge, every node, every vertex, every edge. But if you don't have that

2:36:49.120 --> 2:36:53.360
 need for it, if no one's sitting there saying, hey, Wikipedia monetize every character, every

2:36:53.360 --> 2:36:59.840
 byte, every phrase, then generative human dynamics will naturally sort of arise, assuming we respect

2:36:59.840 --> 2:37:05.200
 a few principles around online communications. So the greatest and biggest social network

2:37:05.200 --> 2:37:12.000
 in the world is still like email SMS. So we're fine there. The issue with the social media,

2:37:12.000 --> 2:37:17.040
 as we call it now, is they're actually just new amplification systems. Now it's benefit

2:37:17.040 --> 2:37:23.200
 to certain people like yourself who have interesting content to be amplified. So it's

2:37:23.200 --> 2:37:26.720
 created a creator economy and that's cool. There's a lot of great content out there.

2:37:26.720 --> 2:37:31.520
 But giving everyone a shot at the fame lottery saying, hey, you could also have your, if you

2:37:31.520 --> 2:37:36.320
 wiggle your butt the right way on TikTok, you can have your 15 seconds of microfame. That's not

2:37:36.320 --> 2:37:44.160
 healthy for society at large. So I think if we can create tools that help people be conscientious

2:37:44.160 --> 2:37:49.520
 about their attention, spend time looking at the past and really retrieving memory and calling,

2:37:49.520 --> 2:37:55.200
 not calling, but processing and thinking about that, I think that's certainly possible. And

2:37:55.200 --> 2:38:01.040
 hopefully that's what we get. So the bigger picture, the bigger question that you're asking about,

2:38:01.040 --> 2:38:10.800
 what gives me hope is that these early shocks of COVID lockdowns and remote work and all these

2:38:10.800 --> 2:38:16.880
 different kinds of things, I think it's getting people to a point where they are looking, they're

2:38:16.880 --> 2:38:22.640
 sort of no longer in the reverie. As my friend Jim Rutt says, there's more people with ears to hear

2:38:22.640 --> 2:38:27.920
 now with the pandemic and education. Everyone's like, wait, wait, what have you guys been doing

2:38:27.920 --> 2:38:31.680
 with my kids? How are you teaching them? What is this crap you're giving them as homework?

2:38:32.240 --> 2:38:36.720
 So I think these are the kinds of things that are getting in the supply chain disruptions,

2:38:36.720 --> 2:38:41.040
 getting more people to think about, how do we actually just make stuff? This is all good,

2:38:42.800 --> 2:38:49.200
 but the concern is that it's still going to take a while for these things, for people to learn how

2:38:49.200 --> 2:38:56.320
 to be agentic again and to be in right relationship with each other and with the world. So the

2:38:56.320 --> 2:39:01.280
 message of hope is still people are resilient and we are building some really amazing technology.

2:39:01.280 --> 2:39:09.440
 And I also, to me, I derive a lot of hope from individuals in that van. The power of a single

2:39:09.440 --> 2:39:15.120
 individual to transform the world, to do positive things to the world is quite incredible. You've

2:39:15.120 --> 2:39:19.520
 been talking about it's nice to have as many of those individuals as possible, but even the power

2:39:19.520 --> 2:39:25.120
 of one is kind of magical. It is. We're in a mode now where we can do that. I think also,

2:39:25.120 --> 2:39:30.080
 you know, part of what I try to do is in coming to podcasts like yours and then spamming with all

2:39:30.080 --> 2:39:34.960
 this philosophical stuff that I've got going on, there are a lot of good people out there trying

2:39:34.960 --> 2:39:42.560
 to put words around the current technological, social, economic crises that we're facing.

2:39:43.120 --> 2:39:46.560
 And the space of a few short years, I think there has been a lot of great content produced

2:39:46.560 --> 2:39:52.000
 around this stuff for people who want to see, want to find out more or think more about this.

2:39:52.000 --> 2:39:56.560
 We're popularizing certain kinds of philosophical ideas that move people beyond just the, oh,

2:39:56.560 --> 2:40:00.480
 you're a communist, oh, you're a capitalist kind of stuff. We're way past that now.

2:40:01.120 --> 2:40:06.240
 So that also gives me hope that I feel like I myself am getting a handle on how to think about

2:40:06.240 --> 2:40:11.760
 these things. It makes me feel like I can hopefully effect change for the better.

2:40:12.400 --> 2:40:17.520
 We've been sneaking up on this question all over the place. Let me ask the big ridiculous question.

2:40:17.520 --> 2:40:24.960
 What is the meaning of life? Wow. The meaning of life.

2:40:28.720 --> 2:40:32.080
 Yeah, I don't know. I mean, I've not really understood that question.

2:40:32.080 --> 2:40:42.480
 When you say meaning crisis, you're saying that there is a search for a kind of experience that's

2:40:42.480 --> 2:40:51.120
 could be described as fulfillment, like the aha moment of just like joy. And maybe when you see

2:40:51.120 --> 2:40:56.160
 something beautiful, or maybe you have created something beautiful, that experience that you get,

2:40:57.280 --> 2:41:03.920
 it feels like it all makes sense. So some of that is just chemicals coming together in your mind

2:41:03.920 --> 2:41:11.600
 and all kinds of things. But it seems like we're building a sophisticated collective intelligence

2:41:11.600 --> 2:41:19.920
 that's providing meaning in all kinds of ways to its members. And there's a theme to that meaning.

2:41:19.920 --> 2:41:27.920
 So for a lot of history, I think faith played an important role. Faith in God is a religion.

2:41:28.800 --> 2:41:34.800
 I think technology in the modern era is kind of serving a little bit of a source of meaning

2:41:34.800 --> 2:41:43.120
 for people like innovation of different kinds. I think the old school things of love and the

2:41:43.120 --> 2:41:51.600
 basics of just being good at stuff. But you were a physicist. So there's a desire to say, okay,

2:41:51.600 --> 2:41:57.600
 yeah, but these seem to be like symptoms of something deeper. Right. Like why little meaning?

2:41:57.600 --> 2:42:02.800
 What's capital M meaning? Yeah, what's capital M meaning? Why are we reaching for order when

2:42:02.800 --> 2:42:10.000
 there is excess of energy? I don't know if I can answer the why. Any why that I come up with,

2:42:10.000 --> 2:42:16.480
 I think, is going to be, I'd have to think about that a little more, maybe get back to you on that.

2:42:16.480 --> 2:42:22.720
 But I will say this. We do look at the world through a traditional, I think most people look

2:42:22.720 --> 2:42:27.120
 at the world through what I would say is a subject object kind of metaphysical lens, that

2:42:27.120 --> 2:42:34.000
 we have our own subjectivity. And then there's all of these object things that are not us.

2:42:34.000 --> 2:42:38.800
 So I'm me and these things are not me. And I'm interacting with them. I'm doing things to them.

2:42:39.760 --> 2:42:45.600
 But a different view of the world that looks at it as much more connected that realizes, oh,

2:42:46.880 --> 2:42:53.040
 I'm really quite embedded in a soup of other things. And I'm simply almost like a standing

2:42:53.040 --> 2:42:59.040
 wave pattern of different things. So when you look at the world in that kind of connected sense,

2:42:59.040 --> 2:43:06.480
 I've recently taken a shine to this particular thought experiment, which is what if it was the

2:43:06.480 --> 2:43:14.560
 case that everything that we touch with our hands, that we pay attention to, that we actually give

2:43:14.560 --> 2:43:24.400
 intimacy to, what if there's actually all the mumbo jumbo people with the magnetic healing

2:43:24.400 --> 2:43:29.440
 crystals and all this other kind of stuff and quantum energy stuff, what if that was a thing?

2:43:30.160 --> 2:43:34.880
 What if when you literally when your hand touches an object, when you really look at

2:43:34.880 --> 2:43:38.000
 something and you concentrate and you focus on it and you really give it attention,

2:43:38.000 --> 2:43:44.800
 you actually give it, there is some physical residue of something, a part of you,

2:43:45.440 --> 2:43:51.280
 a bit of your life force that goes into it. Now, this is, of course, completely mumbo jumbo stuff.

2:43:51.280 --> 2:43:55.600
 This is not like, I don't actually think this is real, but let's do the thought experiment.

2:43:55.600 --> 2:44:03.440
 What if it was? What if there actually was some quantum magnetic crystal and energy field thing

2:44:03.440 --> 2:44:09.680
 that just by touching this can, this can has changed a little bit somehow, and it's not much

2:44:10.400 --> 2:44:14.320
 unless you put a lot into it and you touch it all the time, like your phone, right?

2:44:14.880 --> 2:44:22.000
 These things gain, they gain meaning to you a little bit, but what if there's something that

2:44:23.360 --> 2:44:28.160
 technical objects, the phone is a technical object, it does not really receive attention or

2:44:28.160 --> 2:44:33.280
 intimacy and then allow itself to be transformed by it. But if it's a piece of wood,

2:44:33.280 --> 2:44:39.760
 if it's the handle of a knife that your mother used for 20 years to make dinner for you, right?

2:44:40.320 --> 2:44:45.760
 What if it's a keyboard that you banged out your world transforming software library on?

2:44:46.560 --> 2:44:51.360
 These are technical objects and these are physical objects, but somehow there's something to them.

2:44:51.360 --> 2:44:55.440
 We feel an attraction to these objects as if we have imbued them with life energy.

2:44:57.120 --> 2:45:00.320
 If you walk that thought experiment through, what happens when we touch another person,

2:45:00.320 --> 2:45:08.160
 when we hug them, when we hold them? And the reason this ties into my answer for your question is

2:45:08.160 --> 2:45:16.320
 that if there is such a thing, if we were to hypothesize, you know, hypothesize it's such a

2:45:16.320 --> 2:45:30.560
 thing, it could be that the purpose of our lives is to imbue as many things with that love as possible.

2:45:30.560 --> 2:45:36.480
 That's a beautiful answer and a beautiful way to end it. Peter, you're an incredible person.

2:45:36.480 --> 2:45:36.880
 Thank you.

2:45:36.880 --> 2:45:46.560
 Benning so much in the space of engineering and in the space of philosophy. I'm really proud to

2:45:46.560 --> 2:45:52.320
 be living in the same city as you. And I'm really grateful that you have spent your valuable time

2:45:52.320 --> 2:45:55.200
 with me today. Well, thank you. I appreciate the opportunity to speak with you.

2:45:56.400 --> 2:46:00.480
 Thanks for listening to this conversation with Peter Wang. To support this podcast,

2:46:00.480 --> 2:46:05.680
 please check out our sponsors in the description. And now let me leave you with some words for

2:46:05.680 --> 2:46:13.280
 Peter Wang himself. We tend to think of people as either malicious or incompetent. But in a world

2:46:13.280 --> 2:46:20.880
 filled with corruptible and unchecked institutions, there exists a third thing, malicious incompetence.

2:46:20.880 --> 2:46:27.520
 It's a social cancer and it only appears once human organizations scale beyond personal accountability.

2:46:27.520 --> 2:46:37.520
 Thank you for listening and hope to see you next time.

