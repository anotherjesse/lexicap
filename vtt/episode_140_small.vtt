WEBVTT

00:00.000 --> 00:04.640
 The following is a conversation with Lisa Feldman Barrett, her second time on the

00:04.640 --> 00:11.120
 podcast. She's a neuroscientist at Northeastern University and one of my favorite people.

00:11.120 --> 00:16.720
 Her new book called Seven and a Half Lessons About the Brain is out now as of a couple days ago,

00:16.720 --> 00:21.120
 so you should definitely support Lisa by buying it and sharing with friends if you like it.

00:21.680 --> 00:26.960
 It's a great short intro to the human brain. Quick mention of each sponsor,

00:26.960 --> 00:32.720
 followed by some thoughts related to the episode. Athletic Greens, the all in one drink that I start

00:32.720 --> 00:39.520
 every day with to cover all my nutritional bases. Eighth Sleep, a mattress that cools itself and

00:39.520 --> 00:45.520
 gives me yet another reason to enjoy sleep. Masterclass, online courses that I enjoy from

00:45.520 --> 00:51.360
 some of those amazing people in history and better help. Online therapy with a licensed

00:51.360 --> 00:56.560
 professional. Please check out these sponsors in the description to get a discount and to support

00:56.560 --> 01:03.760
 this podcast. As a side note, let me say that Lisa, just like Minola Skellis, is a local brilliant

01:03.760 --> 01:09.840
 mind and friend and someone I can see talking to many more times. Sometimes it's fun to talk to a

01:09.840 --> 01:15.760
 scientist not just about their field of expertise but also about random topics, even silly ones,

01:15.760 --> 01:22.800
 from love to music to philosophy. Ultimately, it's about having fun, something I know nothing about.

01:22.800 --> 01:28.480
 This conversation is certainly that. It may not always work, but it's worth a shot. I think it's

01:28.480 --> 01:35.280
 valuable to alternate along all kinds of dimensions, like between deeper technical discussions and more

01:35.280 --> 01:42.240
 fun, random discussion, from liberal thinker to conservative thinker, from musician to athlete,

01:42.240 --> 01:49.520
 from CEO to junior engineer, from friend to stranger. Variety makes life and conversation

01:49.520 --> 01:55.760
 more interesting. Let's see where this little podcast journey goes. If you enjoy this thing,

01:55.760 --> 02:01.760
 subscribe on YouTube, review five stars on our podcast, follow on Spotify, support on Patreon,

02:01.760 --> 02:09.680
 or connect with me on Twitter at Lex Freedman. And now here's my conversation with Lisa Feldman Barrett.

02:11.040 --> 02:15.040
 Based on the comments in our previous conversation, I think a lot of people will be

02:15.040 --> 02:21.440
 very disappointed, I should say, to learn that you are in fact married. As they say,

02:21.440 --> 02:29.040
 all the good ones are taken. Okay, so I'm a fan of your husband as well. Dan is a programmer,

02:29.040 --> 02:36.240
 a musician, so a man after my own heart. Can I ask a ridiculously over romanticized question of

02:36.960 --> 02:43.840
 when did you first fall in love with Dan? It's actually, it's a really, it's a really romantic

02:43.840 --> 02:54.000
 story, I think. So I was divorced by the time I was 26, 27, 26, I guess. And I was in my first

02:54.000 --> 03:00.480
 academic job, which was Penn State University, which is in the middle of Pennsylvania, surrounded by

03:00.480 --> 03:05.840
 mountains. So you have, it's four hours to get anywhere to get to Philadelphia, New York, Washington.

03:05.840 --> 03:13.840
 I mean, you're basically stuck, you know. And I was very fortunate to have a lot of other assistant

03:13.840 --> 03:18.320
 professors who were hired at the same time as I was. So there were a lot of us, we were all friends,

03:18.320 --> 03:26.800
 which was really fun. But I was single. And I didn't want to date a student. And there were no,

03:27.440 --> 03:31.840
 and I wasn't going to date somebody in my department, that's just a recipe for disaster.

03:31.840 --> 03:37.120
 Yeah. So even at 20, whatever you were, you were already wise enough to know that.

03:37.120 --> 03:41.600
 Yeah, a little bit maybe. Yeah. I wouldn't call me wise at that age. But anyways,

03:42.560 --> 03:50.960
 not sure that I would say that I'm wise now, but. And so after, you know, I was spending

03:50.960 --> 03:57.200
 probably 16 hours a day in the lab because it was my first year. And as an assistant professor,

03:57.200 --> 04:03.360
 and there's a lot to do. And I was also bitching and moaning to my friends that, you know, I hadn't

04:03.360 --> 04:08.400
 had sex. And I don't know how many, you know, months. And it was, I was starting to, you know,

04:08.400 --> 04:14.400
 become unhappy with my life. And I think at a certain point, they just got tired of listening

04:14.400 --> 04:19.120
 to me bitch and moan and said, just do something about it then, like, do, you know, if you're

04:19.120 --> 04:26.000
 unhappy. And so the first thing I did was I made friends with a sushi chef in town. And this is

04:26.000 --> 04:33.440
 like a state college Pennsylvania in the early 90s was there was like a pizza shop and a sub shop

04:33.440 --> 04:39.120
 and actually a very good bagel shop and one good coffee shop and maybe one nice restaurant. I mean,

04:39.120 --> 04:45.600
 there was really, but there was a the second son of a Japanese sushi chef who was not going to

04:45.600 --> 04:51.040
 inherit the restaurant. And so he moved to Pennsylvania and was giving sushi lessons.

04:51.040 --> 04:56.320
 So I met this guy, the sushi, the sushi chef, and we decided to throw a sushi party

04:56.320 --> 05:01.280
 at the coffee shop. So we basically, it was the goal was to invite every eligible bachelor

05:01.280 --> 05:09.120
 really within like a 20 mile radius. We had a totally fun time. I wore an awesome crushed

05:09.120 --> 05:15.920
 velvet burgundy dress was beautiful dress. And I didn't meet any, I met a lot of friends,

05:15.920 --> 05:19.520
 new friends, but it did not meet anybody. So then I thought, okay, well, maybe I'll try the

05:19.520 --> 05:28.320
 Personals ads, which I had never used before in my life. And I first tried the paper Personals ads,

05:28.960 --> 05:33.760
 like a newspaper, like in the newspaper, that didn't work. And then a friend of mine said,

05:33.760 --> 05:40.640
 oh, you know, there's this thing called net news. So we're going, this is like 1992, maybe. So there

05:40.640 --> 05:47.920
 was this anonymous, you could do it anonymously. So you would, you would read, you could post or

05:47.920 --> 05:55.760
 you could read ads and then respond to an address, which was anonymous and you, that was yoked to

05:55.760 --> 06:03.920
 somebody's real address. And, and there was always a lag because it was this like a bulletin board

06:03.920 --> 06:12.640
 sort of thing. So at first I read, I read them over and I decided to, to respond to one or two.

06:12.640 --> 06:16.880
 And, you know, it was interesting. Sorry, this is not on the internet.

06:16.880 --> 06:20.160
 Yeah, this is totally on the internet. But it takes, there's a delay of a couple of days or

06:20.160 --> 06:26.000
 whatever. Yeah, right, right. It's 1992. There's no web web pictures. There's no pictures. The

06:26.000 --> 06:36.480
 web doesn't exist. It's all done in ASCII formats sort of. And, you know, but the ratio of men to

06:36.480 --> 06:42.080
 women was like 10 to one. I mean, there were many more men because it was basically academics and

06:42.080 --> 06:47.280
 the government. That was it. That's what, no, I mean, I think AOL maybe was just starting to become

06:47.280 --> 06:58.240
 popular. But, and so the first person I met told me that he was a, he worked, he was a scientist

06:58.240 --> 07:06.640
 who worked for NASA and yeah. Anyways, it turned out that he didn't actually.

07:06.640 --> 07:12.640
 Yeah. This is how they brag as you elevate your, as opposed to saying you're taller than you are,

07:12.640 --> 07:17.120
 you say like your position is higher. Yeah. And I actually, I would have been fine dating somebody

07:17.120 --> 07:23.360
 who was a scientist. It's just that they have, it's just that whoever I date has to just accept

07:23.360 --> 07:31.360
 that I am and that I'm, I was pretty ambitious and was trying to make my career. And, you know,

07:31.360 --> 07:36.320
 that's not, that's not, I think it's maybe more common now for men to maybe accept that

07:36.320 --> 07:41.120
 in their female partners, but at that time not, not so common. To be intimidating, I guess.

07:41.760 --> 07:49.120
 Yes. I, that has been said. And so, and so then the next one I actually corresponded with and we

07:49.120 --> 07:53.680
 actually got to the point of talking on the phone and we had this really kind of funny conversation

07:53.680 --> 07:59.920
 where, you know, we're chatting and he said, he's, he introduces the idea that, you know,

07:59.920 --> 08:05.040
 he's really looking for a dominant woman and I'm thinking, I'm a psychologist by training.

08:05.040 --> 08:09.200
 So I'm thinking, oh, he means sex roles. Like, I'm like, no, I'm very assertive and I'm glad

08:09.200 --> 08:13.520
 you think that, you know, okay. Anyways, long story short, that's not really what he meant.

08:16.240 --> 08:22.160
 Okay, got it. Yeah. So, and I just, you know, that will just show you my level of naivete.

08:22.160 --> 08:27.920
 Like I was like, I didn't completely understand. I was like, well, yeah, you know, no. At one point,

08:27.920 --> 08:34.240
 he asked me how I felt about him wearing my lingerie and I was like, I don't even share my

08:34.240 --> 08:41.280
 lingerie with my sister. Like, I don't share my lingerie with anybody, you know, no. The third

08:41.280 --> 08:51.360
 one I interacted with was a banker who lived in Singapore and that conversation didn't last very

08:51.360 --> 09:00.880
 long because he made an analogy, I guess he made an analogy between me and a character in the fountain

09:00.880 --> 09:08.800
 head, the woman who's, who's raped in the fountain head. And I was like, okay, that's not, that's

09:08.800 --> 09:15.600
 not a good, that's not a good one. Not that scene. Not that scene. So then I, so then I was like,

09:15.600 --> 09:20.000
 okay, you know what, I'm going to post my own ad. And so I did, I posted, well, first I wrote my ad

09:20.000 --> 09:24.560
 and then of course I checked it with my, my friends who were all also assistant professors,

09:24.560 --> 09:29.440
 they're like my little Greek chorus and then I posted it and I got something like,

09:29.440 --> 09:35.920
 I don't know, 80 something responses in 24 hours. I mean, it was, do you remember the pitch?

09:37.840 --> 09:43.520
 Like how, how you, I guess, condensed yourself? I don't remember it exactly, although Dan has it.

09:44.720 --> 09:51.520
 But actually for our 20th wedding anniversary, he took our, our exchanges and he printed them off

09:51.520 --> 09:57.760
 and put them in a leather bound book for us to read, which was really sweet. Yeah, I think I was

09:57.760 --> 10:02.640
 just really direct. Like I'm almost 30. I'm a scientist. I'm not looking just, you know, I'm,

10:02.640 --> 10:07.600
 I'm looking for something serious and, you know, but the thing is, I forgot to say where my location

10:07.600 --> 10:16.880
 was and my age, which I forgot. So I got lots of, I mean, I will say, so I printed off all of the

10:16.880 --> 10:23.760
 responses and I had all my friends over and we were, you know, had a big, I made a big pot of

10:23.760 --> 10:30.480
 gumbo and we drank through several bottles of wine reading these responses. And I would say for the

10:30.480 --> 10:36.720
 most part they were really sweet, like earnest and genuine as much as you could tell that somebody's

10:36.720 --> 10:40.640
 being genuine. I mean, it seemed, you know, there were a couple of really funky ones, like, you

10:40.640 --> 10:45.360
 know, this one couple who told me that I was their soulmate, the two of them, then they were looking

10:45.360 --> 10:52.720
 for, you know, a third person. And I was like, okay, but mostly super seem seemed like super genuine

10:52.720 --> 10:59.120
 people. And so I chose five men to start corresponding with and I was corresponding with them. And then

10:59.760 --> 11:05.040
 about a week later, I get this other email. And okay, and then I post something the next day that

11:05.040 --> 11:10.560
 said, okay, you know, thank you so much. And I'm going to answer it every person back. But then

11:10.560 --> 11:14.080
 after that, I said, okay, and I'm not going to answer anymore. You know, because it was, they

11:14.080 --> 11:18.400
 were still coming in, I couldn't, you know, I have a job and, you know, a house to take care of and

11:18.400 --> 11:26.080
 stuff. So and then about a week later, I get this other email. And he says, you know, he just

11:26.080 --> 11:31.120
 describes himself like, I'm this, I'm this, I'm this, I'm a chef, I'm a scientist, I'm a this,

11:31.120 --> 11:38.320
 I'm a this. And so I emailed him back and I said, you know, you seem interesting, you can write me

11:38.320 --> 11:42.240
 at my actual address if you want, here's my address, I'm not really responding, I'm not

11:42.240 --> 11:45.520
 really responding to other people anymore, but you seem interesting, you know, you can write to me

11:45.520 --> 11:53.520
 if you want. And then he wrote to me. And I, and I wrote him back and I it was a it was a non

11:53.520 --> 11:57.440
 discreet kind of email and I wrote him back and I said, thanks for responding, you know, I'm really

11:57.440 --> 12:03.120
 busy right now. I'm I was in the middle of writing my first slate of grant applications. So I was

12:03.120 --> 12:08.240
 really consumed. And I said, I'll get back to you in a couple of days. And so I did, I waited a

12:08.240 --> 12:12.640
 couple of days until my grants were, you know, safe grant application safely out the door.

12:13.280 --> 12:20.720
 And then I emailed him back. And then he emailed me. And then really across two days, we sent 100

12:20.720 --> 12:28.400
 emails. And text only, was there pictures or anything? Text only, text only. And then so this

12:28.400 --> 12:35.520
 was like a Thursday and a Friday. And then Friday, he said, let's talk on the weekend on the phone.

12:35.520 --> 12:44.320
 And I said, okay. And he wanted to talk Sunday night. And I had a date Sunday night. So I said,

12:44.320 --> 12:49.840
 okay, sure, we can talk Sunday night. And then I was like, well, you know, I don't really want to

12:49.840 --> 12:53.840
 cancel my date. So I'm just going to call him on Saturday. So I just called, I call call him on

12:53.840 --> 13:04.000
 Saturday. And a woman answered. Oh, wow. That's not cool. Not cool. And so she says, you know,

13:04.000 --> 13:09.920
 hello, and I say, oh, you know, stay on there. And she said, sure, can I ask who's calling? And I

13:09.920 --> 13:14.880
 said, it tell him it's Lisa. And she went, Oh my God, oh my God, I'm just a friend. I'm just a

13:14.880 --> 13:20.880
 friend. I just wanted to tell you I'm just a friend. And I was like, yeah, this is adorable.

13:20.880 --> 13:25.280
 Right. She doesn't and then he gets on the phone, not high. Nice to meet the first thing he says

13:25.280 --> 13:33.360
 to me, she's just a friend. So I was just so charmed really by the whole thing. So it was,

13:33.360 --> 13:38.640
 it was Yom Kippur. It was the Jewish day of atonement that was ending and they were baking

13:38.640 --> 13:43.040
 cookies and going to a breakfast. So people, you know, as you know, fast all day, and then they

13:43.040 --> 13:49.680
 go to a party and they break fast. So I thought, okay, I'll just, I'll just, you know, cancel my

13:49.680 --> 13:57.920
 date. So I did. And I stayed home and we talked for eight hours. And then the next night for six

13:57.920 --> 14:05.440
 hours. And basically, it just went on like that. And then by the end of the week, he, he flew to

14:05.440 --> 14:09.920
 State College. And, you know, we'd gone through this whole thing where I'd said, we're going to

14:09.920 --> 14:14.880
 take it slow, we're going to get to know each other, you know, and then really by, I think we

14:14.880 --> 14:19.440
 talked like two or three times, these like really long conversations. And then he said, I'm just

14:19.440 --> 14:26.080
 going to fly there. And then so, of course, there's, I don't even know that there were fax

14:26.080 --> 14:32.880
 machines at that point. Maybe there were, but I don't think so. Anyway, so he, we decided we'll

14:32.880 --> 14:39.200
 exchange pictures. And so he, you know, I take my photograph and I give it to my secretary. And I

14:39.200 --> 14:46.160
 say to my secretary, fax this, I say this, send this priority mail. Priority mail. And he goes,

14:46.160 --> 14:49.600
 okay, I'll send a priority mail. I'll make this priority mail. He's like, I know priority mail.

14:49.600 --> 14:58.320
 Okay. And then, so I get Dan's photograph in the, in the mail. And, you know, it's, it's him in a,

14:58.320 --> 15:02.960
 in a, in shorts, and you can see that he's probably somewhere like the Bahamas or something

15:02.960 --> 15:07.920
 like that. And it's like cropped. So clearly what he's done is he's taken a photograph where,

15:07.920 --> 15:12.960
 you know, he's in it with someone else who turned out to be his ex wife. So I'm thinking, well,

15:12.960 --> 15:17.360
 this is awesome. You know, I've hit the jackpot. He's, he's, you know, very appealing to me,

15:17.360 --> 15:24.240
 very attractive. And, and then, you know, my photograph doesn't show up and it doesn't show up.

15:24.240 --> 15:29.840
 And, you know, so like one day and then two days. And then, you know, he's, he's like, you know,

15:29.840 --> 15:35.200
 you're, I said, well, I asked my secretary to send a priority. I mean, I don't know, you know,

15:36.320 --> 15:41.040
 what he did. And, and he's like, I said, I'm like, well, you don't have to, you know,

15:41.040 --> 15:44.240
 you don't have to come. And he's like, no, no, no, I'm gonna, I'm gonna, you know, we've had like

15:44.240 --> 15:50.480
 five dates, the equivalent of five dates practically. And then, so he's supposed to

15:50.480 --> 15:56.880
 fly on a Thursday or Friday, I can't remember. And I get a call like maybe an hour before

15:56.880 --> 16:00.560
 his flight's supposed to leave. And he says, hi. And I say, and it's just something in his voice,

16:00.560 --> 16:04.320
 right. And I say, because at this point, I think I've talked to him like for 25 hours, I don't

16:04.320 --> 16:10.960
 know. And he says, hi. And I'm like, you got the picture. And he's like, yeah. And I'm like,

16:10.960 --> 16:20.880
 you don't like it. And he's like, well, I'm sure it's not, I'm sure it's your, I'm sure it's just

16:20.880 --> 16:27.120
 not a good, you know, it's not just probably not your best. Oh, no. You know, you don't, you don't

16:27.120 --> 16:30.480
 have to come. And he's like, no, no, no, I'm coming. And I'm like, no, you don't have to come.

16:30.480 --> 16:33.920
 And he's like, no, no, I really want to, I'm, you know, I'm getting on the plane. I'm like,

16:33.920 --> 16:39.840
 you don't have to get on the plane. He's like, no, I'm getting on the plane. And so I go down to my,

16:39.840 --> 16:44.480
 I go, I'm in my office, this is happening, right? So I go downstairs to my, one of my closest friends

16:44.480 --> 16:51.520
 who is still actually one of my closest friends, who is one of my colleagues. And Kevin, and I

16:51.520 --> 16:56.000
 say, Kevin, and I go to Kevin, I go, Kevin, Kevin, Kevin, he doesn't like the photograph. And Kevin's

16:56.000 --> 16:59.040
 like, well, which photograph did you send? And I'm like, well, you know, the one where we're

16:59.040 --> 17:05.040
 shooting pool and he's like, you sent that photograph, that's a horrible photograph. I'm

17:05.040 --> 17:09.600
 like, yeah, but it's the only one that I had that was like, where my hair was kind of similar to

17:09.600 --> 17:16.560
 what it is now. And he's like, Lisa, do I have to check everything for you? You should not have

17:16.560 --> 17:23.200
 sent that, you know, but still he flew over. So he flew, where from by the way, he was in,

17:23.200 --> 17:31.600
 he was in graduate school at Amherst, yeah, at UMass Amherst. So he flew and I picked him up and

17:31.600 --> 17:41.280
 at the airport and he was happy. So whatever the concern was was gone. And I was dressed,

17:41.280 --> 17:48.000
 you know, I carefully, carefully dressed. I was really, really nervous. Because I am not,

17:48.000 --> 17:53.760
 I don't really believe in fate. And I don't really think there's only one person that you can be with.

17:53.760 --> 18:04.160
 But I think, you know, people who, some people are curvy, they're kind of complicated. And so the

18:04.160 --> 18:10.480
 number of people who fit them is maybe less than like it mathematically speaking. Yeah. And so

18:10.480 --> 18:15.760
 when I was going to pick him up at the airport, I was thinking, well, this could, I could be

18:15.760 --> 18:23.760
 going to pick up the, the person I'm going to marry or not. I mean, like I really, but I really, you

18:23.760 --> 18:31.760
 know, like our conversations were just very authentic and very moving and, and we really

18:31.760 --> 18:39.760
 connected. And, and I really felt like he understood me actually, in a way that a lot of

18:39.760 --> 18:50.960
 people don't. And, and, and what was really nice was at the time, you know, the airport was this

18:50.960 --> 18:58.400
 tiny little airport out in a cornfield, basically. And so driving back to the town, we were in the

18:58.400 --> 19:03.200
 car for 15 minutes, completely in the dark as I was driving. And so it was very similar to,

19:03.200 --> 19:09.200
 we had just spent, you know, 20 something hours on the telephone, sitting in the dark talking to

19:09.200 --> 19:15.200
 each other. So it was very familiar. And we basically spent the whole weekend together and

19:15.200 --> 19:24.400
 you met all my friends and we had a big party. And, and at the end of the weekend, I said, okay,

19:24.400 --> 19:31.200
 you know, if we're going to give this a shot, we can't, we probably can't, we shouldn't see other

19:31.200 --> 19:39.200
 people. So it's a risk, you know, commitment. But, but I just didn't see how it would work if we

19:39.200 --> 19:43.200
 were dating people locally and then also seeing each other at a distance because I, you know, I've

19:43.200 --> 19:47.200
 had long distance relationships before and they're hard and they, they take a lot of, they take a

19:47.200 --> 19:53.200
 lot of effort. And so we decided we'd give it three months and see what happened. And that was it.

19:53.200 --> 19:59.200
 This is an interesting thing. Like we're all, what is it? There's several billion of us. And

19:59.200 --> 20:05.200
 we're kind of roaming this world. And then you kind of stick together. You find, find somebody that

20:05.200 --> 20:11.200
 just like gets you. And it's interesting to think about there's probably thousands, if not millions

20:11.200 --> 20:17.200
 of people that would, would be sticky to you, depending on the curvature of your space. But

20:19.200 --> 20:25.200
 what, what is the, could you speak to the stickiness, like to the, just the falling in love,

20:25.200 --> 20:35.200
 like seeing that somebody really gets you, maybe by way of telling, do you think, do you remember

20:35.200 --> 20:41.200
 there was a moment when you just realized, damn it. I think I'm like, I think that's, this is the

20:41.200 --> 20:43.200
 guy. I think I'm in love.

20:43.200 --> 20:49.200
 We were having these conversations actually from the, really from the second weekend we were together.

20:49.200 --> 20:53.200
 So he flew back the next weekend to stay college because it was my birthday. It was my 30th birthday.

20:53.200 --> 20:57.200
 My friends were throwing me a party and we went hiking and we hiked up some mountain and we were

20:57.200 --> 21:03.200
 sitting on a cliff over this, you know, overlook and talking to each other. And I was thinking, and

21:03.200 --> 21:07.200
 I actually said to him, like, I, I haven't really known you very long, but I feel like I'm falling

21:07.200 --> 21:13.200
 in love with you, which can't possibly be happening. I must be projecting, but it, but it, but it

21:13.200 --> 21:17.200
 certainly feels that way. Right. Like, I don't believe in love at first sight. So this can't

21:17.200 --> 21:21.200
 really be happening, but it sort of feels like it is. And he was like, I know what you mean.

21:21.200 --> 21:25.200
 And so for the first three months or four months, we would say things to each other like,

21:25.200 --> 21:33.200
 I feel like I'm in love with you, but, you know, but that can't, but things don't really work

21:33.200 --> 21:38.200
 like that. So, but, you know, so, and then it became a joke, like, I feel like I'm in love with you.

21:38.200 --> 21:44.200
 And then eventually, you know, I think, but I think that was one moment where we were, we were

21:44.200 --> 21:54.200
 talking about just, you know, not just all the great aspirations you have or all the things,

21:54.200 --> 21:58.200
 but also things you don't like about yourself, things that you're worried about, things that

21:58.200 --> 22:04.200
 you're scared of. And then I think the, that was sort of solidified the relationship. And then

22:04.200 --> 22:10.200
 there was one weekend where we went to Maine in the winter, which I love, I mean, I really love

22:10.200 --> 22:15.200
 the beach always, but in the winter, particularly.

22:15.200 --> 22:18.200
 Because it's just beautiful and calm and whatever.

22:18.200 --> 22:26.200
 Yeah. And I also, I, I do find beauty in starkness sometimes, like, so there's this grand

22:26.200 --> 22:32.200
 majestic scene of, you know, this very powerful ocean and it's all these like beautiful blue

22:32.200 --> 22:38.200
 grays. And it's just, it's just stunning. And so we were sitting on this huge rock in Maine,

22:38.200 --> 22:45.200
 where we'd gone for the weekend, it was freezing cold. And I honestly can't remember what he

22:45.200 --> 22:54.200
 said or what I said or what, but I, I definitely remember having this feeling of I absolutely

22:54.200 --> 22:59.200
 want to stay with this person. Like I, and I don't know what my life will be like if I'm not

22:59.200 --> 23:02.200
 with this person, like I need to be with this person.

23:02.200 --> 23:09.200
 Can we, from a scientific and a human perspective, dig into your belief that first love at first

23:09.200 --> 23:14.200
 sight is not, is not possible. You don't believe in it. Well, because there is, there, you

23:14.200 --> 23:19.200
 don't think there's like a magic where you see somebody in the, in the Jack Kerouac

23:19.200 --> 23:25.200
 way. And you're like, wow, that's something that's, that's a special little.

23:25.200 --> 23:31.200
 Oh, I definitely, oh, I definitely think you can connect with someone instant in an instance.

23:31.200 --> 23:36.200
 And I definitely think you can say, oh, there's something there. And I'm really clicking with

23:36.200 --> 23:41.200
 that person romantically, but also just with friends. It's possible to do that. You recognize

23:41.200 --> 23:49.200
 a mind that's like yours or that's compatible with yours. There are ways that you feel like

23:49.200 --> 23:53.200
 you're being understood or that you understand something about this person, or maybe you see

23:53.200 --> 23:59.200
 something in this person that you find really compelling or intriguing. But I think, you

23:59.200 --> 24:05.200
 know, your brain is predictive organ, right? You're using your past.

24:05.200 --> 24:06.200
 You're projecting.

24:06.200 --> 24:13.200
 You're using your past to make predictions. And I mean, not deliberately, that's how your

24:13.200 --> 24:20.200
 brain is wired. That's what it does. And so it's filling in all of the gaps that you, you

24:20.200 --> 24:25.200
 know, there are lots of gaps of information that you don't, you know, information you don't

24:25.200 --> 24:30.200
 have. And so your brain is filling those in. And

24:30.200 --> 24:32.200
 But isn't that what love is?

24:32.200 --> 24:38.200
 No, I don't think so, actually. I mean, to some extent, sure, you always, you know, there's

24:38.200 --> 24:44.200
 research to show that people who are in love always see the best in each other. And they,

24:44.200 --> 24:49.200
 you know, when there's a, when there's a negative interpretation or positive interpretation,

24:49.200 --> 24:52.200
 you know, they choose the positive ones, there's a little bit of positive illusion there,

24:52.200 --> 25:02.200
 you know, going on. That's what the research shows. But I think, I think that when you

25:02.200 --> 25:12.200
 find somebody who not just appreciates your faults, but loves you for them, actually,

25:12.200 --> 25:19.200
 you know, like maybe even doesn't see them as a fault. That's, so you have to be honest

25:19.200 --> 25:25.200
 enough about what your, what your faults are. So it's easy to love someone for all the things

25:25.200 --> 25:36.200
 that they, for all the wonderful characteristics they have, it's harder, I think, to love someone

25:36.200 --> 25:40.200
 despite their faults, or maybe even the faults that they see aren't really faults at all to

25:40.200 --> 25:43.200
 you. They're actually something really special.

25:43.200 --> 25:49.200
 But isn't that, can't you explain that by saying the brain kind of, like you're projecting, it's

25:49.200 --> 25:58.200
 you're, you have a conception of a human being or just a spirit that really connects with you

25:58.200 --> 26:04.200
 and you're projecting that onto that person. And within that framework, all their faults

26:04.200 --> 26:06.200
 then become beautiful, like little.

26:06.200 --> 26:10.200
 Maybe, but you just have to pay attention to the prediction error.

26:10.200 --> 26:17.200
 No, but maybe that's what love, like maybe you start ignoring the prediction error.

26:17.200 --> 26:22.200
 That's maybe love is just your ability, like to ignore the prediction error.

26:22.200 --> 26:28.200
 Well, I think that there's some research that might say that, but that's not my experience,

26:28.200 --> 26:33.200
 I guess. But there is some research that says, I mean, there's some research that says you

26:33.200 --> 26:41.200
 have to have an optimal margin of illusion, which means that you put a positive spin on

26:41.200 --> 26:45.200
 smaller things, but you don't ignore the bigger things, right?

26:45.200 --> 26:51.200
 And I think without being judgmental at all, when someone says to me, you know, you're

26:51.200 --> 26:55.200
 not who I thought you were, I mean, nobody says, I said that to me in a really long time,

26:55.200 --> 26:58.200
 but certainly when I was younger, that was, you know, you're not who I thought you were.

26:58.200 --> 27:07.200
 My reaction to that was, well, whose fault is that? You know, I'm a pretty upfront person.

27:07.200 --> 27:16.200
 I mean, I will though say that in my experience, people don't lie to you about who they are.

27:16.200 --> 27:21.200
 They lie to themselves in your presence.

27:21.200 --> 27:30.200
 And so, you know, you don't want to get tied up in that, tangled up in that.

27:30.200 --> 27:35.200
 And I think from the get go, Dan and I were just for whatever reason, maybe it's because

27:35.200 --> 27:44.200
 we've both have been divorced already. And, you know, he told me who we thought he was

27:44.200 --> 27:51.200
 and he was pretty accurate as far as I can, pretty much actually. I mean, there's very,

27:51.200 --> 27:58.200
 I can't say that I've ever come across a characteristic in him that really surprised me in a bad way.

27:58.200 --> 28:00.200
 It's hard to know yourself.

28:00.200 --> 28:01.200
 It is hard to know yourself.

28:01.200 --> 28:02.200
 And to communicate that.

28:02.200 --> 28:08.200
 For sure. I mean, I'll say, you know, I had the advantage of training as a therapist,

28:08.200 --> 28:14.200
 which meant for five years I was under a microscope. You know, when I was training as a therapist,

28:14.200 --> 28:20.200
 it was hour for hour supervision, which meant if you were in a room with a client for an hour,

28:20.200 --> 28:28.200
 you had an hour with a supervisor. So that supervisor was behind the mirror for your session

28:28.200 --> 28:32.200
 and then you went and had an hour of discussion about what you said, what you didn't say,

28:32.200 --> 28:42.200
 learning to use your own feelings and thoughts as a tool to probe the mind of the client and so on.

28:42.200 --> 28:48.200
 And so you can't help but learn a lot about yourself in that process.

28:48.200 --> 28:58.200
 Do you think knowing or learning how the sausage is made ruins the magic of the actual experience?

28:58.200 --> 29:06.200
 Like using your scientist who studies the brain, do you think it ruins the magic of, like, love at first sight?

29:06.200 --> 29:11.200
 Do you consciously are still able to lose yourself in the moment?

29:11.200 --> 29:13.200
 I'm definitely able to lose myself in the moment.

29:13.200 --> 29:15.200
 Is wine involved?

29:15.200 --> 29:22.200
 Not always. Chocolate. I mean, some kind of mind altering substance, right?

29:22.200 --> 29:31.200
 Yeah, for sure. I mean, I guess what I would say, though, is that for me, part of the magic is the process.

29:31.200 --> 29:41.200
 Like, so, you know, so I remember a day, while I was working on this book of essays, I was in New York.

29:41.200 --> 29:47.200
 I can't remember why I was in New York, but I was in New York for something and I was in Central Park

29:47.200 --> 29:52.200
 and I was looking at all the people with their babies and I was thinking,

29:52.200 --> 30:00.200
 every, every, each one of these, there's a tiny little brain that's wiring itself right now.

30:00.200 --> 30:08.200
 And I just, I felt in that moment, I was like, I am never going to look at an infant in the same way ever again.

30:08.200 --> 30:14.200
 And so to me, I mean, honestly, before I started learning about brain development,

30:14.200 --> 30:21.200
 I thought babies were cute, but, you know, not that interesting until they could interact with you and do things.

30:21.200 --> 30:27.200
 Of course, my own infant, I thought, was extraordinarily interesting, but, you know, they're kind of like lumps.

30:27.200 --> 30:32.200
 That's, you know, until they can, you know, interact with you, but they are anything but lumps.

30:32.200 --> 30:39.200
 I mean, like, you know, so, and part of the, I mean, all I can say is I have deep affection now

30:39.200 --> 30:51.200
 like tiny little babies in a way that I didn't really before because of the, I'm just so curious.

30:51.200 --> 30:58.200
 But the actual process, the mechanisms of the wiring of the brain, the learning, all the magic of the neurobiology.

30:58.200 --> 31:05.200
 Yeah. And, or, you know, something like, you know, when you make eye contact with someone directly,

31:05.200 --> 31:11.200
 sometimes, you know, you feel something, right?

31:11.200 --> 31:13.200
 Yeah, that's weird.

31:13.200 --> 31:15.200
 What is it? And what is that?

31:15.200 --> 31:22.200
 And so to me, that's not backing away from the moment. That's like expanding the moment.

31:22.200 --> 31:30.200
 It's like, that's incredibly cool. You know, when I was, I'll just say that when I was in graduate school,

31:30.200 --> 31:38.200
 I also was in therapy because it's almost a given that you're going to be in therapy yourself if you're going to become a therapist.

31:38.200 --> 31:45.200
 And I had a deal, you know, with my therapist, which was that I could call time out at any moment that I wanted to,

31:45.200 --> 31:50.200
 as long as I was being responsible about it. And I wasn't using it as a way to get out of something.

31:50.200 --> 31:56.200
 And he could tell me, no, you know, he could decline and say, no, you're, you know, you're using this to get out of something.

31:56.200 --> 32:00.200
 But I could call time out whenever I want and say, what are you doing right now?

32:00.200 --> 32:03.200
 Like, what are you, here's what I'm experiencing. What are you trying to do?

32:03.200 --> 32:10.200
 Like, I wanted to use my own experience to interrogate what the process was.

32:10.200 --> 32:18.200
 And that made it more helpful in a way. Do you know what I mean?

32:18.200 --> 32:23.200
 So, yeah, I don't, I don't think learning how something works makes it less magical, actually.

32:23.200 --> 32:27.200
 But that's just me, I guess. I don't know, would you?

32:27.200 --> 32:35.200
 Yes. I tend to have two modes. One is one is an engineer and one is romantic.

32:35.200 --> 32:43.200
 And I'm conscious of like, like the gear, like you like, there's two rooms, you can go into the one, the engineer room.

32:43.200 --> 32:48.200
 And I think that ruins the romance. So I tend to, there's two rooms.

32:48.200 --> 32:55.200
 One is the engineering room. Think from first principles. How do we build the thing that creates this kind of behavior?

32:55.200 --> 33:00.200
 And then you go into the romantic room where you're like emotional, it's a roller coaster.

33:00.200 --> 33:05.200
 And then you're, the thing is let's take it slow and then you get married the next night.

33:05.200 --> 33:14.200
 That you just this giant mess and you write a song and then you cry and then you send a bunch of text and anger and whatever.

33:14.200 --> 33:21.200
 And somehow you're in Vegas and there's random people and you're drunk and whatever, all that, like in poetry and just mess of it.

33:21.200 --> 33:27.200
 Fighting, yeah, that's not, those are two rooms and you go back between them.

33:27.200 --> 33:37.200
 But I think the way you put it is quite poetic. I think you're much, you're much better at adulting with love than perhaps I am.

33:37.200 --> 33:45.200
 Because there's a magic to children. I also think like of adults as children.

33:45.200 --> 33:52.200
 It's kind of cool to see, it's a cool thought experiment to look at adults and think like that used to be a baby.

33:52.200 --> 34:01.200
 And then that's like a fully wired baby. And it's just walking around pretending to be like all serious and important, wearing a suit or something.

34:01.200 --> 34:07.200
 But that used to be a baby. And then you think of like the parenting and all the experiences they had.

34:07.200 --> 34:13.200
 Like it's cool to think of it that way. But then I start thinking like from a machine learning perspective.

34:13.200 --> 34:20.200
 But once you're like the romantic moments, all that kind of stuff, all that falls away. I forget about all that.

34:20.200 --> 34:23.200
 I don't know. That's the Russian thing.

34:23.200 --> 34:28.200
 Maybe, maybe. But I also think it might be an age thing or maybe an experience thing.

34:28.200 --> 34:45.200
 So I think we all, I mean, if you're exposed to Western culture at all, you are exposed to the sort of idealized, stereotypic, romantic exchange.

34:45.200 --> 34:53.200
 And what does it mean to be romantic? And so here's a test.

34:53.200 --> 35:03.200
 I'm going to say how to phrase it. Okay, so not really a test, but this tells you something about your own ideas about romance.

35:03.200 --> 35:10.200
 For Valentine's Day one year, my husband bought me a six way plug.

35:10.200 --> 35:15.200
 Is that romantic or not romantic?

35:15.200 --> 35:18.200
 Like, sorry, six way plug. That's like an outlet.

35:18.200 --> 35:24.200
 Like to put it in an outlet. Is that romantic or not romantic?

35:24.200 --> 35:33.200
 I mean, it depends the look in his eyes when he does it. I mean, it depends on the conversation that led up to that point.

35:33.200 --> 35:44.200
 It depends how much, it's like the music, because you have a very, you're both from the, my experiences with you as a fan.

35:44.200 --> 35:51.200
 You have both a romantic nature, but you have a very pragmatic, like you cut through the bullshit of the fuzziness.

35:51.200 --> 35:55.200
 And there's something about a six way plug that cuts through the bullshit that connects to the human.

35:55.200 --> 35:57.200
 Like he understands who you are.

35:57.200 --> 36:05.200
 Exactly. Exactly. That was the most romantic gift he could have given me because he knows me so well.

36:05.200 --> 36:15.200
 He has a deep understanding of me, which is that I will sit and suffer and complain about the fact that I have to plug in unplug things.

36:15.200 --> 36:23.200
 And I will bitch and moan until the cows come home, but it would never occur to me to go buy a bloody six way plug.

36:23.200 --> 36:31.200
 Whereas for him, he bought it, he plugged it in, he arranged, he taped up all my wires, he made it like really usable.

36:31.200 --> 36:37.200
 And for me, that was the best present.

36:37.200 --> 36:38.200
 The most romantic thing.

36:38.200 --> 36:50.200
 It was the most romantic thing because he understood who I was and he did something very, or you know, just the casual, like we moved into a house that went,

36:50.200 --> 36:52.200
 we went from having a two car garage to a one car garage.

36:52.200 --> 36:56.200
 And I said, okay, you know, I'm from Canada, I'm not bothered by snow.

36:56.200 --> 37:03.200
 I mean, I'm a little bothered by snow, but he's very bothered by snow. So I'm like, okay, you can park your car in the garage, it's fine.

37:03.200 --> 37:08.200
 Every day when it snows, he goes out and cleans my car. Every day.

37:08.200 --> 37:18.200
 Like, I never asked him to do it. He just does it because he knows that I'm cutting it really close in the morning, you know, when we all used to go to work.

37:18.200 --> 37:29.200
 I have a time to the second so that I can get up as late as possible, work out as long as possible, you know, just to, and make it into my office like a minute before my first meeting.

37:29.200 --> 37:36.200
 And so if it snows unexpectedly or something, I'm screwed because now that's an added, you know, an added 10 or 15 minutes and I'm going to be late.

37:36.200 --> 37:47.200
 Anyways, you know, it's just these little tiny things that he's, he's, he's a really easygoing guy and he doesn't look like somebody who pays attention to detail.

37:47.200 --> 38:04.200
 He doesn't fuss about detail, but he definitely pays attention to detail and it's, it is very, very romantic in the sense that he, you know, he loves me despite my little details.

38:04.200 --> 38:19.200
 And it understands you, but it is kind of hilarious that that is the Six Way Plug is the most fulfilling, richest display of romance in your life. I love it.

38:19.200 --> 38:20.200
 I love it.

38:20.200 --> 38:27.200
 That's what I mean about romance. Romance is really, it's not all about chocolates and flowers and, you know, whatever. I mean, those are all nice too, but...

38:27.200 --> 38:29.200
 Sometimes it's about the Six Way Plug.

38:29.200 --> 38:31.200
 Sometimes it's about the Six Way Plug.

38:31.200 --> 38:40.200
 So maybe one way I could ask before we talk about the details, you also have the author of another book as we talked about how emotions are made.

38:40.200 --> 38:45.200
 So it's interesting to talk about the process of writing. You mentioned you were in New York.

38:45.200 --> 38:50.200
 What have you learned from writing these two books about the actual process of writing?

38:50.200 --> 38:54.200
 And maybe, I don't know, what's the most interesting thing to talk about there?

38:54.200 --> 39:08.200
 Maybe the biggest challenges or the boring, mundane, systematic, like day to day of what worked for you, like hacks or even just about the neuroscience that you've learned through the process of trying to write them.

39:08.200 --> 39:15.200
 Here's the thing I learned. If you think that it's going to take you a year to write your book, it's going to take you three years to write your book.

39:15.200 --> 39:28.200
 That's the first thing I learned is that no matter how organized you are, it's always going to take way longer than what you think.

39:28.200 --> 39:35.200
 In part because very few people make an outline and then just stick to it.

39:35.200 --> 39:52.200
 Some of the topics really take on a life of their own and to some extent you want to let them have their voice. You want to follow leads until you feel satisfied that you've dealt with the topic appropriately.

39:52.200 --> 39:59.200
 And that part is actually fun. It's not fun to feel like you're constantly behind the eight ball in terms of time.

39:59.200 --> 40:05.200
 But it is the exploration and the foraging for information is incredibly fun.

40:05.200 --> 40:15.200
 For me, anyways, I found it really enjoyable. And if I wasn't also running a lab at the same time and trying to keep my family going, you know, it would have been the whole thing would have just been fun.

40:15.200 --> 40:27.200
 But I would say the hardest thing about the most important thing I think I learned is also the hardest thing and that it for me, which is knowing what to leave out.

40:27.200 --> 40:40.200
 A really good storyteller knows what to leave out. In academic writing, you shouldn't leave anything out. All the details should be there.

40:40.200 --> 41:06.200
 And I've written or participated in writing over 200 papers, peer reviewed papers. So I'm pretty good with detail. Knowing what to leave out and not harming the validity of the story, that is a tricky, tricky thing.

41:06.200 --> 41:23.200
 It was tricky when I wrote How Motions Are Made, but that's a standard popular science book. So it's 300 something pages and then, you know, it has like 1000 end notes and then each of the end notes is attached to a web note, which is also long.

41:23.200 --> 41:44.200
 So I mean, you know, it's, and it's start and I mean the final draft, I mean, I wrote three drafts of that book, actually, and the final draft and then I had to cut by third, I mean, or, I mean, I, you know, it was like 150,000 words or something and I had to cut it down to like 110.

41:44.200 --> 41:59.200
 So obviously, I struggle with what to leave out, you know, brevity is not my strong suit. I'm always telling people that it's a warning. So that's why this book was a, I, you know, I'd always been really fascinated with essays. I love reading essays.

41:59.200 --> 42:10.200
 And after reading a small set of essays by Anne Fadiman called At Large and At Small, which I just love these little essays.

42:10.200 --> 42:26.200
 What's the topic of those essays? They are, they're called familiar essays. So the topics are like everyday topics like mail, coffee, chocolate, I mean, just like, and what she does is she weaves her own experience.

42:26.200 --> 42:47.200
 It's a little bit like these conversations that you're so good at curating, actually. You're weaving together history and philosophy and science and also personal reflections. And a little bit, you feel like you're like eavesdropping on someone's train of thought in a way.

42:47.200 --> 42:51.200
 It's really, they're really compelling to me.

42:51.200 --> 42:53.200
 Even if it's just a mundane topic.

42:53.200 --> 43:14.200
 Yeah, but it's so interesting to learn about like all of these little stories in the, in the wrapping of the history of like mail. Like that's, that's really interesting. And so I read these essays and then I wrote to her a little fangirl email.

43:14.200 --> 43:28.200
 And this was many years ago. And, and I said, I, I, I just love your, I love this book. And how did you learn to write essays like this? And she gave me a reading list of essays that I should read like writers. And so I read them all.

43:28.200 --> 43:50.200
 And anyway, so I decided it would be a really good challenge for me to try to write something really brief where I could focus on, you know, one or two really fascinating tidbits of neuroscience, connect it to connect each one to something

43:50.200 --> 44:12.200
 philosophical or, you know, like just a question about human nature, do it in a really brief format without violating the validity of the science. That was a, I just set myself this, what I thought of as a really, really big challenge in part because it was an incredibly hard thing for me to do in the first

44:12.200 --> 44:33.200
 book. Yeah, we should say that this is the seven and a half lessons, a very short book. I mean, it's a, it's like, it embodies brevity, right? The whole point throughout is just, I mean, you could, you could tell that there's editing, like, there's pain in trying to bring it as brief as possible, as clean as

44:33.200 --> 44:49.200
 possible. Yeah. Yeah. So it's, the way I think of it is, you know, it's a little book of big science and big ideas. Yeah, really big ideas and brief little packages. And, you know, I wrote it so that people could read it.

44:49.200 --> 44:58.200
 I love reading on the beach. I love reading essays on the beach. I read it. I wrote it so people could read it on the beach or in the bathtub or, you know, a subway stop.

44:58.200 --> 45:10.200
 Even if the beach is frozen over in the snow. Yeah. So my husband, Dan, calls it the first neuroscience beach read. That's his, that's his phrasing. Yeah.

45:10.200 --> 45:15.200
 And like, like you said, you learn a lot about writing from your husband, like you were saying offline.

45:15.200 --> 45:36.200
 Well, he's, he is, of the two of us, he is the better writer. He's a masterful writer. He, he's also, I mean, he, you know, he's a PhD in computer science. He's, he's a software engineer, but he's, he's also really good at organization of knowledge.

45:36.200 --> 45:46.200
 So he built for a company he used to work for, he built one of the first knowledge management systems. And he's, he now works at Google where he does engineering education.

45:46.200 --> 45:58.200
 Like he's, he understands how to tell a good story, just, you know, about anything really. He's got impeccable timing. He's really funny.

45:58.200 --> 46:24.200
 And luckily for me, he knows very little about psychology or neuroscience. Well, now he knows more, obviously. But so, you know, he was really, when how emotions were made, you know, he was really, really helpful to me because the first draft of every chapter was me talking to him about what, you know, I would talk out loud about what I wanted to say and the order in which I wanted to say it.

46:24.200 --> 46:32.200
 And then I would write it. And then he would read it and tell me all the bits that could be excised.

46:32.200 --> 46:33.200
 Yeah.

46:33.200 --> 46:46.200
 And sometimes we would, you know, I should say, I mean, we don't, he and I don't really argue about much except directions in the car. Like we're, that's, we're, that's, if we're going to have an argument, that's going to be where it's going to happen. Where

46:46.200 --> 46:50.200
 What's the, what's the nature of the argument about directions exactly?

46:50.200 --> 47:07.200
 I don't really know. It's just that we're very, I think it's that spatially, you know, he, he, I use egocentric space. So I want to say, you know, turn left, like I was, I'm reasoning in relation to like my own physical corporeal body.

47:07.200 --> 47:21.200
 You walk to the church and you turn left and you, then, you know, whatever, you know, I'm always like, and his, you know, he gives directions allocentrically, which means organized around north, south, east, west.

47:21.200 --> 47:25.200
 So to you, the, the earth is at the center of the solar system. And to him,

47:25.200 --> 47:26.200
 No, I'm at the center.

47:26.200 --> 47:27.200
 Reasonably.

47:27.200 --> 47:28.200
 I'm at the center.

47:28.200 --> 47:30.200
 You're at the center of the solar system.

47:30.200 --> 47:31.200
 Okay.

47:31.200 --> 47:43.200
 So we, but, but here we, you know, we, we had some really rip roaring arguments, like really rip roaring arguments where he would say, like, who is this for? Is this for the 1%?

47:43.200 --> 47:54.200
 And I'd be like 1% meaning not, you know, not wealth, but like civilians versus academics, you know, so are these for the scientists or for the, is this for the civilians, right?

47:54.200 --> 47:56.200
 So he speaks for the, for the people, for the civilians.

47:56.200 --> 48:08.200
 And he speaks for the people. And I'd be like, no, you have to. And so he made, you know, after one terrible argument that we had where it was really starting to affect our, our relationship, because we were so mad at each other all the time.

48:08.200 --> 48:24.200
 He made these little signs, writing and science. And we only use them. This, this was like, when you, when you pulled out a sign, that's it, like the other person just wins and you have to stop fighting about it.

48:24.200 --> 48:25.200
 Yeah.

48:25.200 --> 48:38.200
 And so we just did that. And we didn't really have to use it too much for this book, because this book was in some ways, you know, I didn't have to learn a lot of new things for this book.

48:38.200 --> 48:50.200
 I had to learn some, but I, a lot of what I learned for seven, for how emotions are made really stood me in good stead for, for this book.

48:50.200 --> 48:56.200
 So there was a little bit, each essay was a little bit of learning, a couple were, was a little more than, than the small amount.

48:56.200 --> 49:10.200
 But, but I didn't have so much trouble here. I had a lot of trouble with the first book, but still even here, you know, you know, he would tell me that I could take something out and I really wanted to keep it.

49:10.200 --> 49:15.200
 And I think we only use the signs once.

49:15.200 --> 49:20.200
 Well, if we could dive in some aspects of the book, I would love that.

49:20.200 --> 49:28.200
 Can we talk about, so one of the essays looks at evolution.

49:28.200 --> 49:39.200
 Let me ask the big question, did the human brain evolve to think that's essentially the question that you address in the essay. Can you speak to it?

49:39.200 --> 49:40.200
 Sure.

49:40.200 --> 49:45.200
 You know, the big caveat here is that we don't really know why brains evolved.

49:45.200 --> 49:49.200
 The big why questions are called teleological questions.

49:49.200 --> 49:58.200
 And in general, scientists should avoid those questions because we don't know really what we don't know the why.

49:58.200 --> 50:14.200
 However, for a very long time, the assumption was that evolution worked in a progressive upward scale, that you start off with simple organisms and those organisms get more complex and more complex and more complex.

50:14.200 --> 50:19.200
 Now, obviously, that's true in some like really general way, right?

50:19.200 --> 50:39.200
 That life started off as single cell organisms and things got more complex, but the idea that brains evolved in some upward trajectory from simple brains in simple animals to complex brains in complex animals is called a phylogenetic scale.

50:39.200 --> 50:48.200
 And that phylogenetic scale is embedded in a lot of evolutionary thinking, including Darwin's actually.

50:48.200 --> 50:57.200
 And it's been seriously challenged, I would say, by modern evolutionary biology.

50:57.200 --> 51:10.200
 And so, you know, thinking is something that rationality is something that humans, at least in the West, really prize as a great human achievement.

51:10.200 --> 51:23.200
 And so, the idea that the most common evolutionary story is that, you know, brains evolved in like sedimentary rock with, you know, a layer for instincts.

51:23.200 --> 51:30.200
 That's your lizard brain and a layer on top of that for emotions.

51:30.200 --> 51:33.200
 That's your limbic system, limbic meaning border.

51:33.200 --> 51:36.200
 So it borders the parts that are for instincts.

51:36.200 --> 51:37.200
 Oh, interesting.

51:37.200 --> 51:46.200
 And then the neocortex or new cortex where rationality is supposed to live.

51:46.200 --> 51:48.200
 That's the sort of traditional story.

51:48.200 --> 51:52.200
 It just keeps getting layered on top by evolution.

51:52.200 --> 51:53.200
 Right.

51:53.200 --> 52:06.200
 And so you can think about, you know, I mean, sedimentary rock is the way typically people describe it, the way I sometimes like to think about it is, you know, thinking about the cerebral cortex like icing on an already baked cake.

52:06.200 --> 52:15.200
 You know, where, you know, the cake is your inner beast, these like boiling, you know, roiling instincts and emotions that have to be contained.

52:15.200 --> 52:22.200
 And by the cortex, and it's just, it's a fiction.

52:22.200 --> 52:23.200
 It's a myth.

52:23.200 --> 52:30.200
 It's a myth that you can trace all the way back to stories about morality in ancient Greece.

52:30.200 --> 52:37.200
 But what you can do is look at the scientific record and say, well, there, there's others.

52:37.200 --> 52:45.200
 There are other stories that you could tell about brain evolution and, and the context in which brains evolved.

52:45.200 --> 52:55.200
 So when you look at creatures who don't have brains and you look at creatures who do, what's the difference?

52:55.200 --> 53:09.200
 And you can look at, you know, some animals, so we call scientists call an environment that an animal lives in a niche, their environmental niche.

53:09.200 --> 53:13.200
 What are the things, what are the parts of the environment that matter to that animal?

53:13.200 --> 53:18.200
 And so there are some animals whose niche hasn't changed in 400 million years.

53:18.200 --> 53:24.200
 So they're, they're not, these creatures are modern creatures, but they're living in a niche that hasn't changed much.

53:24.200 --> 53:27.200
 And so their biology hasn't changed much.

53:27.200 --> 53:35.200
 And you can kind of verify that by looking at the genes that lurk deep, you know, in the molecular structure of cells.

53:35.200 --> 53:43.200
 And so you can, by looking at various animals in their developmental state, meaning not, you don't look at adult animals.

53:43.200 --> 53:50.200
 You look at embryos of animals and developing animals, you can see, you can piece together a different story.

53:50.200 --> 53:58.200
 And that story is that brains evolved under the selection pressure of hunting.

53:58.200 --> 54:05.200
 That in the Cambrian period, hunting emerged on the scene where animals deliberately ate one another.

54:05.200 --> 54:19.200
 And what, so, you know, before the Cambrian period, the animals didn't really have, well, they didn't have brains, but they also didn't have senses really.

54:19.200 --> 54:21.200
 The very, very rudimentary senses.

54:21.200 --> 54:29.200
 So the animal that I wrote about in seven and a half lessons is called an amphyoxys or a Lancelot.

54:29.200 --> 54:34.200
 And little amphyoxys has no eyes.

54:34.200 --> 54:35.200
 It has no ears.

54:35.200 --> 54:37.200
 It has no nose.

54:37.200 --> 54:39.200
 It, it, it has no eyes.

54:39.200 --> 54:47.200
 It has a couple of cells for detecting light and dark for circadian rhythm purposes.

54:47.200 --> 54:50.200
 So, and it, it, it can't hear.

54:50.200 --> 54:54.200
 It has a vestibular cell to keep its body upright.

54:54.200 --> 54:57.200
 It has a very rudimentary sense of touch.

54:57.200 --> 55:03.200
 And it doesn't really have any internal organs other than this, like, basically stomach.

55:03.200 --> 55:07.200
 It's like a, just like a, it doesn't, it doesn't have an enteric nervous system.

55:07.200 --> 55:11.200
 It doesn't have like a gut that, you know, moves like we do.

55:11.200 --> 55:13.200
 It just has basically a tube.

55:13.200 --> 55:14.200
 Yeah.

55:14.200 --> 55:15.200
 So it's like a little container.

55:15.200 --> 55:17.200
 Like a little container. Yeah.

55:17.200 --> 55:20.200
 And so, and really it doesn't, it doesn't move very much.

55:20.200 --> 55:21.200
 It can move.

55:21.200 --> 55:22.200
 It just sort of wriggles.

55:22.200 --> 55:24.200
 It doesn't have very sophisticated movement.

55:24.200 --> 55:27.200
 And it's this really sweet little animal.

55:27.200 --> 55:37.200
 It sort of wriggles its way to a spot and then plants itself in the sand and just filters food as the food goes by.

55:37.200 --> 55:45.200
 And then when the food concentration decreases, it, it just, it just ejects itself,

55:45.200 --> 55:52.200
 wriggles to some spot randomly where probabilistically there will be more food and plants itself again.

55:52.200 --> 55:58.200
 So it's, it's not, it's not really aware, very aware that it has an environment.

55:58.200 --> 56:05.200
 It has a niche, but that niche is very small and it's not really experiencing that niche very much.

56:05.200 --> 56:08.200
 So it's, it's basically like a little stomach on a stick.

56:08.200 --> 56:10.200
 That's, that's really what it is.

56:10.200 --> 56:26.200
 And, but, but when animals start to literally hunt each other, all of a sudden it becomes important to have, to be able to sense your environment.

56:26.200 --> 56:33.200
 Because you need to know, is that blob up ahead going to eat me or should I eat it?

56:33.200 --> 56:37.200
 So all of a sudden you want, distant senses are very useful.

56:37.200 --> 56:45.200
 And so in the water, distant senses are vision and a little bit hearing,

56:45.200 --> 56:49.200
 olfaction, smelling and touch.

56:49.200 --> 56:53.200
 Because in the water, touch is a distant sense because you can feel the vibration.

56:53.200 --> 56:55.200
 So it's right.

56:55.200 --> 57:00.200
 So in, on air, on land, you know, vision is a distant sense.

57:00.200 --> 57:03.200
 Touch not so much, but for elephants maybe.

57:03.200 --> 57:04.200
 Right.

57:04.200 --> 57:05.200
 The vibrations.

57:05.200 --> 57:06.200
 Vibrations.

57:06.200 --> 57:14.200
 Olfaction definitely because of the concentration of, you know, the more concentrated something is, the more likely it is to be close to you.

57:14.200 --> 57:17.200
 So animals developed senses.

57:17.200 --> 57:20.200
 They developed a head, like a literal head.

57:20.200 --> 57:22.200
 So Amphioxas doesn't even have a head really.

57:22.200 --> 57:23.200
 It's just a, you know.

57:23.200 --> 57:25.200
 What's the purpose of a head?

57:25.200 --> 57:27.200
 That's a great question.

57:27.200 --> 57:29.200
 Is it, is it to have a jaw?

57:29.200 --> 57:30.200
 That's a great question.

57:30.200 --> 57:35.200
 So jaw, so yes, jaws are a major.

57:35.200 --> 57:36.200
 Useful feature.

57:36.200 --> 57:37.200
 Yeah.

57:37.200 --> 57:42.200
 Obviously they're a major adaptation after there's a split between vertebrates and invertebrates.

57:42.200 --> 57:48.200
 So Amphioxas is thought to be very, very similar to the animal that's before that split.

57:48.200 --> 57:55.200
 But then after the development, very quickly after the development of a head is the development of a jaw, which is a big thing.

57:55.200 --> 58:01.200
 And, and what goes along with that is the development of a brain.

58:01.200 --> 58:02.200
 It's weird.

58:02.200 --> 58:21.200
 Is that just a coincidence that the thing, the part of our body of the mammal, I think body that we eat with and like attack others with is also the thing that contains the, all the majority of the brain type of stuff.

58:21.200 --> 58:31.200
 Well, actually the brain goes with the development of a head and the development of a visual system and an auditory system and an olfactory system and so on.

58:31.200 --> 58:40.200
 So your senses are developing and, and the other thing that's happening, right, is that animals are getting bigger.

58:40.200 --> 58:41.200
 Yeah.

58:41.200 --> 58:44.200
 Because they're, and also their niche is getting bigger.

58:44.200 --> 58:56.200
 Well, this is the, just sorry to take a tiny tangent on the niche thing is, it seems like the niche is getting bigger, but not just bigger, like more complicated, like shaped in weird ways.

58:56.200 --> 59:03.200
 So like predation seems to create, like, like the whole world becomes your oyster, whatever.

59:03.200 --> 59:08.200
 But like, you also start to carve out like the places in which you can operate the best.

59:08.200 --> 59:09.200
 Yeah.

59:09.200 --> 59:10.200
 And in fact, that's absolutely right.

59:10.200 --> 59:27.200
 And in fact, some scientists think that theory of mind, your ability to make inferences about the inner life of other creatures actually developed under the selection pressure of predation because it makes you a better predator.

59:27.200 --> 59:34.200
 Do you ever look at, you just said you looked at babies as these wiring creatures.

59:34.200 --> 59:48.200
 Do you ever think of humans as just clever predators, like that there is under, underneath it all is this the Nietzschean will to power in all of its forms?

59:48.200 --> 59:51.200
 Or are we now friendlier?

59:51.200 --> 59:52.200
 Yeah.

59:52.200 --> 59:53.200
 So it's interesting.

59:53.200 --> 59:59.200
 I mean, there, there, there are zeitgeists and how humans think about themselves, right?

59:59.200 --> 1:00:18.200
 And so if you look in the 20th century, you can see that the idea of an inner beast that we're just predators, we're just basically animals, baseless animals, violent animals that have to be contained by culture and by our prodigious neocortex,

1:00:18.200 --> 1:00:31.200
 really took hold, particularly after World War I, and really held sway for much of that century.

1:00:31.200 --> 1:00:42.200
 And then around, at least in Western writing, I would say, you know, we're talking mainly about Western, Western scientific writing, Western philosophical writing.

1:00:42.200 --> 1:00:53.200
 And, and then, you know, late 90s, maybe you start to see books and articles about our social nature that were social animals.

1:00:53.200 --> 1:00:56.200
 And we are social animals, but what does that mean exactly?

1:00:56.200 --> 1:01:03.200
 And about it's just carving out different niches in the space of ideas, it looks like.

1:01:03.200 --> 1:01:04.200
 I think so.

1:01:04.200 --> 1:01:05.200
 I think so.

1:01:05.200 --> 1:01:14.200
 So, you know, do humans, can humans be violent?

1:01:14.200 --> 1:01:15.200
 Yes.

1:01:15.200 --> 1:01:17.200
 Can humans be really helpful?

1:01:17.200 --> 1:01:19.200
 Yes, yes, actually.

1:01:19.200 --> 1:01:28.200
 And humans are interesting creatures because, you know, other animals can also be helpful to one another.

1:01:28.200 --> 1:01:38.200
 In fact, there's a whole literature, booming literature on how other animals are, you know, support one another.

1:01:38.200 --> 1:01:43.200
 They regulate each other's nervous systems in interesting ways and they will be helpful to one another, right?

1:01:43.200 --> 1:02:05.200
 So, for example, there's a whole literature on rodents and how they signal one another what is safe to eat and they will perform acts of generosity to their conspecifics that are related to them or who they were raised with.

1:02:05.200 --> 1:02:13.200
 So, if an animal was raised in a litter that they were raised in, although not even at the same time, they'll be more likely to help that animal.

1:02:13.200 --> 1:02:21.200
 So, there's always some kind of physical relationship between animals that predicts whether or not they'll help one another.

1:02:21.200 --> 1:02:37.200
 For humans, you know, we have ways of categorizing who's in our group and who isn't by nonphysical ways, right, even by just something abstract like an idea.

1:02:37.200 --> 1:02:50.200
 And we are much more likely to extend help to people in our own group, whatever that group may be, at that moment, whatever feature you're using to define who's in your group

1:02:50.200 --> 1:02:58.200
 and who isn't, we're more likely to help those people than even members of our own family at times.

1:02:58.200 --> 1:03:08.200
 So, humans are much more flexible in their, in the way that they help one another, but also in the way that they harm one another.

1:03:08.200 --> 1:03:20.200
 So, I don't think I subscribe to, you know, we are primarily this or we are primarily that.

1:03:20.200 --> 1:03:24.200
 I don't think humans have assences in that way, really.

1:03:24.200 --> 1:03:33.200
 I apologize to take us in this direction for a brief moment, but I've been really deep on Stalin and Hitler recently in terms of reading.

1:03:33.200 --> 1:03:43.200
 And is there something that you think about in terms of the nature of evil from a neuroscience perspective?

1:03:43.200 --> 1:04:00.200
 Is there some lessons that are sort of hopeful about human civilization that we can find in our brain with regard to the hitlers of the world?

1:04:00.200 --> 1:04:05.200
 Do you think about the nature of evil?

1:04:05.200 --> 1:04:07.200
 Yeah, I do.

1:04:07.200 --> 1:04:14.200
 I don't know that what I have to say is so useful from a, I don't know that I can say as a neuroscientist.

1:04:14.200 --> 1:04:20.200
 Well, here's a study that, you know, what I, so I sort of have to take off my lab coat, right?

1:04:20.200 --> 1:04:28.200
 And now I'm going to now conjecture as a human who just also, who has opinions, but who also maybe has some knowledge about neuroscience.

1:04:28.200 --> 1:04:34.200
 But I'm not speaking as a neuroscientist when I say this, because I don't think neuroscientists know enough, really, to be able to say.

1:04:34.200 --> 1:04:48.200
 But I guess the kinds of things I think about are what, so I have always thought, even before I knew anything about neuroscience,

1:04:48.200 --> 1:05:05.200
 I've always thought that I don't think anybody could become Hitler, but I think the majority of people can be, can do, are capable of doing very bad things.

1:05:05.200 --> 1:05:11.200
 It's just the question is really how much encouragement does it take from the environment to get them to do something bad?

1:05:11.200 --> 1:05:19.200
 That's what I kind of, when I look at the life of Hitler, it seems like there's so many places where...

1:05:19.200 --> 1:05:21.200
 Something could have intervened.

1:05:21.200 --> 1:05:23.200
 Intervened, no, it could change completely the person.

1:05:23.200 --> 1:05:28.200
 I mean, there's like the caricature, like the obvious places where he was an artist.

1:05:28.200 --> 1:05:32.200
 And if he wasn't rejected as an artist, he was a reasonably good artist.

1:05:32.200 --> 1:05:33.200
 So that, that could have changed.

1:05:33.200 --> 1:05:40.200
 But just his entire like where he went in Vienna and all these kinds of things, like like little interactions could have changed.

1:05:40.200 --> 1:05:57.200
 And there's probably millions of other people who are capable, who the environment may be able to mold in the same way did this particular person to create this particular kind of charismatic leader in this particular moment of time.

1:05:57.200 --> 1:05:58.200
 Absolutely.

1:05:58.200 --> 1:06:02.200
 And I guess the way that I would say it, I would agree 100%.

1:06:02.200 --> 1:06:06.200
 And I guess the way that I would say it is like this.

1:06:06.200 --> 1:06:19.200
 In the West, we have a way of reasoning about causation, which focuses on single simple causes for things.

1:06:19.200 --> 1:06:22.200
 There's an essence to Hitler.

1:06:22.200 --> 1:06:24.200
 There's an essence to his character.

1:06:24.200 --> 1:06:29.200
 He was born with that essence or it was forged very, very early in his life.

1:06:29.200 --> 1:06:37.200
 And that explains the landscape of his, the horrible landscape of his behavior.

1:06:37.200 --> 1:06:48.200
 But there's another way to think about it, a way that actually is much more consistent with what we know about biology, how biology works in the physical world.

1:06:48.200 --> 1:06:56.200
 And that is that most things are complex, not as in, wow, this is really complex and hard, but complex as in complexity.

1:06:56.200 --> 1:06:59.200
 That is more than the sum of their parts.

1:06:59.200 --> 1:07:08.200
 And that most phenomena have many, many weak nonlinear interacting causes.

1:07:08.200 --> 1:07:18.200
 And so little things that we might not even be aware of can shift someone's developmental trajectory from this to that.

1:07:18.200 --> 1:07:28.200
 And that's enough to take it on a whole set of other paths and that these things are happening all the time.

1:07:28.200 --> 1:07:35.200
 So it's not random and it's not really, it's not deterministic in the sense that like everything you do determines your outcome.

1:07:35.200 --> 1:07:46.200
 But it's a little more like, you know, you're nudging someone from one set of possibilities to another set of possibilities.

1:07:46.200 --> 1:07:55.200
 But I think the thing is, the thing that I find optimistic is that the other side of that coin is also true, right?

1:07:55.200 --> 1:08:05.200
 So look at all the people who risked their lives to help people they didn't even know.

1:08:05.200 --> 1:08:09.200
 I mean, I just watched Borat, the new Borat movie.

1:08:09.200 --> 1:08:19.200
 And the thing that I came away with, but you know, the thing I came away with was, look at how generous people were in that.

1:08:19.200 --> 1:08:23.200
 Because he's making, there are a lot of people he makes fun of and that's fine.

1:08:23.200 --> 1:08:25.200
 But think about like those two guys.

1:08:25.200 --> 1:08:28.200
 The Trump supporter guys.

1:08:28.200 --> 1:08:29.200
 The Trump supporter guys.

1:08:29.200 --> 1:08:30.200
 Those guys.

1:08:30.200 --> 1:08:31.200
 That was cool.

1:08:31.200 --> 1:08:33.200
 There was kindness in them, right?

1:08:33.200 --> 1:08:38.200
 They took a complete stranger in a pandemic.

1:08:38.200 --> 1:08:41.200
 Into their house.

1:08:41.200 --> 1:08:42.200
 Who does that?

1:08:42.200 --> 1:08:44.200
 Like that's a really nice thing.

1:08:44.200 --> 1:08:54.200
 Or there's one scene, I mean, I don't want to spoil it for people who haven't seen it, but there's, you know, there's one scene where he goes in, he dresses up as a Jew.

1:08:54.200 --> 1:08:58.200
 I laugh myself sick at that scene, seriously.

1:08:58.200 --> 1:09:03.200
 But he goes in and there are these two old Jewish ladies.

1:09:03.200 --> 1:09:06.200
 What a bunch of sweethearts.

1:09:06.200 --> 1:09:07.200
 Oh my gosh.

1:09:07.200 --> 1:09:09.200
 Like, really?

1:09:09.200 --> 1:09:10.200
 Yeah.

1:09:10.200 --> 1:09:12.200
 I mean, that was what I was struck by actually.

1:09:12.200 --> 1:09:15.200
 I mean, there are other ones or like the babysitter, right?

1:09:15.200 --> 1:09:18.200
 I mean, she was really kind.

1:09:18.200 --> 1:09:22.200
 And yeah, so that's really what I was more struck by.

1:09:22.200 --> 1:09:30.200
 Like, you know, sure, there are other people who, you know, who do very bad things or say bad things or whatever.

1:09:30.200 --> 1:09:39.200
 But, you know, or like there's one guy who's completely stoic, like the guy at the, who's doing the like, you know, sending the messages.

1:09:39.200 --> 1:09:41.200
 I don't know if it's facts or whatever.

1:09:41.200 --> 1:09:45.200
 He's just completely stoic, but he's doing his job actually.

1:09:45.200 --> 1:09:48.200
 You know, like you can't, you don't know what he was thinking inside his head.

1:09:48.200 --> 1:09:52.200
 You don't know what he's feeling, but he was totally professional doing his job.

1:09:52.200 --> 1:09:58.200
 So I guess I just, I had a bit of a different, you know, view, I guess.

1:09:58.200 --> 1:10:00.200
 And so I also think that about people.

1:10:00.200 --> 1:10:04.200
 I think everybody is capable of kindness.

1:10:04.200 --> 1:10:09.200
 And, but, but, you know, it's the question is how much does it take and what are the circumstances?

1:10:09.200 --> 1:10:11.200
 So for a lot, some people it's going to take a lot.

1:10:11.200 --> 1:10:14.200
 And for some people, it only takes a little bit.

1:10:14.200 --> 1:10:27.200
 But, you know, are we actually cultivating an environment for the next generation that provides opportunities

1:10:27.200 --> 1:10:31.200
 for people to go in the direction of caring and kindness?

1:10:31.200 --> 1:10:38.200
 Or, you know, and I'm not saying that as like a, you know, Pollyanna ish person.

1:10:38.200 --> 1:10:44.200
 You know, I think there's a lot of room for competition and debate and so on.

1:10:44.200 --> 1:10:48.200
 But I don't see Hitler as an anomaly.

1:10:48.200 --> 1:10:52.200
 And I never have, that was even before I learned anything about neuroscience.

1:10:52.200 --> 1:10:58.200
 And now I would say knowing what we know about developmental trajectories and life histories and how important that is,

1:10:58.200 --> 1:11:07.200
 you know, knowing what we know about that the whole question of like nature versus nurture is a completely wrong question.

1:11:07.200 --> 1:11:10.200
 You know, we have the kind of nature that requires nurture.

1:11:10.200 --> 1:11:16.200
 We have the kind of genes that allow infants to be born with unfinished brains,

1:11:16.200 --> 1:11:25.200
 where their brains are wired across a 25 year period with wiring instructions from the world that is created for them.

1:11:25.200 --> 1:11:30.200
 And so I don't think Hitler is an anomaly.

1:11:30.200 --> 1:11:39.200
 You know, even if it's less probable that that would happen, it's possible that it could happen again.

1:11:39.200 --> 1:11:43.200
 And it's not like, you know, he's a bad seed.

1:11:43.200 --> 1:11:50.200
 I mean, that doesn't, I just want to say for like, of course, he's completely 100% responsible for his actions and all the bad things that happen.

1:11:50.200 --> 1:11:53.200
 So I'm not in any way, this is not me saying.

1:11:53.200 --> 1:11:59.200
 But the environment is also responsible in part for creating the evil in this world.

1:11:59.200 --> 1:12:07.200
 So like Hitler's in different versions of even more subtle, more smaller scale versions of evil.

1:12:07.200 --> 1:12:16.200
 But I tend to believe that there's a much stronger, I don't like to talk about evolutionary advantages,

1:12:16.200 --> 1:12:23.200
 but it seems like it makes sense for love to be a more powerful,

1:12:23.200 --> 1:12:30.200
 emergent phenomena of our collective intelligence versus hate and evil and destruction.

1:12:30.200 --> 1:12:38.200
 Because from a survival, from a niche perspective, it seems to be like in my own life,

1:12:38.200 --> 1:12:44.200
 and my thinking about the intuition about the way humans work together to solve problems,

1:12:44.200 --> 1:12:47.200
 it seems that love is a very useful tool.

1:12:47.200 --> 1:12:49.200
 I definitely agree with you.

1:12:49.200 --> 1:13:06.200
 But I think the caveat here is that, you know, humans, the research suggests that humans are capable of great acts of kindness and great acts of generosity to people in their in group.

1:13:06.200 --> 1:13:08.200
 Right.

1:13:08.200 --> 1:13:11.200
 So we're also tribal.

1:13:11.200 --> 1:13:14.200
 Yeah, I mean, that's the kitschy way to say it.

1:13:14.200 --> 1:13:15.200
 We're tribes, we're tribal.

1:13:15.200 --> 1:13:16.200
 Yeah.

1:13:16.200 --> 1:13:18.200
 So that's the kitschy way to say it.

1:13:18.200 --> 1:13:28.200
 But what I would say is that, you know, there are a lot of features that you can use to describe yourself.

1:13:28.200 --> 1:13:34.200
 You don't have one identity, you don't have one self, you have many selves, you have many identities.

1:13:34.200 --> 1:13:40.200
 Sometimes you're a man, sometimes you're a scientist, sometimes you're a, do you have a brother or a sister?

1:13:40.200 --> 1:13:41.200
 Yeah, brother.

1:13:41.200 --> 1:13:45.200
 So sometimes you're a brother, you know, you, sometimes you're a friend.

1:13:45.200 --> 1:13:49.200
 As you're human, so you can keep zooming out, living organism on earth.

1:13:49.200 --> 1:13:50.200
 Yes, exactly.

1:13:50.200 --> 1:13:53.200
 That's exactly, that's exactly right.

1:13:53.200 --> 1:14:11.200
 And so there are, there are some people who, there is research which suggests that there are some people who will tell you, I think it's appropriate and better to help, I should help my family more than I should help my neighbors.

1:14:11.200 --> 1:14:15.200
 And I should help my neighbors more than I should help the average stranger.

1:14:15.200 --> 1:14:22.200
 And I should help, you know, the average stranger in my country more than I should help somebody outside my country.

1:14:22.200 --> 1:14:26.200
 And I should help humans more than I should help, you know, other animals.

1:14:26.200 --> 1:14:27.200
 Right.

1:14:27.200 --> 1:14:29.200
 So there's a clear hierarchy of helping.

1:14:29.200 --> 1:14:37.200
 And there are other people who, you know, they are, their niche is much more inclusive, right?

1:14:37.200 --> 1:14:41.200
 And that they're humans first, right?

1:14:41.200 --> 1:14:45.200
 Or creatures of the earth first, let's say.

1:14:45.200 --> 1:14:54.200
 And I don't think we know how flexible those attitudes are because I don't think the research really tells us that.

1:14:54.200 --> 1:15:06.200
 But in any case, there are, you know, and there are beliefs, people also have beliefs about, there's this really interesting research in really an anthropology that looks at, you know,

1:15:06.200 --> 1:15:12.200
 what are cultures particularly afraid of?

1:15:12.200 --> 1:15:20.200
 Like what the people in a particular culture are organizing their social systems to prevent certain types of problems.

1:15:20.200 --> 1:15:22.200
 So what are the problems that they're worried about?

1:15:22.200 --> 1:15:30.200
 And so there are some cultures that are much more hierarchical and some cultures that are, you know, much more egalitarian.

1:15:30.200 --> 1:15:40.200
 There are some cultures that, you know, in the debate of like getting along versus getting ahead, there are some cultures that really prioritize the individual over the group.

1:15:40.200 --> 1:15:43.200
 And there are other cultures that really prioritize the group over the individual.

1:15:43.200 --> 1:15:46.200
 You know, it's not like one of these is right and one of these is wrong.

1:15:46.200 --> 1:15:59.200
 It's that, you know, different combinations of these features are different solutions that humans have come up with for, for living in groups, which is a major adaptive advantage of our species.

1:15:59.200 --> 1:16:03.200
 And it's not the case that one of these is better and one of these is worse.

1:16:03.200 --> 1:16:07.200
 Although as a person, of course, I have opinions about that.

1:16:07.200 --> 1:16:17.200
 And as a person, I can say I would very much prefer certain, I have certain beliefs and I really want everyone in the world to live by those beliefs, you know.

1:16:17.200 --> 1:16:26.200
 But as a scientist, I know that it's not really the case that for the species, any one of these is better than any other.

1:16:26.200 --> 1:16:35.200
 There are different solutions that work differentially well in particular, you know, ecological parts of the world.

1:16:35.200 --> 1:16:43.200
 But for individual humans, there are definitely some systems that are better and some systems that are worse, right?

1:16:43.200 --> 1:16:51.200
 But when anthropologists or when neuroscientists or biologists are talking, they're not usually talking about the lives of individual people.

1:16:51.200 --> 1:16:57.200
 They're talking about, you know, the species, what's better for the species, the survivability of the species.

1:16:57.200 --> 1:17:05.200
 And what's better for the survivability of the species is variation, that we have lots of cultures with lots of different solutions.

1:17:05.200 --> 1:17:17.200
 Because if the environment were to change drastically, some of those solutions will work better than others.

1:17:17.200 --> 1:17:21.200
 And you can see that happening with COVID.

1:17:21.200 --> 1:17:26.200
 Right. So some people might be more susceptible to this virus and others.

1:17:26.200 --> 1:17:28.200
 And so variation is very useful.

1:17:28.200 --> 1:17:31.200
 Say COVID was much, much more destructive than it is.

1:17:31.200 --> 1:17:37.200
 And like, I don't know, 20% of the population was died.

1:17:37.200 --> 1:17:42.200
 You know, that's, it's good to have variability because then at least some percent will survive.

1:17:42.200 --> 1:18:01.200
 Yeah. I mean, the, you know, the way that I used to describe it was, you know, using, you know, those movies like The War of the Worlds or Pacific Rim, you know, where like aliens come down from outer space and they, you know, want to kill humans.

1:18:01.200 --> 1:18:10.200
 And so all the humans band together as a species, like, and they all, like all the, you know, little squabbling from countries and whatever all, you know, goes away.

1:18:10.200 --> 1:18:19.200
 And everyone is just one big, you know, well, that, you know, that doesn't happen.

1:18:19.200 --> 1:18:29.200
 I mean, because COVID is, you know, the virus, like COVID 19 is like a creature from outer space.

1:18:29.200 --> 1:18:31.200
 And that's not what you see happening.

1:18:31.200 --> 1:18:37.200
 What you do see happening, it is true that some people, I mean, we could use this as an example of essentialism also.

1:18:37.200 --> 1:18:44.200
 So just to say, like exposure to the virus does not mean that you will become infected with a disease.

1:18:44.200 --> 1:18:54.200
 So, I mean, in controlled studies, one of which was actually a coronavirus, not COVID, but this was, these are studies from 10 years ago.

1:18:54.200 --> 1:19:04.200
 You know, only somewhere between 20 and 40% of people were developed respiratory illness when a virus was placed in their nose.

1:19:04.200 --> 1:19:07.200
 Yeah. And so...

1:19:07.200 --> 1:19:09.200
 Then there's a dose question and all those...

1:19:09.200 --> 1:19:10.200
 Well, not in these studies, actually.

1:19:10.200 --> 1:19:14.200
 So in these studies, the dose was consistent across all people.

1:19:14.200 --> 1:19:23.200
 And everything, you know, they were sequestered in hotel rooms and what they ate was, you know, measured out by scientists and so on.

1:19:23.200 --> 1:19:28.200
 And so when you hold dose, I mean, the dose issue is a real issue in the real world.

1:19:28.200 --> 1:19:34.200
 In these studies, that was controlled and only somewhere between...

1:19:34.200 --> 1:19:38.200
 Depending on the study, between 20 and 40% of people became infected with a disease.

1:19:38.200 --> 1:19:46.200
 So exposure to a virus doesn't mean de facto that you will develop an illness.

1:19:46.200 --> 1:19:52.200
 You will be a carrier and you will spread the virus to other people, but you yourself may not...

1:19:52.200 --> 1:20:04.200
 Your immune system may be in a state that you can make enough antibodies to not show symptoms, not develop symptoms.

1:20:04.200 --> 1:20:17.200
 And so, of course, what this means is, again, is that, you know, like if I asked you, do you think, you know, a virus is the cause of a common cold?

1:20:17.200 --> 1:20:25.200
 You know, most people, if I asked this question, I can tell you, I asked this question, so do you think a virus is the cause of a cold?

1:20:25.200 --> 1:20:27.200
 Most people would say, yes, I think it is.

1:20:27.200 --> 1:20:34.200
 And then I say, yeah, well, only 20 to 40% of people develop respiratory illness in exposure to a virus.

1:20:34.200 --> 1:20:39.200
 So clearly, it is a necessary cause, but it's not a sufficient cause.

1:20:39.200 --> 1:20:40.200
 And there are other causes.

1:20:40.200 --> 1:20:47.200
 Again, so not simple single causes for things, right? Multiple interacting influences.

1:20:47.200 --> 1:21:05.200
 So it is true that individuals vary in their susceptibility to illness upon exposure, but different cultures have different sets of norms and practices that allow, that will slow or speed the spread.

1:21:05.200 --> 1:21:21.200
 And that's the point that I was actually trying to make here, that, you know, when the environment changes, that is, there's a mutation of a virus that is incredibly infectious.

1:21:21.200 --> 1:21:36.200
 Some cultures will succumb, people in some cultures will succumb faster because of the particular norms and practices that they've developed in their culture versus other cultures.

1:21:36.200 --> 1:21:46.200
 Now, there could be some other, you know, thing that changes that where those other cultures would do better.

1:21:46.200 --> 1:21:53.200
 So very individualistic cultures like ours may do much better under other types of selection pressures.

1:21:53.200 --> 1:22:04.200
 But for COVID, for things like COVID, you know, my colleague, Michelle Gelfand, her research shows that she looks at like loose cultures and tight cultures.

1:22:04.200 --> 1:22:13.200
 So cultures that have very, very strict rules versus cultures that are much more individualistic and where personal freedoms are more valued.

1:22:13.200 --> 1:22:24.200
 And she, you know, her research suggests that for pandemic circumstances, tight cultures actually, the people survive better.

1:22:24.200 --> 1:22:26.200
 She's still lingering a little bit longer.

1:22:26.200 --> 1:22:41.200
 We started this part of the conversation talking about, you know, did humans evolve to think, did the human brain evolve to think, implying, is there like a progress to the thing that's always improving?

1:22:41.200 --> 1:22:43.200
 That's right, we never, yeah.

1:22:43.200 --> 1:22:45.200
 And so the answer is no.

1:22:45.200 --> 1:22:47.200
 But let me sort of push back.

1:22:47.200 --> 1:22:53.200
 But so your intuition is very strong here, not your intuition, the way you describe this.

1:22:53.200 --> 1:22:58.200
 But is it possible there's a direction to this evolution?

1:22:58.200 --> 1:23:01.200
 Like, do you think of this evolution as having a direction?

1:23:01.200 --> 1:23:06.200
 Like it's like walking along a certain path towards something.

1:23:06.200 --> 1:23:12.200
 Is it, you know, what is it?

1:23:12.200 --> 1:23:24.200
 Is it Elon Musk said like the Earth got bombarded with photons, and then all of a sudden, like a Tesla was launched into space or whatever, rockets started coming.

1:23:24.200 --> 1:23:35.200
 Like, is there a sense in which, even though within the system, the evolution seems to be this massive variation, we're kind of trying to find our niches and so on.

1:23:35.200 --> 1:23:48.200
 But do you think there ultimately, when you zoom out, there is a direction that's strong that does tend towards greater complexity and intelligence?

1:23:48.200 --> 1:23:50.200
 No.

1:23:50.200 --> 1:23:59.200
 So, I mean, and I, and again, what I would say is I'm really, I'm really just echoing people who are much smarter than I am about this.

1:23:59.200 --> 1:24:01.200
 But see, you're saying smarter.

1:24:01.200 --> 1:24:04.200
 I thought it doesn't, there's no, I thought there's no smarter.

1:24:04.200 --> 1:24:07.200
 No, I didn't say there's no smarter. I said there's no direction.

1:24:07.200 --> 1:24:18.200
 So, I think the thing to say, or what I understand to be the case is that there's variation, it's not unbounded variation, and there are selectors.

1:24:18.200 --> 1:24:22.200
 There are pressures that will select.

1:24:22.200 --> 1:24:30.200
 And so, not anything is possible because we live on a planet that has certain physical realities to it, right?

1:24:30.200 --> 1:24:38.200
 But those physical realities are what constrain the possibilities.

1:24:38.200 --> 1:24:51.200
 The physical realities of our genes and the physical realities of our corporeal bodies and the physical realities of, you know, the, of life on this planet.

1:24:51.200 --> 1:25:12.200
 So, what I would say is that there's no direction, but there is, it's not infinite possibility because we live on a particular planet that has particular statistical regularities in it, and some things will never happen.

1:25:12.200 --> 1:25:26.200
 And so, all of those things are interacting with, with our genes and so on, and our, you know, the physical nature of our bodies to make some things more possible and some things less possible.

1:25:26.200 --> 1:25:37.200
 Look, I mean, humans have very complex brains, but birds have complex brains, and so do, you know, so do octopuses have very complex brains.

1:25:37.200 --> 1:25:43.200
 And all three sets of, all three of those brains are somewhat different from one another.

1:25:43.200 --> 1:25:50.200
 You know, birds, birds, some birds have very complex brains. Some even have rudimentary language. They have no cerebral cortex.

1:25:50.200 --> 1:25:57.200
 I mean, they, admittedly, they have, this is now lesson two, right? They have, is it lesson two or lesson one? Let me think.

1:25:57.200 --> 1:26:10.200
 No, this is lesson one. They have, they have the same neurons, the same neurons that, that in a human become the cerebral cortex, birds have those neurons.

1:26:10.200 --> 1:26:13.200
 They just don't form themselves into a cerebral cortex.

1:26:13.200 --> 1:26:19.200
 I mean, crows, for example, are very sophisticated animals. They can do a lot of the things that humans can do.

1:26:19.200 --> 1:26:28.200
 In fact, all of the things that humans do that are very special, that seem very special, there's at least one other animal on the planet that can do those things too.

1:26:28.200 --> 1:26:35.200
 What's special about the human brain is that we put them all together. So we learn from one another.

1:26:35.200 --> 1:26:42.200
 We don't have to experience everything ourselves. We can watch another animal or another human learn, experience something and we can learn from that.

1:26:42.200 --> 1:26:45.200
 Well, there are many other animals who can learn by copying.

1:26:45.200 --> 1:26:52.200
 Yeah. That we communicate with each other very, very efficiently. We have language, but we're not the only animals who are efficiently efficient communicators.

1:26:52.200 --> 1:26:57.200
 There are lots of other animals who can efficiently communicate like bees, for example.

1:26:57.200 --> 1:27:03.200
 You know, we cooperate really well with one another to do grand things, but there are other animals that cooperate too.

1:27:03.200 --> 1:27:07.200
 And so every innovation that we have, other animals have too.

1:27:07.200 --> 1:27:35.200
 What we have is we have all of those together interwoven in this very complex dance in a brain that is not unique exactly, but it does have some features that make it particularly useful for us to have all of these things intertwined.

1:27:35.200 --> 1:27:55.200
 So, you know, our brains are actually the last time we talked, I made a mistake because I said in my enthusiasm, I said, you know, our brains are not larger, are relative to our bodies, our brains are not larger than other primates.

1:27:55.200 --> 1:28:01.200
 And that's actually not true, actually. Our brains relative to our body size is somewhat larger.

1:28:01.200 --> 1:28:13.200
 So an ape who's not a human, that's not a human, their brains are larger than their body sizes than, say, relative to like a smaller monkey.

1:28:13.200 --> 1:28:18.200
 And a human's brain is larger relative to its body size than a gorilla.

1:28:18.200 --> 1:28:25.200
 So that's a good approximation of your, of whatever, of the bunch of stuff that you can shove in there.

1:28:25.200 --> 1:28:33.200
 But, well, what I was going to say is, but our cerebral cortex is not larger than what you would expect for a brain of its size.

1:28:33.200 --> 1:28:53.200
 So relative to, say, an ape, like a gorilla or a chimp, or even a mammal like a dolphin or an elephant, you know, our brains, our cerebral cortex is as large as you would expect it to be for a brain of our size.

1:28:53.200 --> 1:28:57.200
 So there's nothing special about our cerebral cortex.

1:28:57.200 --> 1:29:07.200
 And this is something I explain in the book where I say, okay, you know, like by analogy, if you walk into somebody's house and you see that they have a huge kitchen,

1:29:07.200 --> 1:29:16.200
 you know, you might think, well, maybe, you know, maybe this is a place I really definitely want to eat dinner at because, you know, these people must be gourmet cooks.

1:29:16.200 --> 1:29:22.200
 But you don't know anything about what the size of their kitchen means unless you consider it in relation to the size of the rest of the house.

1:29:22.200 --> 1:29:29.200
 If it's a big kitchen in a really big house, it's not telling you anything special, right?

1:29:29.200 --> 1:29:39.200
 If it's a big kitchen in a small house, then that might be a place that you want to eat, you want to stay for dinner because it's more likely that that kitchen is large for a special reason.

1:29:39.200 --> 1:30:04.200
 And so the cerebral cortex of a human brain isn't in and of itself special because of its size. However, there are some genetic changes that have happened in the human brain as it's grown to whatever size is, you know, typical for the whole brain size, right?

1:30:04.200 --> 1:30:21.200
 There are some changes that do give the human brain slightly more of some capacities. They're not special, but there's just, they just, you know, we can do some things much better than other animals.

1:30:21.200 --> 1:30:28.200
 And, you know, correspondingly, other animals can do some things much better than we can. We can't grow back limbs. We can't lift 50 times our own body weight.

1:30:28.200 --> 1:30:31.200
 Well, I mean, maybe you can, but I can't lift 50 times my own body.

1:30:31.200 --> 1:30:44.200
 Yeah, ants with that regard are very impressive. And then you're saying with the frontal cortex, like that's, the size is not always the right measure of capability, I guess.

1:30:44.200 --> 1:30:46.200
 So size isn't everything.

1:30:46.200 --> 1:30:48.200
 Size isn't everything.

1:30:48.200 --> 1:30:56.200
 That's a quote about, you know, people like it when I disagree. So let me disagree with you on something or just like play devil's advocate a little bit.

1:30:56.200 --> 1:31:02.200
 So you've painted a really nice picture that evolution doesn't have a direction.

1:31:02.200 --> 1:31:11.200
 But is it possible, if we just ran Earth over and over again, like this video game, that the final result will be the same.

1:31:11.200 --> 1:31:25.200
 So in the sense that we're eventually there'll be an AGI type, Hal 9000 type system that just like flies and colonizes nearby Earth like planets.

1:31:25.200 --> 1:31:34.200
 And it's always will be the same. And the different organisms and the different evolution of the brain, like it doesn't feel like it has like a direction.

1:31:34.200 --> 1:31:47.200
 But given the constraints of Earth and whatever this imperative, whatever the hell is running this universe, like it seems like it's running towards something.

1:31:47.200 --> 1:31:49.200
 Is it possible that will always be the same?

1:31:49.200 --> 1:32:02.200
 Thereby, it will be a direction. Yeah, I think, you know, as you know, better than anyone else that that answer to that question is, of course, there's some probability that that could happen, right?

1:32:02.200 --> 1:32:07.200
 It's not a yes or no answer. It's what's the probability that that would happen.

1:32:07.200 --> 1:32:22.200
 And there's a whole distribution of possibilities. So maybe we end up, what's the probability we end up with exactly the same complement of creatures, including us?

1:32:22.200 --> 1:32:41.200
 What's the likelihood that we end up with, you know, creatures that are similar to humans that are, but, you know, similar in certain ways, let's say, but not exactly humans or, you know, all the way to a completely different distribution of creatures.

1:32:41.200 --> 1:32:47.200
 What's your intuition? Like if you were to bet money, what does that distribution look like if we ran Earth over and over again?

1:32:47.200 --> 1:32:58.200
 I would say given the, you're now asking me questions that. This is not science. This is not science. So, but I would say, okay, well, what's the probability that it's going to be a carbon life form?

1:32:58.200 --> 1:33:02.200
 Probably high. Yeah. But that's because I don't know anything about.

1:33:02.200 --> 1:33:14.200
 Alternative. Yeah, I mean, you know, I don't, I'm not, I'm not really well versed that. What's the probability that, you know, so what's the probability that the animals will begin in the ocean and crawl out onto land?

1:33:14.200 --> 1:33:26.200
 Versus the other way. Versus the, I would say probably high. I don't know. But, you know, but do I think what's the likelihood that we would end up with exactly the same or very similar?

1:33:26.200 --> 1:33:41.200
 I think it's low actually. I wouldn't say it's low, but I would say it's not, it's not 100% and I'm not even sure it's 50%. You know, I would say, I don't think that we're here by accident because I think, like I said, there are constraints.

1:33:41.200 --> 1:33:56.200
 Like, there are some physical constraints about Earth. Now, of course, if you were a cosmologist, you could say, well, the fact that the Earth is, if you were to do the big bang over again and keep doing it over and over and over again, would you still get the same solar systems?

1:33:56.200 --> 1:34:06.200
 Would you still get the same planets? Would, you know, would you still get the same galaxies, the same solar systems, the same planets? You know, I don't know, but my guess is probably not.

1:34:06.200 --> 1:34:16.200
 Because there are random things that happen that can, again, send things in one direction, you know, make one set of trajectories possible and another set impossible.

1:34:16.200 --> 1:34:33.200
 So, but I guess my, if I were going to bet money or something valuable, I would probably say it's not zero and it's not 100% and it's probably not even 50%.

1:34:33.200 --> 1:34:36.200
 So, there's some probability, but it will be similar.

1:34:36.200 --> 1:34:42.200
 But I don't think, I just think there are too many degrees of freedom. There are too many degrees of freedom.

1:34:42.200 --> 1:34:57.200
 I mean, one of the real tensions in writing this book is to, on the one hand, there's some truth in saying that humans are not special.

1:34:57.200 --> 1:35:06.200
 We are just, you know, we're not special in the animal kingdom. All animals are well adapted.

1:35:06.200 --> 1:35:15.200
 If they're survived, they're well adapted to their niche. It does happen to be the case that our niche is large.

1:35:15.200 --> 1:35:26.200
 For any individual human, your niche is whatever it is. But for the species, right, we live almost everywhere, not everywhere, but almost everywhere on the planet.

1:35:26.200 --> 1:35:35.200
 But not in the ocean. And actually other animals like bacteria, for example, have us beat miles, you know, hands down, right?

1:35:35.200 --> 1:35:46.200
 So, by any definition, we're not special. We're just, you know, adapted to our environment.

1:35:46.200 --> 1:35:48.200
 But bacteria don't have a podcast.

1:35:48.200 --> 1:35:50.200
 Exactly, exactly.

1:35:50.200 --> 1:35:51.200
 They're not able to introspect.

1:35:51.200 --> 1:35:58.200
 So that's the tension, right? So on the one hand, you know, we're not special animals. We're just, you know, particularly well adapted to our niche.

1:35:58.200 --> 1:36:04.200
 On the other hand, our niche is huge. And we, you know, we don't just adapt to our environment. We add to our environment.

1:36:04.200 --> 1:36:10.200
 We make stuff up, give it a name, and then it becomes real. And so no other animal can do that.

1:36:10.200 --> 1:36:26.200
 And so I think the thing, the way to think about it from my perspective or the way I made sense of it is to say, you can look at any individual single characteristic that a human has that seems remarkable.

1:36:26.200 --> 1:36:29.200
 And you can find that in some other animal.

1:36:29.200 --> 1:36:44.200
 What you can't find in any other animal is all of those characteristics together in a brain that is souped up in particular ways like ours is.

1:36:44.200 --> 1:36:56.200
 And if you combine these things, multiple interacting causes, right, not one, not one essence like your cortex, your big neocortex, but which isn't really that big.

1:36:56.200 --> 1:37:04.200
 I mean, it's just big for your big brain, for the size of your big brain. It's the size it should be.

1:37:04.200 --> 1:37:11.200
 If you add all those things together and they interact with each other, that produces some pretty remarkable results.

1:37:11.200 --> 1:37:25.200
 And if you're aware of that, then you can start asking different kinds of questions about what it means to be human and what kind of a human you want to be.

1:37:25.200 --> 1:37:31.200
 And what kind of a world do you want to curate for the next generation of humans?

1:37:31.200 --> 1:37:34.200
 I think that's the goal anyways, right?

1:37:34.200 --> 1:37:54.200
 It's just to have a glimpse of, instead of thinking about things in a simple linear way, just to have a glimpse of some of the things that matter that seems, that evidence suggests matters to the kind of brain in the kind of bodies that we have.

1:37:54.200 --> 1:37:58.200
 Once you know that, you can work with it a little bit.

1:37:58.200 --> 1:38:01.200
 You write, words have power over your biology.

1:38:01.200 --> 1:38:08.200
 Right now, I can text the words, I love you, from the United States to my close friend in Belgium.

1:38:08.200 --> 1:38:16.200
 And even though she cannot hear my voice or see my face, I will change her heart rate, her breathing and her metabolism.

1:38:16.200 --> 1:38:24.200
 By the way, beautifully written, or someone could text something ambiguous to you, like, is your door locked?

1:38:24.200 --> 1:38:29.200
 And odds are that it would affect your nervous system in an unpleasant way.

1:38:29.200 --> 1:38:42.200
 So, I mean, there's a lot of stuff to talk about here, but just one way to ask is, why do you think words have so much power over our brain?

1:38:42.200 --> 1:38:48.200
 Well, I think we just have to look at the anatomy of the brain to answer that question.

1:38:48.200 --> 1:39:06.200
 So, if you look at the parts of the brain, the systems that are important for processing language, you can see that some of these regions are also important for controlling your major organ systems.

1:39:06.200 --> 1:39:21.200
 And your autonomic nervous system that controls your cardiovascular system, your respiratory system, and so on, that these regions control your endocrine system, your immune system, and so on.

1:39:21.200 --> 1:39:24.200
 And you can actually see this in other animals too.

1:39:24.200 --> 1:39:31.200
 So, in birds, for example, the neurons that are responsible for birdsong also control the systems of a bird's body.

1:39:31.200 --> 1:39:49.200
 And the reason why I bring that up is that some scientists think that the anatomy of a bird's brain, that control birdsong, are homologous or structurally have a similar origin to the human system for language.

1:39:49.200 --> 1:39:57.200
 So, the parts of the brain that are important for processing language are not unique and specialized for language.

1:39:57.200 --> 1:40:03.200
 They do many things, and one of the things they do is control your major organ systems.

1:40:03.200 --> 1:40:07.200
 Do you think we can fall in love, I have arguments about this all the time.

1:40:07.200 --> 1:40:10.200
 Do you think we can fall in love based on words alone?

1:40:10.200 --> 1:40:13.200
 Well, I think people have been doing it for centuries.

1:40:13.200 --> 1:40:21.200
 I mean, maybe it used to be the case that people wrote letters to each other, you know, and then that was how they communicated.

1:40:21.200 --> 1:40:23.200
 I guess that's how you and Dan got it.

1:40:23.200 --> 1:40:26.200
 Exactly, exactly, exactly.

1:40:26.200 --> 1:40:30.200
 So, is the answer a clear yes there?

1:40:30.200 --> 1:40:41.200
 Because I get a lot of pushback from people often that you need the touch and the smell and, you know, the bodily stuff.

1:40:41.200 --> 1:40:44.200
 I think the touch and the smell and the bodily stuff helps.

1:40:44.200 --> 1:40:45.200
 Okay.

1:40:45.200 --> 1:40:47.200
 But I don't think it's necessary.

1:40:47.200 --> 1:40:57.200
 Do you think you're going to have a lifelong monogamous relationship with the AI system that only communicates with you on text romantic relationship?

1:40:57.200 --> 1:41:10.200
 Well, I suppose that's an empirical question that hasn't been answered yet, but I guess what I would say is I don't think I could.

1:41:10.200 --> 1:41:12.200
 Could any human?

1:41:12.200 --> 1:41:14.200
 Could the average human?

1:41:14.200 --> 1:41:31.200
 You know, so if I even modify that and say, I'm thinking now of Tom Hanks and the movie.

1:41:31.200 --> 1:41:32.200
 Castaway?

1:41:32.200 --> 1:41:33.200
 Yeah, you know, with Wilson.

1:41:33.200 --> 1:41:34.200
 Yeah.

1:41:34.200 --> 1:41:39.200
 I think if that was, if you had to make that work, if you had to make that work.

1:41:39.200 --> 1:41:40.200
 With a volleyball, yeah.

1:41:40.200 --> 1:41:45.200
 If you had to make it work, could you prediction and simulation, right?

1:41:45.200 --> 1:41:53.200
 So if you had to make it work, could you make it work using simulation and, you know, your past experience?

1:41:53.200 --> 1:41:56.200
 Could you make it work?

1:41:56.200 --> 1:41:57.200
 Could you make it work?

1:41:57.200 --> 1:41:59.200
 You as a human, could you?

1:41:59.200 --> 1:42:08.200
 Could you have a relationship literally with an inanimate object and have it sustain you in the way that another human could?

1:42:08.200 --> 1:42:15.200
 Your life would probably be shorter because you wouldn't actually derive the body budgeting benefits from, right?

1:42:15.200 --> 1:42:27.200
 So we've talked about, you know, how your brain, its most important job is to control your body and you can describe that as your brain running a budget for your body.

1:42:27.200 --> 1:42:28.200
 Yes.

1:42:28.200 --> 1:42:40.200
 And there are metaphorical, you know, deposits and withdrawals into your body budget and you also make deposits and withdrawals in other people's body budgets, figuratively speaking.

1:42:40.200 --> 1:42:45.200
 So you wouldn't have that particular benefit.

1:42:45.200 --> 1:42:52.200
 So your life would probably be shorter, but I think it would be harder for some people than for other people.

1:42:52.200 --> 1:42:59.200
 Yeah, I think my intuition is that you can have a deep fulfilling relationship with a volleyball.

1:42:59.200 --> 1:43:05.200
 I think a lot of the environments that set up, I think that's a really good example.

1:43:05.200 --> 1:43:21.200
 Like the constraints of your particular environment define the, like, I believe like scarcity is a good catalyst for deep meaningful connection with other humans and with inanimate objects.

1:43:21.200 --> 1:43:25.200
 So the less you have, the more fulfilling those relationships are.

1:43:25.200 --> 1:43:38.200
 And I would say a relationship with a volleyball, the sex is not great, but everything else, I feel like it could be a very fulfilling relationship, which I don't know from an engineering perspective what to do with that.

1:43:38.200 --> 1:43:41.200
 And just like you said, it is an empirical question.

1:43:41.200 --> 1:43:43.200
 But there are places to learn about that, right?

1:43:43.200 --> 1:43:49.200
 So for example, think about children and their blankets, right?

1:43:49.200 --> 1:43:53.200
 So there, there's something tactile and there's something olfactory.

1:43:53.200 --> 1:43:56.200
 And it's very comforting.

1:43:56.200 --> 1:44:00.200
 I mean, even for nonhuman little animals, right?

1:44:00.200 --> 1:44:04.200
 Like puppies and so I don't know about cats, but...

1:44:04.200 --> 1:44:08.200
 Cats are coldhearted and there's no, there's nothing going on there.

1:44:08.200 --> 1:44:09.200
 I don't know.

1:44:09.200 --> 1:44:13.200
 There are some cats that are very dog like, I mean, really.

1:44:13.200 --> 1:44:15.200
 Some cats identify as dogs, yes.

1:44:15.200 --> 1:44:16.200
 I think that's true.

1:44:16.200 --> 1:44:20.200
 Yeah, they're species fluid.

1:44:20.200 --> 1:44:27.200
 So you also write, when it comes to human minds, variation is the norm.

1:44:27.200 --> 1:44:33.200
 And what we call, quote, human nature is really many human natures.

1:44:33.200 --> 1:44:44.200
 Again, many questions I can ask here, but maybe an interesting one to ask is, I often hear, you know, we often hear this idea of be yourself.

1:44:44.200 --> 1:44:48.200
 Is this possible to be yourself?

1:44:48.200 --> 1:44:51.200
 Is it a good idea to strive to be yourself?

1:44:51.200 --> 1:44:54.200
 Does that even have any meaning?

1:44:54.200 --> 1:45:00.200
 It's a very Western question, first of all, because which self are you talking about?

1:45:00.200 --> 1:45:02.200
 You don't have one self.

1:45:02.200 --> 1:45:04.200
 There is no self that's an essence of you.

1:45:04.200 --> 1:45:06.200
 You have multiple selves.

1:45:06.200 --> 1:45:13.200
 Actually, there is research on this, you know, to quote the great social psychologist Hazel Marcus.

1:45:13.200 --> 1:45:18.200
 You cannot be a self by yourself.

1:45:18.200 --> 1:45:31.200
 And so different contexts pull for or draw on different features of who you are or what you believe, what you feel, what your actions are.

1:45:31.200 --> 1:45:39.200
 Different contexts will put certain things or make more, some features be more in the foreground and some in the background.

1:45:39.200 --> 1:45:45.200
 It takes us back right to our discussion earlier about Stalin and Hitler and so on.

1:45:45.200 --> 1:45:55.200
 The thing that I would caution, in addition to the fact that there is no single self, you know, that you have multiple selves who you can be,

1:45:55.200 --> 1:46:01.200
 and you can certainly choose the situations that you put yourself in to some extent.

1:46:01.200 --> 1:46:04.200
 Not everybody has complete choice, but everybody has a little bit of choice.

1:46:04.200 --> 1:46:11.200
 And I think I said this to you before that one of the pieces of advice that we gave Sophia, you know, when she went,

1:46:11.200 --> 1:46:18.200
 our daughter, when she was going off to college was try to spend time around people,

1:46:18.200 --> 1:46:23.200
 choose relationships that allow you to be your best self.

1:46:23.200 --> 1:46:26.200
 We should have said your best selves.

1:46:26.200 --> 1:46:31.200
 The pool of selves given the environment.

1:46:31.200 --> 1:46:42.200
 Yeah. But the one thing I do want to say is that the risk of saying be yourself, just be yourself, is that that can be used as an excuse.

1:46:42.200 --> 1:46:45.200
 Well, this is just the way that I am. I'm just like this.

1:46:45.200 --> 1:46:51.200
 And that I think should be tremendously resistant.

1:46:51.200 --> 1:47:01.200
 So that's one, that's the, that's for the excuse side, but you know, I'm really self critical often, I'm full of doubt.

1:47:01.200 --> 1:47:04.200
 And people often tell me just don't worry about it, just be yourself, man.

1:47:04.200 --> 1:47:12.200
 And it's the thing is, it almost, it's not from an engineering perspective, does not seem like actionable advice.

1:47:12.200 --> 1:47:29.200
 Because I guess constantly worrying about who, what are the right words to say to express how I'm feeling is, I guess, myself.

1:47:29.200 --> 1:47:40.200
 There's, there's a kind of line, I guess that this might be a Western idea, but something that feels genuine and something that feels non genuine.

1:47:40.200 --> 1:47:48.200
 And I'm not sure what that means, because I would like to be fully genuine and fully open, but I'm also aware.

1:47:48.200 --> 1:47:52.200
 Like this morning, I was like, very like silly and giddy.

1:47:52.200 --> 1:47:57.200
 I was just being funny and relaxed and light.

1:47:57.200 --> 1:48:01.200
 Like there's nothing that could bother me in the world.

1:48:01.200 --> 1:48:03.200
 I was just smiling and happy.

1:48:03.200 --> 1:48:09.200
 And I remember last night was just feeling like very grumpy, like, like stuff was bothering me.

1:48:09.200 --> 1:48:11.200
 Like certain things were bothering me.

1:48:11.200 --> 1:48:13.200
 And like, what are those?

1:48:13.200 --> 1:48:15.200
 Those are different selves.

1:48:15.200 --> 1:48:17.200
 Like what? Who am I in that?

1:48:17.200 --> 1:48:18.200
 And what do I do?

1:48:18.200 --> 1:48:29.200
 Because if, you know, if you take Twitter as an example, if I actually send a tweet last night and a tweet this morning, it's going to be very two different people tweeting that.

1:48:29.200 --> 1:48:35.200
 And I don't know what to do with that, because one does seem to be more me than the other.

1:48:35.200 --> 1:48:43.200
 That's maybe because there's a narrative, a story that I'm trying. There's something I'm striving to be, like the ultimate human that I might become.

1:48:43.200 --> 1:48:46.200
 I have maybe a vision of that and I'm trying to become that.

1:48:46.200 --> 1:48:51.200
 But it does seem like there's a lot of different minds in there.

1:48:51.200 --> 1:48:56.200
 And they're all like, like having a discussion and a battle for who's going to win.

1:48:56.200 --> 1:49:10.200
 I suppose you could think of it that way, but there's another way to think of it, I think, and that is that maybe the more Buddhist way to think of it, right? Or a more contemplative way to think about it, which is not that you have multiple personalities inside your head.

1:49:10.200 --> 1:49:36.200
 But your brain has this amazing capacity. It has a population of experiences that you've had that it can regenerate, reconstitute, and it can even take bits and pieces of those experiences and combine them into something new.

1:49:36.200 --> 1:49:42.200
 And it's often doing this to predict what's going to happen next and to plan your actions.

1:49:42.200 --> 1:49:52.200
 But this also happens just, that's what mind wandering is, or just internal thought and so on. It's the same mechanism, really.

1:49:52.200 --> 1:50:06.200
 And so a lot of times we hear the saying, you know, just think, if you think differently, you'll feel differently. But your brain is having a conversation continually with your body.

1:50:06.200 --> 1:50:30.200
 And your body, your brain is, you know, trying to control your body. Well, trying. Your brain is controlling your body. Your body is sending information back to the brain. And in part, the information that your body sends back to your brain, just like the information coming from the world, initiates the next volley of predictions or simulations.

1:50:30.200 --> 1:50:50.200
 So in some ways you could also say, the way that you feel, I think we talked before about affective feeling or mood coming from the sensations of body budgeting, you know, influences what you think.

1:50:50.200 --> 1:50:58.200
 And as much as, so feelings influence thought as much as thought influence feeling and maybe more.

1:50:58.200 --> 1:51:01.200
 But just the whole thing doesn't seem stable.

1:51:01.200 --> 1:51:04.200
 Well, it's a dynamic system, Mr. Engineer.

1:51:04.200 --> 1:51:05.200
 Yeah.

1:51:05.200 --> 1:51:14.200
 Right? It's a dynamics, it's a dynamical system, right? Nonlinear dynamical system. And I think that's, I'm actually writing a paper with a bunch of engineers about this actually.

1:51:14.200 --> 1:51:24.200
 But I mean, other people have talked about the brain as a dynamical system before, but, you know, the real tricky bit is trying to figure out how do you get mental features out of that system.

1:51:24.200 --> 1:51:38.200
 It's one thing to figure out how you get a motor movement out of that system. It's another thing to figure out how you get a mental feature, like a feeling of being loved or a feeling of being worthwhile or a feeling of, you know, just basically feeling like shit.

1:51:38.200 --> 1:51:43.200
 How do you get a feeling of mental features out of that system?

1:51:43.200 --> 1:51:58.200
 So what I would say is that you aren't, the Buddhist thing to say is that you're not one person and you're not many people. You are the sum of your experiences.

1:51:58.200 --> 1:52:10.200
 And who you are in any given moment, meaning what your actions will be, is influenced by the state of your body and the state of the world that you've put yourself in.

1:52:10.200 --> 1:52:15.200
 And you can change either of those things. One is a little easier to change than the other, right?

1:52:15.200 --> 1:52:30.200
 You can change your environment by literally getting up and moving, or you can change it by paying attention to some things differently and letting some features come to the fore and other features be backgrounded, like I'm looking around your place.

1:52:30.200 --> 1:52:32.200
 Oh, no. This is not something you should do.

1:52:32.200 --> 1:52:39.200
 No, but I'm going to say one thing. No green plants. No green plants.

1:52:39.200 --> 1:52:43.200
 Because green plants mean a home and I want this to be temporary.

1:52:43.200 --> 1:52:48.200
 Fair. Fair. But what's what's what goes to your mind when you see no green plants?

1:52:48.200 --> 1:52:59.200
 No, I'm just making the point that what if you, again, you know, not everybody has control over their environment.

1:52:59.200 --> 1:53:04.200
 Some people don't have control over the noise or the temperature or, you know, any of those things.

1:53:04.200 --> 1:53:19.200
 But everybody is a little bit of control and you can place things in your environment, photographs, plants, anything that's meaningful to you and use it as a shift of environment when you need it.

1:53:19.200 --> 1:53:20.200
 Yes.

1:53:20.200 --> 1:53:24.200
 You can also do things to change the conditions of your body.

1:53:24.200 --> 1:53:29.200
 When you exercise every day, you're making an investment in your body.

1:53:29.200 --> 1:53:36.200
 Actually, you're making an investment in your brain too. It makes your, even though it's unpleasant and, you know, there's a cost to it.

1:53:36.200 --> 1:53:51.200
 If you replenish, if you invest and you make up that, you make a deposit and you make up that what you've spent, you're basically making an investment in making it easier for your brain to control your body in the future.

1:53:51.200 --> 1:53:59.200
 So you can make sure you're hydrated, drink water. You don't have to buy drink bottled water. You can drink water from the tap.

1:53:59.200 --> 1:54:06.200
 This is in most places, maybe not, you know, maybe not everywhere, but most places in the developed world.

1:54:06.200 --> 1:54:18.200
 You can try to get enough sleep. Not everybody has that luxury, but everybody can do something to make their, you know, body budgets a little more solvent.

1:54:18.200 --> 1:54:27.200
 And that will also make it more likely that certain thoughts will emerge from that prediction machine, basically.

1:54:27.200 --> 1:54:33.200
 That's the control you do have is being able to control the environment that's really well put.

1:54:33.200 --> 1:54:41.200
 I don't think we've talked about this. So let's go to the biggest unanswerable questions of consciousness.

1:54:41.200 --> 1:54:43.200
 What is, you just rolled your eyes.

1:54:43.200 --> 1:54:45.200
 I did. That was my, yeah.

1:54:45.200 --> 1:54:52.200
 So what is consciousness from a neuroscience perspective? I know you, I mean,

1:54:52.200 --> 1:54:58.200
 I made notes, you know, because you gave me some questions in advance and I made notes for every single.

1:54:58.200 --> 1:54:59.200
 Oh, except that one?

1:54:59.200 --> 1:55:01.200
 Yeah. Well, that one I had. What the fuck?

1:55:01.200 --> 1:55:03.200
 And then I took it out.

1:55:03.200 --> 1:55:13.200
 So is there something interesting because you're so pragmatic? Is there something interesting to say about intuition building about consciousness?

1:55:13.200 --> 1:55:22.200
 Or is this something that we're just totally clueless about that this is a, let's focus on the body, the brain, listen to the body.

1:55:22.200 --> 1:55:30.200
 The body speaks to the brain and let's just figure this piece out and then consciousness will probably emerge somehow after that.

1:55:30.200 --> 1:55:40.200
 No, I think, you know, well, first of all, let's just say up front, I am not a philosopher of consciousness and I'm not a neuroscientist who focuses on consciousness.

1:55:40.200 --> 1:55:44.200
 I mean, in some sense, I do study it because I study affect and mood.

1:55:44.200 --> 1:55:54.200
 And that's, that is the, you know, to use the phrase, that is the hard question of consciousness.

1:55:54.200 --> 1:55:58.200
 How is it that your brain is modeling your body?

1:55:58.200 --> 1:56:01.200
 Brain is modeling the sensory conditions of your body.

1:56:01.200 --> 1:56:11.200
 It's, and it's being updated, that model is being updated by the sense data that's coming from your body and it's happening continuously your whole life.

1:56:11.200 --> 1:56:15.200
 And you don't feel those sensations directly.

1:56:15.200 --> 1:56:22.200
 You, what you feel is a general sense of pleasantness or unpleasantness, comfort, discomfort, feeling worked up, feeling calm.

1:56:22.200 --> 1:56:26.200
 So we call that affect, you know, most people call it mood.

1:56:26.200 --> 1:56:39.200
 So how is it that your brain gives you this very low dimensional feeling of mood or affect when it's presumably receiving a very high dimensional array of sense data.

1:56:39.200 --> 1:56:47.200
 And the model that the brain is running of the body has to be high dimensional because there's a lot going on in there, right?

1:56:47.200 --> 1:56:54.200
 You're not aware, but as you're sitting there quietly, as your listeners or our, as our viewers are sitting.

1:56:54.200 --> 1:57:01.200
 They might be working out, running now, or as many of them write to me, they're laying in bed, smoking weed with their eyes closed.

1:57:01.200 --> 1:57:02.200
 That's fair.

1:57:02.200 --> 1:57:04.200
 So maybe we should say that bit again then.

1:57:04.200 --> 1:57:16.200
 So if, so some people may be working out, some people may be relaxing, but you know, even if you're sitting very still while you're watching this or listening to this,

1:57:16.200 --> 1:57:21.200
 there's a whole drama going on inside your body that you're largely unaware of.

1:57:21.200 --> 1:57:33.200
 Yet your brain makes you aware or gives you a status report in a sense by virtue of these mental features of feeling pleasant, feeling unpleasant,

1:57:33.200 --> 1:57:38.200
 feeling comfortable, feeling uncomfortable, feeling energetic, feeling tired and so on.

1:57:38.200 --> 1:57:41.200
 And so how the hell is it doing that?

1:57:41.200 --> 1:57:46.200
 That is the basic question of consciousness.

1:57:46.200 --> 1:57:52.200
 And like the status reports seem to be in the way we experienced them seem to be quite simple.

1:57:52.200 --> 1:57:56.200
 Like it doesn't feel like there's a lot of data.

1:57:56.200 --> 1:57:57.200
 Yeah, I know that there isn't.

1:57:57.200 --> 1:58:05.200
 So when you feel, when you feel discomfort, when you're feeling basically like shit, you feel like shit.

1:58:05.200 --> 1:58:06.200
 What does that tell you?

1:58:06.200 --> 1:58:08.200
 Like, what are you supposed to do next?

1:58:08.200 --> 1:58:09.200
 What caused it?

1:58:09.200 --> 1:58:12.200
 I mean, the thing is not one thing caused it, right?

1:58:12.200 --> 1:58:17.200
 It's multiple factors probably influencing your physical state, your body budget.

1:58:17.200 --> 1:58:18.200
 Because it's very high dimensional, yeah.

1:58:18.200 --> 1:58:20.200
 It's very high dimensional.

1:58:20.200 --> 1:58:28.200
 And that, and the, there are different temporal scales of influence, right?

1:58:28.200 --> 1:58:34.200
 So, you know, the state of your gut is not just influenced by what you ate five minutes ago.

1:58:34.200 --> 1:58:38.200
 It's also what you ate a day ago and two days ago and so on.

1:58:38.200 --> 1:58:50.200
 So, so I think the, you know, when I'm, I'm not trying to weasel out of the question.

1:58:50.200 --> 1:58:55.200
 I just think it's a, it's the hardest question actually.

1:58:55.200 --> 1:58:59.200
 Do you think we'll ever understand it?

1:58:59.200 --> 1:59:03.200
 I'm a scientist.

1:59:03.200 --> 1:59:17.200
 I think that we will understand it as well as we understand other things like the birth of the universe or the, you know, the nature of the, of the universe.

1:59:17.200 --> 1:59:21.200
 I guess I would say, so I, do I think we can get to that level of an explanation?

1:59:21.200 --> 1:59:30.200
 I do actually, but I think that we have to start asking somewhat different questions and approaching the science somewhat differently than we have in the past.

1:59:30.200 --> 1:59:35.200
 I mean, it's also possible that consciousness is much more difficult to understand than the nature of the universe.

1:59:35.200 --> 1:59:41.200
 It is, but I wasn't necessarily saying that it was a question that was of equivalent complexity.

1:59:41.200 --> 1:59:57.200
 I was saying that I do think that we could get to some, I am optimistic that I would not, I would be very willing to invest the time, my time on this Earth as a scientist

1:59:57.200 --> 2:00:04.200
 and try and answer that question if I could do it the way that I want to do it, not in the way that it's currently being done.

2:00:04.200 --> 2:00:06.200
 So like rigorously?

2:00:06.200 --> 2:00:08.200
 I don't want to say unrigorously.

2:00:08.200 --> 2:00:14.200
 I just want to say that there are certain set of assumptions that, you know, scientists have what I would call ontological commitments.

2:00:14.200 --> 2:00:19.200
 They're commitments about the way the world is or the way that nature is.

2:00:19.200 --> 2:00:29.200
 And they, these commitments lead scientists sometimes blindly without, they don't, scientists sometimes, sometimes scientists are aware of these commitments, but sometimes they're not.

2:00:29.200 --> 2:00:36.200
 And these commitments on the list influence how scientists ask questions, how, what they measure, how they measure.

2:00:36.200 --> 2:00:43.200
 And I, I just have very different views than a lot of my colleagues about the ways to approach this.

2:00:43.200 --> 2:00:53.200
 Not everybody, but, but the way that I would approach it would be different and it would cost more and it would take longer.

2:00:53.200 --> 2:00:56.200
 It doesn't fit very well into the current incentive structure of science.

2:00:56.200 --> 2:01:04.200
 And so do I think that doing science the way science is currently done with the budget that it currently has and the incentive structure that it currently has?

2:01:04.200 --> 2:01:05.200
 Will we have an answer?

2:01:05.200 --> 2:01:07.200
 No, I think absolutely not.

2:01:07.200 --> 2:01:09.200
 Good luck is what I would say.

2:01:09.200 --> 2:01:13.200
 People love book recommendations.

2:01:13.200 --> 2:01:15.200
 Let me ask what three books.

2:01:15.200 --> 2:01:17.200
 Oh, you can't just like, you can't just give me three.

2:01:17.200 --> 2:01:19.200
 I mean, like really three?

2:01:19.200 --> 2:01:22.200
 What seven and a half books you can recommend.

2:01:22.200 --> 2:01:26.200
 So you're also the author of seven and a half lessons about the brain.

2:01:26.200 --> 2:01:29.200
 You're author of how emotions are made.

2:01:29.200 --> 2:01:30.200
 Okay.

2:01:30.200 --> 2:01:35.200
 So definitely those are the top two recommendations of all the two greatest books of all time.

2:01:35.200 --> 2:01:42.200
 Other than that, are there books that technical fiction philosophical that you've enjoyed or you might recommend to others?

2:01:42.200 --> 2:01:44.200
 Yes.

2:01:44.200 --> 2:01:59.200
 Actually, you know, every PhD student when they, when they graduate with their PhD, I give them a set of like a little library, like a set of books, you know, some of which they've already read some of which I want them to read or.

2:01:59.200 --> 2:02:10.200
 But I think nonfiction books, I would read the things I would recommend are The Triple Helix by Richard Luanton.

2:02:10.200 --> 2:02:25.200
 It's a little book published in 2000, which is, I think, a really good introduction to complexity and population thinking as opposed to essentialism.

2:02:25.200 --> 2:02:38.200
 So this idea, essentialism is this idea that, you know, there's an essence to each person, whether it's a soul or your genes or what have you, as opposed to this idea that you, we have the kind of nature that requires a nurture.

2:02:38.200 --> 2:02:54.200
 We are, we are, you are the product of a complex dance between an environment, between a set of genes and an environment that turns those genes on and off to produce your brain and your body.

2:02:54.200 --> 2:02:57.200
 And really who you are at any given moment.

2:02:57.200 --> 2:02:59.200
 It's a good title for that triple helix.

2:02:59.200 --> 2:03:03.200
 So playing on the double helix where it's just the biology, it's bigger than the biology.

2:03:03.200 --> 2:03:05.200
 Exactly.

2:03:05.200 --> 2:03:06.200
 It's a wonderful book.

2:03:06.200 --> 2:03:08.200
 I've read it probably six or seven times throughout the year.

2:03:08.200 --> 2:03:14.200
 He has another book, too, which is, it's more, I think, scientists would find it.

2:03:14.200 --> 2:03:15.200
 I don't know.

2:03:15.200 --> 2:03:16.200
 I've loved it.

2:03:16.200 --> 2:03:18.200
 It's called Biology as Ideology.

2:03:18.200 --> 2:03:31.200
 And it really is all about, I wouldn't call it one of the best books of all time, but I love the book because it really does point out, you know, that science says it's currently practiced.

2:03:31.200 --> 2:03:41.200
 I mean, the book was written in 1991, but it actually, I think, still holds that scientists, science is currently practiced has a set of ontological commitments, which are somewhat problematic.

2:03:41.200 --> 2:03:43.200
 So the assumptions are limiting.

2:03:43.200 --> 2:03:44.200
 Yeah.

2:03:44.200 --> 2:03:47.200
 In ways that you, it's, you know, it's like you're a fish in water and you don't like, okay.

2:03:47.200 --> 2:03:48.200
 Right.

2:03:48.200 --> 2:03:49.200
 Yeah.

2:03:49.200 --> 2:03:50.200
 So here's the.

2:03:50.200 --> 2:03:51.200
 Favorite foster walls and stuff.

2:03:51.200 --> 2:03:52.200
 Yeah.

2:03:52.200 --> 2:03:55.200
 But, you know, but here's a, here's a really cool thing I just learned recently.

2:03:55.200 --> 2:03:58.200
 Is it okay to, to, to go off on this tangent for a minute?

2:03:58.200 --> 2:03:59.200
 Yeah.

2:03:59.200 --> 2:04:00.200
 Yeah.

2:04:00.200 --> 2:04:01.200
 Let's go tangents.

2:04:01.200 --> 2:04:02.200
 Great.

2:04:02.200 --> 2:04:06.200
 Um, I was just going to say that I just learned recently that we don't have water receptors on our skin.

2:04:06.200 --> 2:04:08.200
 So how do you know when you're sweating?

2:04:08.200 --> 2:04:16.200
 How do you know when, when a raindrop, when, you know, when it's going to rain and, you know, like a raindrop hits your skin and you can feel that little drop of wetness?

2:04:16.200 --> 2:04:21.200
 How is it that you feel that drop of wetness when we don't have water receptors in our skin?

2:04:21.200 --> 2:04:22.200
 And I was, when I.

2:04:22.200 --> 2:04:24.200
 My mind is blown already.

2:04:24.200 --> 2:04:25.200
 Yeah.

2:04:25.200 --> 2:04:26.200
 That was, I have my reaction too.

2:04:26.200 --> 2:04:27.200
 Right.

2:04:27.200 --> 2:04:30.200
 I was like, of course we don't because we evolved in the water.

2:04:30.200 --> 2:04:31.200
 Yeah.

2:04:31.200 --> 2:04:37.200
 Like why would we need, you know, it just, it was just this like, you know, you have these moments where you're like, of course there's like a, yeah.

2:04:37.200 --> 2:04:38.200
 So.

2:04:38.200 --> 2:04:40.200
 You'll never see rain the same way again.

2:04:40.200 --> 2:04:47.200
 So the answer is it's a, it's a, it's a combination of temperature and touch.

2:04:47.200 --> 2:04:48.200
 Yeah.

2:04:48.200 --> 2:04:52.200
 But it's a complex sense that's only computed in your brain.

2:04:52.200 --> 2:04:54.200
 There's no receptor for it.

2:04:54.200 --> 2:04:55.200
 Anyways.

2:04:55.200 --> 2:04:56.200
 Yeah.

2:04:56.200 --> 2:05:05.200
 That's why like snow versus cold rain versus warm rain all feel different because you're, you're trying to infer stuff from the temperature and the size of the droplets is fascinating.

2:05:05.200 --> 2:05:06.200
 Yeah.

2:05:06.200 --> 2:05:11.200
 Your brain is a prediction machine and using lots and lots of information and combining it.

2:05:11.200 --> 2:05:12.200
 Yeah.

2:05:12.200 --> 2:05:22.200
 Anyway, so, but so biology is ideology is, I wouldn't say it's one of the greatest books of all time, but it is a, it is a really useful book.

2:05:22.200 --> 2:05:35.200
 There's a book by, if you're interested in psychology or the mind at all, there's a wonderful book, a little, it's a fairly, fairly small book called Naming the Mind by Kurt Danzig.

2:05:35.200 --> 2:05:38.200
 Or who's a historian of psychology.

2:05:38.200 --> 2:05:42.200
 Everybody in my lab reads both of these books.

2:05:42.200 --> 2:05:43.200
 So what's the book?

2:05:43.200 --> 2:05:56.200
 It's about the origin of the, where do, where did we get the theory of mind that we have that the human mind is populated by thoughts and feelings and perceptions?

2:05:56.200 --> 2:05:58.200
 And where did those categories come from?

2:05:58.200 --> 2:06:01.200
 Because they don't exist in all cultures.

2:06:01.200 --> 2:06:05.200
 Oh, so this isn't, that's a cultural construct.

2:06:05.200 --> 2:06:12.200
 The idea that you have thoughts and feelings and they're very distinct is definitely a cultural construct.

2:06:12.200 --> 2:06:15.200
 It's another mind blowing thing, just like the rain.

2:06:15.200 --> 2:06:26.200
 So Kurt Danziger is a, the opening chapter in that book is absolutely mind blowing.

2:06:26.200 --> 2:06:28.200
 I love it.

2:06:28.200 --> 2:06:29.200
 I love it.

2:06:29.200 --> 2:06:31.200
 I just think it's fantastic.

2:06:31.200 --> 2:06:42.200
 And I would say that there are many, many popular science books that I could recommend that I think are extremely well written in their own way.

2:06:42.200 --> 2:06:58.200
 You know, before I, maybe I said this to you, but before I undertook writing how emotions are made, I read, I don't know, somewhere on the order of 50 or 60 popular science books to try to figure out how to write.

2:06:58.200 --> 2:07:00.200
 To write a popular science book.

2:07:00.200 --> 2:07:14.200
 Because while there are many books about writing, Stephen King has a great book on writing and, you know, where he gives tips interlaced with his own personal history.

2:07:14.200 --> 2:07:17.200
 That was where I learned you write for a specific person.

2:07:17.200 --> 2:07:19.200
 You have a specific person in mind.

2:07:19.200 --> 2:07:22.200
 And that's, for me, that person is down.

2:07:22.200 --> 2:07:31.200
 That's fascinating. I mean, that's a whole nother conversation to have like, which popular science books, like what you learned from that search.

2:07:31.200 --> 2:07:39.200
 Because there's a, I have some, for me, some popular science books are like, I just roll my eyes like this is two.

2:07:39.200 --> 2:07:51.200
 It's the same with Ted Talks, like some of them go too much into the flowery and don't, I don't, I would say don't give enough respect to the intelligence of the reader.

2:07:51.200 --> 2:07:54.200
 But this is my own bias, very specifically.

2:07:54.200 --> 2:07:56.200
 I completely agree with you.

2:07:56.200 --> 2:08:13.200
 And in fact, I have a colleague, his name is Van Yang, who, you know, he produced a cinematic lecture of how emotions are made that we wrote together with Joseph Friedman in a relation.

2:08:13.200 --> 2:08:14.200
 Yes.

2:08:14.200 --> 2:08:15.200
 Well, we're all related.

2:08:15.200 --> 2:08:18.200
 Well, I mean, you and I are probably, you know, have some, yeah.

2:08:18.200 --> 2:08:19.200
 Yeah.

2:08:19.200 --> 2:08:20.200
 I remember.

2:08:20.200 --> 2:08:22.200
 It's the memories are in there somewhere.

2:08:22.200 --> 2:08:23.200
 Yeah.

2:08:23.200 --> 2:08:25.200
 It's from many, many, many generations ago.

2:08:25.200 --> 2:08:27.200
 Well, half my family is Russian.

2:08:27.200 --> 2:08:29.200
 So from the good half.

2:08:29.200 --> 2:08:32.200
 The good half, right.

2:08:32.200 --> 2:08:49.200
 But, you know, he wanted his goal actually is to produce, you know, videos and lectures that are beautiful and educational.

2:08:49.200 --> 2:08:55.200
 And that don't, don't dumb the material down.

2:08:55.200 --> 2:08:59.200
 And he's really remarkable at it actually.

2:08:59.200 --> 2:09:02.200
 I mean, just, but again, you know, that's good.

2:09:02.200 --> 2:09:04.200
 That requires a bit of a paradigm shift.

2:09:04.200 --> 2:09:11.200
 We could have a whole conversation about the split between entertainment and education in this country and why it is the way it is.

2:09:11.200 --> 2:09:13.200
 But that's another conversation.

2:09:13.200 --> 2:09:14.200
 To be continued.

2:09:14.200 --> 2:09:25.200
 But I would say the, if I were to pick one book that I think is a really good example of good science writing, it would be The Beak of the Finch.

2:09:25.200 --> 2:09:30.200
 Which is, it won a Pulitzer Prize a number of years ago.

2:09:30.200 --> 2:09:34.200
 And I'm not, I'm not remembering the author's name.

2:09:34.200 --> 2:09:35.200
 I'm blanking.

2:09:35.200 --> 2:09:42.200
 But the, I'm guessing, is it, is it focusing on birds and the evolution of birds?

2:09:42.200 --> 2:09:45.200
 Actually, there's also the evolution of beauty.

2:09:45.200 --> 2:09:46.200
 That's, yeah.

2:09:46.200 --> 2:09:47.200
 Yeah.

2:09:47.200 --> 2:09:48.200
 Which is also a great book.

2:09:48.200 --> 2:09:57.200
 But no, The Beak of the Finch is, it's a, it, it has two storylines that are interwoven.

2:09:57.200 --> 2:10:04.200
 One is about Darwin and Darwin's explorations in the Galapagos Island.

2:10:04.200 --> 2:10:13.200
 And then modern day researchers from Princeton who have a research program in the Galapagos looking at Darwin's Finches.

2:10:13.200 --> 2:10:21.200
 And it's just a really, first of all, there's top notch science in there.

2:10:21.200 --> 2:10:28.200
 And really science, like, you know, evolutionary biology that a lot of people don't know.

2:10:28.200 --> 2:10:30.200
 And it's told really, really well.

2:10:30.200 --> 2:10:34.200
 It sounds like there's a narrative in there.

2:10:34.200 --> 2:10:35.200
 It's like storytelling too.

2:10:35.200 --> 2:10:36.200
 Yeah.

2:10:36.200 --> 2:10:44.200
 I think all good popular science books are storytelling, but storytelling grounded, constrained by, you know, the evidence.

2:10:44.200 --> 2:10:54.200
 And then I just want to say that there are, for fiction, I'm a really big fan of love stories just to return us to the topic that we began with.

2:10:54.200 --> 2:11:04.200
 And so my, some of my favorite love stories are Major Pedigrees Last Stand by Helen Simonson.

2:11:04.200 --> 2:11:15.200
 It's a, it's a love story about people who you wouldn't expect to fall in love and all the people around them who have to overcome their prejudices.

2:11:15.200 --> 2:11:19.200
 And, and I love this book.

2:11:19.200 --> 2:11:20.200
 What do you like?

2:11:20.200 --> 2:11:22.200
 Like, what makes a good love story?

2:11:22.200 --> 2:11:26.200
 There isn't one thing, you know, there are many different things that make a good love story.

2:11:26.200 --> 2:11:42.200
 But I think in this case, you can feel, you can feel the journey, you can feel the journey that these characters are on and all the people around them are on this journey too.

2:11:42.200 --> 2:11:55.200
 Basically, to come to grips with this really unexpected love, really profound love that develops between these two characters who are very unlikely to have fallen in love, but they do.

2:11:55.200 --> 2:11:59.200
 And it's just, it's very gentle.

2:11:59.200 --> 2:12:17.200
 Another book like that is the, the storied life of AJ Fierke, which is also a love story, but in this case, it's a love story between a little girl and her adopted dad.

2:12:17.200 --> 2:12:25.200
 And the dad is this like real curmudgeony, you know, guy.

2:12:25.200 --> 2:12:31.200
 But of course, there's a story there. And it's just a beautiful love story.

2:12:31.200 --> 2:12:40.200
 And, but it also, it's like everybody in this community falls in love with him because he falls in love with her.

2:12:40.200 --> 2:12:46.200
 And he, you know, she just gets left at his store, his bookstore, his this failing bookstore.

2:12:46.200 --> 2:12:56.200
 And he discovers that, you know, he feels like inexplicably this need to take care of this little baby.

2:12:56.200 --> 2:13:04.200
 And this whole life emerges out of that one decision, which is really beautiful, actually.

2:13:04.200 --> 2:13:06.200
 Very poignant.

2:13:06.200 --> 2:13:13.200
 Do you think the greatest stories have a happy ending or a heartbreak at the end?

2:13:13.200 --> 2:13:17.200
 That's such a Russian question. It's like, it's like Russian tragedies, you know.

2:13:17.200 --> 2:13:21.200
 So I would say the answer to that for me, there has to be heartbreak.

2:13:21.200 --> 2:13:25.200
 Yeah, I really don't like heartbreak. I don't like heartbreak.

2:13:25.200 --> 2:13:31.200
 I want there to be a happy ending or at least a hopeful ending.

2:13:31.200 --> 2:13:37.200
 But the, but, you know, like Dr. Shavago, like, or the English patient.

2:13:37.200 --> 2:13:40.200
 Oh my goodness, like, why?

2:13:40.200 --> 2:13:44.200
 Oh, it's just, yeah, no.

2:13:44.200 --> 2:13:50.200
 Well, I don't think there's a better way to end it on a happy note like this.

2:13:50.200 --> 2:13:57.200
 Lisa, like I said, I'm a huge fan of yours. Thank you for wasting yet more time with me talking again.

2:13:57.200 --> 2:13:59.200
 People should definitely get your book.

2:13:59.200 --> 2:14:03.200
 And maybe one day I can't wait to talk to your husband as well.

2:14:03.200 --> 2:14:07.200
 Well, right back at you, Alexi.

2:14:07.200 --> 2:14:12.200
 Thanks for listening to this conversation with Lisa Feldman Barrett and thank you to our sponsors.

2:14:12.200 --> 2:14:18.200
 Athletic Greens, the all in one drink that I start every day with to cover all my nutritional bases.

2:14:18.200 --> 2:14:24.200
 AteSleep, a mattress that cools itself and gives me yet another reason to enjoy sleep.

2:14:24.200 --> 2:14:31.200
 Masterclass, online courses that I enjoy from some of the most amazing humans in history.

2:14:31.200 --> 2:14:35.200
 And BetterHelp, online therapy with a licensed professional.

2:14:35.200 --> 2:14:41.200
 Please check out these sponsors in the description to get a discount and to support this podcast.

2:14:41.200 --> 2:14:46.200
 If you enjoy this thing, subscribe on YouTube, review it with Five Stars on Apple Podcasts,

2:14:46.200 --> 2:14:51.200
 follow on Spotify, support on Patreon, or connect with me on Twitter at Lex Freedman.

2:14:51.200 --> 2:14:57.200
 And now, let me leave you some words from SunZoo and the art of war.

2:14:57.200 --> 2:15:06.200
 There are not more than five musical notes, yet the combination of these five give rise to more melodies that can ever be heard.

2:15:06.200 --> 2:15:14.200
 There are not more than five primary colors, yet in combination they produce more hues than can ever be seen.

2:15:14.200 --> 2:15:25.200
 There are not more than five cardinal tastes, and yet combinations of them yield more flavors than can ever be tasted.

2:15:25.200 --> 2:15:29.200
 Thank you for listening, and hope to see you next time.

