WEBVTT

00:00.000 --> 00:02.640
 The following is a conversation with Chris Latner,

00:02.640 --> 00:04.640
 his second time in the podcast.

00:04.640 --> 00:06.600
 He's one of the most brilliant engineers

00:06.600 --> 00:08.760
 in modern computing, having created

00:08.760 --> 00:11.480
 LLVM compiler infrastructure project,

00:11.480 --> 00:14.640
 the Clang compiler, the Swift programming language,

00:14.640 --> 00:17.640
 a lot of key contributions to TensorFlow and TPUs

00:17.640 --> 00:19.040
 as part of Google.

00:19.040 --> 00:23.520
 He served as vice president of autopilot software at Tesla,

00:23.520 --> 00:26.200
 was a software innovator and leader at Apple,

00:26.200 --> 00:29.360
 and now is at SyFive as senior vice president

00:29.360 --> 00:30.920
 of platform engineering,

00:30.920 --> 00:33.520
 looking to revolutionize chip design

00:33.520 --> 00:36.600
 to make it faster, better, and cheaper.

00:36.600 --> 00:38.240
 Quick mention of each sponsor,

00:38.240 --> 00:40.960
 followed by some thoughts related to the episode.

00:40.960 --> 00:42.440
 First sponsor is Blinkist,

00:42.440 --> 00:45.440
 an app that summarizes key ideas from thousands of books.

00:45.440 --> 00:48.040
 I use it almost every day to learn new things

00:48.040 --> 00:52.320
 or to pick which books I want to read or listen to next.

00:52.320 --> 00:53.960
 Second is Neuro,

00:53.960 --> 00:56.520
 the maker of functional sugar free gum and mints

00:56.520 --> 00:58.560
 that I use to supercharge my mind

00:58.560 --> 01:01.640
 with caffeine, Althianine, and B vitamins.

01:01.640 --> 01:03.280
 Third is Masterclass,

01:03.280 --> 01:06.720
 online courses from the best people in the world

01:06.720 --> 01:09.280
 on each of the topics covered from rockets,

01:09.280 --> 01:13.960
 to game design, to poker, to writing, and to guitar.

01:13.960 --> 01:15.720
 And finally, Cash App,

01:15.720 --> 01:18.560
 the app I use to send money to friends for food,

01:18.560 --> 01:21.800
 drinks, and unfortunately lost bets.

01:21.800 --> 01:23.800
 Please check out the sponsors in the description

01:23.800 --> 01:27.360
 to get a discount and to support this podcast.

01:27.360 --> 01:29.360
 As a side note, let me say that Chris

01:29.360 --> 01:32.600
 has been an inspiration to me on a human level

01:32.600 --> 01:35.280
 because he is so damn good as an engineer

01:35.280 --> 01:38.640
 and leader of engineers and yet he's able to stay humble,

01:38.640 --> 01:41.080
 especially humble enough to hear the voices

01:41.080 --> 01:43.840
 of disagreement and to learn from them.

01:43.840 --> 01:46.120
 He was supportive of me and this podcast

01:46.120 --> 01:49.560
 from the early days and for that, I'm forever grateful.

01:49.560 --> 01:51.240
 To be honest, most of my life,

01:51.240 --> 01:53.960
 no one really believed that I would amount to much.

01:53.960 --> 01:56.560
 So when another human being looks at me,

01:56.560 --> 01:58.960
 it makes me feel like I might be someone special,

01:58.960 --> 02:00.880
 it can be truly inspiring.

02:00.880 --> 02:02.800
 That's a lesson for educators.

02:02.800 --> 02:05.680
 The weird kid in the corner with a dream

02:05.680 --> 02:08.200
 is someone who might need your love and support

02:08.200 --> 02:10.080
 in order for that dream to flourish.

02:10.960 --> 02:13.360
 If you enjoy this thing, subscribe on YouTube,

02:13.360 --> 02:15.520
 review it with five stars on Apple Podcast,

02:15.520 --> 02:18.000
 follow us on Spotify, support on Patreon,

02:18.000 --> 02:21.360
 or connect with me on Twitter at Lex Freedman.

02:21.360 --> 02:24.800
 And now, here's my conversation with Chris Latner.

02:24.800 --> 02:27.840
 What are the strongest qualities of Steve Jobs,

02:27.840 --> 02:31.840
 Elon Musk, and the great and powerful Jeff Dean

02:31.840 --> 02:34.840
 since you've gotten the chance to work with each?

02:34.840 --> 02:37.240
 You're starting with an easy question there.

02:37.240 --> 02:39.680
 These are three very different people.

02:39.680 --> 02:42.920
 I guess you could do maybe a pairwise comparison

02:42.920 --> 02:44.880
 between them instead of a group comparison.

02:44.880 --> 02:47.160
 So if you look at Steve Jobs and Elon,

02:47.160 --> 02:49.880
 I worked a lot more with Elon than I did with Steve.

02:49.880 --> 02:51.360
 They have a lot of commonality.

02:51.360 --> 02:54.000
 They're both visionary in their own way.

02:54.000 --> 02:56.200
 They're both very demanding in their own way.

02:57.400 --> 03:01.240
 My sense is Steve is much more human factor focused,

03:01.240 --> 03:03.440
 where Elon is more technology focused.

03:03.440 --> 03:04.800
 What does human factor mean?

03:04.800 --> 03:07.240
 Steve's trying to build things that feel good,

03:07.240 --> 03:10.400
 that people love, that affect people's lives, how they live.

03:10.400 --> 03:13.440
 He's looking into the future a little bit

03:13.440 --> 03:16.240
 in terms of what people want.

03:16.240 --> 03:18.680
 Where I think that Elon focuses more on

03:18.680 --> 03:20.400
 learning how exponentials work

03:20.400 --> 03:22.640
 and predicting the development of those.

03:22.640 --> 03:24.880
 Steve worked a lot of engineers.

03:24.880 --> 03:27.480
 That was one of the things that reading the biography

03:27.480 --> 03:32.080
 and how can a designer essentially talk to engineers

03:32.080 --> 03:33.880
 and get their respect?

03:33.880 --> 03:36.480
 I think so I did not work very closely with Steve.

03:36.480 --> 03:37.480
 I'm not an expert at all.

03:37.480 --> 03:40.480
 My sense is that he pushed people really hard,

03:40.480 --> 03:43.080
 but then when he got an explanation that made sense to him,

03:43.080 --> 03:44.640
 then he'd let go.

03:44.640 --> 03:48.440
 And he did actually have a lot of respect for engineering,

03:48.440 --> 03:50.440
 but he also knew when to push.

03:50.440 --> 03:52.840
 And when you can read people well,

03:52.840 --> 03:55.640
 you can know when they're holding back

03:55.640 --> 03:57.240
 and when you can get a little bit more out of them.

03:57.240 --> 03:59.640
 And I think he was very good at that.

03:59.640 --> 04:02.240
 I mean, if you compare the other folks,

04:02.240 --> 04:04.040
 so Jeff Dean, right?

04:04.040 --> 04:05.040
 Jeff Dean's an amazing guy.

04:05.040 --> 04:08.040
 He's super smart, as are the other guys.

04:09.240 --> 04:11.840
 Jeff is a really, really, really nice guy.

04:11.840 --> 04:14.040
 Well meaning, he's a classic Googler.

04:14.040 --> 04:16.640
 He wants people to be happy.

04:16.640 --> 04:18.440
 He combines it with brilliance

04:18.440 --> 04:21.440
 so he can pull people together in a really great way.

04:21.440 --> 04:23.440
 He's definitely not a CEO type.

04:23.440 --> 04:26.440
 I don't think he would even want to be that.

04:26.440 --> 04:28.440
 If he's still programs.

04:28.440 --> 04:29.440
 Oh yeah, he definitely programs.

04:29.440 --> 04:31.440
 Jeff is an amazing engineer today.

04:31.440 --> 04:33.440
 And that has never changed.

04:33.440 --> 04:37.440
 It's really hard to compare Jeff to either of those two.

04:37.440 --> 04:42.440
 I think that Jeff leads through technology

04:42.440 --> 04:43.440
 and building it himself

04:43.440 --> 04:45.440
 and then pulling people in and inspiring them.

04:45.440 --> 04:49.440
 And so I think that that's one of the amazing things about Jeff.

04:49.440 --> 04:52.440
 But each of these people, with their pros and cons,

04:52.440 --> 04:54.440
 all are really inspirational

04:54.440 --> 04:56.440
 and have achieved amazing things.

04:56.440 --> 05:00.440
 I've been very fortunate to get to work with these guys.

05:00.440 --> 05:03.440
 For yourself, you've led large teams,

05:03.440 --> 05:05.440
 you've done so many incredible,

05:05.440 --> 05:07.440
 difficult technical challenges.

05:07.440 --> 05:10.440
 Is there something you've picked up from them

05:10.440 --> 05:12.440
 about how to lead?

05:12.440 --> 05:14.440
 Yeah, I mean, I think leadership is really hard.

05:14.440 --> 05:16.440
 It really depends on what you're looking for there.

05:16.440 --> 05:19.440
 I think you really need to know what you're talking about.

05:19.440 --> 05:22.440
 So being grounded on the product, on the technology,

05:22.440 --> 05:26.440
 on the business, on the mission is really important.

05:26.440 --> 05:29.440
 Being understanding what people are looking for,

05:29.440 --> 05:30.440
 why they're there.

05:30.440 --> 05:32.440
 One of the most amazing things about Tesla is

05:32.440 --> 05:34.440
 the unifying vision.

05:34.440 --> 05:36.440
 People are there because they believe in clean energy

05:36.440 --> 05:41.440
 and electrification and all these kinds of things.

05:41.440 --> 05:44.440
 The other is to understand what really motivates people,

05:44.440 --> 05:45.440
 how to get the best people,

05:45.440 --> 05:48.440
 how to build a plan that actually can be executed.

05:48.440 --> 05:50.440
 There's so many different aspects of leadership

05:50.440 --> 05:54.440
 and it really depends on the time, the place, the problems.

05:54.440 --> 05:56.440
 There's a lot of issues that don't need to be solved

05:56.440 --> 05:59.440
 and so if you focus on the right things and prioritize well,

05:59.440 --> 06:01.440
 that can really help move things.

06:01.440 --> 06:03.440
 Two interesting things you mentioned.

06:03.440 --> 06:06.440
 One is you really have to know what you're talking about.

06:06.440 --> 06:11.440
 You've worked on a lot of very challenging technical things.

06:11.440 --> 06:17.440
 So I kind of assume you were born technically savvy,

06:17.440 --> 06:20.440
 but assuming that's not the case,

06:20.440 --> 06:24.440
 how did you develop technical expertise?

06:24.440 --> 06:28.440
 Even at Google, you worked on, I don't know, how many projects,

06:28.440 --> 06:31.440
 but really challenging, very varied.

06:31.440 --> 06:34.440
 Compilers, TPUs, hardware, cloud stuff,

06:34.440 --> 06:36.440
 a bunch of different things.

06:36.440 --> 06:39.440
 The thing that I've become more comfortable with

06:39.440 --> 06:45.440
 as I've gained experience is being okay with not knowing

06:45.440 --> 06:48.440
 and so a major part of leadership is actually,

06:48.440 --> 06:50.440
 it's not about having the right answer,

06:50.440 --> 06:52.440
 it's about getting the right answer

06:52.440 --> 06:55.440
 and so if you're working in a team of amazing people

06:55.440 --> 06:58.440
 and many of these places, many of these companies

06:58.440 --> 07:00.440
 all have amazing people,

07:00.440 --> 07:02.440
 it's the question of how do you get people together,

07:02.440 --> 07:05.440
 how do you build trust, how do you get people to open up,

07:05.440 --> 07:09.440
 how do you get people to be vulnerable sometimes

07:09.440 --> 07:11.440
 with an idea that maybe isn't good enough,

07:11.440 --> 07:13.440
 but it's the start of something beautiful,

07:13.440 --> 07:17.440
 how do you provide an environment where you're not just

07:17.440 --> 07:20.440
 like top down, don't do the thing that I tell you to do,

07:20.440 --> 07:23.440
 but you're encouraging people to be part of the solution

07:23.440 --> 07:27.440
 and providing a safe space where if you're not doing the right thing,

07:27.440 --> 07:29.440
 they're willing to tell you about it.

07:29.440 --> 07:31.440
 So you're asking dumb questions?

07:31.440 --> 07:33.440
 Yeah, dumb questions are my specialty.

07:33.440 --> 07:35.440
 So I've been in the harbor room recently

07:35.440 --> 07:38.440
 and I don't know much at all about how chips are designed,

07:38.440 --> 07:41.440
 I know a lot about using them, I know some of the principles

07:41.440 --> 07:43.440
 and the arse technical level of this,

07:43.440 --> 07:47.440
 but it turns out that if you ask a lot of dumb questions,

07:47.440 --> 07:49.440
 you get smarter really quick

07:49.440 --> 07:51.440
 and when you're surrounded by people that want to teach

07:51.440 --> 07:55.440
 and learn themselves, it can be a beautiful thing.

07:55.440 --> 07:58.440
 So let's talk about programming languages if it's okay.

07:58.440 --> 08:01.440
 At the highest absurd philosophical level.

08:01.440 --> 08:03.440
 Don't get romantic on me, Lex.

08:03.440 --> 08:07.440
 I will forever get romantic and torture you.

08:07.440 --> 08:09.440
 I apologize.

08:09.440 --> 08:13.440
 Why do programming languages even matter?

08:13.440 --> 08:15.440
 Okay, well, thank you very much.

08:15.440 --> 08:18.440
 So you're saying why should you care about any one programming language

08:18.440 --> 08:20.440
 or why do we care about programming computers?

08:20.440 --> 08:24.440
 No, why do we care about programming language design,

08:24.440 --> 08:29.440
 creating effective programming languages,

08:29.440 --> 08:32.440
 choosing a, you know, one programming languages

08:32.440 --> 08:34.440
 versus another programming language,

08:34.440 --> 08:37.440
 why we keep struggling and improving

08:37.440 --> 08:39.440
 through the evolution of these programming languages?

08:39.440 --> 08:40.440
 Sure, sure, sure.

08:40.440 --> 08:41.440
 Okay, so I mean, I think you have to come back

08:41.440 --> 08:43.440
 to what are we trying to do here, right?

08:43.440 --> 08:46.440
 So we have these beasts called computers

08:46.440 --> 08:48.440
 that are very good at specific kinds of things

08:48.440 --> 08:51.440
 and we think it's useful to have them do it for us, right?

08:51.440 --> 08:55.440
 Now, you have this question of how best to express that

08:55.440 --> 08:58.440
 because you have a human brain still that has an idea in its head

08:58.440 --> 09:00.440
 and you want to achieve something, right?

09:00.440 --> 09:03.440
 So, well, there's lots of ways of doing this.

09:03.440 --> 09:06.440
 You can go directly to the machine and speak assembly language

09:06.440 --> 09:09.440
 and then you can express directly what the computer understands.

09:09.440 --> 09:10.440
 That's fine.

09:10.440 --> 09:13.440
 You can then have higher and higher and higher levels of abstraction

09:13.440 --> 09:15.440
 up until machine learning

09:15.440 --> 09:17.440
 and you're designing a neural net to do the work for you.

09:17.440 --> 09:20.440
 The question is where along this way do you want to stop

09:20.440 --> 09:23.440
 and what benefits do you get out of doing so?

09:23.440 --> 09:25.440
 And so, programming languages in general, you have C,

09:25.440 --> 09:30.440
 you have Fortran and Java and Ada, Pascal, Swift,

09:30.440 --> 09:32.440
 you have lots of different things.

09:32.440 --> 09:34.440
 They all have different tradeoffs

09:34.440 --> 09:36.440
 and they're tackling different parts of the problems.

09:36.440 --> 09:39.440
 Now, one of the things that most programming languages do

09:39.440 --> 09:42.440
 is they're trying to make it so that you have pretty basic things

09:42.440 --> 09:44.440
 like portability across different hardware.

09:44.440 --> 09:47.440
 So you've got, I'm going to run on an Intel PC,

09:47.440 --> 09:51.440
 I'm going to run on a RISC 5 PC, I'm going to run on an ARM phone

09:51.440 --> 09:53.440
 or something like that, fine.

09:53.440 --> 09:55.440
 I want to write one program and have it portable

09:55.440 --> 09:57.440
 and this is something the assembly doesn't do.

09:57.440 --> 10:00.440
 Now, when you start looking at the space of programming languages,

10:00.440 --> 10:02.440
 this is where I think it's fun

10:02.440 --> 10:05.440
 because programming languages all have tradeoffs

10:05.440 --> 10:07.440
 and most people will walk up to them

10:07.440 --> 10:10.440
 and they look at the surface level of syntax

10:10.440 --> 10:13.440
 and say, oh, I like curly braces or I like tabs

10:13.440 --> 10:16.440
 or I like, you know, semicolons or not or whatever, right?

10:16.440 --> 10:20.440
 It's subjective, fairly subjective, very shallow things.

10:20.440 --> 10:22.440
 But programming languages, when done right,

10:22.440 --> 10:24.440
 can actually be very powerful

10:24.440 --> 10:29.440
 and the benefit they bring is expression.

10:29.440 --> 10:32.440
 Okay, and if you look at programming languages,

10:32.440 --> 10:34.440
 there's really kind of two different levels to them.

10:34.440 --> 10:37.440
 One is the down in the dirt, nuts and bolts,

10:37.440 --> 10:39.440
 how do you get the computer to be efficient, stuff like that,

10:39.440 --> 10:42.440
 how they work, type systems, compiler stuff, things like that.

10:42.440 --> 10:46.440
 The other is the UI and the UI for programming language

10:46.440 --> 10:48.440
 is really a design problem

10:48.440 --> 10:50.440
 and a lot of people don't think about it that way.

10:50.440 --> 10:53.440
 And the UI, you mean all that stuff with the braces and...

10:53.440 --> 10:55.440
 Yeah, all that stuff's the UI and what it is

10:55.440 --> 10:57.440
 and UI means user interface

10:57.440 --> 10:59.440
 and so what's really going on

10:59.440 --> 11:03.440
 is it's the interface between the guts and the human

11:03.440 --> 11:05.440
 and humans are hard, right?

11:05.440 --> 11:08.440
 Humans have feelings, they have things they like,

11:08.440 --> 11:10.440
 they have things they don't like

11:10.440 --> 11:13.440
 and a lot of people treat programming languages as though

11:13.440 --> 11:17.440
 humans are just kind of abstract creatures that cannot be predicted

11:17.440 --> 11:21.440
 but it turns out that actually there is better and worse.

11:21.440 --> 11:24.440
 People can tell when a programming language is good

11:24.440 --> 11:26.440
 or when it was an accident, right?

11:26.440 --> 11:29.440
 And one of the things with Swift in particular

11:29.440 --> 11:31.440
 is that a tremendous amount of time

11:31.440 --> 11:33.440
 by a tremendous number of people

11:33.440 --> 11:36.440
 have been put into really polishing and making it feel good

11:36.440 --> 11:39.440
 but it also has really good nuts and bolts underneath it.

11:39.440 --> 11:42.440
 You said that Swift makes a lot of people feel good.

11:42.440 --> 11:45.440
 How do you get to that point?

11:45.440 --> 11:51.440
 So how do you predict that tens of thousands,

11:51.440 --> 11:53.440
 hundreds of thousands of people are going to enjoy

11:53.440 --> 11:57.440
 using the user experience of this programming language?

11:57.440 --> 11:59.440
 Well, you can look at it in terms of better and worse, right?

11:59.440 --> 12:01.440
 So if you have to write lots of boilerplate

12:01.440 --> 12:03.440
 or something like that, you will feel unproductive

12:03.440 --> 12:05.440
 and so that's a bad thing.

12:05.440 --> 12:07.440
 You can look at it in terms of safety.

12:07.440 --> 12:10.440
 Safety, for example, is what's called a memory unsafe language

12:10.440 --> 12:13.440
 and so you get dangling pointers and you get all these kind of bugs

12:13.440 --> 12:15.440
 that then you have spent tons of time debugging

12:15.440 --> 12:18.440
 and it's a real pain in the butt and you feel unproductive

12:18.440 --> 12:20.440
 and so by subtracting these things from the experience

12:20.440 --> 12:23.440
 you get happier people.

12:23.440 --> 12:25.440
 But again, keep interrupting.

12:25.440 --> 12:27.440
 I'm sorry.

12:27.440 --> 12:29.440
 It's so hard to deal with.

12:29.440 --> 12:34.440
 If you look at the people that are most productive on Stack Overflow

12:34.440 --> 12:39.440
 they have a set of priorities that may not always correlate perfectly

12:39.440 --> 12:42.440
 with the experience of the majority of users.

12:42.440 --> 12:46.440
 If you look at the most upvoted, quote unquote,

12:46.440 --> 12:48.440
 correct answer on Stack Overflow,

12:48.440 --> 12:56.440
 it usually really prioritizes like safe code,

12:56.440 --> 13:01.440
 proper code, stable code, that kind of stuff

13:01.440 --> 13:06.440
 as opposed to if I want to use go to statements in my basic,

13:06.440 --> 13:09.440
 I want to use go to statements.

13:09.440 --> 13:12.440
 What if 99% of people want to use go to statements

13:12.440 --> 13:16.440
 or use completely improper unsafe syntax?

13:16.440 --> 13:17.440
 I don't think that people actually,

13:17.440 --> 13:19.440
 if you boil it down and you get below the surface level

13:19.440 --> 13:23.440
 people don't actually care about go tos or if statements or things like this.

13:23.440 --> 13:26.440
 They care about achieving a goal.

13:26.440 --> 13:29.440
 So the real question is I want to set up a web server

13:29.440 --> 13:32.440
 and I want to do a thing and whatever.

13:32.440 --> 13:34.440
 How quickly can I achieve that?

13:34.440 --> 13:36.440
 From a programming language perspective

13:36.440 --> 13:38.440
 there's really two things that matter there.

13:38.440 --> 13:41.440
 One is what libraries exist

13:41.440 --> 13:44.440
 and then how quickly can you put it together

13:44.440 --> 13:47.440
 and what are the tools around that look like?

13:47.440 --> 13:49.440
 And when you want to build a library that's missing,

13:49.440 --> 13:51.440
 what do you do?

13:51.440 --> 13:55.440
 This is where you see huge divergence in the force between worlds.

13:55.440 --> 13:57.440
 So you look at Python, for example.

13:57.440 --> 13:59.440
 Python is really good at assembling things

13:59.440 --> 14:02.440
 but it's not so great at building all the libraries.

14:02.440 --> 14:04.440
 And so you get, because of performance reasons,

14:04.440 --> 14:05.440
 other things like this,

14:05.440 --> 14:09.440
 is you get Python layered on top of C, for example.

14:09.440 --> 14:11.440
 And that means that doing certain kinds of things,

14:11.440 --> 14:13.440
 well, it doesn't really make sense to do in Python.

14:13.440 --> 14:15.440
 Instead you do it in C and then you wrap it

14:15.440 --> 14:17.440
 and then you have, you're living in two worlds

14:17.440 --> 14:19.440
 and two worlds never is really great

14:19.440 --> 14:21.440
 because tooling and the debugger doesn't work right

14:21.440 --> 14:23.440
 and like all these kinds of things.

14:23.440 --> 14:26.440
 Can you clarify a little bit what you mean by

14:26.440 --> 14:28.440
 Python is not good at building libraries,

14:28.440 --> 14:30.440
 meaning it doesn't make a conducive...

14:30.440 --> 14:31.440
 Certain kinds of libraries.

14:31.440 --> 14:34.440
 No, but it's just the actual meaning of the sentence.

14:34.440 --> 14:38.440
 Meaning like it's not conducive to developers

14:38.440 --> 14:40.440
 to come in and add libraries

14:40.440 --> 14:44.440
 or is it the duality of the...

14:44.440 --> 14:47.440
 it's a dance between Python and C and...

14:47.440 --> 14:49.440
 Well, so Python's amazing.

14:49.440 --> 14:50.440
 Python's a great language.

14:50.440 --> 14:53.440
 I do not mean to say that Python is bad for libraries.

14:53.440 --> 14:58.440
 What I meant to say is there are libraries that Python's really good at

14:58.440 --> 15:00.440
 that you can write in Python,

15:00.440 --> 15:03.440
 but there are other things like if you want to build a machine learning framework,

15:03.440 --> 15:05.440
 you're not going to build a machine learning framework in Python

15:05.440 --> 15:07.440
 because of performance, for example,

15:07.440 --> 15:10.440
 or you want GPU acceleration or things like this.

15:10.440 --> 15:15.440
 Instead what you do is you write a bunch of C or C++ code or something like that

15:15.440 --> 15:18.440
 and then you talk to it from Python.

15:18.440 --> 15:22.440
 And so this is because of decisions that were made in the Python design

15:22.440 --> 15:26.440
 and those decisions have other counterbalancing forces.

15:26.440 --> 15:30.440
 But the trick when you start looking at this from a programming language perspective

15:30.440 --> 15:32.440
 is you start to say, okay, cool,

15:32.440 --> 15:37.440
 how do I build this catalog of libraries that are really powerful?

15:37.440 --> 15:41.440
 And how do I make it so that then they can be assembled into ways that feel good

15:41.440 --> 15:43.440
 and they generally work the first time?

15:43.440 --> 15:46.440
 Because when you're talking about building a thing,

15:46.440 --> 15:50.440
 you have to include the debugging, the fixing, the turnaround cycle,

15:50.440 --> 15:55.440
 the development cycle, all that kind of stuff into the process of building the thing.

15:55.440 --> 15:57.440
 It's not just about pounding out the code.

15:57.440 --> 16:03.440
 And so this is where things like catching bugs at compile time is valuable, for example.

16:03.440 --> 16:07.440
 But if you dive into the details in this,

16:07.440 --> 16:10.440
 Swift, for example, has certain things like value semantics,

16:10.440 --> 16:17.440
 which is this fancy way of saying that when you treat a variable like a value,

16:17.440 --> 16:21.440
 it acts like a mathematical object would.

16:21.440 --> 16:24.440
 So you have used PyTorch a little bit.

16:24.440 --> 16:26.440
 In PyTorch, you have tensors.

16:26.440 --> 16:31.440
 Tensors are n dimensional grid of numbers, very simple.

16:31.440 --> 16:34.440
 You can do plus and other operators on them.

16:34.440 --> 16:35.440
 It's all totally fine.

16:35.440 --> 16:38.440
 But why do you need to clone a tensor sometimes?

16:38.440 --> 16:40.440
 Have you ever run into that?

16:40.440 --> 16:41.440
 Yeah.

16:41.440 --> 16:42.440
 Okay.

16:42.440 --> 16:43.440
 And so why is that?

16:43.440 --> 16:44.440
 Why do you need to clone a tensor?

16:44.440 --> 16:46.440
 It's the usual object thing that's in Python.

16:46.440 --> 16:47.440
 Yeah.

16:47.440 --> 16:50.440
 So in Python, and just like with Java and many other languages,

16:50.440 --> 16:51.440
 this isn't unique to Python.

16:51.440 --> 16:53.440
 In Python, it has a thing called reference semantics,

16:53.440 --> 16:55.440
 which is the nerdy way of explaining this.

16:55.440 --> 17:00.440
 And what that means is you actually have a pointer do a thing instead of the thing.

17:00.440 --> 17:01.440
 Okay.

17:01.440 --> 17:06.440
 Now, this is due to a bunch of implementation details that you don't want to go into.

17:06.440 --> 17:09.440
 But in Swift, you have this thing called value semantics.

17:09.440 --> 17:12.440
 And so when you have a tensor in Swift, it is a value.

17:12.440 --> 17:15.440
 If you copy it, it looks like you have a unique copy.

17:15.440 --> 17:19.440
 If you change one of those copies, then it doesn't update the other one because you

17:19.440 --> 17:21.440
 just made a copy of this thing.

17:21.440 --> 17:28.440
 So that's like highly error prone in at least computer science math centric disciplines

17:28.440 --> 17:30.440
 about Python.

17:30.440 --> 17:34.440
 That like the thing you would expect to behave.

17:34.440 --> 17:35.440
 Like math.

17:35.440 --> 17:36.440
 Like math.

17:36.440 --> 17:38.440
 It doesn't behave like math.

17:38.440 --> 17:43.440
 And in fact, quietly it doesn't behave like math and then can ruin the entirety of your

17:43.440 --> 17:44.440
 math.

17:44.440 --> 17:46.440
 It puts you in debugging land again.

17:46.440 --> 17:49.440
 Now, you just want to get something done and you're like, wait a second.

17:49.440 --> 17:51.440
 Where do I need to put clone?

17:51.440 --> 17:55.440
 And what level of the stack, which is very complicated, which I thought I was reusing

17:55.440 --> 17:59.440
 somebody's library and now I need to understand it to know where to clone a thing.

17:59.440 --> 18:01.440
 And hard to debug, by the way.

18:01.440 --> 18:02.440
 Exactly.

18:02.440 --> 18:04.440
 And so this is where programming languages really matter.

18:04.440 --> 18:10.440
 And so in Swift, having value semantics so that both you get the benefit of math working

18:10.440 --> 18:11.440
 like math.

18:11.440 --> 18:16.440
 Right, but also the efficiency that comes with certain advantages there, certain implementation

18:16.440 --> 18:18.440
 details there really benefit you as a programmer.

18:18.440 --> 18:19.440
 Right.

18:19.440 --> 18:20.440
 And clarify the values.

18:20.440 --> 18:21.440
 Manics.

18:21.440 --> 18:23.440
 Like how do you know that a thing should be treated like a value?

18:23.440 --> 18:24.440
 Yeah.

18:24.440 --> 18:30.440
 So, so Swift has a pretty strong culture and good language support for defining values.

18:30.440 --> 18:31.440
 And so if you have an array.

18:31.440 --> 18:36.440
 So tensors are one example that the machine learning folks are very used to.

18:36.440 --> 18:37.440
 Just think about arrays.

18:37.440 --> 18:39.440
 Same thing where you have an array.

18:39.440 --> 18:44.440
 You put, you create an array, you put two or three or four things into it, and then you

18:44.440 --> 18:46.440
 pass it off to another function.

18:46.440 --> 18:51.440
 What happens if that function adds some more things to it?

18:51.440 --> 18:54.440
 Well, you'll see it on the side that you pass it in, right?

18:54.440 --> 18:56.440
 This is called reference semantics.

18:56.440 --> 19:01.440
 Now, what if you pass an array off to a function?

19:01.440 --> 19:04.440
 It scrolls it away in some dictionary or some other data structure somewhere.

19:04.440 --> 19:05.440
 Right.

19:05.440 --> 19:07.440
 Well, it thought that you just handed it that array.

19:07.440 --> 19:12.440
 But then you return back and that reference to that array still exists in the caller.

19:12.440 --> 19:14.440
 And they go and put more stuff in it.

19:14.440 --> 19:15.440
 Right.

19:15.440 --> 19:20.440
 The person you handed it off to may have thought they had the only reference to that.

19:20.440 --> 19:23.440
 And so they didn't know what they, that this was going to change underneath the covers.

19:23.440 --> 19:26.440
 And so this is where you end up having to do clone.

19:26.440 --> 19:27.440
 So like, I was passed a thing.

19:27.440 --> 19:30.440
 I'm not sure if I have the only version of it.

19:30.440 --> 19:32.440
 So now I have to clone it.

19:32.440 --> 19:38.440
 So what value semantics does is it allows you to say, hey, I have a, so in Swift, it defaults to value semantics.

19:38.440 --> 19:40.440
 Also defaults to value semantics.

19:40.440 --> 19:46.440
 And then because most things should end up being like this, then it makes sense for that to be the default.

19:46.440 --> 19:53.440
 And one of the important things about that is that arrays and dictionaries and all these other collections that are aggregations of other things also have value semantics.

19:53.440 --> 19:59.440
 And so when you pass this around to different parts of your program, you don't have to do these defensive copies.

19:59.440 --> 20:01.440
 And so this is, this is great for two sides.

20:01.440 --> 20:08.440
 It's great because you define away the bug, which is a big deal for productivity than the number one thing most people care about.

20:08.440 --> 20:13.440
 But it's also good for performance because when you're doing a clone, so you pass the array down to the thing.

20:13.440 --> 20:15.440
 It was like, I don't know if anybody else has it.

20:15.440 --> 20:16.440
 I have to clone it.

20:16.440 --> 20:18.440
 Well, you just did a copy of a bunch of data.

20:18.440 --> 20:19.440
 It could be big.

20:19.440 --> 20:23.440
 And then it could be the thing that called you is not keeping track of the old thing.

20:23.440 --> 20:27.440
 So you just made a copy of it and you may not have had to.

20:27.440 --> 20:36.440
 And so the way the value semantics work is in Swift is that it uses this thing called copy on right, which means that you get, you get the benefit of safety and performance.

20:36.440 --> 20:43.440
 And it has another special trick because if you think certain languages like Java, for example, they have immutable strings.

20:43.440 --> 20:48.440
 And so what they're trying to do is they provide value semantics by having pure immutability.

20:48.440 --> 20:55.440
 Functional languages have pure immutability in lots of different places and this provides a much safer model and it provides value semantics.

20:55.440 --> 20:59.440
 The problem with this is if you have immutability, everything is expensive.

20:59.440 --> 21:01.440
 Everything requires a copy.

21:01.440 --> 21:11.440
 For example, in Java, if you have a string X and a string Y, you append them together, we have to allocate a new string to hold X, Y.

21:11.440 --> 21:13.440
 Oh, if they're immutable.

21:13.440 --> 21:16.440
 Well, and strings and Java are immutable.

21:16.440 --> 21:24.440
 And if there's there's optimizations for short runs and it's complicated, but but generally think about them as a separate allocation.

21:24.440 --> 21:31.440
 And so when you append them together, you have to go allocate a third thing because somebody might have a point or two either of the other ones, right?

21:31.440 --> 21:32.440
 And you can't go change them.

21:32.440 --> 21:37.440
 So you have to go allocate a third thing because of the beauty of how the Swift value semantics system works out.

21:37.440 --> 21:40.440
 If you have a string in Swift, you say, hey, put in X, right?

21:40.440 --> 21:43.440
 And they say, append on YZW.

21:43.440 --> 21:49.440
 It knows that there's only one reference to that and so can do an in place update.

21:49.440 --> 21:55.440
 And so you're not allocating tons of stuff on the side, you're not you don't have all this problems when you pass it off.

21:55.440 --> 21:57.440
 You can know you have the only reference.

21:57.440 --> 22:02.440
 If you pass it off to multiple different people, but nobody changes it, they can all share the same thing.

22:02.440 --> 22:05.440
 So you get a lot of the benefit of purely immutable design.

22:05.440 --> 22:09.440
 And so you get a really nice sweet spot that I haven't seen in other languages.

22:09.440 --> 22:10.440
 Yeah, that's interesting.

22:10.440 --> 22:19.440
 I thought I thought there was going to be a philosophical like narrative here that you're going to have to pay a cost for it.

22:19.440 --> 22:35.440
 Because it sounds like I think value semantics is beneficial for easing of debugging or minimizing the risk of errors, like bringing the errors closer to the source.

22:35.440 --> 22:40.440
 Bringing the symptom of the air closer to the source of the air, however you say that.

22:40.440 --> 22:46.440
 But you're saying there's not a performance cost either if you implement correctly.

22:46.440 --> 22:48.440
 Well, so there's tradeoffs with everything.

22:48.440 --> 22:53.440
 And so if you are doing very low level stuff, then sometimes you can notice cost.

22:53.440 --> 22:56.440
 But then what you're doing is you're saying, what is the right default?

22:56.440 --> 23:04.440
 So coming back to user interface, when you talk about programming languages, one of the major things that Swift does that makes people love it.

23:04.440 --> 23:13.440
 That is not obvious when it comes to designing a language is this UI principle of progressive disclosure of complexity.

23:13.440 --> 23:16.440
 So Swift, like many languages, is very powerful.

23:16.440 --> 23:20.440
 The question is, when do you have to learn the power as a user?

23:20.440 --> 23:24.440
 So Swift, like Python, allows you to start with like print hello world, right?

23:24.440 --> 23:31.440
 Certain other languages start with like public static void main class, like all the ceremony, right?

23:31.440 --> 23:34.440
 And so you go to teach a new person.

23:34.440 --> 23:36.440
 Hey, welcome to this new thing.

23:36.440 --> 23:40.440
 Let's talk about public access control classes.

23:40.440 --> 23:41.440
 What's that?

23:41.440 --> 23:43.440
 String system.out.println.

23:43.440 --> 23:45.440
 Like packages.

23:45.440 --> 23:46.440
 Right.

23:46.440 --> 23:51.440
 And so instead, if you take this and you say, hey, we need packages, you know, modules.

23:51.440 --> 23:54.440
 We need powerful things like classes.

23:54.440 --> 23:55.440
 We need data structures.

23:55.440 --> 23:57.440
 We need like all these things.

23:57.440 --> 24:09.440
 The question is, how do you factor the complexity and how do you make it so that the normal case scenario is you're dealing with things that work the right way and the right way and give you good performance by default.

24:09.440 --> 24:16.440
 But then as a power user, if you want to dive down to it, you have full cc performance, full control over low level pointers.

24:16.440 --> 24:18.440
 You can call malloc if you want to call malloc.

24:18.440 --> 24:23.440
 This is not recommended on the first page of every tutorial, but it's actually really important when you want to get work done.

24:23.440 --> 24:28.440
 Right. And so being able to have that is really the design and program language design.

24:28.440 --> 24:31.440
 And design is really, really hard.

24:31.440 --> 24:39.440
 It's something that I think a lot of people kind of outside of UI, again, a lot of people just think is subjective.

24:39.440 --> 24:43.440
 Like there's nothing, you know, it's just like curly braces or whatever.

24:43.440 --> 24:45.440
 It's just like somebody's preference.

24:45.440 --> 24:48.440
 But actually good design is something that you can feel.

24:48.440 --> 24:51.440
 And how many people are involved with good design?

24:51.440 --> 24:59.440
 So if we look at Swift, but look at historically, I mean, this might touch like, it's almost like a Steve Jobs question too.

24:59.440 --> 25:07.440
 Like how much dictatorial decision making is required versus collaborative.

25:07.440 --> 25:11.440
 And we'll talk about how all that can go wrong or right.

25:11.440 --> 25:12.440
 Yeah, we'll Swift.

25:12.440 --> 25:15.440
 So I can't speak to in general all designed everywhere.

25:15.440 --> 25:19.440
 So the way it works with Swift is that there's a core team.

25:19.440 --> 25:26.440
 And so core team is six or seven people ish something like that that is people that have been working with Swift since very early days.

25:26.440 --> 25:29.440
 And so by early days is not that long ago.

25:29.440 --> 25:30.440
 Okay. Yeah.

25:30.440 --> 25:33.440
 So it's it became public in 2014.

25:33.440 --> 25:35.440
 So it's been six years public now.

25:35.440 --> 25:39.440
 But but so that's enough time that there's a story there.

25:39.440 --> 25:43.440
 And there's mistakes have been made that then get fixed and you learn something.

25:43.440 --> 25:48.440
 And then you, you know, and so what the core team does is it provides continuity.

25:48.440 --> 25:53.440
 And so you want to have a, okay, well, there's a big hole that we want to fill.

25:53.440 --> 25:55.440
 We know we want to fill it.

25:55.440 --> 25:59.440
 So don't do other things that invade that space until we fill the hole, right?

25:59.440 --> 26:01.440
 There, there's a boulder that's missing here.

26:01.440 --> 26:04.440
 We want to, we will do that boulder, even though it's not today.

26:04.440 --> 26:06.440
 Keep, keep out of that space.

26:06.440 --> 26:11.440
 And the whole team remembers of the, remembers the myth of the boulder that's there.

26:11.440 --> 26:12.440
 Yeah. Yeah.

26:12.440 --> 26:16.440
 There's a general sense of what the future looks like in broad strokes and a shared understanding of that.

26:16.440 --> 26:21.440
 Combined with the shared understanding of what has happened in the past that worked out well and didn't work out well.

26:21.440 --> 26:25.440
 The next level out is you have the, what's called the swift evolution community.

26:25.440 --> 26:30.440
 And you've got in that case, hundreds of people that really care passionately about the ways swift evolves.

26:30.440 --> 26:36.440
 And that's like an amazing thing to again, the core team doesn't necessarily need to come up with all the good ideas.

26:36.440 --> 26:40.440
 You got hundreds of people out there that care about something and they come up with really good ideas too.

26:40.440 --> 26:44.440
 And that provides this like tumbling rock tumbler for ideas.

26:44.440 --> 26:49.440
 And so the, the evolution process is, you know, a lot of people in a discourse forum,

26:49.440 --> 26:53.440
 they're like hatching it out and trying to like talk about, okay, well, should we go left or right?

26:53.440 --> 26:55.440
 Or if we did this, what would be good?

26:55.440 --> 26:57.440
 And, you know, here you're talking about hundreds of people.

26:57.440 --> 26:59.440
 So you're not going to get consensus necessarily.

26:59.440 --> 27:01.440
 They're not obvious consensus.

27:01.440 --> 27:08.440
 And so there's a proposal process that then allows the core team and the community to work this out.

27:08.440 --> 27:14.440
 And what the core team does is it aims to get consensus out of the community and provide guardrails,

27:14.440 --> 27:20.440
 but also provide long term, make sure we're going the right direction kind of things.

27:20.440 --> 27:27.440
 So does that group represent like the, how much people will love the user interface?

27:27.440 --> 27:29.440
 Like, do you think they're able to capture that?

27:29.440 --> 27:31.440
 Well, I mean, it's something we talk about a lot.

27:31.440 --> 27:32.440
 It's something we care about.

27:32.440 --> 27:34.440
 How will we, how will we do that for debate?

27:34.440 --> 27:36.440
 But I think that we've done pretty well so far.

27:36.440 --> 27:38.440
 Is the beginner in mind?

27:38.440 --> 27:40.440
 Because you said the progressive disclosure.

27:40.440 --> 27:41.440
 Yeah.

27:41.440 --> 27:46.440
 So we care a lot about, a lot about that, a lot about power, a lot about efficiency,

27:46.440 --> 27:48.440
 a lot about there are many factors to good design.

27:48.440 --> 27:53.440
 And you have to figure out a way to kind of work your way through that.

27:53.440 --> 27:57.440
 So if you like think about like the language I love is Lisp,

27:57.440 --> 27:59.440
 probably still because I use Emacs,

27:59.440 --> 28:02.440
 but I haven't done anything any serious working lists,

28:02.440 --> 28:05.440
 but it has a ridiculous amount of parentheses.

28:05.440 --> 28:14.440
 I've also, you know, with Java and C++, the braces, you know,

28:14.440 --> 28:20.440
 I like, I enjoyed the comfort of being between braces, you know,

28:20.440 --> 28:23.440
 and then Python is really sorry to interrupt, just like,

28:23.440 --> 28:28.440
 and last thing to me as a designer, if I was a language designer, God forbid,

28:28.440 --> 28:36.440
 as I would be very surprised that Python with no braces would nevertheless somehow

28:36.440 --> 28:38.440
 be comforting also.

28:38.440 --> 28:40.440
 So like, I can see arguments for all of these.

28:40.440 --> 28:41.440
 But look at this.

28:41.440 --> 28:44.440
 This is evidence that it's not about braces versus tabs.

28:44.440 --> 28:45.440
 Right.

28:45.440 --> 28:46.440
 Exactly.

28:46.440 --> 28:47.440
 You're good.

28:47.440 --> 28:48.440
 It's a good point.

28:48.440 --> 28:49.440
 Right.

28:49.440 --> 28:50.440
 So like, you know, there's, there's evidence.

28:50.440 --> 28:52.440
 But see, like it's one of the most argued about things.

28:52.440 --> 28:53.440
 Oh yeah, of course.

28:53.440 --> 28:55.440
 Just like tabs and spaces, which it doesn't, I mean,

28:55.440 --> 28:59.440
 there's one obvious right answer, but it doesn't, it doesn't actually matter.

28:59.440 --> 29:00.440
 What's that?

29:00.440 --> 29:01.440
 Come on, friends.

29:01.440 --> 29:02.440
 Like, come on.

29:02.440 --> 29:03.440
 What are you trying to do to me here?

29:03.440 --> 29:05.440
 People are going to, yeah, half the people are going to tune out.

29:05.440 --> 29:06.440
 Yeah.

29:06.440 --> 29:11.440
 So, so these two, you're able to identify things that don't really matter for the

29:11.440 --> 29:12.440
 experience.

29:12.440 --> 29:16.440
 Well, no, no, it's always a really hard, so the easy decisions are easy.

29:16.440 --> 29:17.440
 Right.

29:17.440 --> 29:19.440
 I mean, you can find those are not the interesting ones.

29:19.440 --> 29:21.440
 The hard ones are the ones that are most interesting.

29:21.440 --> 29:22.440
 Right.

29:22.440 --> 29:25.440
 So there's a lot of places where, Hey, we want to do a thing.

29:25.440 --> 29:27.440
 Everybody agrees we should do it.

29:27.440 --> 29:31.440
 There's one proposal on the table, but it has all these bad things associated with

29:31.440 --> 29:32.440
 it.

29:32.440 --> 29:34.440
 Well, okay, what are we going to do about that?

29:34.440 --> 29:35.440
 Do we just take it?

29:35.440 --> 29:36.440
 Do we delay it?

29:36.440 --> 29:39.440
 Do we say, Hey, well, maybe there's this other feature that if we do that first,

29:39.440 --> 29:41.440
 this will work out better.

29:41.440 --> 29:45.440
 How does this, if we do this, are we paying ourselves into a corner?

29:45.440 --> 29:46.440
 Right.

29:46.440 --> 29:50.440
 And so this is where, again, you're having that core team of people that has some

29:50.440 --> 29:54.440
 opportunity and has perspective, has some of the historical understanding is really

29:54.440 --> 29:58.440
 valuable because you get, it's not just like one brain, you get the power of multiple

29:58.440 --> 30:02.440
 people coming together to make good decisions and then you get the best out of all these

30:02.440 --> 30:03.440
 people.

30:03.440 --> 30:06.440
 And you also can harness the community around it.

30:06.440 --> 30:12.440
 What about like the decision of whether like in Python, having one type or having,

30:12.440 --> 30:14.440
 you know, strict typing?

30:14.440 --> 30:15.440
 Yeah, okay.

30:15.440 --> 30:16.440
 Yeah, let's talk about this.

30:16.440 --> 30:19.440
 So I like how you put that, by the way.

30:19.440 --> 30:21.440
 So many people would say that Python doesn't have types.

30:21.440 --> 30:22.440
 Doesn't have types.

30:22.440 --> 30:23.440
 Yeah.

30:23.440 --> 30:24.440
 But you're right.

30:24.440 --> 30:29.440
 I've listened to you enough to where I'm a fan of yours and I've listened to way too

30:29.440 --> 30:32.440
 many podcasts and videos of you talking about this.

30:32.440 --> 30:33.440
 Oh yeah.

30:33.440 --> 30:35.440
 So I would argue that Python has one type.

30:35.440 --> 30:39.440
 And so, so like when you import Python and Swift, which by the way works really well,

30:39.440 --> 30:42.440
 you have everything comes in as a Python object.

30:42.440 --> 30:47.440
 Now here they're trade offs because, you know, it depends on where you're optimizing for

30:47.440 --> 30:50.440
 and Python is a super successful language for a really good reason.

30:50.440 --> 30:55.440
 Because it has one type, you get duck typing for free and things like this.

30:55.440 --> 31:00.440
 But also you're pushing, you're making it very easy to pound out code on one hand, but

31:00.440 --> 31:04.440
 you're also making it very easy to introduce complicated bugs.

31:04.440 --> 31:08.440
 You have to debug and you pass the string into something that expects an integer and

31:08.440 --> 31:10.440
 it doesn't immediately die.

31:10.440 --> 31:13.440
 It goes all the way down the stack trace and you find yourself in the middle of some code

31:13.440 --> 31:16.440
 that you really didn't want to know anything about and it blows up and you're just saying,

31:16.440 --> 31:17.440
 well, what did I do wrong?

31:17.440 --> 31:18.440
 Right.

31:18.440 --> 31:22.440
 And so types are good and bad and they have trade offs are good for performance and certain

31:22.440 --> 31:26.440
 other things, depending on where you're coming from, but it's all about trade offs.

31:26.440 --> 31:28.440
 And so this is, this is what design is, right?

31:28.440 --> 31:33.440
 Design is about weighing trade offs and trying to understand the ramifications of the things

31:33.440 --> 31:38.440
 that you're weighing, like types or not, or one type or many types.

31:38.440 --> 31:42.440
 But also within many types, how powerful do you make that type system is another very

31:42.440 --> 31:46.440
 complicated question with lots of trade offs.

31:46.440 --> 31:51.440
 It's very interesting, by the way, but, but that's like one, one dimension.

31:51.440 --> 31:55.440
 And there's a bunch of other dimensions, JIT compiled versus static compiled garbage

31:55.440 --> 32:00.440
 collected versus reference counted versus memory, manual memory management versus, you

32:00.440 --> 32:04.440
 know, like in like all these different trade offs and how you balance them or what make

32:04.440 --> 32:05.440
 the program language good.

32:05.440 --> 32:06.440
 Good currency.

32:06.440 --> 32:07.440
 Yep.

32:07.440 --> 32:11.440
 So in all those things, I guess when you're designing the language, you also have to

32:11.440 --> 32:14.440
 think of how that's going to get all compiled down to.

32:14.440 --> 32:16.440
 If you care about performance.

32:16.440 --> 32:17.440
 Yeah.

32:17.440 --> 32:18.440
 Well, and go back to list, right?

32:18.440 --> 32:23.440
 So list also, I would say JavaScript is another example of a very simple language, right?

32:23.440 --> 32:26.440
 And so one of the, so I also love Lisp.

32:26.440 --> 32:29.440
 I don't use it as much as maybe you do or you did.

32:29.440 --> 32:32.440
 No, I think we're both everyone who loves Lisp.

32:32.440 --> 32:37.440
 It's like, you love, it's like, I don't know, I love Frank Sinatra, but like how often do

32:37.440 --> 32:39.440
 I seriously listen to Frank Sinatra?

32:39.440 --> 32:40.440
 Sure.

32:40.440 --> 32:44.440
 But, but, but you look at that or you look at JavaScript, which is another very different,

32:44.440 --> 32:46.440
 but relatively simple language.

32:46.440 --> 32:50.440
 And there's certain things that don't exist in the language, but there's, there is inherent

32:50.440 --> 32:52.440
 complexity to the problems that we're trying to model.

32:52.440 --> 32:54.440
 And so what happens to the complexity?

32:54.440 --> 32:59.440
 In the case of both of them, for example, you say, well, what about large scale software

32:59.440 --> 33:00.440
 development?

33:00.440 --> 33:01.440
 Okay.

33:01.440 --> 33:02.440
 Well, you need something like packages.

33:02.440 --> 33:05.440
 Neither language has a like language affordance for packages.

33:05.440 --> 33:07.440
 And so what you get is patterns.

33:07.440 --> 33:08.440
 You get things like NPN.

33:08.440 --> 33:12.440
 You get things like, you know, like these ecosystems that get built around.

33:12.440 --> 33:17.440
 And I'm a believer that if you don't model at least the most important inherent complexity

33:17.440 --> 33:22.440
 in the language, then what ends up happening is that complexity gets pushed elsewhere.

33:22.440 --> 33:26.440
 And when it gets pushed elsewhere, sometimes that's great because often building things

33:26.440 --> 33:30.440
 as libraries is very flexible and very powerful and allows you to evolve and things like that.

33:30.440 --> 33:35.440
 But often it leads to a lot of unnecessary divergence in the force and fragmentation.

33:35.440 --> 33:39.440
 And, and when that happens, you just get kind of a mess.

33:39.440 --> 33:42.440
 And so the question is, how do you, how do you balance that?

33:42.440 --> 33:45.440
 Don't put too much stuff in the language because that's really expensive and makes

33:45.440 --> 33:46.440
 things complicated.

33:46.440 --> 33:51.440
 But how do you model enough of the inherent complexity of the problem that you provide

33:51.440 --> 33:54.440
 the framework and the structure for people to think about?

33:54.440 --> 33:59.440
 Well, so, so the, the, the key thing to think about with, with programming languages and

33:59.440 --> 34:03.440
 you think about what a programming language is there for is it's about making a human

34:03.440 --> 34:04.440
 more productive.

34:04.440 --> 34:09.440
 So like there's an old, I think it's Steve Jobs quote about it's a bicycle for the mind.

34:09.440 --> 34:10.440
 Right.

34:10.440 --> 34:16.440
 You can, you can, you can definitely walk, but you'll get there a lot faster if you can

34:16.440 --> 34:17.440
 bicycle on your way.

34:17.440 --> 34:20.440
 And a programming language is a bicycle for the mind.

34:20.440 --> 34:21.440
 Yeah.

34:21.440 --> 34:22.440
 Basically.

34:22.440 --> 34:23.440
 Wow.

34:23.440 --> 34:24.440
 That's a really interesting way to think about it.

34:24.440 --> 34:27.440
 By, by raising the level of abstraction now, you can fit more things in your head.

34:27.440 --> 34:33.440
 By being able to just directly leverage somebody's library, you can now get something done quickly.

34:33.440 --> 34:37.440
 In the case of Swift, Swift UI is this new framework that Apple has released recently

34:37.440 --> 34:39.440
 for doing UI programming.

34:39.440 --> 34:45.440
 And it has this declarative programming model, which defines away entire classes of bugs.

34:45.440 --> 34:48.440
 It's made, it builds on value semantics and many other nice Swift things.

34:48.440 --> 34:53.440
 And what this does is allows you to just get way more done with way less code.

34:53.440 --> 34:56.440
 And now your productivity as a developer is much higher.

34:56.440 --> 34:57.440
 Right.

34:57.440 --> 35:00.440
 And so that, that's really what programming languages should be about is it's not about

35:00.440 --> 35:02.440
 tabs versus spaces or curly braces or whatever.

35:02.440 --> 35:05.440
 It's about how productive do you make the person.

35:05.440 --> 35:11.440
 And you can only see that when you have libraries that were built with the right intention that

35:11.440 --> 35:13.440
 the language was designed for.

35:13.440 --> 35:16.440
 And with Swift, I think we're still a little bit early.

35:16.440 --> 35:20.440
 But Swift UI and many other things that are coming out now are really showing that.

35:20.440 --> 35:22.440
 And I think that they're opening people's eyes.

35:22.440 --> 35:29.440
 It's kind of interesting to think about like how that, you know, the knowledge of something,

35:29.440 --> 35:33.440
 of how good the bicycle is, how people learn about that.

35:33.440 --> 35:35.440
 You know, so I've used C++.

35:35.440 --> 35:41.440
 Now this is not going to be a trash talking session about C++, but use C++ for a really

35:41.440 --> 35:42.440
 long time.

35:42.440 --> 35:43.440
 I think you're there if you want.

35:43.440 --> 35:45.440
 I have the scars.

35:45.440 --> 35:52.440
 I feel like I spent many years without realizing like there's languages that could, for my

35:52.440 --> 35:58.440
 particular life style, brain style, thinking style, there's languages that could make me

35:58.440 --> 36:04.440
 more productive in the debugging stage, in the just the development stage and thinking

36:04.440 --> 36:07.440
 like the bicycle for the mind that I could fit more stuff into my.

36:07.440 --> 36:09.440
 Python's a great example of that, right?

36:09.440 --> 36:12.440
 I mean, a machine learning framework in Python is a great example of that.

36:12.440 --> 36:14.440
 It's just very high abstraction level.

36:14.440 --> 36:18.440
 And so you can be thinking about things on a like very high level algorithmic level.

36:18.440 --> 36:22.440
 Instead of thinking about, okay, well, am I copying this tensor to a GPU or not?

36:22.440 --> 36:23.440
 Right?

36:23.440 --> 36:25.440
 It's not, it's not what you want to be thinking about.

36:25.440 --> 36:30.440
 And as I was telling you, I mean, I guess the question I had is, you know, how does a

36:30.440 --> 36:36.440
 person like me or in general people discover more productive, you know, languages?

36:36.440 --> 36:41.440
 Like how I was, as I've been telling you offline, I've been looking for like a project

36:41.440 --> 36:45.440
 to work on in Swift so I can really try it out.

36:45.440 --> 36:51.440
 I mean, my intuition was like doing a Hello World is not going to get me there to get

36:51.440 --> 36:53.440
 me to experience the power of language.

36:53.440 --> 36:55.440
 You need a few weeks to change your metabolism.

36:55.440 --> 36:56.440
 Exactly.

36:56.440 --> 36:59.440
 I think that's beautifully put.

36:59.440 --> 37:01.440
 That's one of the problems with people with diets.

37:01.440 --> 37:07.440
 Like I'm actually currently to go in parallel, but in a small tangent is I've been recently

37:07.440 --> 37:09.440
 eating only meat.

37:09.440 --> 37:10.440
 Okay.

37:10.440 --> 37:11.440
 And okay.

37:11.440 --> 37:16.440
 So most people are like, I think that's horribly unhealthy or whatever.

37:16.440 --> 37:22.440
 You have like a million, whatever the science is, it just doesn't sound right.

37:22.440 --> 37:25.440
 Well, so back when I was in college, we did the Atkins diet.

37:25.440 --> 37:26.440
 That was, that was a thing.

37:26.440 --> 37:27.440
 And similar.

37:27.440 --> 37:30.440
 And but if you, you have to always give these things a chance.

37:30.440 --> 37:35.440
 I mean, I was dieting, I was not dieting, but it's just the things that you like.

37:35.440 --> 37:41.440
 If I eat personally, if I eat meat, just everything, I could be super focused or more focused than

37:41.440 --> 37:42.440
 usual.

37:42.440 --> 37:44.440
 I just feel great.

37:44.440 --> 37:47.440
 I've been running a lot of, you know, doing pushups and posts and so on.

37:47.440 --> 37:50.440
 And you Python is similar in that sense for me.

37:50.440 --> 37:53.440
 Where are you going with this?

37:53.440 --> 37:59.440
 I mean, literally, I just felt ahead like a stupid smile on my face when I first started

37:59.440 --> 38:00.440
 using Python.

38:00.440 --> 38:03.440
 I could code up really quick things.

38:03.440 --> 38:05.440
 Like I would see the world.

38:05.440 --> 38:11.440
 I'll be empowered to write a script to, to, you know, to do some basic data processing,

38:11.440 --> 38:13.440
 to rename files on my computer.

38:13.440 --> 38:14.440
 Yeah.

38:14.440 --> 38:15.440
 Right.

38:15.440 --> 38:19.440
 And like Pearl didn't do that for me a little bit.

38:19.440 --> 38:23.440
 And again, like none of these are about which, which is best or something like that.

38:23.440 --> 38:25.440
 But there's definitely better and worse here.

38:25.440 --> 38:26.440
 But it clicks.

38:26.440 --> 38:27.440
 Well, yeah.

38:27.440 --> 38:32.440
 And if you, if you look at Pearl, for example, you get bogged down and scalers versus arrays

38:32.440 --> 38:35.440
 versus hashes versus type globs and like all that kind of stuff.

38:35.440 --> 38:38.440
 And, and Python's like, yeah, let's not do this.

38:38.440 --> 38:39.440
 Right.

38:39.440 --> 38:40.440
 And some of it is debugging.

38:40.440 --> 38:41.440
 Like everyone has different priorities.

38:41.440 --> 38:47.440
 But for me, it's, can I create systems for myself that empower me to debug quickly?

38:47.440 --> 38:55.440
 Like I've always been a big fan, even just crewing like asserts, like always stating

38:55.440 --> 39:00.440
 things that should be true, which in Python I found in myself do more because of type,

39:00.440 --> 39:02.440
 all these kinds of stuff.

39:02.440 --> 39:05.440
 Well, you could think of types in a program language as being kind of assert.

39:05.440 --> 39:06.440
 Yeah.

39:06.440 --> 39:08.440
 They could check to compile time.

39:08.440 --> 39:09.440
 Right.

39:09.440 --> 39:11.440
 So how do you learn a new thing?

39:11.440 --> 39:13.440
 Well, so this, or how do, how do people learn new things?

39:13.440 --> 39:14.440
 Right.

39:14.440 --> 39:15.440
 This, this is hard.

39:15.440 --> 39:16.440
 People don't like to change.

39:16.440 --> 39:19.440
 People generally don't like change around them either.

39:19.440 --> 39:23.440
 And so we're all very slow to adapt and change.

39:23.440 --> 39:27.440
 And usually there's a catalyst that's required to, to force yourself over the, over, over

39:27.440 --> 39:28.440
 this.

39:28.440 --> 39:33.440
 So for learning a programming language, it really comes down to finding an excuse, like

39:33.440 --> 39:37.440
 build a thing that that's that the language is actually good for that the ecosystem is

39:37.440 --> 39:38.440
 ready for.

39:38.440 --> 39:44.440
 And so, and so if you were to write an iOS app, for example, that'd be the easy case.

39:44.440 --> 39:46.440
 Obviously you would use Swift for that.

39:46.440 --> 39:47.440
 Right.

39:47.440 --> 39:48.440
 Android.

39:48.440 --> 39:50.440
 So Swift runs on Android.

39:50.440 --> 39:51.440
 Oh, does it?

39:51.440 --> 39:52.440
 Oh, yeah.

39:52.440 --> 39:53.440
 Yeah.

39:53.440 --> 39:54.440
 Swift runs in lots of places.

39:54.440 --> 39:55.440
 How does that work?

39:55.440 --> 39:56.440
 Okay.

39:56.440 --> 39:58.440
 So Swift, Swift is built on top of LLVM.

39:58.440 --> 39:59.440
 Yeah.

39:59.440 --> 40:00.440
 LLVM runs everywhere.

40:00.440 --> 40:03.440
 LLVM, for example, bills the Android kernel.

40:03.440 --> 40:04.440
 Oh, okay.

40:04.440 --> 40:05.440
 So yeah.

40:05.440 --> 40:06.440
 Okay.

40:06.440 --> 40:07.440
 They realize this.

40:07.440 --> 40:08.440
 Yeah.

40:08.440 --> 40:10.440
 So Swift, Swift is very portable, runs on Windows.

40:10.440 --> 40:12.440
 There's, it runs on lots of different things.

40:12.440 --> 40:14.440
 And Swift, sorry to interrupt that.

40:14.440 --> 40:15.440
 Swift UI.

40:15.440 --> 40:17.440
 And then there's a thing called UIKit.

40:17.440 --> 40:20.440
 So can I build an app with Swift?

40:20.440 --> 40:24.440
 Well, so that's the thing is the ecosystem is what matters there.

40:24.440 --> 40:27.440
 So Swift UI and UIKit are Apple technologies.

40:27.440 --> 40:28.440
 Okay, got it.

40:28.440 --> 40:31.440
 And so they happen to like Swift UI happens to be written in Swift, but it's an Apple

40:31.440 --> 40:36.440
 proprietary framework that Apple loves and wants to keep on its platform, which makes

40:36.440 --> 40:37.440
 total sense.

40:37.440 --> 40:39.440
 You go to Android and you don't have that library.

40:39.440 --> 40:40.440
 Yeah.

40:40.440 --> 40:44.440
 So Android has a different ecosystem of things that hasn't been built out and doesn't

40:44.440 --> 40:45.440
 work as well with Swift.

40:45.440 --> 40:50.440
 And so you can totally use Swift to do like arithmetic and things like this, but building

40:50.440 --> 40:54.440
 a UI with Swift on Android is not a great experience right now.

40:54.440 --> 41:01.440
 So if I wanted to learn Swift, what's the, I mean, the one practical different version

41:01.440 --> 41:05.440
 of that is Swift for TensorFlow, for example.

41:05.440 --> 41:11.440
 And one of the inspiring things for me with both TensorFlow and PyTorch is how quickly

41:11.440 --> 41:14.440
 the community can like switch from different libraries.

41:14.440 --> 41:15.440
 Yep.

41:15.440 --> 41:21.440
 Like you could see some of the communities switching to PyTorch now, but it's very easy

41:21.440 --> 41:22.440
 to see.

41:22.440 --> 41:24.440
 And then TensorFlow is really stepping up its game.

41:24.440 --> 41:26.440
 And then there's no reason why.

41:26.440 --> 41:30.440
 I think the way it works is basically it has to be one GitHub repo, like one paper steps

41:30.440 --> 41:31.440
 up.

41:31.440 --> 41:32.440
 It gets people excited.

41:32.440 --> 41:35.440
 And they're like, ah, I have to learn this.

41:35.440 --> 41:37.440
 Swift for what?

41:37.440 --> 41:38.440
 Swift again.

41:38.440 --> 41:39.440
 Yeah.

41:39.440 --> 41:41.440
 And then they learn and they fall in love with them.

41:41.440 --> 41:42.440
 I mean, that's what happened with PyTorch.

41:42.440 --> 41:44.440
 There has to be a reason, a catalyst.

41:44.440 --> 41:45.440
 Yeah.

41:45.440 --> 41:50.440
 And so, and, and there, I mean, people don't like change, but it turns out that once you've

41:50.440 --> 41:54.440
 worked with one or two programming languages, the basics are pretty similar.

41:54.440 --> 41:58.440
 And so one of the fun things about learning programming languages, even, even maybe less,

41:58.440 --> 42:01.440
 I don't know if you agree with this is that when you start doing that, you start learning

42:01.440 --> 42:02.440
 new things.

42:02.440 --> 42:06.440
 Because you have a new way to do things and you're forced to do them.

42:06.440 --> 42:09.440
 And that forces you to explore and to put you in learning mode.

42:09.440 --> 42:13.440
 And when you get in learning mode, your mind kind of opens a little bit and you can, you

42:13.440 --> 42:16.440
 can see things in a new way, even when you go back to the old place.

42:16.440 --> 42:17.440
 Right.

42:17.440 --> 42:18.440
 Yeah.

42:18.440 --> 42:20.440
 So it would list with functional stuff.

42:20.440 --> 42:23.440
 But I wish there was a kind of window.

42:23.440 --> 42:25.440
 Maybe you can tell me if there is, there you go.

42:25.440 --> 42:30.440
 This is a question to ask what is the most beautiful feature in a programming language.

42:30.440 --> 42:36.440
 Before I ask it, let me say like with Python, I remember I saw list comprehensions.

42:36.440 --> 42:37.440
 Yeah.

42:37.440 --> 42:40.440
 It was like when I like really took it in.

42:40.440 --> 42:41.440
 Yeah.

42:41.440 --> 42:42.440
 I don't know.

42:42.440 --> 42:43.440
 I just loved it.

42:43.440 --> 42:45.440
 It was like fun to do.

42:45.440 --> 42:52.440
 Like it was fun to do that kind of something about it to be able to filter through a list

42:52.440 --> 42:56.440
 and to create a new list on a single line was elegant.

42:56.440 --> 42:58.440
 I could all get into my head.

42:58.440 --> 43:01.440
 It just made me fall in love with the language.

43:01.440 --> 43:02.440
 Yep.

43:02.440 --> 43:04.440
 So is there, let me ask you a question.

43:04.440 --> 43:10.440
 Is there, what do you use the most beautiful feature in a programming languages that you've

43:10.440 --> 43:14.440
 ever encountered in Swift maybe and then outside of Swift?

43:14.440 --> 43:18.440
 I think the thing that I like the most from a programming language.

43:18.440 --> 43:22.440
 So, so I think the thing you have to think about with the programming language, again,

43:22.440 --> 43:23.440
 what is the goal?

43:23.440 --> 43:26.440
 You're trying to get people to get things done quickly.

43:26.440 --> 43:32.440
 And so you need libraries, you need high quality libraries, and then you need a user base around

43:32.440 --> 43:34.440
 them that can assemble them and do cool things with them.

43:34.440 --> 43:35.440
 Right.

43:35.440 --> 43:38.440
 And so to me, the question is what enables high quality libraries?

43:38.440 --> 43:39.440
 Yeah.

43:39.440 --> 43:48.440
 And there's a huge divide in the world between libraries who enable high quality libraries

43:48.440 --> 43:52.440
 versus the ones that put special stuff in the language.

43:52.440 --> 43:57.440
 So, programming languages that enable high quality libraries, got it.

43:57.440 --> 44:03.440
 So, and what I mean by that is expressive libraries that then feel like a natural integrated

44:03.440 --> 44:05.440
 part of the language itself.

44:05.440 --> 44:11.440
 So, an example of this in Swift is that int and float and also ray and string, things

44:11.440 --> 44:13.440
 like this, these are all part of the library.

44:13.440 --> 44:17.440
 Like int is not hard coded into Swift.

44:17.440 --> 44:22.440
 And so what that means is that because int is just a library thing defined in the standard

44:22.440 --> 44:25.440
 library, along with strings and rays and all the other things that come with the standard

44:25.440 --> 44:26.440
 library.

44:26.440 --> 44:32.440
 Well, hopefully you do like int, but anything that any language features that you needed

44:32.440 --> 44:35.440
 to define int, you can also use in your own types.

44:35.440 --> 44:41.440
 So, if you wanted to find a quaternion or something like this, right?

44:41.440 --> 44:43.440
 Well, it doesn't come in the standard library.

44:43.440 --> 44:48.440
 There's a very special set of people that care a lot about this, but those people are

44:48.440 --> 44:49.440
 also important.

44:49.440 --> 44:51.440
 It's not about classism, right?

44:51.440 --> 44:54.440
 It's not about the people who care about instant fluids are more important than the people

44:54.440 --> 44:55.440
 care about quaternions.

44:55.440 --> 45:00.440
 And so to me, the beautiful things about programming languages is when you allow those communities

45:00.440 --> 45:05.440
 to build high quality libraries that feel native, that feel like they're built into the compiler

45:05.440 --> 45:07.440
 without having to be.

45:07.440 --> 45:13.440
 What does it mean for the int to be part of not hard coded in?

45:13.440 --> 45:18.440
 So what is an int?

45:18.440 --> 45:20.440
 Int is just an integer.

45:20.440 --> 45:24.440
 In this case, it's like a 64 bit integer or something like this.

45:24.440 --> 45:28.440
 But so the 64 bit is hard coded or no?

45:28.440 --> 45:29.440
 No, none of that's hard coded.

45:29.440 --> 45:34.440
 So int, if you go look at how it's implemented, it's just a struct in Swift.

45:34.440 --> 45:37.440
 And so it's a struct, and then how do you add two structs?

45:37.440 --> 45:38.440
 Well, you define plus.

45:38.440 --> 45:41.440
 And so you can define plus on int.

45:41.440 --> 45:43.440
 Well, you can define plus on your thing too.

45:43.440 --> 45:47.440
 You can define int as an odd method or something like that on it.

45:47.440 --> 45:50.440
 And so, yeah, you can add methods on things.

45:50.440 --> 45:51.440
 Yeah.

45:51.440 --> 45:55.440
 So you can define operators like how it behaves.

45:55.440 --> 46:00.440
 That's used beautiful when there's something about the language which enables others to

46:00.440 --> 46:05.440
 create libraries which are not hacky.

46:05.440 --> 46:07.440
 Yeah, they feel native.

46:07.440 --> 46:10.440
 And so one of the best examples of this is Lisp.

46:10.440 --> 46:11.440
 Right?

46:11.440 --> 46:15.440
 Because in Lisp, all the libraries are basically part of the language.

46:15.440 --> 46:18.440
 You write term rewrite systems and things like this.

46:18.440 --> 46:23.440
 Can you, as a counter example, provide what makes it difficult to write a library that's native?

46:23.440 --> 46:25.440
 Is it the Python C?

46:25.440 --> 46:32.440
 Well, so one example, I'll give you two examples, Java and C++ or Java and C.

46:32.440 --> 46:35.440
 They both allow you to define your own types.

46:35.440 --> 46:38.440
 But int is hard coded in the language.

46:38.440 --> 46:39.440
 Okay.

46:39.440 --> 46:40.440
 Well, why?

46:40.440 --> 46:43.440
 Well, in Java, for example, coming back to this whole reference semantic value, semantic

46:43.440 --> 46:48.440
 thing, int gets passed around by value.

46:48.440 --> 46:49.440
 Yeah.

46:49.440 --> 46:54.440
 But if you make like a pair or something like that, a complex number, right?

46:54.440 --> 46:59.440
 It's a class in Java and now it gets passed around by reference, by pointer.

46:59.440 --> 47:02.440
 And so now you lose value semantics, right?

47:02.440 --> 47:03.440
 You lost math.

47:03.440 --> 47:04.440
 Okay.

47:04.440 --> 47:06.440
 Well, that's not great, right?

47:06.440 --> 47:09.440
 If you can do something with int, why can't I do it with my type?

47:09.440 --> 47:10.440
 Yeah.

47:10.440 --> 47:11.440
 Right?

47:11.440 --> 47:17.440
 So that's the negative side of the thing I find beautiful is when you can solve that,

47:17.440 --> 47:22.440
 when you can have full expressivity where you as a user of the language have as much

47:22.440 --> 47:27.440
 or almost as much power as the people who implemented all the standard built in stuff.

47:27.440 --> 47:31.440
 Because what that enables is that enables truly beautiful libraries.

47:31.440 --> 47:36.440
 You know, it's kind of weird because I've gotten used to that.

47:36.440 --> 47:39.440
 That's one, I guess, other aspect of program language design.

47:39.440 --> 47:44.440
 You have to think, you know, the old first principles thinking, like, why are we doing

47:44.440 --> 47:45.440
 it this way?

47:45.440 --> 47:51.440
 By the way, I mean, I remember because I was thinking about the Waller's operator and

47:51.440 --> 47:57.440
 I'll ask you about it later, but it hit me that like the equal sign for assignment.

47:57.440 --> 47:58.440
 Yeah.

47:58.440 --> 48:00.440
 Like, why are we using the equal sign?

48:00.440 --> 48:01.440
 It's wrong.

48:01.440 --> 48:04.440
 And that's not the only solution, right?

48:04.440 --> 48:11.440
 So if you look at Pascal, they use colon equals for assignment and equals for equality.

48:11.440 --> 48:14.440
 And they use like less than greater than instead of the not equal.

48:14.440 --> 48:15.440
 Yeah.

48:15.440 --> 48:16.440
 Like there are other answers here.

48:16.440 --> 48:24.440
 So, but like, and yeah, I'd like to ask you all, but how do you then decide to break convention

48:24.440 --> 48:27.440
 to say, you know what?

48:27.440 --> 48:29.440
 Everybody's doing it wrong.

48:29.440 --> 48:31.440
 We're going to do it right.

48:31.440 --> 48:32.440
 Yeah.

48:32.440 --> 48:35.440
 So it's like an ROI, like return on investment trade off, right?

48:35.440 --> 48:40.440
 So if you do something weird, let's just say like not like colon equal instead of equal

48:40.440 --> 48:44.440
 for assignment, that would be weird with today's aesthetic, right?

48:44.440 --> 48:49.440
 And so you'd say, cool, this is theoretically better, but is it better in which ways?

48:49.440 --> 48:50.440
 Like, what do I get out of that?

48:50.440 --> 48:52.440
 Do I define away class of bugs?

48:52.440 --> 48:57.440
 Well, one of the class of bugs that C has is that you can use like, you know, if X equals

48:57.440 --> 49:01.440
 without equals equals, if X equals Y, right?

49:01.440 --> 49:05.440
 Well, turns out you can solve that problem in lots of ways.

49:05.440 --> 49:10.440
 Clang, for example, GCC, all these compilers will detect that as a, as a likely bug, produce

49:10.440 --> 49:11.440
 a warning.

49:11.440 --> 49:12.440
 Do they?

49:12.440 --> 49:13.440
 Yeah.

49:13.440 --> 49:14.440
 GCC didn't.

49:14.440 --> 49:19.440
 And it's like, one of the important things about programming language design is like,

49:19.440 --> 49:23.440
 you're literally creating suffering in the world.

49:23.440 --> 49:24.440
 Okay.

49:24.440 --> 49:29.440
 Like, I feel like, I mean, one way to see it is the bicycle for the mind, but the other

49:29.440 --> 49:31.440
 way is to like, minimizing suffering.

49:31.440 --> 49:33.440
 Well, you have to decide if it's worth it, right?

49:33.440 --> 49:35.440
 And so let's go back to that.

49:35.440 --> 49:36.440
 Okay.

49:36.440 --> 49:39.440
 But, but if you, if you look at this, and again, this is where there's a lot of detail

49:39.440 --> 49:45.440
 that goes into each of these things, equal and C returns a value.

49:45.440 --> 49:46.440
 Yeah.

49:46.440 --> 49:48.440
 That's messed up.

49:48.440 --> 49:52.440
 That allows you say X equals Y equals Z, like that works in C.

49:52.440 --> 49:53.440
 Yeah.

49:53.440 --> 49:54.440
 Is it messed up?

49:54.440 --> 49:59.440
 You know, well, so that most people think it's messed up, I think it is very by messed

49:59.440 --> 50:00.440
 up.

50:00.440 --> 50:03.440
 What I mean is it is very rarely used for good.

50:03.440 --> 50:05.440
 And it's often used for bugs.

50:05.440 --> 50:06.440
 Yeah.

50:06.440 --> 50:07.440
 Right.

50:07.440 --> 50:09.440
 That's a good definition of messed up.

50:09.440 --> 50:10.440
 Yeah.

50:10.440 --> 50:13.440
 You could use, you know, it's a, in hindsight, this was not such a great idea.

50:13.440 --> 50:14.440
 Right.

50:14.440 --> 50:17.440
 Now, one of the things with Swift that is really powerful and one of the reasons it's actually

50:17.440 --> 50:24.440
 good versus it being full of good ideas is that when, when we launched Swift one, we

50:24.440 --> 50:28.440
 announced that it was public, people could use it, people could build apps, but it was

50:28.440 --> 50:30.440
 going to change and break.

50:30.440 --> 50:31.440
 Okay.

50:31.440 --> 50:34.440
 When Swift two came out, we said, Hey, it's open source and there's this open process

50:34.440 --> 50:38.000
 which people can help evolve and direct the language.

50:38.000 --> 50:43.440
 So the community at large, like Swift users can now help shape the language as it is.

50:43.440 --> 50:47.840
 And what happened is that part, as part of that process is a lot of really bad mistakes

50:47.840 --> 50:49.680
 got taken out.

50:49.680 --> 50:54.440
 So for example, Swift used to have the C style plus plus and minus minus operators.

50:54.440 --> 50:58.440
 Like, what does it mean when you put it before versus after?

50:58.440 --> 50:59.440
 Right.

50:59.440 --> 51:02.440
 Well, that got cargo culted from C into Swift early on.

51:02.440 --> 51:03.440
 What's cargo culted?

51:03.440 --> 51:07.440
 Cargo culted means brought forward without really considering it.

51:07.440 --> 51:08.440
 Okay.

51:08.440 --> 51:11.440
 This is maybe not the most PC term.

51:11.440 --> 51:13.440
 But I have to look it up in urban dictionary.

51:13.440 --> 51:14.440
 Yeah.

51:14.440 --> 51:15.440
 Yeah.

51:15.440 --> 51:20.840
 So it got pulled into C without, or it got pulled into Swift without very good consideration.

51:20.840 --> 51:24.720
 And we went through this process and one of the first things got ripped out was plus

51:24.720 --> 51:27.800
 plus and minus minus because they lead to confusion.

51:27.800 --> 51:32.560
 They have very little value over saying, you know, X plus equals one and X plus equals

51:32.560 --> 51:34.360
 one is way more clear.

51:34.360 --> 51:38.960
 And so when you're optimizing for teachability and clarity and bugs and this multidimensional

51:38.960 --> 51:42.400
 space that you're looking at, things like that really matter.

51:42.400 --> 51:46.400
 And so being first principles on where you're coming from and what you're trying to achieve

51:46.400 --> 51:49.680
 and being anchored on the objective is really important.

51:49.680 --> 51:58.200
 Well, let me ask you about the most sort of this podcast isn't about information, it's

51:58.200 --> 51:59.200
 about drama.

51:59.200 --> 52:00.200
 Okay.

52:00.200 --> 52:01.200
 Let me talk to you about some drama.

52:01.200 --> 52:08.040
 So you mentioned Pascal and colon equals, there's something that's called the walrus

52:08.040 --> 52:09.040
 operator.

52:09.040 --> 52:10.040
 Okay.

52:10.040 --> 52:15.760
 And Python and Python 3.8 added the walrus operator.

52:15.760 --> 52:21.720
 And the reason I think it's interesting is not just because of the feature, it has the

52:21.720 --> 52:26.000
 same kind of expression feature that you can mention to see that it returns the value of

52:26.000 --> 52:27.000
 the assignment.

52:27.000 --> 52:31.480
 And then maybe you can comment on that in general, but on the other side of it, it's

52:31.480 --> 52:38.040
 also the thing that toppled the dictator.

52:38.040 --> 52:42.920
 It finally drove Guido to step down from BDFL, the toxicity of the community.

52:42.920 --> 52:47.040
 So maybe what do you think about the walrus operator in Python?

52:47.040 --> 52:54.520
 Is there an equivalent thing in Swift that really stress tested the community?

52:54.520 --> 52:58.840
 And then on the flip side, what do you think about Guido stepping down over it?

52:58.840 --> 52:59.840
 Yeah.

52:59.840 --> 53:03.280
 Well, if I look past the details of the walrus operator, one of the things that makes it

53:03.280 --> 53:05.840
 most polarizing is that it's syntactic sugar.

53:05.840 --> 53:06.840
 Okay.

53:06.840 --> 53:09.160
 What do you mean by syntactic sugar?

53:09.160 --> 53:12.440
 It means you can take something that already exists in language and you can express it

53:12.440 --> 53:14.480
 in a more concise way.

53:14.480 --> 53:16.040
 So okay, I'm going to play Dolph's advocate.

53:16.040 --> 53:18.880
 So this is great.

53:18.880 --> 53:22.440
 Is that an objective or subjective statement?

53:22.440 --> 53:27.600
 Can you argue that basically anything is syntactic sugar or not?

53:27.600 --> 53:28.600
 No.

53:28.600 --> 53:30.400
 Not everything is syntactic sugar.

53:30.400 --> 53:40.480
 So for example, the type system, can you have classes versus, do you have types or not?

53:40.480 --> 53:44.880
 So one type versus many types is not something that affects syntactic sugar.

53:44.880 --> 53:49.360
 And so if you say, I want to have the ability to define types, I have to have all this language

53:49.360 --> 53:54.840
 mechanics to define classes and oh, now I have to have inheritance and I have all this

53:54.840 --> 53:57.200
 stuff, that's just making the language more complicated.

53:57.200 --> 54:00.960
 That's not about sugaring it.

54:00.960 --> 54:02.440
 Swift has the sugar.

54:02.440 --> 54:09.000
 So Swift has this thing called iflet and it has various operators that are used to concisify

54:09.000 --> 54:10.560
 specific use cases.

54:10.560 --> 54:14.840
 So the problem with syntactic sugar, when you're talking about, hey, I have a thing

54:14.840 --> 54:17.720
 that takes a lot to write and I have a new way to write it.

54:17.720 --> 54:23.400
 You have this horrible trade off, which becomes almost completely subjective, which is how

54:23.400 --> 54:26.400
 often does this happen and does it matter?

54:26.400 --> 54:29.160
 And one of the things that is true about human psychology, particularly when you're talking

54:29.160 --> 54:36.240
 about introducing a new thing, is that people overestimate the burden of learning something.

54:36.240 --> 54:38.520
 And so it looks foreign when you haven't gotten used to it.

54:38.520 --> 54:42.400
 But if it was there from the beginning, of course, it's just part of Python.

54:42.400 --> 54:47.160
 Unquestionably, this is just the thing I know and it's not a new thing that you're worried

54:47.160 --> 54:48.160
 about learning.

54:48.160 --> 54:49.520
 It's just part of the deal.

54:49.520 --> 54:54.040
 Now with Guido, I don't know Guido well.

54:54.040 --> 54:55.040
 Yeah.

54:55.040 --> 54:56.800
 Have you passed cost much?

54:56.800 --> 54:57.800
 Yeah.

54:57.800 --> 55:00.200
 I've met him a couple of times, but I don't know Guido well.

55:00.200 --> 55:06.860
 But the sense that I got out of that whole dynamic was that he had put not just the decision

55:06.860 --> 55:13.400
 maker weight on his shoulders, but it was so tied to his personal identity that he took

55:13.400 --> 55:16.880
 it personally and he felt the need and he kind of put himself in the situation of being

55:16.880 --> 55:21.040
 the person instead of building a base of support around him.

55:21.040 --> 55:24.200
 I mean, this is probably not quite literally true.

55:24.200 --> 55:28.960
 But by too much, so there's too much too much concentrated on him, right?

55:28.960 --> 55:31.000
 And so and that can wear you down.

55:31.000 --> 55:35.400
 Well, yeah, particularly because people then say Guido, you're a horrible person.

55:35.400 --> 55:38.800
 I hate this thing, blah, blah, blah, blah, blah, blah, and sure, it's like, you know,

55:38.800 --> 55:41.440
 maybe 1% of the community that's doing that.

55:41.440 --> 55:46.840
 But Python's got a big community and 1% of millions of people is a lot of hate mail.

55:46.840 --> 55:51.960
 And that just from human factor will just wear on you to clarify, it looked from just

55:51.960 --> 55:55.960
 what I saw in the messaging for the let's not look at the million Python users, but

55:55.960 --> 56:02.720
 at the Python core developers, it feels like the majority, the big majority on a vote were

56:02.720 --> 56:03.720
 opposed to it.

56:03.720 --> 56:04.720
 Okay.

56:04.720 --> 56:05.720
 I'm not that close to it.

56:05.720 --> 56:12.080
 So, so, so this, okay, so the situation is like literally, uh, yeah, I mean, the majority

56:12.080 --> 56:14.400
 of the core developers again, we're opposed it.

56:14.400 --> 56:21.000
 So I, and they weren't, they weren't even like against it.

56:21.000 --> 56:25.480
 It was, uh, there was a few, well, they were against it, but the against it wasn't like,

56:25.480 --> 56:27.880
 this is a bad idea.

56:27.880 --> 56:31.520
 They were more like, we don't see why this is a good idea.

56:31.520 --> 56:38.080
 And what that results in is there's a stalling feeling, like you, you just slow things down.

56:38.080 --> 56:44.520
 Now, from my perspective, that you could argue this, and I think it's a very, it's very interesting

56:44.520 --> 56:49.200
 if we look at politics today and the way Congress works, it's slowed down everything.

56:49.200 --> 56:50.200
 It's a dampener.

56:50.200 --> 56:51.200
 Yeah.

56:51.200 --> 56:56.440
 It's a dampener, but like that's a dangerous thing too, because if it dampens things like,

56:56.440 --> 56:59.440
 you know, well, what are you talking about?

56:59.440 --> 57:03.600
 Like it's a low pass filter, but if you need billions of dollars injected into the economy

57:03.600 --> 57:06.400
 or trillions of dollars, then suddenly stuff happens.

57:06.400 --> 57:07.400
 Right.

57:07.400 --> 57:08.400
 Yeah.

57:08.400 --> 57:09.400
 For sure.

57:09.400 --> 57:10.400
 So you're talking about...

57:10.400 --> 57:13.840
 I'm not, I'm not, I'm not defending our political situation just to be clear, but you're talking

57:13.840 --> 57:16.440
 about like a global pandemic.

57:16.440 --> 57:22.680
 Well, I was hoping we could fix like the healthcare system and the educations and like, you know,

57:22.680 --> 57:23.680
 uh...

57:23.680 --> 57:24.680
 I'm not, I'm not a politics person.

57:24.680 --> 57:25.680
 I don't, I don't, I don't know.

57:25.680 --> 57:31.280
 Um, when it comes to languages, the community's kind of right in terms of it's a very high

57:31.280 --> 57:33.320
 burden to add something to a language.

57:33.320 --> 57:35.920
 So as soon as you add something, you have a community of people building on it and you

57:35.920 --> 57:37.480
 can't remove it.

57:37.480 --> 57:38.480
 Okay.

57:38.480 --> 57:42.080
 And if there's a community of people that feel really uncomfortable with it, then taking

57:42.080 --> 57:45.720
 it slow, I think is, is, is an important thing to do.

57:45.720 --> 57:50.280
 And there's no rush, particularly if something that's 25 years old and is very established

57:50.280 --> 57:53.920
 and, you know, it's not like coming, coming into its own.

57:53.920 --> 57:55.400
 What about features?

57:55.400 --> 58:00.440
 Well, well, so I think that the issue with, with Guido is that maybe this is a case where

58:00.440 --> 58:05.800
 he realized that had outgrown him and it went from being the language.

58:05.800 --> 58:12.360
 So Python, I mean, Guido is amazing, but, but Python isn't about Guido anymore.

58:12.360 --> 58:13.640
 It's about the users.

58:13.640 --> 58:15.640
 And to a certain extent, the users own it.

58:15.640 --> 58:23.160
 And, you know, Guido spent years of his life, a significant fraction of his career on Python.

58:23.160 --> 58:25.760
 And from his perspective, I imagine he's like, well, this is my thing.

58:25.760 --> 58:28.480
 I should be able to do the thing I think is right.

58:28.480 --> 58:33.080
 But you can also understand the users where they feel like, you know, this is my thing.

58:33.080 --> 58:38.360
 I use this like, and, um, and I don't know, it's, it's, it's a hard, it's a hard thing.

58:38.360 --> 58:42.480
 But what, if we could talk about leadership in this, because it's so interesting to me,

58:42.480 --> 58:44.680
 I'm going to, I'm going to make, I'm going to work.

58:44.680 --> 58:45.680
 Hopefully somebody makes it.

58:45.680 --> 58:50.560
 If not, I'll make it a water supply shirt because I think it represents to me, maybe

58:50.560 --> 58:53.920
 it's my Russian roots or something.

58:53.920 --> 58:56.240
 You know, it's the burden of leadership.

58:56.240 --> 59:01.000
 Like I feel like to push back.

59:01.000 --> 59:06.560
 I feel like progress can only, like most difficult decisions, just like you said, there'll be

59:06.560 --> 59:12.280
 a lot of divisiveness over, especially in the passionate community.

59:12.280 --> 59:20.600
 It just feels like leaders need to take those risky decisions that, that if you like listen,

59:20.600 --> 59:25.080
 that with some non zero probability, maybe even a high probability would be the wrong

59:25.080 --> 59:28.800
 decision, but they have to use their gut and make that decision.

59:28.800 --> 59:34.840
 Well, this, this is like one of the things where you see amazing founders, the founders

59:34.840 --> 59:37.960
 understand exactly what's happened and why, how the company got there and are willing

59:37.960 --> 59:43.720
 to say to, we have been doing thing X the last 20 years, but today we're going to do

59:43.720 --> 59:47.440
 a thing Y and they make a major pivot for the whole company.

59:47.440 --> 59:50.640
 The company lines up behind them, they move and it's the right thing.

59:50.640 --> 59:57.240
 But then when the founder dies, the successor doesn't always feel that, that agency to be

59:57.240 --> 59:59.280
 able to make those kinds of decisions.

59:59.280 --> 1:00:02.440
 Even though they're the CEO, they could theoretically do whatever.

1:00:02.440 --> 1:00:07.520
 There's two reasons for that in my opinion, or in many cases, it's always different.

1:00:07.520 --> 1:00:11.720
 But one of which is they weren't there for all the decisions that were made.

1:00:11.720 --> 1:00:15.520
 And so they don't know the principles in which those decisions were made.

1:00:15.520 --> 1:00:20.280
 And once the principles change, you're, you should be obligated to change what you're

1:00:20.280 --> 1:00:22.760
 doing and change direction.

1:00:22.760 --> 1:00:27.520
 And so if you don't know how you got to where you are, it just seems like gospel.

1:00:27.520 --> 1:00:29.880
 And you're not going to question it.

1:00:29.880 --> 1:00:33.320
 You may not understand that it really is the right thing to do, so you just may not see

1:00:33.320 --> 1:00:34.320
 it.

1:00:34.320 --> 1:00:35.320
 That's so brilliant.

1:00:35.320 --> 1:00:36.320
 I never thought of it that way.

1:00:36.320 --> 1:00:41.160
 It's so much higher burden when as a leader you step into a thing that's already worked

1:00:41.160 --> 1:00:42.160
 for a long time.

1:00:42.160 --> 1:00:43.160
 Yeah.

1:00:43.160 --> 1:00:44.160
 Yeah.

1:00:44.160 --> 1:00:46.520
 And if you change it and it doesn't work out, now you're the person who screwed it up.

1:00:46.520 --> 1:00:47.840
 People always second guess that.

1:00:47.840 --> 1:00:48.840
 Yeah.

1:00:48.840 --> 1:00:52.080
 And the second thing is that even if you decide to make a change, even if you're theoretically

1:00:52.080 --> 1:00:57.240
 in charge, you're just a person that thinks they're in charge.

1:00:57.240 --> 1:00:58.240
 Yeah.

1:00:58.240 --> 1:00:59.240
 Meanwhile, you have to motivate the troops.

1:00:59.240 --> 1:01:00.560
 You have to explain it to them in terms they'll understand.

1:01:00.560 --> 1:01:04.560
 You have to get them to buy into it and believe in it because if they don't, then they're

1:01:04.560 --> 1:01:07.840
 not going to be able to make the turn even if you tell them their bonuses are going to

1:01:07.840 --> 1:01:08.840
 be curtailed.

1:01:08.840 --> 1:01:10.880
 They're just not going to buy into it.

1:01:10.880 --> 1:01:15.120
 And so there's only so much power you have as a leader and you have to understand what

1:01:15.120 --> 1:01:16.360
 those limitations are.

1:01:16.360 --> 1:01:21.640
 I used to be BDFL, you've been BDFL of some stuff.

1:01:21.640 --> 1:01:28.760
 You're very heavy on the B, the benevolent, benevolent, dictated for life, I guess LVM.

1:01:28.760 --> 1:01:29.760
 Yeah.

1:01:29.760 --> 1:01:32.520
 So I still lead the LVM world.

1:01:32.520 --> 1:01:38.400
 I mean, what's the role of, so then on Swift, you said that there's a group of people.

1:01:38.400 --> 1:01:39.400
 Yeah.

1:01:39.400 --> 1:01:44.440
 So if you contrast Python with Swift, right, one of the reasons, so everybody on the core

1:01:44.440 --> 1:01:46.360
 team takes the role really seriously.

1:01:46.360 --> 1:01:49.480
 And I think we all really care about where Swift goes.

1:01:49.480 --> 1:01:55.040
 But you're almost delegating the final decision making to the wisdom of the group.

1:01:55.040 --> 1:01:57.680
 And so it doesn't become personal.

1:01:57.680 --> 1:02:02.400
 And also when you're talking with the community, so yeah, some people are very annoyed at certain

1:02:02.400 --> 1:02:04.480
 decisions that get made.

1:02:04.480 --> 1:02:08.400
 There's a certain faith in the process because it's a very transparent process.

1:02:08.400 --> 1:02:12.320
 And when a decision gets made, a full rationale is provided, things like this.

1:02:12.320 --> 1:02:16.840
 These are almost defense mechanisms to help both guide future discussions and provide

1:02:16.840 --> 1:02:21.040
 case lock and like Supreme Court does about, this decision was made for this reason and

1:02:21.040 --> 1:02:24.720
 here's the rationale and what we want to see more of or less of.

1:02:24.720 --> 1:02:29.040
 But it's also a way to provide a defense mechanism so that when somebody's griping about it,

1:02:29.040 --> 1:02:32.080
 they're not saying that person did the wrong thing.

1:02:32.080 --> 1:02:38.560
 They're saying, well, this thing sucks and later they move on and they get over it.

1:02:38.560 --> 1:02:39.560
 Yeah.

1:02:39.560 --> 1:02:42.720
 The analogy is Supreme Court, I think, is really good.

1:02:42.720 --> 1:02:47.640
 But then, okay, not to get person on the SWIFT team, but like, is there, is there, like,

1:02:47.640 --> 1:02:52.440
 it just seems like it's impossible for their, for division not to emerge.

1:02:52.440 --> 1:02:57.600
 Well, each of the humans on the SWIFT core team, for example, are different and the membership

1:02:57.600 --> 1:03:02.660
 of the SWIFT core team changes slowly over time, which is I think a healthy thing.

1:03:02.660 --> 1:03:05.440
 And so each of these different humans have different opinions.

1:03:05.440 --> 1:03:11.080
 Trust me, it's not, it's not a singular consciousness by any stretch of the imagination.

1:03:11.080 --> 1:03:16.600
 You've got three major organizations, including Apple, Google and SciFive all working together.

1:03:16.600 --> 1:03:20.240
 And it's a small group of people, but you need high trust.

1:03:20.240 --> 1:03:26.040
 You need, again, it comes back to the principles of what you're trying to achieve and understanding

1:03:26.040 --> 1:03:27.800
 what you're optimizing for.

1:03:27.800 --> 1:03:32.760
 And I think that starting with strong principles and working towards decisions is always a

1:03:32.760 --> 1:03:37.800
 good way to both make wise decisions in general, but then be able to communicate them to people

1:03:37.800 --> 1:03:41.480
 so that they can buy into them and that, that is hard.

1:03:41.480 --> 1:03:46.840
 And so you mentioned LVM, LVM is going to be 20 years old this December.

1:03:46.840 --> 1:03:48.960
 So it's, it's showing its own age.

1:03:48.960 --> 1:03:53.400
 Do you have like, like a, like a, like a dragon cake plan or do you have a?

1:03:53.400 --> 1:03:54.600
 No, I should definitely do that.

1:03:54.600 --> 1:03:55.600
 Yeah.

1:03:55.600 --> 1:04:01.520
 If we can have a pandemic cake, everybody gets a slice of cake and it gets, you know,

1:04:01.520 --> 1:04:04.520
 sent through email.

1:04:04.520 --> 1:04:09.240
 But the, but LVM has had tons of its own challenges over time too, right?

1:04:09.240 --> 1:04:14.600
 And one of the challenges that the LVM community has in my opinion is that it has a whole bunch

1:04:14.600 --> 1:04:19.120
 of people that have been working on LVM for 10 years, right?

1:04:19.120 --> 1:04:21.200
 Cause this happens some somehow.

1:04:21.200 --> 1:04:25.120
 And LVM has always been one way, but it needs to be a different way, right?

1:04:25.120 --> 1:04:28.880
 And they've worked on it for like 10 years is a long time to work on something.

1:04:28.880 --> 1:04:33.560
 And you know, you suddenly can't see the faults in the thing that you're working on.

1:04:33.560 --> 1:04:36.760
 And LVM has lots of problems and we need to address them and we need to make it better.

1:04:36.760 --> 1:04:40.360
 And if we don't make it better, then somebody else will come up with a better idea, right?

1:04:40.360 --> 1:04:45.240
 And so it's just kind of of that age where the community is like in danger of getting

1:04:45.240 --> 1:04:51.200
 too calcified and, um, and so I'm happy to see new projects joining and new things mixing

1:04:51.200 --> 1:04:52.200
 it up.

1:04:52.200 --> 1:04:55.400
 You know, Fortran is now a new, a new thing in the LVM community, which is an area some

1:04:55.400 --> 1:04:56.400
 good.

1:04:56.400 --> 1:05:01.200
 I've been trying to find, uh, on this little tangent, find people who program in Cobalt

1:05:01.200 --> 1:05:04.880
 or Fortran, Fortran especially to talk to it.

1:05:04.880 --> 1:05:06.360
 They're hard to find.

1:05:06.360 --> 1:05:07.360
 Yeah.

1:05:07.360 --> 1:05:09.880
 Look to the, uh, scientific community.

1:05:09.880 --> 1:05:12.160
 They still use Fortran quite a bit.

1:05:12.160 --> 1:05:16.400
 Interesting thing you kind of mentioned with LVM or just in general, that as something

1:05:16.400 --> 1:05:19.800
 evolved, you're not able to see the faults.

1:05:19.800 --> 1:05:24.480
 So do you, uh, fall in love with the thing over time or do you start hating everything

1:05:24.480 --> 1:05:26.200
 about the thing over time?

1:05:26.200 --> 1:05:33.480
 Well, so, so my, my, my personal folly is that, um, I see maybe not all, but many of the faults

1:05:33.480 --> 1:05:35.600
 and they grate on me and I don't have time to go fix them.

1:05:35.600 --> 1:05:36.600
 Yeah.

1:05:36.600 --> 1:05:37.600
 And they get magnified over time.

1:05:37.600 --> 1:05:41.160
 Well, and they may not get magnified, but they never get fixed and it's like sand underneath

1:05:41.160 --> 1:05:45.400
 the, you know, it's just like grating against you and it's like sand underneath your fingernails

1:05:45.400 --> 1:05:46.400
 or something.

1:05:46.400 --> 1:05:47.400
 It's just like, you know, it's there.

1:05:47.400 --> 1:05:48.640
 You can't get rid of it.

1:05:48.640 --> 1:05:55.040
 Um, and so the, the problem is that if other people don't see it, right, nobody ever, like

1:05:55.040 --> 1:05:58.520
 I can't go, I don't have time to go write the code and fix it anymore.

1:05:58.520 --> 1:06:02.680
 But then, uh, people are resistant to change and so you say, Hey, we should go fix this

1:06:02.680 --> 1:06:03.680
 thing.

1:06:03.680 --> 1:06:04.680
 Like, oh yeah, that sounds risky.

1:06:04.680 --> 1:06:05.680
 Yeah.

1:06:05.680 --> 1:06:06.680
 Well, is it the right thing or not?

1:06:06.680 --> 1:06:11.520
 Are the challenges, uh, the, the group dynamics or is it also just technical?

1:06:11.520 --> 1:06:16.560
 I mean, some of these features like, yeah, I think, uh, as an observer is almost like

1:06:16.560 --> 1:06:23.640
 a fan in, in the, uh, you know, as a spectator, the whole thing, I don't often think about,

1:06:23.640 --> 1:06:27.080
 you know, some things might actually be technically difficult to implement.

1:06:27.080 --> 1:06:30.840
 An example of this is we, we built this new compiler framework called MLAR.

1:06:30.840 --> 1:06:31.840
 Yes.

1:06:31.840 --> 1:06:34.280
 MLAR is this a whole new framework.

1:06:34.280 --> 1:06:37.360
 It's not, many people think it's about machine learning.

1:06:37.360 --> 1:06:41.360
 The ML stands for multi level because compiler people can't name things very well.

1:06:41.360 --> 1:06:42.360
 I guess.

1:06:42.360 --> 1:06:44.960
 Can we dig into what MLIR is?

1:06:44.960 --> 1:06:45.960
 Yeah.

1:06:45.960 --> 1:06:51.840
 So when you look at compilers, compilers have historically been solutions for a given space.

1:06:51.840 --> 1:06:58.200
 So LLVM is a, it's really good for dealing with CPUs, let's just say at a high level.

1:06:58.200 --> 1:07:01.720
 You look at, um, Java, Java has a JVM.

1:07:01.720 --> 1:07:05.760
 The JVM is very good for garbage collected languages that need dynamic compilations.

1:07:05.760 --> 1:07:08.520
 It's very optimized for specific space.

1:07:08.520 --> 1:07:11.560
 And so hotspot is one of the compilers that gets used in that space and that compiler's

1:07:11.560 --> 1:07:13.400
 really good at that kind of stuff.

1:07:13.400 --> 1:07:18.000
 Um, usually when you build these domain specific compilers, you end up building whole thing

1:07:18.000 --> 1:07:21.120
 from scratch for each domain.

1:07:21.120 --> 1:07:23.480
 Uh, what's a domain?

1:07:23.480 --> 1:07:26.760
 So what, what, what's the scope of a domain?

1:07:26.760 --> 1:07:30.480
 Well, so here I would say like, if you look at Swift, there's several different parts

1:07:30.480 --> 1:07:35.880
 to the Swift compiler, um, one of which is covered by, um, the LLVM part of it.

1:07:35.880 --> 1:07:41.480
 There's also a high level piece that's specific to Swift and there's a huge amount of redundancy

1:07:41.480 --> 1:07:46.480
 between those two different infrastructures and a lot of re, re implemented stuff that

1:07:46.480 --> 1:07:48.560
 is similar but different.

1:07:48.560 --> 1:07:50.080
 What is LLVM defined?

1:07:50.080 --> 1:07:53.120
 LLVM is effectively an infrastructure.

1:07:53.120 --> 1:07:55.200
 So you can mix and match it in different ways.

1:07:55.200 --> 1:07:56.200
 It's built out of libraries.

1:07:56.200 --> 1:08:00.680
 You can use it for different things, but it's really good at CPUs and GPUs, CPUs and like

1:08:00.680 --> 1:08:02.600
 the tip of the iceberg on GPUs.

1:08:02.600 --> 1:08:04.160
 It's not really great at GPUs.

1:08:04.160 --> 1:08:05.160
 Okay.

1:08:05.160 --> 1:08:11.200
 Um, but it turns out languages that then use it to talk to CPUs.

1:08:11.200 --> 1:08:14.920
 And so it turns out there's a lot of hardware out there that is custom accelerators.

1:08:14.920 --> 1:08:18.680
 So machine learning, for example, there are a lot of, uh, matrix multiply accelerators

1:08:18.680 --> 1:08:22.920
 and things like this, there, there's a whole world of hardware synthesis.

1:08:22.920 --> 1:08:26.360
 So we're, we're using MLIR to build circuits.

1:08:26.360 --> 1:08:27.360
 Okay.

1:08:27.360 --> 1:08:30.960
 And so you're compiling for a domain of transistors.

1:08:30.960 --> 1:08:34.840
 And so what MLIR does is it provides a tremendous amount of compiler infrastructure that allows

1:08:34.840 --> 1:08:40.440
 you to build these domain specific compilers in a much faster way and have the result be

1:08:40.440 --> 1:08:41.440
 good.

1:08:41.440 --> 1:08:46.800
 If we're, if we're thinking about the future, now we're talking about like ASICs, so anything.

1:08:46.800 --> 1:08:47.800
 Yeah.

1:08:47.800 --> 1:08:53.680
 And so if we project into the future, it's very possible that the number of these kinds

1:08:53.680 --> 1:09:04.320
 of ASICs, very specific, uh, infrastructure thing, the architecture things, uh, like multiplies

1:09:04.320 --> 1:09:05.320
 exponentially.

1:09:05.320 --> 1:09:06.320
 I hope so.

1:09:06.320 --> 1:09:07.320
 Yeah.

1:09:07.320 --> 1:09:08.320
 So that's MLIR.

1:09:08.320 --> 1:09:12.720
 So what MLIR, what MLIR does is it allows you to build these compilers very efficiently.

1:09:12.720 --> 1:09:13.720
 Right.

1:09:13.720 --> 1:09:18.160
 So one of the things that coming back to the LLVM thing, and then we'll go to hardware,

1:09:18.160 --> 1:09:23.360
 is, um, LLVM is a, is a specific compiler for a specific domain.

1:09:23.360 --> 1:09:28.200
 MLIR is now this very general, very flexible thing that can solve lots of different kinds

1:09:28.200 --> 1:09:29.360
 of problems.

1:09:29.360 --> 1:09:32.480
 So LLVM is a subset of what MLIR does.

1:09:32.480 --> 1:09:35.200
 So MLIR is, I mean, it's an ambitious project then.

1:09:35.200 --> 1:09:36.200
 Yeah.

1:09:36.200 --> 1:09:37.200
 It's a very ambitious project.

1:09:37.200 --> 1:09:38.200
 Yeah.

1:09:38.200 --> 1:09:42.480
 And so to make it even more confusing, MLIR has joined the LLVM umbrella project.

1:09:42.480 --> 1:09:44.200
 So it's part of the LLVM family.

1:09:44.200 --> 1:09:45.200
 Right.

1:09:45.200 --> 1:09:50.000
 Um, but where this comes full circle is now folks that work on the LLVM part, the classic

1:09:50.000 --> 1:09:54.280
 part that's 20 years old, um, aren't aware of all the cool new things that have been

1:09:54.280 --> 1:09:59.520
 done in the new, the new thing that, you know, MLIR was built by me and many other people

1:09:59.520 --> 1:10:01.920
 that knew a lot about LLVM.

1:10:01.920 --> 1:10:04.320
 And so we fixed a lot of the mistakes that lived in LLVM.

1:10:04.320 --> 1:10:08.640
 I mean, we have this community dynamic where it's like, well, there's this new thing, but

1:10:08.640 --> 1:10:09.640
 it's not familiar.

1:10:09.640 --> 1:10:10.640
 Nobody knows it.

1:10:10.640 --> 1:10:12.840
 It's like it's new and so let's not trust it.

1:10:12.840 --> 1:10:16.480
 And so it's just really interesting to see the cultural social dynamic that comes out

1:10:16.480 --> 1:10:17.480
 of that.

1:10:17.480 --> 1:10:21.600
 And, and, you know, I think it's super healthy because we're seeing the ideas percolate and

1:10:21.600 --> 1:10:25.240
 we're seeing the technology diffusion happen as people get more comfortable with it.

1:10:25.240 --> 1:10:29.200
 They start to understand things in their own terms and this just gets to the, it takes

1:10:29.200 --> 1:10:34.320
 a while for ideas to propagate, even though, um, they may be very different than what people

1:10:34.320 --> 1:10:35.320
 are used to.

1:10:35.320 --> 1:10:40.200
 So maybe let's talk about that a little bit, the world of basics and well, actually you're

1:10:40.200 --> 1:10:45.720
 a, you're, you're, you have a new role at sci five.

1:10:45.720 --> 1:10:47.520
 What's that place about?

1:10:47.520 --> 1:10:53.360
 What is the vision for their vision for, I would say the future of computer.

1:10:53.360 --> 1:10:56.040
 So I lead the engineering and product teams at sci five.

1:10:56.040 --> 1:11:03.240
 Sci five is a company who's was founded with this architecture called risk five risk fives

1:11:03.240 --> 1:11:06.520
 a new instruction set instruction sets are the things inside of your computer that tell

1:11:06.520 --> 1:11:12.360
 you how to run things, um, x 86 from Intel and arm from the arm company and things like

1:11:12.360 --> 1:11:13.880
 this or other instruction sets.

1:11:13.880 --> 1:11:14.880
 I've talked to science.

1:11:14.880 --> 1:11:17.720
 I've talked to Dave Patterson who's super excited about risk five.

1:11:17.720 --> 1:11:18.720
 Dave, Dave is awesome.

1:11:18.720 --> 1:11:19.720
 He's brilliant.

1:11:19.720 --> 1:11:20.720
 Yeah.

1:11:20.720 --> 1:11:24.720
 The risk five is distinguished by not being proprietary.

1:11:24.720 --> 1:11:30.440
 And so x a six can only be made by Intel and AMD arm can only be made by arm.

1:11:30.440 --> 1:11:34.840
 They sell licenses to build arm ships to other companies, things like this MIPS is another

1:11:34.840 --> 1:11:39.520
 instruction set that is owned by the MIPS company now wave and then it gets licensed out things

1:11:39.520 --> 1:11:40.520
 like that.

1:11:40.520 --> 1:11:45.240
 Um, and so risk five is an open standard that anybody can build chips for.

1:11:45.240 --> 1:11:50.320
 And so sci five was founded by three of the founders of risk five that designed and built

1:11:50.320 --> 1:11:53.320
 it in Berkeley working with Dave.

1:11:53.320 --> 1:11:58.240
 And so that was the, the genesis of the company sci five today has some of the world's best

1:11:58.240 --> 1:12:01.440
 risk five cores and we're selling them and that's really great.

1:12:01.440 --> 1:12:02.480
 They're going to tons of products.

1:12:02.480 --> 1:12:03.480
 It's very exciting.

1:12:03.480 --> 1:12:07.520
 Um, so they're taking this, uh, thing that's open source and just being, uh, trying to

1:12:07.520 --> 1:12:10.760
 be or are the best in the world at building these things.

1:12:10.760 --> 1:12:11.760
 Yeah.

1:12:11.760 --> 1:12:13.360
 So here it's the specifications open source.

1:12:13.360 --> 1:12:18.560
 It's like saying TCP IP is an open standard or C is an open standard, but then you have

1:12:18.560 --> 1:12:20.880
 to build an implementation of the standard.

1:12:20.880 --> 1:12:26.360
 And so sci five on the one hand pushes forward and defined and pushes forward the standard.

1:12:26.360 --> 1:12:30.360
 On the other hand, we have implementations that are best in class for different points

1:12:30.360 --> 1:12:34.680
 in the space, depending on if you want a really tiny CPU or if you want a really big beefy

1:12:34.680 --> 1:12:39.000
 one that, that, uh, is faster, but it uses more area and things like this.

1:12:39.000 --> 1:12:41.200
 What about the actual manufacturer chip?

1:12:41.200 --> 1:12:42.200
 So like what?

1:12:42.200 --> 1:12:43.200
 Yeah.

1:12:43.200 --> 1:12:44.200
 So where does that all fit?

1:12:44.200 --> 1:12:48.320
 I'm going to ask a bunch of dumb questions because this is how we learn, right?

1:12:48.320 --> 1:12:54.200
 And so, uh, what the way this works is that there's generally a separation of the people

1:12:54.200 --> 1:12:57.000
 who design the circuits and then people who manufacture them.

1:12:57.000 --> 1:13:02.360
 And so that you'll hear about fabs like TSMC and Samsung and things like this that actually

1:13:02.360 --> 1:13:08.760
 produce the chips, but they take a design coming in and that design specifies how, um,

1:13:08.760 --> 1:13:16.360
 how the, you know, you turn, uh, code for the chip into, uh, little rectangles that

1:13:16.360 --> 1:13:22.240
 then use photo lithography to make, uh, mask sets and then burn transistors onto a chip

1:13:22.240 --> 1:13:24.880
 or onto onto silicon rather.

1:13:24.880 --> 1:13:27.520
 So we're talking about mass manufacturing.

1:13:27.520 --> 1:13:31.480
 So yeah, they're talking about making hundreds of millions of parts and things like that.

1:13:31.480 --> 1:13:34.840
 And so the fab handles the volume production, things like that.

1:13:34.840 --> 1:13:39.240
 But when you look at this problem, um, the interesting thing about the space when you

1:13:39.240 --> 1:13:44.920
 look at it is that, um, these, the steps that you go from designing a chip and writing the

1:13:44.920 --> 1:13:49.960
 quote unquote code for it and things like fair log and languages like that down to what

1:13:49.960 --> 1:13:55.080
 you hand off to the fab is a really well studied, really old problem.

1:13:55.080 --> 1:13:56.080
 Okay.

1:13:56.080 --> 1:14:00.080
 Um, tons of people have worked on it, lots of smart people have built systems and tools.

1:14:00.080 --> 1:14:04.920
 Um, these tools then have generally gone through acquisitions and so they've ended up at three

1:14:04.920 --> 1:14:07.880
 different major companies that build and sell these tools.

1:14:07.880 --> 1:14:11.120
 They're called EDA tools like for electronic design automation.

1:14:11.120 --> 1:14:14.640
 Um, the problem with this is you have huge amounts of fragmentation.

1:14:14.640 --> 1:14:20.120
 You have loose standards, um, and the tools don't really work together.

1:14:20.120 --> 1:14:23.800
 So you have tons of duct tape and you have tons of, uh, lost productivity.

1:14:23.800 --> 1:14:26.800
 Now these are, uh, these are tools for design.

1:14:26.800 --> 1:14:30.360
 So the risk five is a instruction.

1:14:30.360 --> 1:14:32.200
 Like what is risk five?

1:14:32.200 --> 1:14:33.400
 Like how deep does it go?

1:14:33.400 --> 1:14:36.040
 How, how, how much does it touch the hardware?

1:14:36.040 --> 1:14:38.360
 How much does it define how much of the hardware is?

1:14:38.360 --> 1:14:39.360
 Yeah.

1:14:39.360 --> 1:14:42.000
 So risk, risk five is all about, um, given a CPU.

1:14:42.000 --> 1:14:47.440
 So the, the, the processor and your computer, how does the, the compiler, like Swift compiler,

1:14:47.440 --> 1:14:50.560
 the C compiler, things like this, how does it make it work?

1:14:50.560 --> 1:14:52.800
 So it's, what is the assembly code?

1:14:52.800 --> 1:14:57.160
 And so you write risk five assembly instead of XA six assembly, for example.

1:14:57.160 --> 1:14:59.720
 But it's the set of instructions as opposed to instructions.

1:14:59.720 --> 1:15:00.720
 Yeah.

1:15:00.720 --> 1:15:02.880
 What, what do you say it tells you how the compiler works?

1:15:02.880 --> 1:15:05.360
 Well, sorry, it's what the compiler talks to.

1:15:05.360 --> 1:15:06.360
 Okay.

1:15:06.360 --> 1:15:07.360
 Yeah.

1:15:07.360 --> 1:15:11.160
 And then, uh, the tooling you mentioned that the disparate tools are for what, for,

1:15:11.160 --> 1:15:13.440
 when you're building a specific chip.

1:15:13.440 --> 1:15:15.600
 So risk five in hardware, in hardware.

1:15:15.600 --> 1:15:16.600
 Yeah.

1:15:16.600 --> 1:15:20.440
 So, so risk five, you can buy a risk five core from sci five and say, Hey, I want to

1:15:20.440 --> 1:15:23.360
 have a certain number of run a certain number of gigahertz.

1:15:23.360 --> 1:15:24.640
 I want it to be this big.

1:15:24.640 --> 1:15:26.800
 I want it to be, have these features.

1:15:26.800 --> 1:15:31.160
 I want to have, um, like I want floating point or not, for example.

1:15:31.160 --> 1:15:36.680
 Um, and then what you get is you get a description of a CPU with those characteristics.

1:15:36.680 --> 1:15:40.200
 Now if you want to make a chip and you want to build like an iPhone chip or something

1:15:40.200 --> 1:15:41.200
 like that, right?

1:15:41.200 --> 1:15:44.480
 You have to take both the CPU, but then you have to talk to memory.

1:15:44.480 --> 1:15:48.640
 You have to have timers, IOs, a GPU, other components.

1:15:48.640 --> 1:15:54.400
 And so you need to pull all those things together into what's called an ASIC, an application

1:15:54.400 --> 1:15:57.000
 specific in a grade circuit, so custom chip.

1:15:57.000 --> 1:16:01.160
 And then you take that design and then you have to transform it into something that the

1:16:01.160 --> 1:16:06.880
 fabs like TSMC, for example, know how to turn, take to production.

1:16:06.880 --> 1:16:07.880
 Got it.

1:16:07.880 --> 1:16:08.880
 So, but yeah.

1:16:08.880 --> 1:16:09.880
 And so that process.

1:16:09.880 --> 1:16:15.760
 I will, I can't help but see it as, is a big compiler.

1:16:15.760 --> 1:16:16.760
 Yeah.

1:16:16.760 --> 1:16:21.040
 It's a whole bunch of compilers written without thinking about it through that lens.

1:16:21.040 --> 1:16:22.040
 And so.

1:16:22.040 --> 1:16:24.040
 Isn't the universe a compiler?

1:16:24.040 --> 1:16:25.040
 Yeah.

1:16:25.040 --> 1:16:26.840
 Compilers do two things.

1:16:26.840 --> 1:16:28.600
 They represent things and transform them.

1:16:28.600 --> 1:16:29.600
 Yeah.

1:16:29.600 --> 1:16:31.960
 And so there's a lot of things that end up being compilers.

1:16:31.960 --> 1:16:36.400
 But this is, this is a space where we're talking about design and usability and the way you

1:16:36.400 --> 1:16:41.000
 think about things, the way things compose correctly, it matters a lot.

1:16:41.000 --> 1:16:43.760
 And so sci fi is investing a lot into that space.

1:16:43.760 --> 1:16:47.440
 And we think that there's a lot, a lot of benefit that can be made by allowing people

1:16:47.440 --> 1:16:53.920
 to design chips faster, get them to market quicker and scale out because, you know, at

1:16:53.920 --> 1:17:00.120
 the alleged more end of Moore's law, you've got this problem of you're not getting free

1:17:00.120 --> 1:17:03.720
 performance just by waiting another year for a faster CPU.

1:17:03.720 --> 1:17:06.640
 And so you have to find performance in other ways.

1:17:06.640 --> 1:17:12.000
 And one of the ways to do that is with custom accelerators and other things in hardware.

1:17:12.000 --> 1:17:17.560
 And so we'll talk a little bit about, a little more about ASICs.

1:17:17.560 --> 1:17:25.640
 But do you see that a lot of people, a lot of companies will try to have like different

1:17:25.640 --> 1:17:28.480
 sets of requirements that this whole process to go for.

1:17:28.480 --> 1:17:35.240
 So like, like almost different car companies might use different and like different PC manufacturers,

1:17:35.240 --> 1:17:42.480
 like, so is this, like, is risk five in this whole process, is it potentially the future

1:17:42.480 --> 1:17:44.400
 of all computing devices?

1:17:44.400 --> 1:17:48.840
 Yeah, I think that, so if you look at risk five and step back from the silicon side of

1:17:48.840 --> 1:17:51.840
 things, risk five is an open standard.

1:17:51.840 --> 1:17:56.040
 And one of the things that has happened over the course of decades, if you look over the

1:17:56.040 --> 1:18:02.160
 long arc of computing, somehow became decades old, is that you have companies that come

1:18:02.160 --> 1:18:04.960
 and go and you have instruction sets that come and go.

1:18:04.960 --> 1:18:11.960
 Like one example of this out of many is Sun with Spark, Sun one way, Spark still lives

1:18:11.960 --> 1:18:18.260
 on it if you just do, but we have HP had this instruction set called PA risk.

1:18:18.260 --> 1:18:22.960
 So PA risk was its big server business and had tons of customers.

1:18:22.960 --> 1:18:27.000
 They decided to move to this architecture called Itanium from Intel.

1:18:27.000 --> 1:18:28.000
 Yeah.

1:18:28.000 --> 1:18:29.480
 It didn't work out so well.

1:18:29.480 --> 1:18:30.480
 Yeah.

1:18:30.480 --> 1:18:31.480
 Right.

1:18:31.480 --> 1:18:36.000
 And so you have this issue of you're making many billion dollar investments on instruction

1:18:36.000 --> 1:18:38.360
 sets that are owned by a company.

1:18:38.360 --> 1:18:42.520
 And even companies as big as Intel don't always execute as well as they could.

1:18:42.520 --> 1:18:44.160
 They have their own issues.

1:18:44.160 --> 1:18:48.120
 HP, for example, decided that it wasn't in their best interest to continue investing

1:18:48.120 --> 1:18:49.760
 in the space because it was very expensive.

1:18:49.760 --> 1:18:54.320
 So they make technology decisions or they make their own business decisions and this

1:18:54.320 --> 1:18:58.000
 means that as a customer, what do you do?

1:18:58.000 --> 1:19:01.440
 You've sunk all this time, all this engineering, all this software work, all these, you've

1:19:01.440 --> 1:19:03.880
 built other products around them and now you're stuck.

1:19:03.880 --> 1:19:04.880
 Right.

1:19:04.880 --> 1:19:10.720
 What risk five does is provide you more optionality in the space because if you buy an implementation

1:19:10.720 --> 1:19:16.440
 of risk five from sci five and you should, they're the best ones.

1:19:16.440 --> 1:19:20.560
 But if something bad happens to sci five in 20 years, right, well, great.

1:19:20.560 --> 1:19:23.520
 You can turn around and buy risk five core from somebody else.

1:19:23.520 --> 1:19:27.080
 And there's an ecosystem of people that are all making different risk five cores with

1:19:27.080 --> 1:19:30.920
 different tradeoffs, which means that if you have more than one requirement, if you have

1:19:30.920 --> 1:19:34.960
 a family of products, you can probably find something in the risk five space that fits

1:19:34.960 --> 1:19:35.960
 your needs.

1:19:35.960 --> 1:19:40.960
 Whereas with, if you're talking about XA six, for example, it's Intel's only going to

1:19:40.960 --> 1:19:43.640
 bother to make certain classes of devices.

1:19:43.640 --> 1:19:44.640
 Right.

1:19:44.640 --> 1:19:46.640
 I see.

1:19:46.640 --> 1:19:54.960
 So maybe a weird question, but like if sci five is like infinitely successful in the

1:19:54.960 --> 1:19:58.160
 next 20, 30 years, what does the world look like?

1:19:58.160 --> 1:20:01.960
 So like, how does the world of computing change?

1:20:01.960 --> 1:20:06.640
 So too much diversity and hardware instruction sets, I think is bad.

1:20:06.640 --> 1:20:11.320
 Like we have a lot of people that are using lots of different instruction sets, particularly

1:20:11.320 --> 1:20:18.440
 in the embedded, the like very tiny microcontroller space, the thing in your toaster that are

1:20:18.440 --> 1:20:21.160
 just weird and different for historical reasons.

1:20:21.160 --> 1:20:27.280
 And so the compilers and the tool chains and the languages on top of them aren't there.

1:20:27.280 --> 1:20:32.560
 And so the developers for that software have to use really weird tools because the ecosystem

1:20:32.560 --> 1:20:34.280
 that supports is not big enough.

1:20:34.280 --> 1:20:35.680
 So I expect that will change, right?

1:20:35.680 --> 1:20:39.880
 People will have better tools and better languages, better features everywhere that then can

1:20:39.880 --> 1:20:43.360
 serve as many different points in the space.

1:20:43.360 --> 1:20:49.240
 And I think risk five will progressively eat more of the ecosystem because it can scale

1:20:49.240 --> 1:20:51.720
 up, it can scale down sideways left, right.

1:20:51.720 --> 1:20:56.360
 It's very flexible and very well considered and well designed instruction set.

1:20:56.360 --> 1:21:00.120
 I think when you look at sci five tackling silicon and how people build chips, which

1:21:00.120 --> 1:21:06.640
 is a very different space, that's where you say, I think we'll see a lot more custom

1:21:06.640 --> 1:21:07.640
 chips.

1:21:07.640 --> 1:21:12.800
 And that means that you get much more battery life, you get better, better tuned solutions

1:21:12.800 --> 1:21:18.320
 for your IOT thingy, you get, you get people to move faster.

1:21:18.320 --> 1:21:21.520
 You get the ability to have faster time to market, for example.

1:21:21.520 --> 1:21:26.120
 So how many custom, so first of all, on the IOT side of things, do you see the number

1:21:26.120 --> 1:21:30.320
 of smart toasters increasing exponentially?

1:21:30.320 --> 1:21:39.000
 So and if you do, like how much customization per toaster is there?

1:21:39.000 --> 1:21:44.160
 Do all toasters in the world run the same silicon, like the same design?

1:21:44.160 --> 1:21:46.200
 Or is it different companies have different design?

1:21:46.200 --> 1:21:49.000
 Like how much customization is possible here?

1:21:49.000 --> 1:21:52.520
 Well, a lot of it comes down to cost, right?

1:21:52.520 --> 1:21:57.560
 And so the way that chips work is you end up paying by the, one of the factors is the

1:21:57.560 --> 1:22:03.280
 size of the chip, and so what ends up happening just from an economic perspective is there's

1:22:03.280 --> 1:22:07.480
 only so many chips that get made in a year of a given design.

1:22:07.480 --> 1:22:11.560
 And so often what customers end up having to do is they end up having to pick up a chip

1:22:11.560 --> 1:22:16.720
 that exists that was built for somebody else so that they can then ship their product.

1:22:16.720 --> 1:22:20.000
 And the reason for that is they don't have the volume of the iPhone, they can't afford

1:22:20.000 --> 1:22:21.560
 to build a custom chip.

1:22:21.560 --> 1:22:27.000
 However, what that means is they're now buying an off the shelf chip that isn't really good,

1:22:27.000 --> 1:22:28.280
 isn't a perfect fit for their needs.

1:22:28.280 --> 1:22:31.880
 And so they're paying a lot of money for it because they're buying silicon that they're

1:22:31.880 --> 1:22:32.880
 not using.

1:22:32.880 --> 1:22:37.960
 Well, if you now reduce the cost of designing the chip, now you get a lot more chips.

1:22:37.960 --> 1:22:42.560
 And the more you reduce it, the easier it is to design chips.

1:22:42.560 --> 1:22:46.800
 The more the world keeps evolving and we get more AI accelerators, we get more other things,

1:22:46.800 --> 1:22:51.680
 we get more standards to talk to, we get 6G, right?

1:22:51.680 --> 1:22:54.880
 You get changes in the world that you want to be able to talk to these different things.

1:22:54.880 --> 1:22:58.840
 There's more diversity in the cross product of features that people want.

1:22:58.840 --> 1:23:03.440
 And that drives differentiated chips in another direction.

1:23:03.440 --> 1:23:07.960
 And so nobody really knows what the future looks like, but I think that there's a lot

1:23:07.960 --> 1:23:09.120
 of silicon in the future.

1:23:09.120 --> 1:23:13.880
 Speaking of the future, you said Moore's Law allegedly is dead.

1:23:13.880 --> 1:23:22.320
 So do you think, do you agree with Dave Patterson and many folks that Moore's Law is dead?

1:23:22.320 --> 1:23:28.880
 Moore, do you agree with Jim Keller, who was standing at the helm of the pirate ship saying

1:23:28.880 --> 1:23:31.240
 it's still alive?

1:23:31.240 --> 1:23:32.240
 Yeah.

1:23:32.240 --> 1:23:37.880
 Well, so I agree with what they're saying and different people are interpreting the

1:23:37.880 --> 1:23:39.800
 animal's law in different ways.

1:23:39.800 --> 1:23:46.200
 So Jim would say, there's another 1,000 X left in physics and we can continue to squeeze

1:23:46.200 --> 1:23:52.600
 the stone and make it faster and smaller and smaller geometries and all that kind of stuff.

1:23:52.600 --> 1:23:53.600
 He's right.

1:23:53.600 --> 1:23:58.720
 So Jim is absolutely right that there's a ton of progress left and we're not at the

1:23:58.720 --> 1:24:01.840
 limit of physics yet.

1:24:01.840 --> 1:24:05.040
 That's not really what Moore's Law is though.

1:24:05.040 --> 1:24:11.560
 If you look at what Moore's Law is, is that it's a very simple evaluation of, okay, well,

1:24:11.560 --> 1:24:16.360
 if you look at the cost per, I think it was cost per area and the most economic point in

1:24:16.360 --> 1:24:17.360
 that space.

1:24:17.360 --> 1:24:23.040
 And if you go look at the now quite old paper that describes this, Moore's Law has a specific

1:24:23.040 --> 1:24:25.560
 economic aspect to it.

1:24:25.560 --> 1:24:28.400
 And I think this is something that Dave and others often point out.

1:24:28.400 --> 1:24:31.400
 And so on a technicality, that's right.

1:24:31.400 --> 1:24:35.080
 I look at it from, so I can acknowledge both of those viewpoints.

1:24:35.080 --> 1:24:36.080
 They're both right.

1:24:36.080 --> 1:24:37.080
 They're both right.

1:24:37.080 --> 1:24:40.400
 I'll give you a third wrong viewpoint that may be right in its own way.

1:24:40.400 --> 1:24:45.960
 Which is single threaded performance doesn't improve like it used to.

1:24:45.960 --> 1:24:51.440
 And it used to be back when you got a, you know, a Pentium 66 or something and the year

1:24:51.440 --> 1:24:56.880
 before you had a Pentium 33 and now it's twice as fast, right?

1:24:56.880 --> 1:25:01.120
 Well it was twice as fast at doing exactly the same thing, okay?

1:25:01.120 --> 1:25:03.880
 Like literally the same program ran twice as fast.

1:25:03.880 --> 1:25:07.240
 You just wrote a check and waited a year, year and a half.

1:25:07.240 --> 1:25:12.000
 So that's what a lot of people think about Moore's Law and I think that is dead.

1:25:12.000 --> 1:25:16.440
 And so what we're seeing instead is we're pushing, we're pushing people to write software

1:25:16.440 --> 1:25:17.440
 in different ways.

1:25:17.440 --> 1:25:22.480
 And so we're pushing people to write CUDA so they can get GPU compute and the thousands

1:25:22.480 --> 1:25:23.480
 of cores on GPU.

1:25:23.480 --> 1:25:27.800
 We're talking about C programmers having to use P threads because they now have, you

1:25:27.800 --> 1:25:32.040
 know, 100 threads or 50 cores in a machine or something like that.

1:25:32.040 --> 1:25:35.320
 You're now talking about machine learning accelerators that are now domain specific.

1:25:35.320 --> 1:25:40.720
 And when you look at these kinds of use cases, you can still get performance.

1:25:40.720 --> 1:25:45.920
 And Jim will come up with cool things that utilize the silicon in new ways for sure.

1:25:45.920 --> 1:25:48.920
 But you're also going to change the programming model.

1:25:48.920 --> 1:25:51.520
 And now when you start talking about changing the programming model, that's when you come

1:25:51.520 --> 1:25:58.480
 back to languages and things like this too because often what you see is like you take

1:25:58.480 --> 1:25:59.800
 the C programming language, right?

1:25:59.800 --> 1:26:03.440
 The C programming language is designed for CPUs.

1:26:03.440 --> 1:26:07.640
 And so if you want to talk to GPU, now you're talking to its cousin, CUDA.

1:26:07.640 --> 1:26:08.640
 Okay.

1:26:08.640 --> 1:26:13.160
 CUDA is a different thing with a different set of tools, a different world, a different

1:26:13.160 --> 1:26:14.520
 way of thinking.

1:26:14.520 --> 1:26:16.600
 And we don't have one world that scales.

1:26:16.600 --> 1:26:18.440
 And I think that we can get there.

1:26:18.440 --> 1:26:21.120
 We can have one world that scales in a much better way.

1:26:21.120 --> 1:26:26.400
 On a small tangent, then I think most programming languages are designed for CPUs, for a single

1:26:26.400 --> 1:26:30.520
 core, even just in their spirit, even if they allow for parallelization.

1:26:30.520 --> 1:26:38.600
 So what does it look like for programming language to have parallelization or massive parallelization

1:26:38.600 --> 1:26:41.400
 as its first principle?

1:26:41.400 --> 1:26:46.480
 So the canonical example of this is the hardware design world.

1:26:46.480 --> 1:26:52.760
 So Verilog, VHDL, these kinds of languages, they're what's called a high level synthesis

1:26:52.760 --> 1:26:53.760
 language.

1:26:53.760 --> 1:26:56.960
 This is the thing people design chips in.

1:26:56.960 --> 1:27:02.920
 When you're designing a chip, it's kind of like a brain where you have infinite parallelism.

1:27:02.920 --> 1:27:06.080
 You're like laying down transistors.

1:27:06.080 --> 1:27:07.080
 Transistors are always running.

1:27:07.080 --> 1:27:08.080
 Okay.

1:27:08.080 --> 1:27:11.920
 And so you're not saying, run this transistor, then this transistor, then this transistor.

1:27:11.920 --> 1:27:13.320
 It's like your brain.

1:27:13.320 --> 1:27:15.320
 Your neurons are always just doing something.

1:27:15.320 --> 1:27:16.320
 They're not clocked.

1:27:16.320 --> 1:27:20.320
 They're just doing their thing.

1:27:20.320 --> 1:27:24.680
 And so when you design a chip, or when you design a CPU, when you design a GPU, when

1:27:24.680 --> 1:27:29.120
 you design, when you're laying down the transistors, similarly, you're talking about, well, okay,

1:27:29.120 --> 1:27:31.400
 well, how do these things communicate?

1:27:31.400 --> 1:27:33.040
 And so these languages exist.

1:27:33.040 --> 1:27:36.040
 Verilog is a kind of mixed example of that.

1:27:36.040 --> 1:27:37.560
 Now, these languages are really great.

1:27:37.560 --> 1:27:39.240
 Yeah, at a very low level.

1:27:39.240 --> 1:27:40.240
 Yeah.

1:27:40.240 --> 1:27:41.240
 They're very low level.

1:27:41.240 --> 1:27:42.600
 And abstraction is necessary here.

1:27:42.600 --> 1:27:49.080
 And there's different approaches with that, and it's itself a very complicated world.

1:27:49.080 --> 1:27:50.800
 But it's implicitly parallel.

1:27:50.800 --> 1:27:57.880
 And so having that as a, as the domain that you program towards makes it so that by default,

1:27:57.880 --> 1:27:59.040
 you get parallel systems.

1:27:59.040 --> 1:28:04.240
 If you look at CUDA, CUDA is a point halfway in the space where in CUDA, when you write

1:28:04.240 --> 1:28:08.200
 a CUDA kernel for your GPU, it feels like you're writing a scalar program.

1:28:08.200 --> 1:28:11.040
 So you're like, you have ifs, you have for loops, stuff like this, you're just writing

1:28:11.040 --> 1:28:12.760
 normal, normal code.

1:28:12.760 --> 1:28:16.800
 But what happens outside of that in your driver is that it actually is running you on like

1:28:16.800 --> 1:28:18.960
 a thousand things at once, right?

1:28:18.960 --> 1:28:24.000
 And so it's parallel, but it has pulled it out of the programming model.

1:28:24.000 --> 1:28:29.640
 And so now you as a programmer are working in a simpler world, and it's solved that for

1:28:29.640 --> 1:28:30.640
 you.

1:28:30.640 --> 1:28:31.640
 All right.

1:28:31.640 --> 1:28:35.520
 How do you take the language like Swift?

1:28:35.520 --> 1:28:40.840
 You know, if we think about GPUs, but also ASICs, maybe if we can dance back and forth

1:28:40.840 --> 1:28:46.840
 between hardware and software, is, you know, how do you design for these features to be

1:28:46.840 --> 1:28:53.160
 able to program, make it a first class citizen to be able to do like Swift for TensorFlow,

1:28:53.160 --> 1:28:59.600
 to be able to do machine learning on current hardware, but also future hardware like TPUs

1:28:59.600 --> 1:29:02.760
 and all kinds of ASICs that I'm sure will be popping up more and more.

1:29:02.760 --> 1:29:03.760
 Yeah.

1:29:03.760 --> 1:29:06.720
 Well, so a lot of this comes down to this whole idea of having the nuts and bolts underneath

1:29:06.720 --> 1:29:08.720
 the covers that work really well.

1:29:08.720 --> 1:29:13.200
 So you need, if you're talking to TPUs, you need, you know, MLIR or XLA or one of these

1:29:13.200 --> 1:29:17.640
 compilers that talks to TPUs to build on top of, okay?

1:29:17.640 --> 1:29:21.440
 And if you're talking to circuits, you need to figure out how to lay down the transistors

1:29:21.440 --> 1:29:24.640
 and how to organize it and how to set up clocking and like all the domain problems that you

1:29:24.640 --> 1:29:27.520
 get with circuits.

1:29:27.520 --> 1:29:29.240
 Then you have to decide how to explain it to a human.

1:29:29.240 --> 1:29:30.720
 What is EY?

1:29:30.720 --> 1:29:31.720
 Right.

1:29:31.720 --> 1:29:36.560
 And if you do it right, that's a library problem, not a language problem.

1:29:36.560 --> 1:29:41.680
 And that works if you have a library or a language which allows your library to write

1:29:41.680 --> 1:29:47.000
 things that feel native in the language by implementing libraries, because then you can

1:29:47.000 --> 1:29:52.600
 innovate in programming models without having to change your syntax again and have to invent

1:29:52.600 --> 1:29:57.760
 new code formatting tools and like all the other things that languages come with.

1:29:57.760 --> 1:30:00.040
 And this gets really interesting.

1:30:00.040 --> 1:30:06.160
 And so if you look at this space, the interesting thing once you separate out syntax becomes

1:30:06.160 --> 1:30:07.920
 what is that programming model?

1:30:07.920 --> 1:30:14.400
 And so do you want the CUDA style, I write one program and it runs in many places?

1:30:14.400 --> 1:30:16.920
 Do you want the implicitly parallel model?

1:30:16.920 --> 1:30:17.920
 How do you reason about that?

1:30:17.920 --> 1:30:24.200
 How do you give developers, you know, chip architects the ability to express their intent?

1:30:24.200 --> 1:30:29.400
 And that comes into this whole design question of how do you detect bugs quickly so you don't

1:30:29.400 --> 1:30:32.720
 have to tape out a chip to find out it's wrong ideally, right?

1:30:32.720 --> 1:30:35.640
 How do you, and you know, this is a spectrum.

1:30:35.640 --> 1:30:40.580
 How do you make it so that people feel productive so their turnaround time is very quick?

1:30:40.580 --> 1:30:42.680
 All these things are really hard problems.

1:30:42.680 --> 1:30:47.960
 And in this world, I think that not a lot of effort has been put into that design problem

1:30:47.960 --> 1:30:50.600
 and thinking about the layering and other pieces.

1:30:50.600 --> 1:30:55.560
 Well, you've, on the topic of concurrency, you've written the Swift concurrency manifest.

1:30:55.560 --> 1:30:57.960
 I think it's kind of interesting.

1:30:57.960 --> 1:31:02.520
 Anything that has the word manifesto in is very interesting.

1:31:02.520 --> 1:31:07.480
 Can you summarize the key ideas of each of the five parts you've written about?

1:31:07.480 --> 1:31:09.000
 So what is a manifesto?

1:31:09.000 --> 1:31:10.000
 Yes.

1:31:10.000 --> 1:31:11.960
 How about, we start there.

1:31:11.960 --> 1:31:17.480
 So in the Swift community, we have this problem, which is on the one hand, you want to have

1:31:17.480 --> 1:31:21.480
 relatively small proposals that you can kind of fit in your head.

1:31:21.480 --> 1:31:26.080
 You can understand the details at a very fine grain level that move the world forward.

1:31:26.080 --> 1:31:29.160
 But then you also have these big arcs, okay?

1:31:29.160 --> 1:31:33.080
 And often when you're working on something that is a big arc, but you're tackling it

1:31:33.080 --> 1:31:36.920
 in small pieces, you have this question of, how do I know I'm not doing a random walk?

1:31:36.920 --> 1:31:38.320
 Where are we going?

1:31:38.320 --> 1:31:39.920
 Like, how does this add up?

1:31:39.920 --> 1:31:45.000
 Furthermore, when you start that first, the first small step, what terminology do you

1:31:45.000 --> 1:31:46.000
 use?

1:31:46.000 --> 1:31:47.000
 How do we think about it?

1:31:47.000 --> 1:31:48.000
 What is better and worse in the space?

1:31:48.000 --> 1:31:49.000
 What are the principles?

1:31:49.000 --> 1:31:50.000
 What are we trying to achieve?

1:31:50.000 --> 1:31:54.040
 And so what a manifesto in the Swift community does is it starts to say, hey, well, let's

1:31:54.040 --> 1:31:58.600
 step back from the details of everything and let's paint a broad picture to talk about

1:31:58.600 --> 1:32:01.400
 how what we're trying to achieve.

1:32:01.400 --> 1:32:02.960
 Let's give an example design point.

1:32:02.960 --> 1:32:07.320
 Let's try to paint the big picture so that then we can zero in on the individual steps

1:32:07.320 --> 1:32:09.800
 and make sure that we're making good progress.

1:32:09.800 --> 1:32:13.960
 And so the Swift concurrency manifesto is something I wrote three years ago.

1:32:13.960 --> 1:32:18.920
 It's been a while, maybe more, trying to do that for Swift in concurrency.

1:32:18.920 --> 1:32:25.400
 It starts with some fairly simple things, like making the observation that when you

1:32:25.400 --> 1:32:29.080
 have multiple different computers or multiple different threads that are communicating, it's

1:32:29.080 --> 1:32:32.120
 best for them to be asynchronous.

1:32:32.120 --> 1:32:35.880
 And so you need things to be able to run separately and then communicate with each other.

1:32:35.880 --> 1:32:37.560
 And this means asynchronous.

1:32:37.560 --> 1:32:41.880
 And this means that you need a way to modeling asynchronous communication.

1:32:41.880 --> 1:32:44.000
 Many languages have features like this.

1:32:44.000 --> 1:32:45.520
 Async await is a popular one.

1:32:45.520 --> 1:32:49.520
 And so that's what I think is very likely in Swift.

1:32:49.520 --> 1:32:53.760
 But as you start building this tower of abstractions, it's not just about how do you write this?

1:32:53.760 --> 1:32:57.600
 You then reach into the, how do you get memory safety?

1:32:57.600 --> 1:32:58.600
 Because you want correctness.

1:32:58.600 --> 1:33:01.800
 You want debugability and sanity for developers.

1:33:01.800 --> 1:33:06.720
 And how do you get that memory safety into the language?

1:33:06.720 --> 1:33:11.000
 So if you take a language like Go or C or any of these languages, you get what's called

1:33:11.000 --> 1:33:15.360
 a race condition when two different threads or Go routines or whatever touch the same

1:33:15.360 --> 1:33:17.520
 point in memory, right?

1:33:17.520 --> 1:33:24.640
 This is a huge like maddening problem to debug because it's not reproducible generally.

1:33:24.640 --> 1:33:28.520
 And so there's tools, there's a whole ecosystem of solutions that built up around this.

1:33:28.520 --> 1:33:31.200
 But it's a huge problem when you're writing concurrent code.

1:33:31.200 --> 1:33:35.920
 And so with Swift, this whole value semantics thing is really powerful there because it turns

1:33:35.920 --> 1:33:40.840
 out that math and copies actually work even in concurrent worlds.

1:33:40.840 --> 1:33:44.560
 And so you get a lot of safety just out of the box, but there are also some hard problems

1:33:44.560 --> 1:33:47.160
 and it talks about some of that.

1:33:47.160 --> 1:33:50.560
 When you start building up to the next level up and you start talking beyond memory safety,

1:33:50.560 --> 1:33:53.080
 you have to talk about what is the programmer model?

1:33:53.080 --> 1:33:54.400
 How does a human think about this?

1:33:54.400 --> 1:33:59.320
 So a developer that's trying to build a program think about this and it proposes a really

1:33:59.320 --> 1:34:02.440
 old model with a new spin called actors.

1:34:02.440 --> 1:34:08.240
 Actors are about saying we have islands of single threadedness logically.

1:34:08.240 --> 1:34:12.640
 So you write something that feels like it's one programming, one program running in a

1:34:12.640 --> 1:34:18.080
 unit, and then it communicates asynchronously with other things.

1:34:18.080 --> 1:34:21.800
 And so making that expressive and natural feel good, be the first thing you reach for

1:34:21.800 --> 1:34:26.120
 and being safe by default is a big part of the design of that proposal.

1:34:26.120 --> 1:34:29.920
 When you start going beyond that, now you start to say, cool, well, these things that

1:34:29.920 --> 1:34:32.360
 communicate asynchronously, they don't have to share memory.

1:34:32.360 --> 1:34:36.200
 Well, if they don't have to share memory and they're sending messages to each other, why

1:34:36.200 --> 1:34:39.360
 do they have to be in the same process?

1:34:39.360 --> 1:34:42.800
 These things should be able to be in different processes on your machine.

1:34:42.800 --> 1:34:44.200
 And why just processes?

1:34:44.200 --> 1:34:46.800
 Well, why not different machines?

1:34:46.800 --> 1:34:51.880
 And so now you have a very nice gradual transition towards distributed programming.

1:34:51.880 --> 1:34:56.560
 And of course, when you start talking about the big future, the manifesto doesn't go

1:34:56.560 --> 1:34:57.560
 into it.

1:34:57.560 --> 1:35:05.080
 But accelerators are things you talk to asynchronously by sending messages to them, and how do you

1:35:05.080 --> 1:35:06.080
 program those?

1:35:06.080 --> 1:35:08.280
 Well, that gets very interesting.

1:35:08.280 --> 1:35:10.100
 That's not in the proposal.

1:35:10.100 --> 1:35:17.440
 And how much do you want to make that explicit, like the control of that whole process explicit

1:35:17.440 --> 1:35:18.440
 to the programmer?

1:35:18.440 --> 1:35:19.440
 Yeah, good question.

1:35:19.440 --> 1:35:25.400
 So when you're designing any of these kinds of features or language features or even libraries,

1:35:25.400 --> 1:35:29.800
 you have this really hard trade off that you have to make, which is how much is it magic

1:35:29.800 --> 1:35:32.200
 or how much is it in the human's control?

1:35:32.200 --> 1:35:34.880
 How much can they predict and control it?

1:35:34.880 --> 1:35:40.400
 What do you do when the default case is the wrong case?

1:35:40.400 --> 1:35:48.840
 And so when you're designing a system, I won't name names, but there are systems where it's

1:35:48.840 --> 1:35:52.720
 really easy to get started, and then you jump it.

1:35:52.720 --> 1:35:54.480
 So let's pick like logo.

1:35:54.480 --> 1:35:55.680
 So something like this.

1:35:55.680 --> 1:35:57.160
 So it's really easy to get started.

1:35:57.160 --> 1:35:59.760
 It's really designed for teaching kids.

1:35:59.760 --> 1:36:03.320
 But as you get into it, you hit a ceiling, and then you can't go any higher.

1:36:03.320 --> 1:36:04.320
 And then what do you do?

1:36:04.320 --> 1:36:07.200
 You have to go switch to a different world and rewrite all your code.

1:36:07.200 --> 1:36:09.160
 And this logo is a silly example here.

1:36:09.160 --> 1:36:11.440
 This exists in many other languages.

1:36:11.440 --> 1:36:15.320
 With Python, you would say like concurrency, right?

1:36:15.320 --> 1:36:17.400
 So Python has the global interpreter lock.

1:36:17.400 --> 1:36:19.520
 So threading is challenging in Python.

1:36:19.520 --> 1:36:23.960
 And so if you start writing a large scale application in Python, and then suddenly you

1:36:23.960 --> 1:36:30.600
 need concurrency, you're kind of stuck with a series of bad trade offs, right?

1:36:30.600 --> 1:36:37.200
 There's other ways to go where you say foist all the complexity on the user all at once.

1:36:37.200 --> 1:36:38.920
 And that's also bad in a different way.

1:36:38.920 --> 1:36:45.680
 And so what I prefer is building a simple model that you can explain that then has an

1:36:45.680 --> 1:36:47.040
 escape hatch.

1:36:47.040 --> 1:36:52.480
 So you get in, you have guardrails, memory safety works like this in Swift where you

1:36:52.480 --> 1:36:57.160
 can start with, by default, if you use all the standard things, it's memory safe, you're

1:36:57.160 --> 1:36:58.720
 not going to shoot your foot off.

1:36:58.720 --> 1:37:04.440
 But if you want to get a C level pointer to something, you can explicitly do that.

1:37:04.440 --> 1:37:07.840
 But by default, it's, there's guardrails.

1:37:07.840 --> 1:37:08.840
 There's guardrails.

1:37:08.840 --> 1:37:09.840
 Okay.

1:37:09.840 --> 1:37:17.520
 So, but like, you know, whose job is it to figure out which part of the code is paralyzable?

1:37:17.520 --> 1:37:21.160
 So in the case of the proposal, it is the humans job.

1:37:21.160 --> 1:37:24.440
 So they decide how to architect their application.

1:37:24.440 --> 1:37:29.240
 And then the runtime in the compiler is very predictable.

1:37:29.240 --> 1:37:33.320
 And so this, this is in contrast to like, there's a long body of work, including on

1:37:33.320 --> 1:37:37.160
 Fortran for auto paralyzing compilers.

1:37:37.160 --> 1:37:39.760
 And this is an example of a bad thing.

1:37:39.760 --> 1:37:43.840
 And my, so as a compiler person, I can write on compiler people.

1:37:43.840 --> 1:37:47.800
 Often compiler people will say, cool, since I can't change the code, I'm going to write

1:37:47.800 --> 1:37:52.400
 my compiler that then takes this unmodified code and makes it go way faster on this machine.

1:37:52.400 --> 1:37:53.400
 Okay.

1:37:53.400 --> 1:37:56.360
 And so it does pattern matching.

1:37:56.360 --> 1:37:58.640
 It does like really deep analysis.

1:37:58.640 --> 1:37:59.640
 Compiler people are really smart.

1:37:59.640 --> 1:38:02.600
 And so they like want to like do something really clever and tricky.

1:38:02.600 --> 1:38:06.680
 And you get like 10 X speed up by taking like an array of structures and turn it into a

1:38:06.680 --> 1:38:09.400
 structure of arrays or something because it's so much better for memory.

1:38:09.400 --> 1:38:12.000
 Like there's bodies, like tons of tricks.

1:38:12.000 --> 1:38:13.000
 Yeah.

1:38:13.000 --> 1:38:14.000
 They love optimization.

1:38:14.000 --> 1:38:15.000
 Yeah.

1:38:15.000 --> 1:38:16.000
 You love optimization.

1:38:16.000 --> 1:38:17.000
 Everyone loves optimization.

1:38:17.000 --> 1:38:20.280
 Well, and it's just this promise of build with my compiler and your thing goes fast.

1:38:20.280 --> 1:38:21.280
 Yeah.

1:38:21.280 --> 1:38:22.280
 Right.

1:38:22.280 --> 1:38:23.280
 But here's the problem.

1:38:23.280 --> 1:38:24.760
 You write a program.

1:38:24.760 --> 1:38:25.760
 You run it with my compiler.

1:38:25.760 --> 1:38:26.760
 It goes fast.

1:38:26.760 --> 1:38:27.760
 You're very happy.

1:38:27.760 --> 1:38:28.760
 Wow.

1:38:28.760 --> 1:38:29.760
 It's so much faster than the other compiler.

1:38:29.760 --> 1:38:30.760
 Yeah.

1:38:30.760 --> 1:38:32.960
 Then you go and you got a feature to your program where you refactor some code and suddenly

1:38:32.960 --> 1:38:34.960
 you got a 10 X loss in performance.

1:38:34.960 --> 1:38:35.960
 Yeah.

1:38:35.960 --> 1:38:36.960
 Well, why?

1:38:36.960 --> 1:38:37.960
 What just happened there?

1:38:37.960 --> 1:38:38.960
 What just happened?

1:38:38.960 --> 1:38:43.080
 There's you, the heuristic, the pattern matching the compiler, whatever analysis it was doing

1:38:43.080 --> 1:38:48.280
 just got defeated because you didn't inline a function or something, right?

1:38:48.280 --> 1:38:49.440
 As a user, you don't know.

1:38:49.440 --> 1:38:50.440
 You don't want to know.

1:38:50.440 --> 1:38:51.440
 That was the whole point.

1:38:51.440 --> 1:38:52.840
 You don't want to know how the compiler works.

1:38:52.840 --> 1:38:54.560
 You don't want to know how the memory hierarchy works.

1:38:54.560 --> 1:38:57.440
 You don't want to know how it got parallelized across all these things.

1:38:57.440 --> 1:39:02.240
 You wanted that abstract away from you, but then the magic is lost as soon as you did

1:39:02.240 --> 1:39:05.080
 something and you fall off a performance cliff.

1:39:05.080 --> 1:39:07.960
 And now you're in this funny position where what do I do?

1:39:07.960 --> 1:39:08.960
 I don't change my code.

1:39:08.960 --> 1:39:11.000
 I don't fix that bug.

1:39:11.000 --> 1:39:12.000
 It costs 10 X performance.

1:39:12.000 --> 1:39:13.440
 Now what do I do?

1:39:13.440 --> 1:39:16.360
 Well, this is the problem with unpredictable performance, right?

1:39:16.360 --> 1:39:19.640
 If you care about performance, predictability is a very important thing.

1:39:19.640 --> 1:39:25.840
 And so what the proposal does is it provides architectural patterns for being able to lay

1:39:25.840 --> 1:39:29.920
 out your code, gives you full control over that, makes it really simple so you can explain

1:39:29.920 --> 1:39:35.560
 it, and then if you want to scale out in different ways, you have full control over

1:39:35.560 --> 1:39:36.560
 that.

1:39:36.560 --> 1:39:43.480
 So in your sense, the intuition is for a compiler is too hard to do automated parallelization.

1:39:43.480 --> 1:39:50.560
 Because the compilers do stuff automatically that's incredibly impressive for other things.

1:39:50.560 --> 1:39:54.560
 But for parallelization, we're not even close to there.

1:39:54.560 --> 1:39:56.240
 Well, it depends on the programming model.

1:39:56.240 --> 1:39:58.440
 So there's many different kinds of compilers.

1:39:58.440 --> 1:40:02.560
 And so if you talk about like a C compiler, a Swift compiler or something like that where

1:40:02.560 --> 1:40:07.000
 you're writing imperative code, parallelizing that and reasoning about all the pointers

1:40:07.000 --> 1:40:10.200
 and stuff like that is a very difficult problem.

1:40:10.200 --> 1:40:15.640
 Now, if you switch domains, so there's this cool thing called machine learning, right?

1:40:15.640 --> 1:40:21.160
 So machine learning nerds among other endearing things like solving cat detectors and other

1:40:21.160 --> 1:40:28.120
 things like that have done this amazing breakthrough of producing a programming model, operations

1:40:28.120 --> 1:40:33.520
 that you can pose together that has raised levels of abstraction high enough that suddenly

1:40:33.520 --> 1:40:36.880
 you can have auto parallelizing compilers.

1:40:36.880 --> 1:40:42.680
 You can write a model using TensorFlow and have it run on 1,024 nodes of a TPU.

1:40:42.680 --> 1:40:44.080
 Yeah, that's true.

1:40:44.080 --> 1:40:48.280
 I didn't even think about like, you know, because there's so much flexibility in the

1:40:48.280 --> 1:40:52.800
 design of architectures that ultimately boiled down to a graph that's parallelizable for

1:40:52.800 --> 1:40:54.520
 you, paralyzed for you.

1:40:54.520 --> 1:40:57.800
 And if you think about it, that's pretty cool, right?

1:40:57.800 --> 1:41:02.000
 And you think about batching, for example, as a way of being able to exploit more parallelism.

1:41:02.000 --> 1:41:03.000
 Yeah.

1:41:03.000 --> 1:41:05.480
 Like that's a very simple thing that now is very powerful.

1:41:05.480 --> 1:41:09.320
 It didn't come out of the programming language, nerds, right, those people, like that came

1:41:09.320 --> 1:41:13.520
 out of people that are just looking to solve a problem and use a few GPUs and organically

1:41:13.520 --> 1:41:18.720
 developed by the community of people focusing on machine learning as an incredibly powerful

1:41:18.720 --> 1:41:22.960
 abstraction layer that enables the compiler people to go and exploit that.

1:41:22.960 --> 1:41:26.960
 And now you can drive supercomputers from Python.

1:41:26.960 --> 1:41:27.960
 That's pretty cool.

1:41:27.960 --> 1:41:28.960
 That's amazing.

1:41:28.960 --> 1:41:34.360
 So just to pause on that, because I'm not sufficiently low level, I forget to admire the beauty and

1:41:34.360 --> 1:41:40.960
 power of that, but maybe just to linger on it, like what does it take to run in your

1:41:40.960 --> 1:41:41.960
 network fast?

1:41:41.960 --> 1:41:44.040
 Like how hard is that compilation?

1:41:44.040 --> 1:41:45.040
 It's really hard.

1:41:45.040 --> 1:41:50.560
 So we just skipped, you said like it's amazing that that's a thing, but yeah, how hard is

1:41:50.560 --> 1:41:51.560
 that of a thing?

1:41:51.560 --> 1:41:52.560
 It's hard.

1:41:52.560 --> 1:41:58.120
 And I would say that not all of the systems are really great, including the ones I helped

1:41:58.120 --> 1:41:59.120
 build.

1:41:59.120 --> 1:42:00.600
 So there's a lot of work left to be done there.

1:42:00.600 --> 1:42:04.520
 Is it the compiler nerds working on that, or is it a whole new group of people?

1:42:04.520 --> 1:42:09.880
 Well, it's a full stack problem, including compiler people, including APIs, so like Keras

1:42:09.880 --> 1:42:16.320
 and the module API and PyTorch and Jax, and there's a bunch of people pushing on all the

1:42:16.320 --> 1:42:20.240
 different parts of these things, because when you look at it, it's both how do I express

1:42:20.240 --> 1:42:21.240
 the computation?

1:42:21.240 --> 1:42:22.240
 Do I stack up layers?

1:42:22.240 --> 1:42:23.240
 Well, cool.

1:42:23.240 --> 1:42:26.920
 Like setting up a linear sequence of layers is great for the simple case, but how do

1:42:26.920 --> 1:42:27.920
 I do the hard case?

1:42:27.920 --> 1:42:29.440
 How do I do reinforcement learning?

1:42:29.440 --> 1:42:32.880
 Well, now I need to integrate my application logic in this, right?

1:42:32.880 --> 1:42:36.760
 Then it's, you know, the next level down of how do you represent that for the runtime?

1:42:36.760 --> 1:42:39.200
 How do you get hardware abstraction?

1:42:39.200 --> 1:42:41.960
 And then you get to the next level down of saying like, forget about abstraction.

1:42:41.960 --> 1:42:47.400
 How do I get the peak performance out of my TPU or my iPhone accelerator or whatever,

1:42:47.400 --> 1:42:48.400
 right?

1:42:48.400 --> 1:42:49.400
 And all these different things.

1:42:49.400 --> 1:42:53.800
 And so this is a layered problem with a lot of really interesting design and work going

1:42:53.800 --> 1:42:57.160
 on in the space and a lot of really smart people working on it.

1:42:57.160 --> 1:43:01.000
 Application learning is a very well funded area of investment right now.

1:43:01.000 --> 1:43:03.040
 And so there's a lot of progress being made.

1:43:03.040 --> 1:43:09.080
 So how much innovation is there on the lower level, so closer to the ASIC, so redesigning

1:43:09.080 --> 1:43:13.240
 the hardware or redesigning concurrently compilers with that hardware?

1:43:13.240 --> 1:43:20.520
 Is that, like if you were to predict the biggest, you know, the equivalent of Moore's law improvements

1:43:20.520 --> 1:43:26.080
 in the inference and the training of neural networks and just all of that, where is that

1:43:26.080 --> 1:43:27.080
 going to come from, you think?

1:43:27.080 --> 1:43:28.080
 So you get scalability.

1:43:28.080 --> 1:43:29.080
 You have different things.

1:43:29.080 --> 1:43:35.080
 And so you get, you know, Jim Keller shrinking process technology, you get three nanometer

1:43:35.080 --> 1:43:38.480
 instead of five or seven or 10 or 28 or whatever.

1:43:38.480 --> 1:43:41.440
 And so that that marches forward and that provides improvements.

1:43:41.440 --> 1:43:44.120
 You get architectural level performance.

1:43:44.120 --> 1:43:48.920
 And so the, you know, a TPU with a matrix multiply unit and a systolic array is much

1:43:48.920 --> 1:43:54.480
 more efficient than having a scaler core doing multiplies and ads and things like that.

1:43:54.480 --> 1:43:58.760
 You then get system level improvements.

1:43:58.760 --> 1:44:03.400
 So how you talk to memory, how you talk across a cluster of machines, how you scale out, how

1:44:03.400 --> 1:44:08.840
 you have fast interconnects between machines, you then get system level programming models.

1:44:08.840 --> 1:44:11.400
 So now that you have all this hardware, how do you utilize it?

1:44:11.400 --> 1:44:14.680
 You then have algorithmic breakthroughs where you say, hey, wow, cool.

1:44:14.680 --> 1:44:20.560
 Instead of training in, you know, ResNet 50 and a week, I'm now training it in, you know,

1:44:20.560 --> 1:44:21.560
 25 seconds.

1:44:21.560 --> 1:44:22.560
 Yeah.

1:44:22.560 --> 1:44:23.560
 And now opening up.

1:44:23.560 --> 1:44:29.000
 And this is a combination of, you know, new, new optimizers and new, new, new just training

1:44:29.000 --> 1:44:33.680
 regimens and different, different approaches to train and, and all of these things come

1:44:33.680 --> 1:44:36.240
 together to push the world forward.

1:44:36.240 --> 1:44:40.160
 That was a beautiful exposition.

1:44:40.160 --> 1:44:45.360
 But if you were to force to bet all your money on one of these, would you?

1:44:45.360 --> 1:44:46.360
 Why do we have to?

1:44:46.360 --> 1:44:47.360
 That's that.

1:44:47.360 --> 1:44:50.920
 Fortunately, we have people working on all of this.

1:44:50.920 --> 1:44:52.360
 It's an exciting time, right?

1:44:52.360 --> 1:44:57.520
 So I mean, you know, open the eye, did this little paper showing the algorithmic improvement

1:44:57.520 --> 1:44:58.520
 you can get.

1:44:58.520 --> 1:45:00.920
 It's been, you know, improving exponentially.

1:45:00.920 --> 1:45:07.200
 I haven't quite seen the same kind of analysis on other layers of the stack, I'm sure it's

1:45:07.200 --> 1:45:09.120
 also improving significantly.

1:45:09.120 --> 1:45:12.280
 I just, it's a, it's a nice intuition builder.

1:45:12.280 --> 1:45:18.480
 I mean, there's a reason why Moore's law, that's the beauty of Moore's law is somebody

1:45:18.480 --> 1:45:21.480
 writes a paper that makes a ridiculous prediction.

1:45:21.480 --> 1:45:23.000
 Yeah.

1:45:23.000 --> 1:45:27.640
 And it, you know, becomes reality in a sense.

1:45:27.640 --> 1:45:33.000
 There's something about these narratives when you, when Chris Lattener on a silly little

1:45:33.000 --> 1:45:38.880
 podcast makes all bets, all his money on a particular thing, somehow it can have a ripple

1:45:38.880 --> 1:45:40.960
 effect of actually becoming real.

1:45:40.960 --> 1:45:46.680
 That's an interesting aspect of it because like, it might have been, you know, we focused

1:45:46.680 --> 1:45:52.920
 with Moore's law, most of the computing industry really, really focused on the hardware.

1:45:52.920 --> 1:45:56.800
 I mean, software innovation, I don't know how much software innovation there was in

1:45:56.800 --> 1:45:57.800
 terms of efficiency.

1:45:57.800 --> 1:45:59.920
 What Intel give a bill takes away, right?

1:45:59.920 --> 1:46:00.920
 Yeah.

1:46:00.920 --> 1:46:03.440
 I mean, compilers improved significantly also.

1:46:03.440 --> 1:46:04.440
 All right.

1:46:04.440 --> 1:46:05.440
 Well, not really.

1:46:05.440 --> 1:46:09.880
 So actually, I mean, some, I'm joking about how software's gotten slower pretty much as

1:46:09.880 --> 1:46:13.400
 fast as hardware got better, at least through the nineties.

1:46:13.400 --> 1:46:17.880
 There's another joke, another law in compilers, which is called, I think it's called Probstein's

1:46:17.880 --> 1:46:26.400
 law, which is compilers double the performance of any given code every 18 years.

1:46:26.400 --> 1:46:27.400
 So they move slowly.

1:46:27.400 --> 1:46:28.400
 Yeah.

1:46:28.400 --> 1:46:30.960
 Well, so well, yeah, it's exponential also.

1:46:30.960 --> 1:46:31.960
 Yeah.

1:46:31.960 --> 1:46:37.160
 You're making progress, but there again, it's not about the power of compilers is not just

1:46:37.160 --> 1:46:39.360
 about how do you make the same thing go faster.

1:46:39.360 --> 1:46:41.840
 It's how do you unlock the new hardware?

1:46:41.840 --> 1:46:43.840
 A new chip came out.

1:46:43.840 --> 1:46:44.840
 How do you utilize it?

1:46:44.840 --> 1:46:47.200
 You say, oh, the programming model, how do we make people more productive?

1:46:47.200 --> 1:46:52.280
 How do we have better error messages?

1:46:52.280 --> 1:46:58.200
 Even such mundane things like how do I generate a very specific error message about your code?

1:46:58.200 --> 1:47:02.000
 It actually makes people happy because then they know how to fix it, right?

1:47:02.000 --> 1:47:04.680
 And it comes back to how do you help people get their job done?

1:47:04.680 --> 1:47:05.680
 Yeah.

1:47:05.680 --> 1:47:06.680
 And yeah.

1:47:06.680 --> 1:47:13.000
 It's a world of exponentially increasing smart toasters, how do you expand computing

1:47:13.000 --> 1:47:16.560
 to all these kinds of devices?

1:47:16.560 --> 1:47:20.560
 Do you see this world where just everything's a computing surface?

1:47:20.560 --> 1:47:22.400
 You see that possibility?

1:47:22.400 --> 1:47:23.640
 Just everything's a computer?

1:47:23.640 --> 1:47:24.640
 Yeah.

1:47:24.640 --> 1:47:26.760
 I don't see any reason that that couldn't be achieved.

1:47:26.760 --> 1:47:33.040
 It turns out that sand goes into glass and glass is pretty useful too.

1:47:33.040 --> 1:47:35.400
 And, you know, why not?

1:47:35.400 --> 1:47:36.400
 Why not?

1:47:36.400 --> 1:47:37.400
 Yeah.

1:47:37.400 --> 1:47:46.040
 A very important question then if we're living in a simulation and the simulation is running

1:47:46.040 --> 1:47:52.000
 a computer, like what's the architecture of that computer, do you think?

1:47:52.000 --> 1:47:54.680
 So you're saying is it a quantum system?

1:47:54.680 --> 1:47:55.680
 Is it a...

1:47:55.680 --> 1:47:57.680
 Yeah, like this whole quantum discussion, is it needed?

1:47:57.680 --> 1:48:05.320
 Or can we run it with a risk five architecture, a bunch of CPUs?

1:48:05.320 --> 1:48:08.080
 I think it comes down to the right tool for the job.

1:48:08.080 --> 1:48:09.080
 And so...

1:48:09.080 --> 1:48:10.080
 And what's the compiler?

1:48:10.080 --> 1:48:11.080
 Yeah.

1:48:11.080 --> 1:48:12.080
 Exactly.

1:48:12.080 --> 1:48:13.080
 That's my question.

1:48:13.080 --> 1:48:14.080
 Did I get that job?

1:48:14.080 --> 1:48:16.920
 Made the universe compiler.

1:48:16.920 --> 1:48:25.720
 And so there, as far as we know, quantum systems are the bottom of the pile of turtles so far.

1:48:25.720 --> 1:48:32.440
 And so we don't know efficient ways to implement quantum systems without using quantum computers.

1:48:32.440 --> 1:48:35.200
 And that's totally outside of everything we've talked about.

1:48:35.200 --> 1:48:37.160
 But who runs that quantum computer?

1:48:37.160 --> 1:48:38.160
 Yeah.

1:48:38.160 --> 1:48:39.160
 Right.

1:48:39.160 --> 1:48:44.440
 So if we really are living in a simulation, then is it bigger quantum computers?

1:48:44.440 --> 1:48:45.440
 Is it different ones?

1:48:45.440 --> 1:48:46.440
 Like how does that work?

1:48:46.440 --> 1:48:47.440
 How does that scale?

1:48:47.440 --> 1:48:50.040
 Well, it's the same size.

1:48:50.040 --> 1:48:51.040
 It's the same size.

1:48:51.040 --> 1:48:54.200
 But then the thought of the simulation is that you don't have to run the whole thing

1:48:54.200 --> 1:48:56.880
 that, you know, we humans are cognitively very limited.

1:48:56.880 --> 1:48:57.880
 Do you do checkpoints?

1:48:57.880 --> 1:49:00.880
 Checkpoints, yeah.

1:49:00.880 --> 1:49:06.960
 And if we, the point at which we humans, so you basically do minimal amount of, what

1:49:06.960 --> 1:49:12.280
 is it, the SWIFT does, unwrite, copy unwrite.

1:49:12.280 --> 1:49:15.760
 So you only adjust the simulation.

1:49:15.760 --> 1:49:17.640
 Parallel universe theories, right?

1:49:17.640 --> 1:49:23.040
 And so every time a decision's made, somebody opens the shorting in your box, then there's

1:49:23.040 --> 1:49:24.040
 a fork.

1:49:24.040 --> 1:49:25.920
 And then this could happen.

1:49:25.920 --> 1:49:30.440
 And then thank you for considering the possibility.

1:49:30.440 --> 1:49:31.440
 But yeah.

1:49:31.440 --> 1:49:36.440
 So it may not require, you know, the entirety of the universe to simulate it, but it's interesting

1:49:36.440 --> 1:49:43.600
 to think about as we create this, this higher and higher fidelity systems.

1:49:43.600 --> 1:49:47.560
 But I do want to ask on the, on the quantum computer side, because everything we've talked

1:49:47.560 --> 1:49:52.960
 about with us, with your work with sci fi, with everything with compilers, none of that

1:49:52.960 --> 1:49:55.160
 includes quantum computers, right?

1:49:55.160 --> 1:49:56.160
 That's true.

1:49:56.160 --> 1:50:05.760
 So if you ever thought about what a, you know, this whole serious engineering work of quantum

1:50:05.760 --> 1:50:10.760
 computers looks like of compilers, of architectures, all of that kind of stuff.

1:50:10.760 --> 1:50:11.760
 So I've looked at it a little bit.

1:50:11.760 --> 1:50:16.720
 I'd know almost nothing about it, which means that at some point I will have to find an excuse

1:50:16.720 --> 1:50:17.720
 to get involved.

1:50:17.720 --> 1:50:18.720
 Because that's how it works.

1:50:18.720 --> 1:50:22.840
 But do you think, do you think that's the thing to be, like, is, with your little tingly

1:50:22.840 --> 1:50:26.360
 senses of the timing of when to be involved?

1:50:26.360 --> 1:50:27.360
 Is it not yet?

1:50:27.360 --> 1:50:32.120
 Well, so, so the thing I do really well is I jump into messy systems and figure out how

1:50:32.120 --> 1:50:37.760
 to make them figure out what the truth in the situation is, try to figure out what, what

1:50:37.760 --> 1:50:42.080
 the unifying theory is, how to like factor the complexity, how to find a beautiful answer

1:50:42.080 --> 1:50:46.400
 to a problem that has been well studied and lots of people have bashed their heads against

1:50:46.400 --> 1:50:47.400
 it.

1:50:47.400 --> 1:50:52.760
 I don't know that quantum computers are mature enough and accessible enough to be figured

1:50:52.760 --> 1:50:53.760
 out yet.

1:50:53.760 --> 1:50:54.760
 Right.

1:50:54.760 --> 1:51:00.200
 And the, I think the open question with quantum computers is, is there a useful problem that

1:51:00.200 --> 1:51:05.880
 gets solved with a quantum computer that makes it worth the economic cost of like having

1:51:05.880 --> 1:51:11.560
 one of these things and having, having legions of people that, that, that set it up.

1:51:11.560 --> 1:51:12.840
 You go back to the fifties, right?

1:51:12.840 --> 1:51:17.040
 And there's the projections of the world can, will only need seven, seven computers.

1:51:17.040 --> 1:51:18.040
 Right.

1:51:18.040 --> 1:51:19.040
 Yeah.

1:51:19.040 --> 1:51:22.120
 Well, and part of that was that people hadn't figured out what's useful for.

1:51:22.120 --> 1:51:23.320
 What are the algorithms we want to run?

1:51:23.320 --> 1:51:24.320
 What are the problems that get solved?

1:51:24.320 --> 1:51:28.920
 And this comes back to how do we make the world better either economically or making

1:51:28.920 --> 1:51:33.440
 somebody's life better or like solving a problem that wasn't solved before, things like this.

1:51:33.440 --> 1:51:37.080
 And I think that just we're a little bit too early in that development cycle because it's

1:51:37.080 --> 1:51:41.640
 still like literally a science project, not a negative connotation, right?

1:51:41.640 --> 1:51:45.560
 It's literally a science project and the progress there's amazing.

1:51:45.560 --> 1:51:50.760
 And so I don't know if it's 10 years away, if it's two years away, exactly where that

1:51:50.760 --> 1:51:58.600
 breakthrough happens, but you look at machine learning, it, we went through a few winners

1:51:58.600 --> 1:52:03.720
 before the AlexNet transition and then suddenly it had its breakout moment and that was the

1:52:03.720 --> 1:52:07.800
 catalyst that then drove the talent flocking into it.

1:52:07.800 --> 1:52:10.320
 That's what drove the economic applications of it.

1:52:10.320 --> 1:52:14.640
 That's what drove the, the technology to go faster because you know, have more minds

1:52:14.640 --> 1:52:16.000
 thrown at the problem.

1:52:16.000 --> 1:52:21.800
 This is what caused like a serious knee and deep learning and the algorithms that we're

1:52:21.800 --> 1:52:22.800
 using.

1:52:22.800 --> 1:52:25.600
 And, and so I think that's what quantum needs to go through.

1:52:25.600 --> 1:52:30.520
 And so right now it's in that, that formidable finding itself, getting the, the, like literally

1:52:30.520 --> 1:52:33.320
 the physics figured out.

1:52:33.320 --> 1:52:37.480
 And then it has to figure out the application that makes it so that's useful.

1:52:37.480 --> 1:52:40.800
 Yeah, but I'm not skeptical that I think that will happen.

1:52:40.800 --> 1:52:43.480
 I think it's just, you know, 10 years away, something like that.

1:52:43.480 --> 1:52:49.160
 I forgot to ask what programming language do you think the simulation is written in?

1:52:49.160 --> 1:52:50.160
 Probably Lisp.

1:52:50.160 --> 1:52:58.120
 So not Swift, like if you were to bet, you were to bet, I'll just leave it at that.

1:52:58.120 --> 1:53:01.760
 So I mean, we've mentioned that you worked with all these companies with, with talked

1:53:01.760 --> 1:53:04.040
 about all these projects.

1:53:04.040 --> 1:53:10.320
 It's kind of, if we just step back and zoom out about the way you did that work and we

1:53:10.320 --> 1:53:15.760
 look at COVID times, this pandemic we're living through, that may, if I look at the

1:53:15.760 --> 1:53:20.280
 way Silicon Valley folks are talking about it, the way MIT is talking about it, this

1:53:20.280 --> 1:53:28.400
 might last for a long time, not just the virus, but the, the remote nature.

1:53:28.400 --> 1:53:29.400
 The economic impact.

1:53:29.400 --> 1:53:30.400
 Yeah.

1:53:30.400 --> 1:53:31.400
 Yeah.

1:53:31.400 --> 1:53:32.400
 It's going to be a mess.

1:53:32.400 --> 1:53:34.480
 Do you think, what's your prediction?

1:53:34.480 --> 1:53:42.960
 I mean, from sci fi to Google to, to just all the places you worked in, just Silicon

1:53:42.960 --> 1:53:44.360
 Valley, you're in the middle of it.

1:53:44.360 --> 1:53:46.560
 What do you think is, how is this whole place going to change?

1:53:46.560 --> 1:53:47.560
 Yeah.

1:53:47.560 --> 1:53:50.440
 So, I mean, I, I really can only speak to the tech perspective.

1:53:50.440 --> 1:53:54.160
 I am in that bubble.

1:53:54.160 --> 1:53:58.160
 I think it's going to be really interesting because the, you know, the zoom culture of

1:53:58.160 --> 1:54:02.120
 being remote and on video chat all the time has really interesting effects on people.

1:54:02.120 --> 1:54:05.120
 So on the one hand, it's a great normalizer.

1:54:05.120 --> 1:54:10.600
 It's a normalizer that I think will help communities of people that have traditionally

1:54:10.600 --> 1:54:16.600
 been underrepresented because now you're taking, in some cases, a face off because you don't

1:54:16.600 --> 1:54:18.880
 have to have a camera going, right?

1:54:18.880 --> 1:54:21.840
 And so you can have conversations without physical appearance being part of the, part

1:54:21.840 --> 1:54:24.600
 of the dynamic, which is pretty powerful.

1:54:24.600 --> 1:54:28.080
 You're taking remote employees that have already been remote and you're saying you're

1:54:28.080 --> 1:54:33.560
 now on the same level and footing as everybody else, nobody gets whiteboards.

1:54:33.560 --> 1:54:36.360
 You're not going to be the one person that doesn't get to be participating in the whiteboard

1:54:36.360 --> 1:54:39.440
 conversation and that's pretty powerful.

1:54:39.440 --> 1:54:45.320
 You've got, you're forcing people to think asynchronously in some cases because it's

1:54:45.320 --> 1:54:50.000
 hard to just, just get people physically together and the bumping into each other forces people

1:54:50.000 --> 1:54:52.880
 to find new ways to solve those problems.

1:54:52.880 --> 1:54:56.800
 And I think that that leads to more inclusive behavior, which is good.

1:54:56.800 --> 1:55:01.040
 On the other hand, it's also, it just sucks, right?

1:55:01.040 --> 1:55:08.600
 And so the, the nature, the, the actual communication or it just sucks being not in, with people

1:55:08.600 --> 1:55:11.680
 like on a daily basis and collaborating with them.

1:55:11.680 --> 1:55:12.680
 Yeah.

1:55:12.680 --> 1:55:13.680
 All of that.

1:55:13.680 --> 1:55:15.720
 I mean, everything, this whole situation is terrible.

1:55:15.720 --> 1:55:22.280
 What I meant primarily was the, I think that the most humans like working physically with

1:55:22.280 --> 1:55:23.280
 humans.

1:55:23.280 --> 1:55:27.400
 And this is something that not everybody, but many people are programmed to do.

1:55:27.400 --> 1:55:30.640
 And I think that we get something out of that that is very hard to express, at least for

1:55:30.640 --> 1:55:31.640
 me.

1:55:31.640 --> 1:55:37.000
 And so maybe this isn't true of everybody, but, and so the question to me is, you know,

1:55:37.000 --> 1:55:41.960
 when you get through that time of adaptation, right, you get out of March and April and

1:55:41.960 --> 1:55:46.400
 you get into December and you get into next March, if it's not changed, right?

1:55:46.400 --> 1:55:47.880
 It's already terrifying.

1:55:47.880 --> 1:55:52.000
 Well, you think about that and you think about what is the nature of work and how do, how

1:55:52.000 --> 1:55:53.000
 do we adapt?

1:55:53.000 --> 1:55:54.960
 Well, humans are very adaptable species, right?

1:55:54.960 --> 1:55:57.320
 And we can, we can learn things.

1:55:57.320 --> 1:56:00.680
 And when we're forced to, and there's a catalyst to make that happen.

1:56:00.680 --> 1:56:04.640
 And so what is it that comes out of this and are we better or worse off, right?

1:56:04.640 --> 1:56:08.600
 I think that, you know, you look at the Bay Area, housing prices are insane.

1:56:08.600 --> 1:56:09.600
 Well, why?

1:56:09.600 --> 1:56:15.280
 Well, there's a high incentive to be physically located because if you don't have proximity,

1:56:15.280 --> 1:56:18.520
 you end up paying for it and commute, right?

1:56:18.520 --> 1:56:23.680
 And there's, there has been huge social pressure in terms of like, you will be there for the

1:56:23.680 --> 1:56:24.680
 meeting, right?

1:56:24.680 --> 1:56:26.680
 Or whatever scenario it is.

1:56:26.680 --> 1:56:28.200
 And I think that's going to be way better.

1:56:28.200 --> 1:56:31.880
 I think it's going to be much more of the norm to have remote employees and I think

1:56:31.880 --> 1:56:33.400
 this is going to be really great.

1:56:33.400 --> 1:56:37.200
 Do you, do you have friends or do you hear of people moving?

1:56:37.200 --> 1:56:43.720
 I know one family friend that moved, they moved back to Michigan and, you know, they

1:56:43.720 --> 1:56:49.480
 were a family with three kids living in a small apartment and like, we're going insane,

1:56:49.480 --> 1:56:50.960
 right?

1:56:50.960 --> 1:56:54.360
 And they're in tech, husband works for Google.

1:56:54.360 --> 1:56:59.880
 So first of all, friends of mine have, are in the process of or are, have already lost

1:56:59.880 --> 1:57:00.880
 the business.

1:57:00.880 --> 1:57:03.440
 The thing that represents their passion, their dream.

1:57:03.440 --> 1:57:07.240
 It could be small entrepreneur projects, but it could be large businesses like people that

1:57:07.240 --> 1:57:10.400
 run gyms, like restaurants, like tons of things.

1:57:10.400 --> 1:57:16.280
 So, but also just people like look at themselves in the mirror and ask the question of like,

1:57:16.280 --> 1:57:17.680
 what do I want to do in life?

1:57:17.680 --> 1:57:21.960
 For some reason they don't, haven't done it until COVID like, they really ask that question

1:57:21.960 --> 1:57:27.960
 and that results often in moving or leaving the company here with starting your business

1:57:27.960 --> 1:57:30.640
 or transitioning to a different company.

1:57:30.640 --> 1:57:34.240
 Do you think we're going to see that a lot?

1:57:34.240 --> 1:57:36.760
 Like, well, I can't speak to that.

1:57:36.760 --> 1:57:40.080
 I mean, we're definitely going to see it at a higher frequency than we did before.

1:57:40.080 --> 1:57:45.760
 Just because I think what you're trying to say is there are decisions that you make yourself

1:57:45.760 --> 1:57:47.920
 and big life decisions that you make yourself.

1:57:47.920 --> 1:57:50.560
 And like, I'm going to like quit my job and start a new thing.

1:57:50.560 --> 1:57:53.000
 There's also decisions that get made for you.

1:57:53.000 --> 1:57:54.720
 Like I got fired from my job.

1:57:54.720 --> 1:57:55.720
 What am I going to do?

1:57:55.720 --> 1:57:56.720
 Right?

1:57:56.720 --> 1:58:01.040
 And that's not a decision that you think about, but you're forced to act.

1:58:01.040 --> 1:58:05.240
 And so I think that those you're forced to act kind of moments where like, you know,

1:58:05.240 --> 1:58:10.400
 the global pandemic comes and wipes out the economy and now your business doesn't exist.

1:58:10.400 --> 1:58:12.560
 I think that does lead to more reflection, right?

1:58:12.560 --> 1:58:15.080
 Because you're less anchored on what you have.

1:58:15.080 --> 1:58:20.600
 And it's not a, what do I have to lose versus what do I have to gain AB comparison?

1:58:20.600 --> 1:58:22.080
 It's more of a fresh slate.

1:58:22.080 --> 1:58:23.080
 Cool.

1:58:23.080 --> 1:58:24.440
 I could do anything now.

1:58:24.440 --> 1:58:26.520
 Do I want to do the same thing I was doing?

1:58:26.520 --> 1:58:28.440
 Did that make me happy?

1:58:28.440 --> 1:58:33.200
 Is this now time to go back to college and take a class and learn new skill?

1:58:33.200 --> 1:58:36.320
 Is this, is this a time to spend time with family?

1:58:36.320 --> 1:58:40.440
 If you can afford to do that, is this time to like, you know, literally move into the

1:58:40.440 --> 1:58:41.440
 parents?

1:58:41.440 --> 1:58:42.440
 Right?

1:58:42.440 --> 1:58:47.760
 I mean, all these things that were not normative before suddenly become, I think, very, the

1:58:47.760 --> 1:58:48.760
 value system has changed.

1:58:48.760 --> 1:58:54.440
 And I think that's actually a good thing in the short term, at least, because it leads

1:58:54.440 --> 1:59:00.680
 to, you know, there's kind of been an over optimization along one, one set of priorities

1:59:00.680 --> 1:59:05.120
 for the world, and now maybe we'll get to a more balanced and more interesting world

1:59:05.120 --> 1:59:06.760
 where people are doing different things.

1:59:06.760 --> 1:59:07.760
 I think it could be good.

1:59:07.760 --> 1:59:10.440
 I think there could be more innovation that comes out of it, for example.

1:59:10.440 --> 1:59:13.840
 What do you think about all the social chaos when in the middle of like,

1:59:13.840 --> 1:59:14.840
 It sucks.

1:59:14.840 --> 1:59:20.600
 You think it's, let me ask you, I hope, do you think it's all going to be okay?

1:59:20.600 --> 1:59:23.720
 Well, I think humanity will survive.

1:59:23.720 --> 1:59:27.160
 The, from the next extension, look, we're not all going to kill, yeah, well.

1:59:27.160 --> 1:59:28.160
 Yeah.

1:59:28.160 --> 1:59:29.560
 I don't think the virus is going to kill all the humans.

1:59:29.560 --> 1:59:31.960
 I don't think all the humans are going to kill all the humans.

1:59:31.960 --> 1:59:42.520
 I think that's unlikely, but I look at it as progress requires a catalyst, right?

1:59:42.520 --> 1:59:47.720
 So you need a reason for people to be willing to do things that are uncomfortable.

1:59:47.720 --> 1:59:54.840
 I think that the U.S., at least, but I think the world in general is a pretty unoptimal

1:59:54.840 --> 1:59:56.880
 place to live in for a lot of people.

1:59:56.880 --> 2:00:00.680
 And I think that what we're seeing right now is we're seeing a lot of unhappiness.

2:00:00.680 --> 2:00:05.720
 And because of all the pressure, because of all the badness in the world that's coming

2:00:05.720 --> 2:00:09.000
 together, it's really kind of igniting some of that debate that should have happened a

2:00:09.000 --> 2:00:10.000
 long time ago, right?

2:00:10.000 --> 2:00:11.680
 I mean, I think that we'll see more progress.

2:00:11.680 --> 2:00:15.160
 You're asking about, offline, you're asking about politics and wouldn't be great if politics

2:00:15.160 --> 2:00:18.280
 moved faster because there's all these problems in the world and we can move it.

2:00:18.280 --> 2:00:22.400
 Well, people are intentional or inherently conservative.

2:00:22.400 --> 2:00:26.640
 And so if you're talking about conservative people, particularly if they have heavy burdens

2:00:26.640 --> 2:00:32.200
 on their shoulders, because they represent literally thousands of people, it makes sense

2:00:32.200 --> 2:00:33.200
 to be conservative.

2:00:33.200 --> 2:00:37.280
 But on the other hand, when you need change, how do you get it?

2:00:37.280 --> 2:00:40.840
 The global pandemic will probably lead to some change.

2:00:40.840 --> 2:00:46.880
 And it's not a directed plan, but I think that it leads to people asking really interesting

2:00:46.880 --> 2:00:47.880
 questions.

2:00:47.880 --> 2:00:50.200
 And some of those questions should have been asked a long time ago.

2:00:50.200 --> 2:00:53.520
 Well, let me know if you've observed this as well.

2:00:53.520 --> 2:00:56.960
 Something that's bothered me in the machine learning community, I'm guessing it might

2:00:56.960 --> 2:01:03.920
 be prevalent in other places, is something that feels like in 2020 increased level of

2:01:03.920 --> 2:01:05.920
 toxicity.

2:01:05.920 --> 2:01:17.120
 People are just quicker to pile on, they're just harsh on each other to mob, pick a person

2:01:17.120 --> 2:01:26.480
 that screwed up and make it a big thing.

2:01:26.480 --> 2:01:29.000
 Have you observed that in other places?

2:01:29.000 --> 2:01:30.160
 Is there some way out of this?

2:01:30.160 --> 2:01:34.600
 I think there's an inherent thing in humanity that's kind of an us versus them thing, which

2:01:34.600 --> 2:01:37.200
 is that you want to succeed and how do you succeed?

2:01:37.200 --> 2:01:39.720
 Well, it's relative to somebody else.

2:01:39.720 --> 2:01:45.880
 And so what's happening, at least in some part, is that with the internet and with online

2:01:45.880 --> 2:01:52.880
 communication, the world's getting smaller, and so we're having some of the social ties

2:01:52.880 --> 2:02:03.320
 of my town versus your town's football team turn into much larger and yet shallower problems.

2:02:03.320 --> 2:02:09.440
 And people don't have time, the incentives, clickbait and all these things really feed

2:02:09.440 --> 2:02:12.080
 into this machine, and I don't know where that goes.

2:02:12.080 --> 2:02:19.760
 Yeah, the reason I think about that, I mentioned to you this offline a little bit, but I have

2:02:19.760 --> 2:02:26.280
 a few difficult conversations scheduled, some of them political related, some of them within

2:02:26.280 --> 2:02:31.200
 the community, difficult personalities that went through some stuff, I mean, one of them

2:02:31.200 --> 2:02:39.160
 I've talked before, we'll talk again is Yann LeCun, he got a little crap on Twitter for

2:02:39.160 --> 2:02:43.000
 talking about a particular paper and the bias within a data set.

2:02:43.000 --> 2:02:51.280
 And then there's been a huge in my view, and I'm only comfortable saying it irrational,

2:02:51.280 --> 2:02:57.240
 over exaggerated pile on on his comments, because he made pretty basic comments about

2:02:57.240 --> 2:03:02.480
 the fact that if there's bias in the data, there's going to be bias in the results.

2:03:02.480 --> 2:03:07.360
 So we should not have bias in the data, but people piled on to him because he said he

2:03:07.360 --> 2:03:13.320
 trivialized the problem of bias, like it's a lot more than just bias in the data.

2:03:13.320 --> 2:03:16.640
 But like, yes, that's a very good point.

2:03:16.640 --> 2:03:19.880
 But that's that's not what he was saying, it's not what he was saying.

2:03:19.880 --> 2:03:28.840
 And the response, like the implied response that he's basically sexist and racist is something

2:03:28.840 --> 2:03:33.160
 that completely drives away the possibility of nuanced discussion.

2:03:33.160 --> 2:03:40.360
 One nice thing about like a pocket long form conversation is you can talk it out.

2:03:40.360 --> 2:03:42.960
 You can lay your reasoning out.

2:03:42.960 --> 2:03:47.800
 And even if you're wrong, you can still show that you're a good human being underneath

2:03:47.800 --> 2:03:48.800
 it.

2:03:48.800 --> 2:03:50.600
 You know, your point about you can't have a productive discussion.

2:03:50.600 --> 2:03:55.160
 Well, how do you get to that point where people can turn, they can learn, they can listen,

2:03:55.160 --> 2:04:01.120
 they can think, they can engage versus just being a shallow like, like, and then keep

2:04:01.120 --> 2:04:02.120
 moving, right?

2:04:02.120 --> 2:04:07.080
 And I don't think that that progress really comes from that, right?

2:04:07.080 --> 2:04:09.800
 And I don't think that one should expect that.

2:04:09.800 --> 2:04:14.080
 I think that you'd see that as reinforcing individual circles and the us versus them

2:04:14.080 --> 2:04:15.080
 thing.

2:04:15.080 --> 2:04:17.080
 And I think that's fairly divisive.

2:04:17.080 --> 2:04:24.200
 Yeah, I think there's a big role in like the people that bother me most on Twitter when

2:04:24.200 --> 2:04:30.280
 I observe things is not the people who get very emotional, angry, like over the top.

2:04:30.280 --> 2:04:34.000
 It's the people who like prop them up.

2:04:34.000 --> 2:04:40.600
 It's all the, it's, it's, I think what should be the, we should teach each other is to be

2:04:40.600 --> 2:04:42.600
 sort of empathetic.

2:04:42.600 --> 2:04:46.560
 The thing that it's really easy to forget, particularly on like Twitter or the internet

2:04:46.560 --> 2:04:49.760
 or the email, is that sometimes people just have a bad day.

2:04:49.760 --> 2:04:50.760
 Yeah.

2:04:50.760 --> 2:04:51.760
 Right.

2:04:51.760 --> 2:04:55.000
 You have a bad day or you're like, I've been in this situation where it's like between

2:04:55.000 --> 2:04:58.640
 meetings, like fire off a quick response in emails because I want to like help get

2:04:58.640 --> 2:05:03.600
 something unblocked phrase it really objectively wrong.

2:05:03.600 --> 2:05:09.600
 I screwed up and suddenly this is now something that sticks with people and it's not because

2:05:09.600 --> 2:05:10.600
 they're bad.

2:05:10.600 --> 2:05:15.840
 It's not because you're bad, just psychology of like, you said a thing, it sticks with

2:05:15.840 --> 2:05:16.840
 you.

2:05:16.840 --> 2:05:20.600
 You didn't mean it that way, but it really impacted somebody because the way they interpreted

2:05:20.600 --> 2:05:21.600
 it.

2:05:21.600 --> 2:05:25.360
 And this is just an aspect of working together as humans and I have a lot of optimism in

2:05:25.360 --> 2:05:29.600
 the long term, the very long term about what we as humanity can do, but I think that's

2:05:29.600 --> 2:05:31.280
 going to be, it's just always a rough ride.

2:05:31.280 --> 2:05:36.280
 And you came into this by saying like, what is COVID and all the social strife that's

2:05:36.280 --> 2:05:38.400
 happening right now mean?

2:05:38.400 --> 2:05:42.680
 And I think that it's really bad in the short term, but I think it will lead to progress.

2:05:42.680 --> 2:05:45.000
 And for that, I'm very thankful.

2:05:45.000 --> 2:05:46.000
 Yeah.

2:05:46.000 --> 2:05:47.840
 It's painful in the short term though.

2:05:47.840 --> 2:05:48.840
 Well, yeah.

2:05:48.840 --> 2:05:54.960
 I mean, people are out of jobs, like some people can't eat, like it's horrible.

2:05:54.960 --> 2:05:57.080
 But you know, it's progress.

2:05:57.080 --> 2:05:58.520
 So we'll see what happens.

2:05:58.520 --> 2:06:03.640
 I mean, the real question is when you look back 10 years, 20 years, 100 years from now,

2:06:03.640 --> 2:06:06.800
 how do we evaluate the decisions that are being made right now?

2:06:06.800 --> 2:06:10.480
 I think that's really the way you can frame that and look at it.

2:06:10.480 --> 2:06:15.360
 And you say, you know, you integrate across all the short term horribleness that's happening

2:06:15.360 --> 2:06:19.640
 and you look at what that means and is the, you know, improvement across the world or

2:06:19.640 --> 2:06:24.640
 the regression across the world significant enough to make it a good or a bad thing.

2:06:24.640 --> 2:06:26.280
 I think that's the question.

2:06:26.280 --> 2:06:27.280
 Yeah.

2:06:27.280 --> 2:06:29.480
 And for that, it's good to study history.

2:06:29.480 --> 2:06:33.920
 I mean, one of the big problems for me right now is I'm reading the rise and fall of the

2:06:33.920 --> 2:06:34.920
 third Reich.

2:06:34.920 --> 2:06:35.920
 Okay.

2:06:35.920 --> 2:06:36.920
 Light reading.

2:06:36.920 --> 2:06:42.920
 So it's everything is just, I just see parallels and it means it's, it's, you have to be really

2:06:42.920 --> 2:06:49.440
 careful not to overstep it, but just the thing that worries me the most is the pain that

2:06:49.440 --> 2:06:56.440
 people feel when a few things combined, which is like economic depression, which is quite

2:06:56.440 --> 2:06:58.240
 possible in this country.

2:06:58.240 --> 2:07:04.040
 And then just being disrespected by, in some kind of way, which the German people were

2:07:04.040 --> 2:07:10.880
 really disrespected by most of the world, like in a way that's over the top, that something

2:07:10.880 --> 2:07:18.280
 can build up and then all you need is a charismatic leader just to go either positive or negative

2:07:18.280 --> 2:07:21.360
 in both work as long as they're charismatic.

2:07:21.360 --> 2:07:26.320
 And it's taking advantage of, again, that, that inflection point that the world's in

2:07:26.320 --> 2:07:29.960
 and what they do with it could be good or bad.

2:07:29.960 --> 2:07:34.880
 And so it's, it's a good way to think about times now, like on the individual level, what

2:07:34.880 --> 2:07:40.040
 we decide to do is when, when history is written, you know, 30 years from now, what happened

2:07:40.040 --> 2:07:47.000
 in 2020, probably history is going to remember 2020 either for good or bad.

2:07:47.000 --> 2:07:49.480
 And it's like up to us to write it, so it's good.

2:07:49.480 --> 2:07:54.240
 Well, one of the things I've observed that I find fascinating is most people act as

2:07:54.240 --> 2:07:56.520
 though the world doesn't change.

2:07:56.520 --> 2:08:02.480
 You make decision knowingly, right, you make a decision where you're predicting the future

2:08:02.480 --> 2:08:04.880
 based on what you've seen in the recent past.

2:08:04.880 --> 2:08:08.080
 And so if something's always been, it's rained every single day, then of course you expect

2:08:08.080 --> 2:08:10.120
 it to rain today too, right?

2:08:10.120 --> 2:08:15.720
 On the other hand, the world changes all the time, yeah, constantly, like for better and

2:08:15.720 --> 2:08:17.040
 for worse.

2:08:17.040 --> 2:08:21.200
 And so the question is, if you're interested in something that's not right, what is the

2:08:21.200 --> 2:08:24.480
 inflection point that led to a change and you can look to history for this?

2:08:24.480 --> 2:08:28.960
 Like what is, what is the catalyst that led to that, that explosion that led to that bill

2:08:28.960 --> 2:08:33.480
 that led to the, like you, you can kind of work your way backwards from that.

2:08:33.480 --> 2:08:37.080
 And maybe if you pull together the right people and you get the right ideas together, you

2:08:37.080 --> 2:08:40.760
 can actually start driving that change and doing it in a way that's productive and hurts

2:08:40.760 --> 2:08:41.760
 fewer people.

2:08:41.760 --> 2:08:44.960
 Yeah, like a single person, a single event can turn all of this.

2:08:44.960 --> 2:08:45.960
 Absolutely.

2:08:45.960 --> 2:08:46.960
 Everything starts somewhere.

2:08:46.960 --> 2:08:50.840
 And often it's a combination of multiple factors, but, but yeah, this is, these, these

2:08:50.840 --> 2:08:52.720
 things can be engineered.

2:08:52.720 --> 2:08:57.440
 That's actually the optimistic view that I'm a long term optimist on pretty much everything

2:08:57.440 --> 2:09:01.680
 and human nature, you know, we can look to all the negative things that the humanity

2:09:01.680 --> 2:09:08.960
 has all the pettiness and all the like self self servingness and the just the, the cruelty,

2:09:08.960 --> 2:09:09.960
 right?

2:09:09.960 --> 2:09:13.440
 The, the biases, the just humans can be very horrible.

2:09:13.440 --> 2:09:17.400
 But on the other hand, we're capable of amazing things.

2:09:17.400 --> 2:09:23.680
 And, and the progress across, you know, 100 year chunks is striking.

2:09:23.680 --> 2:09:27.440
 And even across decades, it's, we've come a long ways and there's still a long ways

2:09:27.440 --> 2:09:29.440
 to go, but that doesn't mean that we've stopped.

2:09:29.440 --> 2:09:30.440
 Yeah.

2:09:30.440 --> 2:09:35.000
 The kind of stuff we did in the last 100 years is, is unbelievable.

2:09:35.000 --> 2:09:37.440
 It's kind of scary to think what's going to happen this 100 years.

2:09:37.440 --> 2:09:42.400
 It's scary, like exciting, like scary in a sense that it's kind of sad that the kind

2:09:42.400 --> 2:09:47.000
 of technology is going to come out in 10, 20, 30 years will probably too old to really

2:09:47.000 --> 2:09:49.200
 appreciate because you don't grow up with it.

2:09:49.200 --> 2:09:54.000
 It'll be like kids these days with their virtual reality and their tiktoks and stuff

2:09:54.000 --> 2:09:55.000
 like this.

2:09:55.000 --> 2:10:00.960
 Like, how does this thing and like, come on, give me my, you know, static photo, you know,

2:10:00.960 --> 2:10:02.480
 my Commodore 64.

2:10:02.480 --> 2:10:03.480
 Yeah.

2:10:03.480 --> 2:10:04.480
 Exactly.

2:10:04.480 --> 2:10:05.480
 Okay.

2:10:05.480 --> 2:10:06.480
 Sorry, we kind of skipped over.

2:10:06.480 --> 2:10:15.080
 It asks on, you know, the machine learning world has been kind of inspired, their imagination

2:10:15.080 --> 2:10:18.720
 captivated with GPT three and these language models.

2:10:18.720 --> 2:10:22.360
 I thought it'd be cool to get your opinion on it.

2:10:22.360 --> 2:10:30.240
 What's your thoughts on this exciting world of, it connects to computation actually is

2:10:30.240 --> 2:10:36.880
 of language models that are huge and take multiple, many, many computers, not just to

2:10:36.880 --> 2:10:39.600
 train, but to also do inference on.

2:10:39.600 --> 2:10:40.600
 Sure.

2:10:40.600 --> 2:10:44.400
 Well, I mean, it depends on what you're speaking to there, but I mean, I think that there's

2:10:44.400 --> 2:10:49.520
 been a pretty well understood maximum deep learning that if you make the model bigger

2:10:49.520 --> 2:10:53.040
 and you shove more data into it, assuming you train it right and you have a good model

2:10:53.040 --> 2:10:55.920
 architecture that you'll get a better model out.

2:10:55.920 --> 2:10:59.840
 And so I'm wondering on GPT three was not that surprising.

2:10:59.840 --> 2:11:04.920
 On the other hand, a tremendous amount of engineering went into making it possible.

2:11:04.920 --> 2:11:07.040
 The implications of it are pretty huge.

2:11:07.040 --> 2:11:10.960
 I think that when GPT two came out, there was a very provocative blog post from open

2:11:10.960 --> 2:11:14.640
 AI talking about, you know, we're not going to release it because of the social damage

2:11:14.640 --> 2:11:18.600
 it could cause if it's misused.

2:11:18.600 --> 2:11:20.080
 I think that's still a concern.

2:11:20.080 --> 2:11:25.120
 I think that we need to look at how technology is applied and, you know, well meaning tools

2:11:25.120 --> 2:11:30.560
 can be applied in very horrible ways and they can have very profound impact on that.

2:11:30.560 --> 2:11:34.240
 I think the GPT three is a huge technical achievement.

2:11:34.240 --> 2:11:38.880
 And what will GPT four be will probably be bigger, more expensive to train.

2:11:38.880 --> 2:11:42.360
 Really cool architectural tricks.

2:11:42.360 --> 2:11:43.360
 What do you think?

2:11:43.360 --> 2:11:48.800
 Is there, I don't know how much thought you've done on distributed computing.

2:11:48.800 --> 2:11:54.000
 Is there, is there some technical challenges that are interesting that you're hopeful about

2:11:54.000 --> 2:12:01.200
 exploring in terms of, you know, a system that like a piece of code that, you know,

2:12:01.200 --> 2:12:09.440
 would GPT four, that might have, I don't know, hundreds of trillions of parameters which

2:12:09.440 --> 2:12:11.600
 have to run on thousands of computers.

2:12:11.600 --> 2:12:15.120
 Is there some, is there some hope that we can make that happen?

2:12:15.120 --> 2:12:16.120
 Yeah.

2:12:16.120 --> 2:12:21.720
 Well, I mean, today you can, you can write a check and get access to a thousand TPU cores

2:12:21.720 --> 2:12:26.040
 and do really interesting large scale training and inference and things like that in Google

2:12:26.040 --> 2:12:27.600
 cloud, for example, right.

2:12:27.600 --> 2:12:33.320
 And so I don't think it's a question about scales, a question about utility.

2:12:33.320 --> 2:12:38.080
 And when I look at the transformer series of architectures that the GPT series is based

2:12:38.080 --> 2:12:43.000
 on, it's really interesting to look at that because they're actually very simple designs.

2:12:43.000 --> 2:12:44.760
 They're not recurrent.

2:12:44.760 --> 2:12:47.520
 The training regimens are pretty simple.

2:12:47.520 --> 2:12:52.840
 And so they don't really reflect like human brains, right, but they're really good at

2:12:52.840 --> 2:12:57.560
 learning language models and they're unrolled enough that you get, you can simulate some

2:12:57.560 --> 2:12:59.280
 recurrence, right.

2:12:59.280 --> 2:13:03.120
 And so the question I think about is, where does this take us?

2:13:03.120 --> 2:13:07.720
 Like, so we can just keep scaling it, have more parameters, more data, more things, we'll

2:13:07.720 --> 2:13:09.600
 get a better result for sure.

2:13:09.600 --> 2:13:15.320
 But are there architectural techniques that can lead to progress at a faster pace, right?

2:13:15.320 --> 2:13:20.720
 This is when, you know, how do you get, instead of just like making it a constant time bigger,

2:13:20.720 --> 2:13:24.240
 how do you get like an algorithmic improvement out of this, right?

2:13:24.240 --> 2:13:30.520
 And whether it be a new training regimen, if it becomes sparse networks, for example,

2:13:30.520 --> 2:13:33.880
 human brains sparse, all these networks are dense.

2:13:33.880 --> 2:13:36.080
 The connectivity patterns can be very different.

2:13:36.080 --> 2:13:40.640
 I think this is where I get very interested and I'm way out of my league on the deep learning

2:13:40.640 --> 2:13:41.640
 side of this.

2:13:41.640 --> 2:13:43.760
 But I think that could lead to big breakthroughs.

2:13:43.760 --> 2:13:47.600
 When we talk about large scale networks, one of the things that Jeff Dean likes to talk

2:13:47.600 --> 2:13:53.640
 about and he's given a few talks on is this idea of having a sparsely gated mixture of

2:13:53.640 --> 2:13:59.600
 experts kind of a model where you have, you know, different nets that are trained and

2:13:59.600 --> 2:14:02.240
 are really good at certain kinds of tasks.

2:14:02.240 --> 2:14:05.960
 And so you have this distributor across a cluster and so you have a lot of different

2:14:05.960 --> 2:14:09.880
 computers that end up being kind of locally specialized in different demands.

2:14:09.880 --> 2:14:14.600
 And then when a query comes in, you gait it and use learn techniques to route to different

2:14:14.600 --> 2:14:15.600
 parts of the network.

2:14:15.600 --> 2:14:19.880
 And then you utilize the compute resources of the entire cluster by having specialization

2:14:19.880 --> 2:14:20.880
 within it.

2:14:20.880 --> 2:14:26.640
 And I don't know where that goes or when it starts to work, but I think things like that

2:14:26.640 --> 2:14:28.520
 could be really interesting as well.

2:14:28.520 --> 2:14:35.320
 And on the data side too, if you can think of data selection as a kind of programming.

2:14:35.320 --> 2:14:36.320
 Yeah.

2:14:36.320 --> 2:14:41.960
 I mean, at the center, if you look at like Karpathi talked about software 2.0, I mean,

2:14:41.960 --> 2:14:44.840
 in a sense, data is the programming.

2:14:44.840 --> 2:14:51.240
 So let me try to summarize Andre's position really quick before I disagree with it.

2:14:51.240 --> 2:14:53.520
 So Andre Karpathi is amazing.

2:14:53.520 --> 2:14:55.760
 So this is nothing personal with him.

2:14:55.760 --> 2:14:56.960
 He's an amazing engineer.

2:14:56.960 --> 2:14:59.240
 And also a good blog post writer.

2:14:59.240 --> 2:15:00.240
 Yeah.

2:15:00.240 --> 2:15:01.240
 Well, he's a great communicator.

2:15:01.240 --> 2:15:02.760
 I mean, he's just an amazing person.

2:15:02.760 --> 2:15:04.880
 He's also really sweet.

2:15:04.880 --> 2:15:09.360
 So his basic premise is that software is suboptimal.

2:15:09.360 --> 2:15:12.040
 I think we can all agree to that.

2:15:12.040 --> 2:15:16.040
 He also points out that deep learning and other learning based techniques are really

2:15:16.040 --> 2:15:22.040
 great because you can solve problems in more structured ways with less like ad hoc code

2:15:22.040 --> 2:15:25.200
 that people write out and don't write test cases for in some cases.

2:15:25.200 --> 2:15:27.960
 And so they don't even know if it works in the first place.

2:15:27.960 --> 2:15:34.560
 And so if you start replacing systems of imperative code with deep learning models,

2:15:34.560 --> 2:15:38.640
 then you get a better result.

2:15:38.640 --> 2:15:44.280
 And I think that he argues that software 2.0 is a pervasively learned set of models.

2:15:44.280 --> 2:15:46.240
 And you get away from writing code.

2:15:46.240 --> 2:15:50.560
 And he's given talks where he talks about swapping over more and more and more parts

2:15:50.560 --> 2:15:54.800
 of the code to being learned and driven that way.

2:15:54.800 --> 2:15:56.000
 I think that works.

2:15:56.000 --> 2:16:01.320
 And if you're predisposed to liking machine learning, then I think that that's definitely

2:16:01.320 --> 2:16:02.320
 a good thing.

2:16:02.320 --> 2:16:05.840
 And it's also good for accessibility in many ways because certain people are not going

2:16:05.840 --> 2:16:07.880
 to write C code or something.

2:16:07.880 --> 2:16:12.840
 And so having a data driven approach to do this kind of stuff I think can be very valuable.

2:16:12.840 --> 2:16:14.320
 On the other hand, there are huge trade offs.

2:16:14.320 --> 2:16:19.400
 It's not clear to me that software 2.0 is the answer.

2:16:19.400 --> 2:16:23.240
 And probably Andre wouldn't argue that it's the answer for every problem either.

2:16:23.240 --> 2:16:27.920
 But I look at machine learning as not a replacement for software 1.0.

2:16:27.920 --> 2:16:31.400
 I look at it as a new programming paradigm.

2:16:31.400 --> 2:16:37.120
 And so programming paradigms, when you look across domains, is structured programming

2:16:37.120 --> 2:16:40.480
 where you go tos to if, then, else.

2:16:40.480 --> 2:16:42.480
 Or functional programming from Lisp.

2:16:42.480 --> 2:16:45.960
 And you start talking about higher order functions and values and things like this.

2:16:45.960 --> 2:16:49.920
 Or you talk about object oriented programming, or you're talking about encapsulation, subclassing

2:16:49.920 --> 2:16:50.920
 inheritance.

2:16:50.920 --> 2:16:56.080
 You start talking about generic programming where you start talking about code reuse through

2:16:56.080 --> 2:17:00.240
 specialization and different type instantiations.

2:17:00.240 --> 2:17:04.200
 And you start talking about differentiable programming, something that I am very excited

2:17:04.200 --> 2:17:06.120
 about in the context of machine learning.

2:17:06.120 --> 2:17:11.400
 Talking about taking functions and generating variants like the derivative of another function.

2:17:11.400 --> 2:17:16.440
 That's a programming paradigm that's very useful for solving certain classes of problems.

2:17:16.440 --> 2:17:19.400
 Machine learning is amazing at solving certain classes of problems.

2:17:19.400 --> 2:17:25.280
 You're not going to write a cat detector or even a language translation system by writing

2:17:25.280 --> 2:17:26.280
 C code.

2:17:26.280 --> 2:17:29.040
 That's not a very productive way to do things anymore.

2:17:29.040 --> 2:17:32.040
 And so machine learning is absolutely the right way to do that.

2:17:32.040 --> 2:17:36.280
 In fact, I would say that learned models are really one of the best ways to work with the

2:17:36.280 --> 2:17:38.320
 human world in general.

2:17:38.320 --> 2:17:41.840
 And so anytime you're talking about sensory input of different modalities, anytime that

2:17:41.840 --> 2:17:46.040
 you're talking about generating things in a way that makes sense to a human, I think

2:17:46.040 --> 2:17:48.560
 that learned models are really, really useful.

2:17:48.560 --> 2:17:52.760
 And that's because humans are very difficult to characterize.

2:17:52.760 --> 2:17:56.640
 And so this is a very powerful paradigm for solving classes of problems.

2:17:56.640 --> 2:17:59.760
 But on the other hand, imperative code is two.

2:17:59.760 --> 2:18:04.240
 You're not going to write a bootloader for your computer with a deep learning model.

2:18:04.240 --> 2:18:07.120
 Deep learning models are very hardware intensive.

2:18:07.120 --> 2:18:13.320
 They're very energy intensive because you have a lot of parameters and you can provably

2:18:13.320 --> 2:18:17.760
 implement any function with a learned model like this has been shown.

2:18:17.760 --> 2:18:20.240
 But that doesn't make it efficient.

2:18:20.240 --> 2:18:23.520
 And so if you're talking about caring about a few orders and magnitudes worth of energy

2:18:23.520 --> 2:18:26.720
 usage, then it's useful to have other tools in the toolbox.

2:18:26.720 --> 2:18:28.400
 There's also robustness too.

2:18:28.400 --> 2:18:29.920
 I mean, yeah, exactly.

2:18:29.920 --> 2:18:34.440
 All the problems of dealing with data and bias and data, all the problems of, you know,

2:18:34.440 --> 2:18:35.440
 software 2.0.

2:18:35.440 --> 2:18:40.600
 And one of the great things that Andre is arguing towards, which I completely agree

2:18:40.600 --> 2:18:45.080
 with him, is that when you start implementing things with deep learning, you need to learn

2:18:45.080 --> 2:18:51.160
 from software 1.0 in terms of testing, continuous integration, how you deploy, how do you validate

2:18:51.160 --> 2:18:55.200
 all these things and building systems around that so that you're not just saying, like,

2:18:55.200 --> 2:18:56.560
 ooh, it seems like it's good.

2:18:56.560 --> 2:18:57.560
 Ship it.

2:18:57.560 --> 2:18:58.560
 Right?

2:18:58.560 --> 2:18:59.880
 Well, what happens when I regress something?

2:18:59.880 --> 2:19:05.280
 What happens when I make a classification that's wrong and now I hurt somebody, right?

2:19:05.280 --> 2:19:07.280
 All these things you have to reason about.

2:19:07.280 --> 2:19:08.280
 Yeah.

2:19:08.280 --> 2:19:14.200
 But at the same time, the bootloader that works for us humans looks awfully a lot like

2:19:14.200 --> 2:19:15.680
 a neural network, right?

2:19:15.680 --> 2:19:16.680
 Yeah.

2:19:16.680 --> 2:19:19.880
 It's messy and you can cut out different parts of the brain.

2:19:19.880 --> 2:19:24.320
 There's a lot of this neural plasticity work that shows that it's going to adjust.

2:19:24.320 --> 2:19:27.080
 I mean, it's a really interesting question.

2:19:27.080 --> 2:19:31.880
 How much of the world's programming could be replaced by software 2.0?

2:19:31.880 --> 2:19:32.880
 Like with...

2:19:32.880 --> 2:19:37.000
 Oh, well, I mean, it's provably true that you could replace all of it.

2:19:37.000 --> 2:19:38.000
 Right.

2:19:38.000 --> 2:19:39.000
 So then it's a question of the tradeoffs.

2:19:39.000 --> 2:19:40.000
 Right.

2:19:40.000 --> 2:19:41.000
 So anything that's a function, you can.

2:19:41.000 --> 2:19:45.080
 So it's not a question about if I think it's an economic question.

2:19:45.080 --> 2:19:47.920
 It's a, what kind of talent can you get?

2:19:47.920 --> 2:19:50.560
 What kind of tradeoffs in terms of maintenance, right?

2:19:50.560 --> 2:19:53.280
 Those kinds of questions, I think, what kind of data can you collect?

2:19:53.280 --> 2:19:58.080
 I think one of the reasons that I'm most interested in machine learning as a programming

2:19:58.080 --> 2:20:02.520
 paradigm is that one of the things that we've seen across computing in general is that being

2:20:02.520 --> 2:20:06.640
 laser focused on one paradigm often puts you in a box.

2:20:06.640 --> 2:20:08.640
 It's not super great.

2:20:08.640 --> 2:20:10.520
 And so you look at object engineering programming.

2:20:10.520 --> 2:20:14.200
 Like it was all the rage in the early 80s and like everything has to be objects and

2:20:14.200 --> 2:20:17.720
 people forgot about functional programming even though came first.

2:20:17.720 --> 2:20:22.240
 And then people rediscovered that, hey, if you mix functional and object oriented and

2:20:22.240 --> 2:20:25.800
 structure, like you mix these things together, you can provide very interesting tools that

2:20:25.800 --> 2:20:28.520
 are good at solving different problems.

2:20:28.520 --> 2:20:32.720
 And so the question there is how do you get the best way to solve the problems?

2:20:32.720 --> 2:20:35.080
 It's not about whose tribe should win.

2:20:35.080 --> 2:20:36.080
 Right.

2:20:36.080 --> 2:20:38.760
 It's not about, you know, that shouldn't be the question.

2:20:38.760 --> 2:20:42.200
 The question is how do you make it so that people can solve those problems the fastest

2:20:42.200 --> 2:20:46.000
 and they have the right tools in their box to build good libraries and they can solve

2:20:46.000 --> 2:20:47.280
 these problems.

2:20:47.280 --> 2:20:50.440
 And when you look at that, that's like, you know, you look at reinforcement learning as

2:20:50.440 --> 2:20:53.160
 one really interesting subdomain of this.

2:20:53.160 --> 2:20:58.080
 Reinforcement learning, often you have to have the integration of a learned model combined

2:20:58.080 --> 2:21:02.640
 with your Atari or whatever the other scenario it is that you're working in.

2:21:02.640 --> 2:21:07.760
 You have to combine that thing with the robot control for the arm, right?

2:21:07.760 --> 2:21:12.040
 And so now it's not just about that one paradigm.

2:21:12.040 --> 2:21:16.540
 It's about integrating that with all the other systems that you have, including often legacy

2:21:16.540 --> 2:21:18.240
 systems and things like this, right?

2:21:18.240 --> 2:21:22.160
 And so to me, I think that the interesting thing to say is, like, how do you get the

2:21:22.160 --> 2:21:26.200
 best out of this domain and how do you enable people to achieve things that they otherwise

2:21:26.200 --> 2:21:31.440
 couldn't do without excluding all the good things we already know how to do.

2:21:31.440 --> 2:21:32.440
 Right.

2:21:32.440 --> 2:21:39.280
 But, okay, this is a crazy question, but we talked a lot about GPT3, but do you think

2:21:39.280 --> 2:21:47.960
 it's possible that these language models that, in essence, in the language domain, software

2:21:47.960 --> 2:21:54.560
 2.0 could replace some aspect of compilation, for example, or do program synthesis, replace

2:21:54.560 --> 2:21:56.240
 some aspect of programming?

2:21:56.240 --> 2:21:57.680
 Yeah, absolutely.

2:21:57.680 --> 2:22:02.200
 So I think that the learned models in general are extremely powerful, and I think that people

2:22:02.200 --> 2:22:05.360
 underestimate them.

2:22:05.360 --> 2:22:07.280
 Maybe you can suggest what I should do.

2:22:07.280 --> 2:22:14.320
 If you have access to the GPT3 API, would I be able to generate Swift code, for example?

2:22:14.320 --> 2:22:16.160
 Do you think that could do something interesting?

2:22:16.160 --> 2:22:23.040
 So GPT3 is probably not trained on the right corpus, so it probably has the ability to generate

2:22:23.040 --> 2:22:24.040
 some Swift.

2:22:24.040 --> 2:22:25.040
 I bet it does.

2:22:25.040 --> 2:22:29.480
 It's probably not going to generate a large enough body of Swift to be useful, but take

2:22:29.480 --> 2:22:31.160
 it a next step further.

2:22:31.160 --> 2:22:35.840
 If you had the goal of training something like GPT3 and you wanted to train it to generate

2:22:35.840 --> 2:22:39.440
 source code, it could definitely do that.

2:22:39.440 --> 2:22:44.400
 Now, the question is, how do you express the intent of what you want filled in?

2:22:44.400 --> 2:22:49.840
 You can definitely write a scaffolding of code and say fill in the hole and put in some

2:22:49.840 --> 2:22:53.760
 for loops or put in some classes or whatever, and the power of these models is impressive,

2:22:53.760 --> 2:22:57.960
 but there's an unsolved question, at least unsolved to me, which is, how do I express

2:22:57.960 --> 2:23:01.800
 the intent of what to fill in?

2:23:01.800 --> 2:23:06.320
 What you'd really want to have, and I don't know that these models are up to the task,

2:23:06.320 --> 2:23:12.640
 is you want to be able to say, here's a scaffolding, and here are the assertions at the end, and

2:23:12.640 --> 2:23:16.640
 the assertions always pass, and so you want a generative model, on the one hand, yes.

2:23:16.640 --> 2:23:17.640
 Oh, that's fascinating.

2:23:17.640 --> 2:23:18.640
 Yeah.

2:23:18.640 --> 2:23:19.640
 Right?

2:23:19.640 --> 2:23:24.040
 But you also want some loopback, some reinforcement learning system or something where you're actually

2:23:24.040 --> 2:23:29.000
 saying, I need to hill climb towards something that is more correct, and I don't know that

2:23:29.000 --> 2:23:30.000
 we have that.

2:23:30.000 --> 2:23:35.960
 Well, it would generate not only a bunch of the code, but the checks that do the testing.

2:23:35.960 --> 2:23:37.080
 It would generate the tests.

2:23:37.080 --> 2:23:38.920
 I think the humans would generate the tests, right?

2:23:38.920 --> 2:23:39.920
 Oh, okay.

2:23:39.920 --> 2:23:40.920
 The test would grow.

2:23:40.920 --> 2:23:41.920
 But it would be fascinating if...

2:23:41.920 --> 2:23:42.920
 Well, the tests are the requirements.

2:23:42.920 --> 2:23:43.920
 Yes, but the...

2:23:43.920 --> 2:23:44.920
 Okay, so...

2:23:44.920 --> 2:23:47.160
 Because you have to express to the model what you want to...

2:23:47.160 --> 2:23:49.120
 You don't just want gibberish code.

2:23:49.120 --> 2:23:51.400
 Look at how compelling this code looks.

2:23:51.400 --> 2:23:54.480
 You want a story about four horned unicorns or something.

2:23:54.480 --> 2:23:56.080
 Well, okay, so exactly.

2:23:56.080 --> 2:24:03.560
 That's human requirements, but then I thought it's a compelling idea that the GPT4 model

2:24:03.560 --> 2:24:13.000
 could generate checks that are more high fidelity that check for correctness.

2:24:13.000 --> 2:24:20.720
 Because the code it generates, say I ask it to generate a function that gives me the Fibonacci

2:24:20.720 --> 2:24:21.720
 sequence.

2:24:21.720 --> 2:24:22.720
 Sure.

2:24:22.720 --> 2:24:23.720
 I don't...

2:24:23.720 --> 2:24:27.080
 So, decompose the problem, right, so you have two things.

2:24:27.080 --> 2:24:28.080
 You have...

2:24:28.080 --> 2:24:33.040
 You need the ability to generate syntactically corrects with code that's interesting, right?

2:24:33.040 --> 2:24:37.120
 I think GPT series of model architectures can do that.

2:24:37.120 --> 2:24:41.440
 But then you need the ability to add the requirements.

2:24:41.440 --> 2:24:43.400
 So generate Fibonacci.

2:24:43.400 --> 2:24:46.120
 The human needs to express that goal.

2:24:46.120 --> 2:24:49.000
 We don't have that language that I know of.

2:24:49.000 --> 2:24:50.560
 No, I mean, it can generate stuff.

2:24:50.560 --> 2:24:52.880
 Have you seen what GPT3 can generate?

2:24:52.880 --> 2:24:58.440
 You can say, I mean, there's interface stuff, like it can generate HTML.

2:24:58.440 --> 2:25:02.080
 It can generate basic for loops that give you like...

2:25:02.080 --> 2:25:03.080
 Right, but pick HTML.

2:25:03.080 --> 2:25:05.200
 How do I say I want Google.com?

2:25:05.200 --> 2:25:07.840
 Well, no, you could say...

2:25:07.840 --> 2:25:09.360
 Or not literally Google.com.

2:25:09.360 --> 2:25:13.200
 How do I say I want a webpage that's got a shopping cart and this and that?

2:25:13.200 --> 2:25:14.200
 Yeah, it does that.

2:25:14.200 --> 2:25:15.200
 I mean, so, okay, so just...

2:25:15.200 --> 2:25:20.880
 I don't know if you've seen these demonstrations, but you type in, I want a red button with

2:25:20.880 --> 2:25:24.760
 the text that says, hello, and you typed that natural language and it generates the

2:25:24.760 --> 2:25:25.760
 correct HTML.

2:25:25.760 --> 2:25:26.760
 Okay.

2:25:26.760 --> 2:25:27.760
 I've done this demo.

2:25:27.760 --> 2:25:28.760
 It's kind of compelling.

2:25:28.760 --> 2:25:33.360
 So you have to prompt it with similar kinds of mappings.

2:25:33.360 --> 2:25:38.080
 Of course, it's probably handpicked, I have to experiment that probably...

2:25:38.080 --> 2:25:43.120
 But the fact that you can do that once, even out of like 20, is quite impressive.

2:25:43.120 --> 2:25:48.520
 Again, that's very basic, like the HTML is kind of messy and bad.

2:25:48.520 --> 2:25:52.720
 But yes, the intent is... the idea is the intent is specified in natural language.

2:25:52.720 --> 2:25:53.720
 Okay.

2:25:53.720 --> 2:25:54.720
 Yeah, so I have not seen that.

2:25:54.720 --> 2:25:55.720
 That's really cool.

2:25:55.720 --> 2:25:56.720
 Yeah.

2:25:56.720 --> 2:25:59.960
 Yeah, but the question is the correctness of that.

2:25:59.960 --> 2:26:10.040
 Like visually you can check, oh, the button is red, but for more complicated functions

2:26:10.040 --> 2:26:15.560
 where the intent is harder to check, this goes into like NP completeness kind of things.

2:26:15.560 --> 2:26:22.240
 Like I want to know that this code is correct and generates a giant thing that does some

2:26:22.240 --> 2:26:23.760
 kind of calculation.

2:26:23.760 --> 2:26:25.960
 It seems to be working.

2:26:25.960 --> 2:26:31.160
 It's interesting to think like should the system also try to generate checks for itself

2:26:31.160 --> 2:26:32.160
 for correctness.

2:26:32.160 --> 2:26:33.160
 Yeah.

2:26:33.160 --> 2:26:34.160
 I don't know.

2:26:34.160 --> 2:26:37.200
 And this is way beyond my experience.

2:26:37.200 --> 2:26:42.800
 The thing that I think about is that there doesn't seem to be a lot of equational reasoning

2:26:42.800 --> 2:26:43.800
 going on.

2:26:43.800 --> 2:26:44.800
 Right.

2:26:44.800 --> 2:26:48.720
 It's kind of filling in and kind of propagating patterns that have been seen before into the

2:26:48.720 --> 2:26:50.800
 future and into the generated result.

2:26:50.800 --> 2:26:55.080
 And so if you want to get correctness, you kind of need to improve in kind of things

2:26:55.080 --> 2:26:57.440
 and like higher level logic.

2:26:57.440 --> 2:26:58.680
 And I don't know that...

2:26:58.680 --> 2:27:04.200
 You could talk to Yon about that and see what the bright minds are thinking about right

2:27:04.200 --> 2:27:05.200
 now.

2:27:05.200 --> 2:27:08.320
 But I don't think the GPT is in that vein.

2:27:08.320 --> 2:27:09.320
 It's still really cool.

2:27:09.320 --> 2:27:10.320
 Yeah.

2:27:10.320 --> 2:27:13.520
 And surprisingly, who knows, maybe reasoning is...

2:27:13.520 --> 2:27:14.520
 Is overrated.

2:27:14.520 --> 2:27:15.520
 Yeah.

2:27:15.520 --> 2:27:16.520
 Is overrated.

2:27:16.520 --> 2:27:17.520
 Right.

2:27:17.520 --> 2:27:18.520
 I mean, do we reason?

2:27:18.520 --> 2:27:19.520
 Yeah.

2:27:19.520 --> 2:27:20.520
 How do you tell?

2:27:20.520 --> 2:27:21.520
 Right?

2:27:21.520 --> 2:27:22.520
 Are we just pattern matching based on what we have and then reverse justifying to ourselves?

2:27:22.520 --> 2:27:23.520
 Yeah.

2:27:23.520 --> 2:27:24.520
 Exactly.

2:27:24.520 --> 2:27:25.520
 The reverse...

2:27:25.520 --> 2:27:29.800
 So like I think what the neural networks are missing and I think GPT form might have

2:27:29.800 --> 2:27:33.520
 is to be able to tell stories to itself about what it did.

2:27:33.520 --> 2:27:34.520
 Yeah.

2:27:34.520 --> 2:27:35.520
 Well, that's what humans do.

2:27:35.520 --> 2:27:36.520
 Right?

2:27:36.520 --> 2:27:37.520
 I mean, you talk about like network explainability.

2:27:37.520 --> 2:27:38.520
 Right?

2:27:38.520 --> 2:27:39.520
 And we give...

2:27:39.520 --> 2:27:40.520
 No, that's a hard time about this.

2:27:40.520 --> 2:27:42.480
 But humans don't know why we make decisions.

2:27:42.480 --> 2:27:45.880
 We have this thing called intuition and then we try to like say, this feels like the right

2:27:45.880 --> 2:27:46.880
 thing, but why?

2:27:46.880 --> 2:27:47.880
 Right?

2:27:47.880 --> 2:27:52.480
 And, you know, you wrestle with that when you're making hard decisions and is that science?

2:27:52.480 --> 2:27:53.480
 Not really.

2:27:53.480 --> 2:28:01.520
 Let me ask you about a few high level questions, I guess, is you've done a million things in

2:28:01.520 --> 2:28:04.160
 your life and been very successful.

2:28:04.160 --> 2:28:11.800
 A bunch of young folks listen to this, ask for advice from successful people like you.

2:28:11.800 --> 2:28:17.560
 If you were to give advice to somebody, you know, another graduate student or some high

2:28:17.560 --> 2:28:25.600
 school student about pursuing a career in computing or just advice about life in general,

2:28:25.600 --> 2:28:28.920
 is there some words of wisdom you can give them?

2:28:28.920 --> 2:28:34.640
 So I think you come back to change and, you know, profound leaps happen because people

2:28:34.640 --> 2:28:40.040
 are willing to believe that change is possible and that the world does change and are willing

2:28:40.040 --> 2:28:44.520
 to do the hard thing that it takes to make change happen and whether it be implementing

2:28:44.520 --> 2:28:48.360
 a new programming language or implementing a new system or implementing a new research

2:28:48.360 --> 2:28:53.560
 paper, designing a new thing, moving the world forward in science and philosophy, whatever,

2:28:53.560 --> 2:28:57.200
 it really comes down to somebody who's willing to put in the work, right?

2:28:57.200 --> 2:29:02.080
 And you have, the work is hard for a whole bunch of different reasons, one of which is

2:29:02.080 --> 2:29:06.960
 you, it's work, right?

2:29:06.960 --> 2:29:10.080
 And so you have to have the space in your life in which you can do that work, which is

2:29:10.080 --> 2:29:14.840
 why going to grad school can be a beautiful thing for certain people.

2:29:14.840 --> 2:29:18.440
 But also there's a self doubt that happens, like you're two years into a project, is it

2:29:18.440 --> 2:29:19.440
 going anywhere?

2:29:19.440 --> 2:29:20.440
 Right?

2:29:20.440 --> 2:29:21.440
 Well, what do you do?

2:29:21.440 --> 2:29:22.520
 Do you just give up?

2:29:22.520 --> 2:29:23.520
 Because it's hard?

2:29:23.520 --> 2:29:24.520
 Well, no.

2:29:24.520 --> 2:29:27.160
 I mean, some people like suffering.

2:29:27.160 --> 2:29:29.320
 And so you plow through it.

2:29:29.320 --> 2:29:35.520
 The secret to me is that you have to love what you're doing and follow that passion because

2:29:35.520 --> 2:29:40.160
 if, when you get to the hard times, that's when, you know, if you love what you're doing,

2:29:40.160 --> 2:29:41.960
 you're willing to kind of push through.

2:29:41.960 --> 2:29:48.840
 And this is really hard because it's hard to know what you will love doing until you

2:29:48.840 --> 2:29:50.320
 start doing a lot of things.

2:29:50.320 --> 2:29:55.000
 And so that's why I think that particularly early in your career, it's good to experiment.

2:29:55.000 --> 2:29:56.000
 Do a little bit of everything.

2:29:56.000 --> 2:30:02.760
 Go take the survey class on, you know, the first half of every class in your upper division,

2:30:02.760 --> 2:30:06.720
 you know, lessons and just get exposure to things because certain things will resonate

2:30:06.720 --> 2:30:08.880
 with you and you'll find out, wow, I'm really good at this.

2:30:08.880 --> 2:30:10.440
 I'm really smart at this.

2:30:10.440 --> 2:30:12.960
 Well, it's just because it's, it works with the way your brain.

2:30:12.960 --> 2:30:17.640
 And when something jumps out, I mean, that's one of the things that people often ask about

2:30:17.640 --> 2:30:21.440
 is like, well, I think there's a bunch of cool stuff out there.

2:30:21.440 --> 2:30:23.320
 Like how do I pick the thing?

2:30:23.320 --> 2:30:27.600
 Like, how do you, how do you hook in your life?

2:30:27.600 --> 2:30:30.080
 How did you just hook yourself in and stuck with it?

2:30:30.080 --> 2:30:31.280
 Well, I got lucky.

2:30:31.280 --> 2:30:32.280
 Right?

2:30:32.280 --> 2:30:38.880
 I think that many people forget that a huge amount of it, or most of it is luck, right?

2:30:38.880 --> 2:30:42.040
 So let's not forget that.

2:30:42.040 --> 2:30:48.080
 So for me, I fell in love with computers early on because they spoke to me, I guess.

2:30:48.080 --> 2:30:50.960
 What language did they speak to?

2:30:50.960 --> 2:30:51.960
 Basic.

2:30:51.960 --> 2:30:52.960
 Basic.

2:30:52.960 --> 2:30:53.960
 Yeah.

2:30:53.960 --> 2:31:00.000
 But the, but then it was just kind of following a set of logical progressions, but also deciding

2:31:00.000 --> 2:31:04.200
 that something that was hard was worth doing and a lot of fun, right?

2:31:04.200 --> 2:31:08.160
 And so I think that that is also something that's true for many other domains, which

2:31:08.160 --> 2:31:13.280
 is if you find something that you love doing that's also hard, if you invest yourself in

2:31:13.280 --> 2:31:17.320
 it and add value to the world, then it will mean something generally, right?

2:31:17.320 --> 2:31:21.520
 And again, that can be a research paper, that can be a software system, that can be a new

2:31:21.520 --> 2:31:26.600
 robot, that can be, there's many things that that can be, but a lot of it is like real

2:31:26.600 --> 2:31:29.560
 value comes from doing things that are hard.

2:31:29.560 --> 2:31:33.360
 And that doesn't mean you have to suffer.

2:31:33.360 --> 2:31:34.360
 But it's hard.

2:31:34.360 --> 2:31:36.080
 I mean, you don't often hear that message.

2:31:36.080 --> 2:31:41.960
 We talked about it last time a little bit, but it's one of my, not enough people talk

2:31:41.960 --> 2:31:47.160
 about this, it's beautiful to hear a successful person.

2:31:47.160 --> 2:31:52.280
 Well, in self doubt and imposter syndrome, and these are all things that successful people

2:31:52.280 --> 2:31:56.760
 suffer with as well, particularly when they put themselves in a point of being uncomfortable,

2:31:56.760 --> 2:32:01.480
 which I like to do now and then just because it puts you in learning mode.

2:32:01.480 --> 2:32:06.520
 Like if you want to, if you want to grow as a person, put yourself in a room with a bunch

2:32:06.520 --> 2:32:10.880
 of people that know way more about whatever you're talking about than you do and ask dumb

2:32:10.880 --> 2:32:11.880
 questions.

2:32:11.880 --> 2:32:17.520
 And guess what, smart people love to teach often, not always, but often, and if you listen,

2:32:17.520 --> 2:32:20.760
 if you're prepared to listen, if you're prepared to grow, if you're prepared to make connections,

2:32:20.760 --> 2:32:22.640
 you can do some really interesting things.

2:32:22.640 --> 2:32:26.960
 And I think that a lot of progress is made by people who kind of hop between domains

2:32:26.960 --> 2:32:35.160
 now and then, because they bring a perspective into a field that nobody else has, if people

2:32:35.160 --> 2:32:38.400
 have only been working in that field themselves.

2:32:38.400 --> 2:32:43.800
 We mentioned that the universe is kind of like a compiler, you know, the entirety of

2:32:43.800 --> 2:32:47.960
 it, the whole evolution is kind of a kind of a compilation.

2:32:47.960 --> 2:32:50.640
 Maybe us human beings are kind of compilers.

2:32:50.640 --> 2:32:56.080
 Let me ask the old sort of question that I didn't ask you last time, which is, what's

2:32:56.080 --> 2:32:57.840
 the meaning of it all?

2:32:57.840 --> 2:32:58.840
 Is there a meaning?

2:32:58.840 --> 2:33:04.080
 Like if you asked a compiler why, what would a compiler say, and what's the meaning of

2:33:04.080 --> 2:33:05.080
 life?

2:33:05.080 --> 2:33:06.080
 What's the meaning of life?

2:33:06.080 --> 2:33:09.960
 You know, I'm prepared for not to mean anything.

2:33:09.960 --> 2:33:19.440
 Here we are, all biological things programmed to survive and propagate our DNA, and maybe

2:33:19.440 --> 2:33:25.400
 the universe is just a computer and you just go until entropy takes over the universe and

2:33:25.400 --> 2:33:27.400
 then you're done.

2:33:27.400 --> 2:33:33.160
 I don't think that's a very productive way to live your life, if so.

2:33:33.160 --> 2:33:37.280
 And so I prefer to bias towards the other way, which is saying the universe has a lot

2:33:37.280 --> 2:33:38.280
 of value.

2:33:38.280 --> 2:33:43.960
 And I take happiness out of other people, and a lot of times part of that's having kids,

2:33:43.960 --> 2:33:47.120
 but also the relationships you build with other people.

2:33:47.120 --> 2:33:51.360
 And so the way I try to live my life is what can I do that has value?

2:33:51.360 --> 2:33:52.560
 How can I move the world forward?

2:33:52.560 --> 2:33:57.680
 How can I take what I'm good at and bring it into the world?

2:33:57.680 --> 2:34:02.320
 And I'm one of these people that likes to work really hard and be very focused on the

2:34:02.320 --> 2:34:03.320
 things that I do.

2:34:03.320 --> 2:34:07.480
 And so if I'm going to do that, how can it be in a domain that actually will matter?

2:34:07.480 --> 2:34:12.000
 Because a lot of things that we do, we find ourselves in the cycle of like, okay, I'm

2:34:12.000 --> 2:34:15.840
 doing a thing, I'm very familiar with it, I've done it for a long time, I've never done

2:34:15.840 --> 2:34:18.920
 anything else, but I'm not really learning.

2:34:18.920 --> 2:34:23.920
 I'm not really, I'm keeping things going, but there's a younger generation that can

2:34:23.920 --> 2:34:26.720
 do the same thing, maybe even better than me, right?

2:34:26.720 --> 2:34:31.440
 Maybe if I actually step out of this and jump into something I'm less comfortable with,

2:34:31.440 --> 2:34:32.440
 it's scary.

2:34:32.440 --> 2:34:36.440
 But on the other hand, it gives somebody else a new opportunity, it also then puts you

2:34:36.440 --> 2:34:39.200
 back in learning mode, and that can be really interesting.

2:34:39.200 --> 2:34:43.360
 And one of the things I've learned is that when you go through that, that first you're

2:34:43.360 --> 2:34:47.800
 deep into imposter syndrome, but when you start working your way out, you start to realize,

2:34:47.800 --> 2:34:50.280
 hey, well, there's actually a method to this.

2:34:50.280 --> 2:34:54.800
 And now I'm able to add new things because I bring different perspective.

2:34:54.800 --> 2:35:00.280
 And this is one of the good things about bringing different kinds of people together.

2:35:00.280 --> 2:35:02.240
 Diversity of thought is really important.

2:35:02.240 --> 2:35:06.560
 And if you can pull together people that are coming at things from different directions,

2:35:06.560 --> 2:35:08.080
 you often get innovation.

2:35:08.080 --> 2:35:12.720
 And I love to see that, that aha moment where you're like, we've like really cracked this.

2:35:12.720 --> 2:35:15.360
 This is something nobody's ever done before.

2:35:15.360 --> 2:35:18.960
 And then if you can do it in a context where it adds value, other people can build on it,

2:35:18.960 --> 2:35:22.800
 it helps move the world, then that's what really excites me.

2:35:22.800 --> 2:35:27.060
 So that kind of description of the magic of the human experience, do you think we'll ever

2:35:27.060 --> 2:35:29.920
 create that in like an AGI system?

2:35:29.920 --> 2:35:38.800
 You think we'll be able to create, give AI systems a sense of meaning where they operate

2:35:38.800 --> 2:35:42.760
 in this kind of world, exactly in the way you've described, which is they interact with

2:35:42.760 --> 2:35:44.760
 each other, they interact with us humans.

2:35:44.760 --> 2:35:45.760
 Sure.

2:35:45.760 --> 2:35:46.760
 Sure.

2:35:46.760 --> 2:35:49.640
 Well, so I mean, why are you being so a specist?

2:35:49.640 --> 2:35:50.640
 Right?

2:35:50.640 --> 2:35:51.640
 All right.

2:35:51.640 --> 2:36:00.360
 So AGI versus Bionets versus Bionets, you know, what are we but machines, right?

2:36:00.360 --> 2:36:04.520
 We're just programmed to run our, we have our objective function that we're optimized

2:36:04.520 --> 2:36:06.600
 for, right?

2:36:06.600 --> 2:36:07.680
 And so we're doing our thing.

2:36:07.680 --> 2:36:09.400
 We think we have purpose, but do we really?

2:36:09.400 --> 2:36:10.400
 Yeah.

2:36:10.400 --> 2:36:11.400
 Right?

2:36:11.400 --> 2:36:16.160
 I'm not prepared to say that those new fangled AGI's have no soul just because we don't understand

2:36:16.160 --> 2:36:17.160
 them, right?

2:36:17.160 --> 2:36:23.440
 And I think that would be when they, when they exist, that would be very premature to look

2:36:23.440 --> 2:36:28.280
 at a new thing through your own lens without fully understanding it.

2:36:28.280 --> 2:36:32.880
 You might be just saying that because AI systems in the future will be listening to this and

2:36:32.880 --> 2:36:33.880
 then.

2:36:33.880 --> 2:36:34.880
 Oh yeah.

2:36:34.880 --> 2:36:35.880
 Exactly.

2:36:35.880 --> 2:36:36.880
 You don't want to say anything.

2:36:36.880 --> 2:36:37.880
 Yeah.

2:36:37.880 --> 2:36:38.880
 SkyNet kills everybody.

2:36:38.880 --> 2:36:39.880
 Please spare me.

2:36:39.880 --> 2:36:42.480
 So why is, why is a look ahead thinking?

2:36:42.480 --> 2:36:43.480
 Yeah.

2:36:43.480 --> 2:36:46.560
 But I mean, I think that people spend a lot of time worrying about this kind of stuff.

2:36:46.560 --> 2:36:50.160
 And I think that what we should be worrying about is how do we make the world better?

2:36:50.160 --> 2:36:57.120
 And the thing that I'm most scared about with AGI's is not that, that necessarily the sky

2:36:57.120 --> 2:37:01.840
 net will start shooting everybody with lasers and stuff like that to, to use us for our

2:37:01.840 --> 2:37:02.840
 calories.

2:37:02.840 --> 2:37:08.400
 And the thing that I'm worried about is that humanity, I think, needs a challenge.

2:37:08.400 --> 2:37:13.680
 And if we get into a mode of not having a personal challenge, not having a personal contribution,

2:37:13.680 --> 2:37:18.000
 whether that be like, you know, your kids and seeing what they grow into and helping,

2:37:18.000 --> 2:37:23.000
 helping guide them, whether it be your community that you're engaged in, you're driving forward,

2:37:23.000 --> 2:37:25.720
 whether it be your work and the things that you're doing and the people you're working

2:37:25.720 --> 2:37:29.680
 with and the products you're building and the contribution there, if people don't have

2:37:29.680 --> 2:37:33.720
 a objective, I'm afraid what that means.

2:37:33.720 --> 2:37:40.280
 And I think that this would lead to a rise of the worst part of people, right, instead

2:37:40.280 --> 2:37:45.200
 of people striving together and trying to make the world better.

2:37:45.200 --> 2:37:51.160
 It could degrade into a very unpleasant world, but, but I don't know.

2:37:51.160 --> 2:37:55.080
 I mean, we hopefully have a long ways to go before we discover that.

2:37:55.080 --> 2:37:58.720
 And unfortunately, we have pretty on the ground problems with the pandemic right now.

2:37:58.720 --> 2:38:01.400
 And so I think we should be focused on that as well.

2:38:01.400 --> 2:38:02.400
 Yeah.

2:38:02.400 --> 2:38:04.640
 Ultimately, just as you said, you're optimistic.

2:38:04.640 --> 2:38:09.960
 I think it helps for us to be optimistic because that's faking until you make it.

2:38:09.960 --> 2:38:10.960
 Yeah.

2:38:10.960 --> 2:38:11.960
 Well, and why not?

2:38:11.960 --> 2:38:12.960
 I mean, what's the other side?

2:38:12.960 --> 2:38:13.960
 Right.

2:38:13.960 --> 2:38:18.960
 So, I mean, I'm not personally a very religious person, but I've heard people say like, oh,

2:38:18.960 --> 2:38:20.400
 yeah, of course I believe in God.

2:38:20.400 --> 2:38:25.320
 Of course I go to church because if God's real, you know, I want to be on the right

2:38:25.320 --> 2:38:26.320
 side of that.

2:38:26.320 --> 2:38:27.320
 And if it's not real, it doesn't matter.

2:38:27.320 --> 2:38:28.320
 Yeah, it doesn't matter.

2:38:28.320 --> 2:38:31.600
 So, you know, that's a fair way to do it.

2:38:31.600 --> 2:38:32.600
 Yeah.

2:38:32.600 --> 2:38:38.520
 I mean, the same thing with nuclear deterrence, all, you know, global warming, all these things,

2:38:38.520 --> 2:38:47.680
 all these threats, natural engineer pandemics, all these threats we face, I think it's paralyzing

2:38:47.680 --> 2:38:52.520
 to be terrified of all the possible ways we could destroy ourselves.

2:38:52.520 --> 2:39:00.120
 I think it's much better or at least productive to be hopeful and to engineer defenses against

2:39:00.120 --> 2:39:07.040
 these things to engineer a future where like, you know, see like a positive future and engineer

2:39:07.040 --> 2:39:08.040
 that future.

2:39:08.040 --> 2:39:09.040
 Yeah.

2:39:09.040 --> 2:39:12.960
 Well, and I think that's another thing to think about as, you know, a human, particularly

2:39:12.960 --> 2:39:15.720
 if you're young and trying to figure out what it is that you want to be when you grow

2:39:15.720 --> 2:39:18.040
 up like I am.

2:39:18.040 --> 2:39:20.640
 I'm always looking for that.

2:39:20.640 --> 2:39:24.440
 The question then is, how do you want to spend your time?

2:39:24.440 --> 2:39:29.080
 And right now, there seems to be a norm of being a consumption culture, like I'm going

2:39:29.080 --> 2:39:33.480
 to watch the news and revel in how horrible everything is right now.

2:39:33.480 --> 2:39:38.600
 I'm going to go find out about the latest atrocity and find out all the details of like the terrible

2:39:38.600 --> 2:39:42.000
 thing that happened and be outraged by it.

2:39:42.000 --> 2:39:46.800
 You can spend a lot of time watching TV and watching the news sitcom or whatever people

2:39:46.800 --> 2:39:47.800
 watch these days.

2:39:47.800 --> 2:39:54.040
 But that's a lot of hours, right, and those are hours that if you're turned into being

2:39:54.040 --> 2:40:00.280
 productive, learning, growing, experiencing, you know, when the pandemic's over, going

2:40:00.280 --> 2:40:03.960
 exploring, right, it leads to more growth.

2:40:03.960 --> 2:40:08.360
 And I think it leads to more optimism and happiness because you're, you're, you're building,

2:40:08.360 --> 2:40:09.360
 right?

2:40:09.360 --> 2:40:12.280
 You're building yourself, you're building your capabilities, you're building your viewpoints,

2:40:12.280 --> 2:40:19.080
 you're building your perspective, and I think that a lot of the, the consuming of other people's

2:40:19.080 --> 2:40:24.240
 messages leads to kind of a negative viewpoint, which you need to be aware of what's happening

2:40:24.240 --> 2:40:29.160
 because that's also important, but there's a balance that I think focusing on creation

2:40:29.160 --> 2:40:31.840
 is, is a very valuable thing to do.

2:40:31.840 --> 2:40:32.840
 Yeah.

2:40:32.840 --> 2:40:37.400
 So what you're saying is people should focus on working on the sexiest field of all, which

2:40:37.400 --> 2:40:38.400
 is compiler design.

2:40:38.400 --> 2:40:39.400
 Exactly.

2:40:39.400 --> 2:40:43.560
 Hey, you can go work on machine learning and be crowded out by the, the thousands of graduates

2:40:43.560 --> 2:40:47.040
 popping out of school that all want to do the same thing, or you could work in the place

2:40:47.040 --> 2:40:51.520
 that people will overpay you because there's not enough smart people working in it.

2:40:51.520 --> 2:40:56.280
 And here at the end of Moore's Law, according to some people, actually the software is the

2:40:56.280 --> 2:40:57.280
 hard part too.

2:40:57.280 --> 2:40:58.280
 Yeah.

2:40:58.280 --> 2:41:02.320
 I mean, optimization is truly, truly beautiful.

2:41:02.320 --> 2:41:08.400
 And also on the YouTube side or education side, you know, it's, there's a, it'd be nice

2:41:08.400 --> 2:41:12.000
 to have some material that shows the beauty of compilers.

2:41:12.000 --> 2:41:13.000
 Yeah.

2:41:13.000 --> 2:41:14.000
 Yeah.

2:41:14.000 --> 2:41:15.000
 That's, that's something.

2:41:15.000 --> 2:41:18.920
 So that's a call for, for people to create that kind of content as well.

2:41:18.920 --> 2:41:22.160
 Chris, you're one of my favorite people to talk to.

2:41:22.160 --> 2:41:26.240
 It's such a huge honor that you would waste your time talking to me.

2:41:26.240 --> 2:41:27.840
 I've always appreciated it.

2:41:27.840 --> 2:41:28.840
 Thank you so much.

2:41:28.840 --> 2:41:33.520
 I mean, the truth of it is you spent a lot of time talking to me just on, you know, walks

2:41:33.520 --> 2:41:34.520
 and other things like that.

2:41:34.520 --> 2:41:35.760
 So it's great to catch up with.

2:41:35.760 --> 2:41:37.440
 Thanks, man.

2:41:37.440 --> 2:41:40.160
 Thanks for listening to this conversation with Chris Latner.

2:41:40.160 --> 2:41:45.680
 And thank you to our sponsors, Blinkist, an app that summarizes key ideas from thousands

2:41:45.680 --> 2:41:52.640
 of books, Neuro, which is a maker of functional gum and mints that supercharged my mind, Masterclass,

2:41:52.640 --> 2:41:55.560
 which are online courses from world experts.

2:41:55.560 --> 2:42:00.320
 And finally, Cash App, which is an app for sending money to friends.

2:42:00.320 --> 2:42:06.160
 Please check out these sponsors in the description to get a discount and to support this podcast.

2:42:06.160 --> 2:42:10.840
 If you enjoyed this thing, subscribe on YouTube, review it with 5 stars on Apple Podcast, follow

2:42:10.840 --> 2:42:16.440
 on Spotify, support on Patreon, connect with me on Twitter, Alex Friedman.

2:42:16.440 --> 2:42:19.200
 And now let me leave you with some words from Chris Latner.

2:42:19.200 --> 2:42:24.040
 So much of language design is about tradeoffs and you can't see those tradeoffs unless you

2:42:24.040 --> 2:42:28.720
 have a community of people that really represent those different points.

2:42:28.720 --> 2:42:40.080
 Thank you for listening and hope to see you next time.

