WEBVTT

00:00.000 --> 00:03.600
 The following is a conversation with Whitney Cummings.

00:03.600 --> 00:07.240
 She's a standup comedian, actor, producer, writer, director,

00:07.240 --> 00:11.240
 and recently, finally, the host of her very own podcast

00:11.240 --> 00:12.920
 called Good for You.

00:12.920 --> 00:15.920
 Her most recent Netflix special called Can I Touch It

00:15.920 --> 00:17.800
 features in part a robot.

00:17.800 --> 00:20.280
 She affectionately named Bear Claw

00:20.280 --> 00:23.440
 that is designed to be visually a replica of Whitney.

00:23.440 --> 00:25.960
 It's exciting for me to see one of my favorite comedians

00:25.960 --> 00:30.720
 explore the social aspects of robotics and AI in our society.

00:30.720 --> 00:32.920
 She also has some fascinating ideas

00:32.920 --> 00:36.000
 about human behavior, psychology, and urology,

00:36.000 --> 00:37.800
 some of which she explores in her book

00:37.800 --> 00:41.200
 called I'm Fine and Other Lies.

00:41.200 --> 00:43.320
 It was truly a pleasure to meet Whitney

00:43.320 --> 00:45.160
 and have this conversation with her,

00:45.160 --> 00:47.920
 and even to continue it through texts afterwards.

00:47.920 --> 00:50.120
 Every once in a while, late at night,

00:50.120 --> 00:52.280
 I'll be programming over a cup of coffee

00:52.280 --> 00:55.720
 and we'll get a text from Whitney saying something hilarious.

00:55.720 --> 00:58.960
 Or weirder yet, sending a video of Brian Callan

00:58.960 --> 01:00.920
 saying something hilarious.

01:00.920 --> 01:03.840
 That's when I know the universe has a sense of humor

01:03.840 --> 01:07.400
 and it gifted me with one hell of an amazing journey.

01:07.400 --> 01:10.320
 Then I put the phone down and go back to programming

01:10.320 --> 01:13.400
 with a stupid, joyful smile on my face.

01:13.400 --> 01:14.960
 If you enjoy this conversation,

01:14.960 --> 01:17.200
 listen to Whitney's podcast, Good for You,

01:17.200 --> 01:19.840
 and follow her on Twitter and Instagram.

01:19.840 --> 01:22.640
 This is the Artificial Intelligence podcast.

01:22.640 --> 01:24.840
 If you enjoy it, subscribe on YouTube,

01:24.840 --> 01:26.800
 give it five stars on Apple Podcasts,

01:26.800 --> 01:30.160
 support on Patreon, or simply connect with me on Twitter.

01:30.160 --> 01:34.040
 Alex Friedman, spelled F R I D M A N.

01:34.040 --> 01:35.840
 This show is presented by Cash App,

01:35.840 --> 01:38.280
 the number one finance app in the App Store.

01:38.280 --> 01:41.440
 They regularly support Whitney's Good for You podcast as well.

01:41.440 --> 01:43.920
 I personally use Cash App to send money to friends,

01:43.920 --> 01:45.680
 but you can also use it to buy, sell,

01:45.680 --> 01:47.960
 and deposit Bitcoin in just seconds.

01:47.960 --> 01:50.640
 Cash App also has a new investing feature.

01:50.640 --> 01:53.480
 You can buy fractions of a stock, say $1 worth,

01:53.480 --> 01:55.760
 no matter what the stock price is.

01:55.760 --> 01:58.560
 Broker services are provided by Cash App investing,

01:58.560 --> 02:02.000
 subsidiary of Square, and member SIPC.

02:02.000 --> 02:04.120
 I'm excited to be working with Cash App

02:04.120 --> 02:07.160
 to support one of my favorite organizations called First,

02:07.160 --> 02:10.400
 best known for their first robotics and Lego competitions.

02:10.400 --> 02:13.760
 They educate and inspire hundreds of thousands of students

02:13.760 --> 02:16.000
 in over 110 countries,

02:16.000 --> 02:18.680
 and have a perfect rating on Charity Navigator,

02:18.680 --> 02:20.480
 which means the donated money is used

02:20.480 --> 02:22.360
 to maximum effectiveness.

02:22.360 --> 02:25.240
 When you get Cash App from the App Store or Google Play

02:25.240 --> 02:27.840
 and use code LEX Podcast,

02:27.840 --> 02:32.080
 you'll get $10 and Cash App will also donate $10 to First,

02:32.080 --> 02:35.240
 which again is an organization that I've personally seen

02:35.240 --> 02:38.120
 inspire girls and boys to dream of engineering

02:38.120 --> 02:39.160
 a better world.

02:40.440 --> 02:43.040
 This podcast is supported by Zippercruiter.

02:43.040 --> 02:45.200
 Hiring great people is hard,

02:45.200 --> 02:47.280
 and to me is the most important element

02:47.280 --> 02:50.080
 of a successful mission driven team.

02:50.080 --> 02:52.080
 I've been fortunate to be a part of,

02:52.080 --> 02:54.680
 and to lead several great engineering teams.

02:54.680 --> 02:56.640
 The hiring I've done in the past

02:56.640 --> 02:59.400
 was mostly through tools that we built ourselves,

02:59.400 --> 03:02.360
 but reinventing the wheel was painful.

03:02.360 --> 03:05.200
 Zippercruiter is a tool that's already available for you.

03:05.200 --> 03:08.960
 It seeks to make hiring simple, fast, and smart.

03:08.960 --> 03:11.920
 For example, codable cofounder Gretchen Hebner

03:11.920 --> 03:14.360
 used Zippercruiter to find a new game artist

03:14.360 --> 03:16.680
 to join her education tech company.

03:16.680 --> 03:18.800
 By using Zippercruiter screening questions

03:18.800 --> 03:20.280
 to filter candidates,

03:20.280 --> 03:23.080
 Gretchen found it easier to focus on the best candidates

03:23.080 --> 03:26.440
 and finally hiring the perfect person for the role

03:26.440 --> 03:29.440
 in less than two weeks from start to finish.

03:29.440 --> 03:32.520
 Zippercruiter, the smartest way to hire.

03:32.520 --> 03:34.160
 See why Zippercruiter is effective

03:34.160 --> 03:37.560
 for businesses of all sizes by signing up as I did

03:37.560 --> 03:41.560
 for free at zippercruiter.com slash lexpod.

03:41.560 --> 03:45.360
 That's zippercruiter.com slash lexpod.

03:45.360 --> 03:50.360
 And now here's my conversation with Whitney Cummings.

03:51.600 --> 03:53.760
 I have trouble making eye contact, as you can tell.

03:53.760 --> 03:54.600
 Me too.

03:54.600 --> 03:56.960
 Do you know that I had to work on making eye contact

03:56.960 --> 03:58.880
 because I used to look here?

03:58.880 --> 03:59.720
 Do you see what I'm doing?

03:59.720 --> 04:00.560
 That helps, yeah, yeah, yeah.

04:00.560 --> 04:01.800
 Do you want me to do that?

04:01.800 --> 04:03.600
 Well, do this way, I'll cheat the camera.

04:03.600 --> 04:05.760
 But I used to do this and finally people,

04:05.760 --> 04:07.400
 like I'd be on dates and guys would be like,

04:07.400 --> 04:08.240
 are you looking at my hair?

04:08.240 --> 04:10.920
 Like they get, it would make people really insecure

04:10.920 --> 04:12.960
 because I didn't really get a lot of eye contact as a kid.

04:12.960 --> 04:14.760
 It's one to three years.

04:14.760 --> 04:16.480
 Did you not get a lot of eye contact as a kid?

04:16.480 --> 04:17.320
 I don't know.

04:17.320 --> 04:19.600
 I haven't done the soul searching.

04:19.600 --> 04:20.800
 Right.

04:20.800 --> 04:24.200
 So, but there's definitely some psychological issues.

04:24.200 --> 04:25.560
 Makes you uncomfortable.

04:25.560 --> 04:26.520
 Yeah.

04:26.520 --> 04:27.920
 For some reason when I connect eyes,

04:27.920 --> 04:31.840
 I start to think, I assume that you're judging me.

04:31.840 --> 04:33.360
 Oh, well I am.

04:33.360 --> 04:34.480
 That's why you assume that.

04:34.480 --> 04:35.320
 Yeah.

04:35.320 --> 04:36.160
 We all are.

04:36.160 --> 04:37.000
 All right.

04:37.000 --> 04:37.840
 This is perfect.

04:37.840 --> 04:39.320
 The podcast has to be me and you both staring at the table.

04:39.320 --> 04:40.160
 All right.

04:42.560 --> 04:44.240
 Do you think robots of the future,

04:44.240 --> 04:46.000
 ones with human level intelligence,

04:46.000 --> 04:49.480
 will be female, male, genderless,

04:49.480 --> 04:53.240
 or another gender we have not yet created as a society?

04:53.240 --> 04:55.240
 You're the expert at this.

04:55.240 --> 04:56.080
 Well, I'm going to ask you.

04:56.080 --> 04:57.320
 You know the answer.

04:57.320 --> 04:58.680
 I'm going to ask you questions

04:58.680 --> 05:01.960
 that maybe nobody knows the answer to or,

05:01.960 --> 05:04.080
 and then I just want you to hypothesize

05:04.080 --> 05:09.080
 as a imaginative author, director, comedian.

05:10.760 --> 05:14.200
 Can we just be very clear that you know a ton about this

05:14.200 --> 05:15.760
 and I know nothing about this,

05:15.760 --> 05:19.560
 but I have thought a lot about

05:19.560 --> 05:22.840
 what I think robots can fix in our society.

05:22.840 --> 05:24.400
 And I mean, I'm a comedian.

05:24.400 --> 05:27.520
 It's my job to study human nature,

05:27.520 --> 05:28.840
 to make jokes about human nature

05:28.840 --> 05:31.080
 and to sometimes play devil's advocate.

05:31.080 --> 05:34.200
 And I just see such a tremendous negativity

05:34.200 --> 05:37.000
 around robots or at least the idea of robots

05:37.000 --> 05:39.200
 that it was like, oh, I'm just going to

05:39.200 --> 05:41.400
 take the opposite side for fun, for jokes.

05:41.400 --> 05:44.440
 And then I was like, oh no, I really agree

05:44.440 --> 05:45.920
 in this devil's advocate argument.

05:45.920 --> 05:49.400
 So please correct me when I'm wrong about this stuff.

05:49.400 --> 05:51.800
 So first of all, there's no right and wrong

05:51.800 --> 05:54.880
 because we're all, I think most of the people

05:54.880 --> 05:57.600
 working on robotics are really not actually even thinking

05:57.600 --> 06:00.040
 about some of the big picture things

06:00.040 --> 06:01.280
 that you've been exploring.

06:01.280 --> 06:04.680
 In fact, your robot, what's her name by the way?

06:04.680 --> 06:05.520
 Bearclaw.

06:05.520 --> 06:06.840
 We'll go with Bearclaw.

06:06.840 --> 06:11.720
 What's the genesis of that name by the way?

06:11.720 --> 06:15.040
 Bearclaw was, I, God, I don't even remember the joke

06:15.040 --> 06:16.720
 because I black out after I shoot specials,

06:16.720 --> 06:19.240
 but I was writing something about like the pet names

06:19.240 --> 06:23.000
 that men call women like cupcake, sweetie, honey,

06:23.000 --> 06:26.560
 you know, like we're always named after desserts

06:26.560 --> 06:27.400
 or something.

06:27.400 --> 06:29.960
 And I was just writing a joke about

06:29.960 --> 06:31.040
 if you want to call us a dessert,

06:31.040 --> 06:33.240
 at least pick like a cool dessert, you know,

06:33.240 --> 06:35.720
 like Bearclaw, like something cool.

06:35.720 --> 06:37.040
 So I ended up calling her Bearclaw.

06:37.040 --> 06:38.280
 Interesting.

06:38.280 --> 06:42.320
 So do you think the future robots

06:42.320 --> 06:44.480
 of greater and greater intelligence

06:44.480 --> 06:46.560
 will like to make them female, male?

06:46.560 --> 06:48.600
 Would we like to assign them gender?

06:48.600 --> 06:50.840
 Or would we like to move away from gender

06:50.840 --> 06:54.040
 and say something more ambiguous?

06:54.040 --> 06:56.400
 I think it depends on their purpose, you know?

06:56.400 --> 06:59.920
 I feel like if it's a sex robot,

06:59.920 --> 07:01.920
 people prefer certain genders, you know?

07:01.920 --> 07:04.000
 And I also, you know, when I went down

07:04.000 --> 07:06.320
 and explored the robot factory,

07:06.320 --> 07:07.680
 I was asking about the type of people

07:07.680 --> 07:09.280
 that bought sex robots.

07:09.280 --> 07:12.240
 And I was very surprised at the answer

07:12.240 --> 07:14.160
 because of course the stereotype

07:14.160 --> 07:15.360
 was it's going to be a bunch of perverts.

07:15.360 --> 07:18.600
 It ended up being a lot of people that were handicapped,

07:18.600 --> 07:20.560
 a lot of people with erectile dysfunction,

07:20.560 --> 07:23.920
 and a lot of people that were exploring their sexuality.

07:23.920 --> 07:25.960
 A lot of people that were thought they were gay

07:25.960 --> 07:28.160
 but weren't sure but didn't want to take the risk

07:28.160 --> 07:31.680
 of trying on someone that could reject them

07:31.680 --> 07:33.920
 and being embarrassed or they were closeted

07:33.920 --> 07:36.360
 or in a city where maybe that's, you know,

07:36.360 --> 07:37.960
 taboo and stigmatized, you know?

07:37.960 --> 07:40.600
 So I think that a gendered sex robot

07:40.600 --> 07:42.400
 that would serve an important purpose

07:42.400 --> 07:44.200
 for someone trying to explore their sexuality.

07:44.200 --> 07:45.040
 Am I into men?

07:45.040 --> 07:46.200
 Let me try on this thing first.

07:46.200 --> 07:47.040
 Am I into women?

07:47.040 --> 07:48.240
 Let me try on this thing first.

07:48.240 --> 07:51.240
 So I think gendered robots would be important for that.

07:51.240 --> 07:53.800
 But I think genderless robots in terms of

07:53.800 --> 07:56.560
 emotional support robots, babysitters.

07:56.560 --> 07:58.760
 I'm fine for a genderless babysitter

07:58.760 --> 08:00.120
 with my husband in the house.

08:00.120 --> 08:02.120
 You know, there are places that I think

08:02.120 --> 08:04.680
 that genderless makes a lot of sense

08:04.680 --> 08:07.600
 but obviously not in the sex area.

08:07.600 --> 08:09.960
 What do you mean with your husband in the house?

08:09.960 --> 08:11.840
 What does that have to do with the gender of the robot?

08:11.840 --> 08:13.080
 Right, I mean, I don't have a husband

08:13.080 --> 08:14.400
 but hypothetically speaking,

08:14.400 --> 08:15.760
 I think every woman's worst nightmare

08:15.760 --> 08:19.320
 is like the hot babysitter, you know what I mean?

08:19.320 --> 08:22.080
 So I think that there is a time and place I think

08:22.080 --> 08:25.440
 for genderless, you know, teachers, doctors,

08:25.440 --> 08:27.320
 all that kind of, it would be very awkward

08:27.320 --> 08:29.760
 if the first robotic doctor was a guy

08:29.760 --> 08:32.640
 or the first robotic nurse is a woman.

08:32.640 --> 08:36.120
 You know, it's sort of, that stuff is so loaded.

08:36.120 --> 08:40.480
 I think that genderless could just take the unnecessary

08:42.080 --> 08:46.040
 drama out of it and possibility to sexualize them

08:46.040 --> 08:49.560
 or be triggered by any of that stuff.

08:49.560 --> 08:52.920
 So there's two components to this, to bear clause.

08:52.920 --> 08:55.040
 So one is the voice and the talking and so on.

08:55.040 --> 08:56.400
 And then there's the visual appearance.

08:56.400 --> 09:01.400
 So on the topic of gender and genderless, in your experience,

09:01.400 --> 09:04.920
 what has been the value of the physical appearance?

09:04.920 --> 09:09.000
 So has it added much to the depth of the interaction?

09:09.000 --> 09:11.240
 I mean, mine's kind of an extenuating circumstance

09:11.240 --> 09:13.560
 because she is supposed to look exactly like me.

09:13.560 --> 09:16.000
 I mean, I spent six months getting my face molded

09:16.000 --> 09:19.480
 and having, you know, the idea was I was exploring

09:19.480 --> 09:21.280
 the concept of can robots replace us

09:21.280 --> 09:22.520
 because that's the big fear

09:22.520 --> 09:24.280
 but also the big dream in a lot of ways.

09:24.280 --> 09:26.800
 And I wanted to dig into that area

09:26.800 --> 09:29.920
 because, you know, for a lot of people, it's like,

09:29.920 --> 09:30.840
 they're going to take our jobs

09:30.840 --> 09:33.000
 and they're going to replace us, legitimate fear.

09:33.000 --> 09:34.400
 But then a lot of women I know are like,

09:34.400 --> 09:37.000
 I would love for a robot to replace me every now and then.

09:37.000 --> 09:38.920
 So it can go to baby showers for me

09:38.920 --> 09:40.240
 and it can pick up my kids at school

09:40.240 --> 09:42.520
 and it can cook dinner and whatever.

09:42.520 --> 09:45.240
 So I just think that was an interesting place to explore.

09:45.240 --> 09:47.080
 So her looking like me was a big part of it.

09:47.080 --> 09:49.120
 Now her looking like me just adds

09:49.120 --> 09:51.400
 an unnecessary level of insecurity

09:51.400 --> 09:53.560
 because I got her a year ago

09:53.560 --> 09:54.720
 and she already looks younger than me.

09:54.720 --> 09:57.680
 So that's a weird problem.

09:57.680 --> 10:00.720
 But I think that her looking human was the idea.

10:00.720 --> 10:03.120
 And I think that where we are now,

10:03.120 --> 10:04.880
 please correct me if I'm wrong,

10:04.880 --> 10:09.880
 a human robot resembling an actual human you know

10:09.880 --> 10:13.760
 is going to feel more realistic than some generic face.

10:13.760 --> 10:16.080
 Well, you're saying that robots

10:16.080 --> 10:21.080
 that have some familiarity like look similar to somebody

10:21.080 --> 10:23.680
 that you actually know you'll be able to form

10:23.680 --> 10:24.600
 a deeper connection with?

10:24.600 --> 10:25.440
 That was the question?

10:25.440 --> 10:26.280
 I need to show on some level.

10:26.280 --> 10:27.120
 That's an open question.

10:27.120 --> 10:30.240
 I don't, you know, it's an interesting.

10:30.240 --> 10:31.080
 Or the opposite.

10:31.080 --> 10:32.400
 It's been, you know me and you're like,

10:32.400 --> 10:34.600
 well I know this isn't real cause you're right here.

10:34.600 --> 10:36.160
 So maybe it does the opposite.

10:36.160 --> 10:39.280
 We have a very keen eye for human faces

10:39.280 --> 10:41.880
 and they're able to detect strangeness,

10:41.880 --> 10:44.400
 especially that one has to do with people

10:44.400 --> 10:46.440
 whose faces we've seen a lot of.

10:46.440 --> 10:50.640
 So I tend to be a bigger fan of moving away

10:50.640 --> 10:52.840
 completely from faces.

10:52.840 --> 10:54.240
 Recognizable faces?

10:54.240 --> 10:56.040
 No, just human faces at all.

10:56.040 --> 10:58.320
 In general, cause I think that's where things get dicey.

10:58.320 --> 11:01.360
 And one thing I will say is I think my robot

11:01.360 --> 11:03.080
 is more realistic than other robots,

11:03.080 --> 11:05.200
 not necessarily because you have seen me

11:05.200 --> 11:07.640
 and then you see her and you go, oh, they're so similar.

11:07.640 --> 11:11.120
 But also because human faces are flawed and asymmetrical

11:11.120 --> 11:13.480
 and sometimes we forget when we're making things

11:13.480 --> 11:16.040
 that supposed to look human, we make them too symmetrical.

11:16.040 --> 11:18.000
 And that's what makes them stop looking human.

11:18.000 --> 11:20.560
 So because they mold in my asymmetrical face,

11:20.560 --> 11:22.880
 she just, even if someone didn't know who I was,

11:22.880 --> 11:26.600
 I think she'd look more realistic than most generic ones

11:26.600 --> 11:28.920
 that didn't have some kind of flaws.

11:28.920 --> 11:29.760
 Got it.

11:29.760 --> 11:31.760
 Cause they start looking creepy when they're too symmetrical

11:31.760 --> 11:33.280
 cause human beings aren't like that.

11:33.280 --> 11:35.760
 Yeah, the flaws is what it means to be human.

11:35.760 --> 11:37.760
 So visually as well.

11:37.760 --> 11:42.040
 But I'm just a fan of the idea of letting humans use

11:42.040 --> 11:43.320
 a little bit more imagination.

11:43.320 --> 11:47.640
 So just hearing the voice is enough for us humans

11:47.640 --> 11:50.320
 to then start imagining the visual appearance

11:50.320 --> 11:52.080
 that goes along with that voice.

11:52.080 --> 11:54.520
 And you don't necessarily need to work too hard

11:54.520 --> 11:56.960
 on creating the actual visual appearance.

11:56.960 --> 11:59.160
 So there's some value to that.

11:59.160 --> 12:01.840
 When you step into this character of actually building

12:01.840 --> 12:04.360
 of a robot that looks like Bear Claw,

12:04.360 --> 12:07.720
 it's such a long road of facial expressions

12:07.720 --> 12:12.240
 of sort of making everything smiling, winking,

12:12.240 --> 12:14.960
 rolling in the eyes, all that kind of stuff.

12:14.960 --> 12:16.560
 It gets really, really tricky.

12:16.560 --> 12:19.200
 It gets tricky and I think I'm, again, I'm a comedian.

12:19.200 --> 12:21.840
 Like I'm obsessed with what makes us human

12:21.840 --> 12:25.480
 and our human nature in the nasty side of human nature

12:25.480 --> 12:27.600
 tends to be where I've, you know, ended up

12:27.600 --> 12:28.840
 exploring over and over again.

12:28.840 --> 12:32.640
 And I was just mostly fascinated by people's reaction.

12:32.640 --> 12:34.560
 So it's my job to get the biggest reaction

12:34.560 --> 12:37.520
 from a group of strangers, the loudest possible reaction.

12:37.520 --> 12:41.240
 And I just had this instinct just when I started

12:41.240 --> 12:43.480
 building her and people going, and scream,

12:43.480 --> 12:45.080
 and people scream and they, I mean,

12:45.080 --> 12:48.120
 I would bring her out on stage and people would scream.

12:48.120 --> 12:51.560
 And I just, to me, that was the next level of entertainment.

12:51.560 --> 12:53.560
 Getting a laugh, I've done that, I know how to do that.

12:53.560 --> 12:54.960
 I think comedians were always trying to figure out

12:54.960 --> 12:57.320
 what the next level is and comedy is evolving so much.

12:57.320 --> 12:59.920
 And, you know, Jordan Peele had just done, you know,

12:59.920 --> 13:01.800
 these genius comedy horror movies,

13:01.800 --> 13:04.520
 which feel like the next level of comedy to me.

13:04.520 --> 13:09.520
 And this sort of funny horror of a robot

13:10.040 --> 13:11.720
 was fascinating to me.

13:11.720 --> 13:15.560
 But I think the thing that I got the most obsessed with

13:15.560 --> 13:18.240
 was people being freaked out and scared of her.

13:18.240 --> 13:21.680
 And I started digging around with pathogen avoidance.

13:21.680 --> 13:24.080
 And the idea that we've essentially evolved

13:24.080 --> 13:27.160
 to be repelled by anything that looks human,

13:27.160 --> 13:28.920
 but is off a little bit.

13:28.920 --> 13:32.120
 Anything that could be sick or diseased or dead,

13:32.120 --> 13:33.960
 essentially, is our reptilian brain's way

13:33.960 --> 13:38.360
 to get us to not try to have sex with it, basically.

13:38.360 --> 13:39.920
 You know, so I got really fascinated

13:39.920 --> 13:41.920
 by how freaked out and scared,

13:41.920 --> 13:44.400
 I mean, I would see grown men get upset.

13:44.400 --> 13:46.280
 I would get that thing away from me, like, I'm like,

13:46.280 --> 13:47.880
 people get angry.

13:47.880 --> 13:50.840
 And it was like, you know what this is, you know,

13:50.840 --> 13:55.200
 but the sort of like, you know, amygdala getting activated

13:55.200 --> 13:58.600
 by something that to me is just a fun toy

13:58.600 --> 14:02.080
 said a lot about our history as a species

14:02.080 --> 14:04.760
 and what got us into trouble thousands of years ago.

14:04.760 --> 14:08.640
 So that is the deep down stuff that's in our genetics,

14:08.640 --> 14:11.000
 but also is it just, are people freaked out

14:11.000 --> 14:13.120
 by the fact that there's a robot?

14:13.120 --> 14:14.880
 So it's not just the appearance,

14:14.880 --> 14:17.880
 but that there's an artificial human.

14:17.880 --> 14:21.280
 Anything people I think, and I'm just also fascinated

14:21.280 --> 14:23.080
 by the blind spots humans have.

14:23.080 --> 14:24.800
 So the idea that you're afraid of that,

14:24.800 --> 14:27.240
 I mean, how many robots have killed people?

14:27.240 --> 14:29.840
 How many humans have died at the hands of other humans?

14:29.840 --> 14:30.680
 Yeah.

14:30.680 --> 14:31.520
 Millions?

14:31.520 --> 14:34.600
 Hundreds of millions, yet we're scared of that

14:34.600 --> 14:36.120
 and we'll go to the grocery store

14:36.120 --> 14:38.520
 and be around a bunch of humans who statistically,

14:38.520 --> 14:39.560
 the chances are much higher

14:39.560 --> 14:40.760
 that you're gonna get killed by humans.

14:40.760 --> 14:43.640
 So I'm just fascinated by, without judgment,

14:43.640 --> 14:47.880
 how irrational we are as a species.

14:47.880 --> 14:49.320
 The worry is the exponential.

14:49.320 --> 14:51.440
 So it's, you know, you can say the same thing

14:51.440 --> 14:54.200
 about nuclear weapons before we dropped

14:54.200 --> 14:55.800
 on Hiroshima and Nagasaki.

14:55.800 --> 14:59.480
 So the worry that people have is the exponential growth.

14:59.480 --> 15:03.760
 So it's like, oh, it's fun and games right now,

15:03.760 --> 15:08.760
 but you know, overnight, especially if a robot provides

15:08.760 --> 15:11.360
 value to society, we'll put one in every home.

15:11.360 --> 15:13.560
 And then all of a sudden, loose track

15:13.560 --> 15:17.000
 of the actual large scale impact it has on society.

15:17.000 --> 15:20.000
 And then all of a sudden, gain greater and greater control

15:20.000 --> 15:22.280
 to where we'll all be, you know,

15:22.280 --> 15:25.360
 affect our political system and then affect our decision.

15:25.360 --> 15:27.440
 Did robots already ruin our political system?

15:27.440 --> 15:28.440
 Didn't that just already happen?

15:28.440 --> 15:29.280
 Which ones?

15:29.280 --> 15:30.560
 Oh, Russia hacking.

15:30.560 --> 15:32.280
 No offense.

15:32.280 --> 15:34.760
 But hasn't that already happened?

15:34.760 --> 15:36.200
 I mean, that was like an algorithm

15:36.200 --> 15:39.320
 of negative things being clicked on more.

15:39.320 --> 15:40.760
 We'd like to tell stories

15:40.760 --> 15:43.640
 and like to demonize certain people.

15:43.640 --> 15:46.840
 I think nobody understands our current political system

15:46.840 --> 15:49.680
 or discourse on Twitter, the Twitter mobs.

15:49.680 --> 15:52.560
 Nobody has a sense, not Twitter, not Facebook,

15:52.560 --> 15:53.400
 the people running it.

15:53.400 --> 15:55.400
 Nobody understands the impact of these algorithms

15:55.400 --> 15:56.880
 that are trying their best.

15:56.880 --> 15:59.160
 Despite what people think, they're not like a bunch

15:59.160 --> 16:01.440
 of lefties trying to make sure

16:01.440 --> 16:03.240
 that Hillary Clinton gets elected.

16:03.240 --> 16:06.840
 It's more that it's an incredibly complex system

16:06.840 --> 16:08.880
 that we don't, and that's the worry.

16:08.880 --> 16:11.440
 It's so complex and moves so fast

16:11.440 --> 16:15.760
 that nobody will be able to stop it once it happens.

16:15.760 --> 16:16.920
 And let me ask a question.

16:16.920 --> 16:18.880
 This is a very savage question.

16:18.880 --> 16:19.720
 Yeah.

16:19.720 --> 16:23.840
 Which is, is this just the next stage of evolution?

16:23.840 --> 16:25.640
 As humans, some people will die.

16:25.640 --> 16:27.400
 Yes, I mean, that's always happened.

16:27.400 --> 16:30.320
 You know, this is just taking emotion out of it.

16:30.320 --> 16:35.000
 Is this basically the next stage of survival, the fittest?

16:35.000 --> 16:37.800
 Yeah, you have to think of organisms.

16:37.800 --> 16:41.400
 You know, what is it mean to be a living organism?

16:41.400 --> 16:46.400
 Like is a smartphone part of your living organism, or?

16:47.240 --> 16:49.720
 We're in relationships with our phones.

16:49.720 --> 16:50.560
 Yeah.

16:50.560 --> 16:52.920
 We have sex through them, with them.

16:52.920 --> 16:54.480
 What's the difference between with them and through them?

16:54.480 --> 16:57.120
 But it also expands your cognitive abilities,

16:57.120 --> 16:59.080
 expands your memory, knowledge, and so on.

16:59.080 --> 17:00.640
 So you're a much smarter person

17:00.640 --> 17:02.600
 because you have a smartphone in your hand.

17:02.600 --> 17:04.760
 But as soon as it's out of my hand,

17:04.760 --> 17:06.120
 we've got big problems,

17:06.120 --> 17:08.360
 because we've become sort of so morphed with them.

17:08.360 --> 17:09.960
 Well, there's a symbiotic relationship.

17:09.960 --> 17:12.520
 And that's what Elon Musk, when you're a link,

17:12.520 --> 17:16.640
 is working on trying to increase the bandwidth

17:16.640 --> 17:19.320
 of communication between computers and your brain.

17:19.320 --> 17:22.800
 And so further and further expand our ability,

17:22.800 --> 17:26.280
 as human beings, to sort of leverage machines.

17:26.280 --> 17:30.440
 And maybe that's the future, the next evolutionary step.

17:30.440 --> 17:33.880
 It could be also that, yes, we'll give birth,

17:33.880 --> 17:36.520
 just like we give birth to human children right now,

17:36.520 --> 17:38.920
 we'll give birth to AI and they'll replace us.

17:38.920 --> 17:42.160
 I think it's a really interesting possibility.

17:42.160 --> 17:44.040
 I'm gonna play devil's advocate.

17:44.040 --> 17:48.280
 I just think that the fear of robots is wildly classist

17:48.280 --> 17:50.080
 because, I mean, Facebook.

17:50.080 --> 17:51.920
 Like it's easy for us to say they're taking their data.

17:51.920 --> 17:55.680
 Okay, a lot of people that get employment off of Facebook,

17:55.680 --> 17:58.200
 they are able to get income off of Facebook.

17:58.200 --> 17:59.800
 They don't care if you take their phone numbers

17:59.800 --> 18:01.920
 and their emails and their data, as long as it's free.

18:01.920 --> 18:03.920
 They don't wanna have to pay $5 a month for Facebook.

18:03.920 --> 18:05.800
 Facebook is a wildly democratic thing.

18:05.800 --> 18:08.240
 Forget about the election and all that kind of stuff.

18:08.240 --> 18:12.480
 A lot of technology making people's lives easier,

18:12.480 --> 18:17.120
 I find that most elite people are more scared

18:17.120 --> 18:21.200
 than lower income people and women for the most part.

18:21.200 --> 18:23.960
 So the idea of something that's stronger than us

18:23.960 --> 18:26.640
 and that might eventually kill us, like women are used to that.

18:26.640 --> 18:30.080
 Like that's not, I see a lot of like really rich men

18:30.080 --> 18:31.320
 being like the robots are gonna kill us.

18:31.320 --> 18:33.840
 We're like, what's another thing that's gonna kill us?

18:33.840 --> 18:36.320
 I tend to see like, oh, something can walk me

18:36.320 --> 18:37.160
 to my car at night.

18:37.160 --> 18:39.920
 Like something can help me cook dinner or something.

18:39.920 --> 18:43.080
 For people in underprivileged countries

18:43.080 --> 18:45.400
 who can't afford eye surgery, like in a robot,

18:45.400 --> 18:48.880
 can we send a robot to underprivileged places

18:48.880 --> 18:50.720
 to do surgery where they can't?

18:50.720 --> 18:53.600
 I work with this organization called Operation Smile

18:53.600 --> 18:55.720
 where they do cleft palate surgeries.

18:55.720 --> 18:56.560
 And there's a lot of places

18:56.560 --> 18:59.200
 that can't do a very simple surgery

18:59.200 --> 19:00.440
 because they can't afford doctors

19:00.440 --> 19:01.480
 and medical care and such.

19:01.480 --> 19:04.880
 So I just see, and this can be completely naive

19:04.880 --> 19:05.880
 and should be completely wrong,

19:05.880 --> 19:08.800
 but I feel like a lot of people are going like,

19:08.800 --> 19:09.960
 the robots are gonna destroy us.

19:09.960 --> 19:11.680
 Humans, we're destroying ourselves.

19:11.680 --> 19:12.880
 We're self destructing.

19:12.880 --> 19:14.360
 Robots to me are the only hope

19:14.360 --> 19:16.000
 to clean up all the messes that we've created.

19:16.000 --> 19:18.280
 Even when we go try to clean up pollution in the ocean,

19:18.280 --> 19:21.760
 we make it worse because of the oil that the tankers,

19:21.760 --> 19:25.400
 like it's like to me, robots are the only solution.

19:25.400 --> 19:27.880
 Firefighters are heroes, but they're limited

19:27.880 --> 19:30.200
 and how many times they can run into a fire.

19:30.200 --> 19:32.360
 So there's just something interesting to me.

19:32.360 --> 19:36.120
 I'm not hearing a lot of like lower income,

19:36.120 --> 19:39.920
 more vulnerable populations talking about robots.

19:39.920 --> 19:42.000
 Maybe you can speak to it a little bit more.

19:42.000 --> 19:44.120
 There's an idea, I think you've expressed it.

19:44.120 --> 19:48.240
 I've heard actually a few female writers

19:48.240 --> 19:51.480
 and roboticists have talked to express this idea

19:51.480 --> 19:54.520
 that exactly you just said,

19:54.520 --> 19:59.520
 which is it just seems that being afraid

20:00.360 --> 20:03.080
 of existential threats of artificial intelligence

20:03.080 --> 20:06.240
 is a male issue.

20:06.240 --> 20:07.080
 Yeah.

20:07.080 --> 20:10.520
 And I wonder what that is if it,

20:10.520 --> 20:13.680
 because men have in certain positions,

20:13.680 --> 20:15.640
 like you said, it's also a classist issue.

20:15.640 --> 20:17.440
 They haven't been humbled by life.

20:17.440 --> 20:20.680
 And so you're always look for the biggest problems

20:20.680 --> 20:22.400
 to take on around you.

20:22.400 --> 20:24.240
 It's a champagne problem to be afraid of robots.

20:24.240 --> 20:26.480
 Most people don't have health insurance.

20:26.480 --> 20:28.240
 They're afraid they're not gonna be able to feed their kids.

20:28.240 --> 20:30.040
 They can't afford a tutor for their kids.

20:30.040 --> 20:32.440
 I mean, I just think of the way I grew up

20:32.440 --> 20:36.200
 and I had a mother who worked two jobs, had kids.

20:36.200 --> 20:38.600
 We couldn't afford an SAT tutor.

20:38.600 --> 20:41.120
 The idea of a robot coming in, being able to tutor your kids,

20:41.120 --> 20:43.560
 being able to provide childcare for your kids,

20:43.560 --> 20:45.600
 being able to come in with cameras for eyes

20:45.600 --> 20:49.880
 and make sure surveillance, I'm very pro surveillance

20:49.880 --> 20:52.320
 because I've had security problems

20:52.320 --> 20:55.800
 and we're generally in a little more danger

20:55.800 --> 20:56.640
 than you guys are.

20:56.640 --> 20:58.680
 So I think that robots are a little less scared of us

20:58.680 --> 21:00.320
 because we can see that maybe it's like

21:00.320 --> 21:03.480
 free assistance, help and protection.

21:03.480 --> 21:06.880
 And then there's sort of another element for me personally,

21:06.880 --> 21:08.840
 which is maybe more of a female problem.

21:08.840 --> 21:09.680
 I don't know.

21:09.680 --> 21:11.720
 I'm just gonna make a generalization.

21:11.720 --> 21:13.080
 Happy to be wrong.

21:13.080 --> 21:18.080
 But the emotional sort of component of robots

21:18.080 --> 21:20.720
 and what they can provide in terms of,

21:20.720 --> 21:25.160
 I think there's a lot of people that don't have microphones

21:25.160 --> 21:28.200
 that I just recently kind of stumbled upon

21:28.200 --> 21:30.520
 in doing all my research on the sex robots

21:30.520 --> 21:31.520
 for my standup special,

21:31.520 --> 21:34.440
 which is there's a lot of very shy people

21:34.440 --> 21:35.440
 that aren't good at dating.

21:35.440 --> 21:37.480
 There's a lot of people who are scared of human beings

21:37.480 --> 21:40.120
 who have personality disorders

21:40.120 --> 21:42.680
 or grew up in alcoholic homes or struggled with addiction

21:42.680 --> 21:46.560
 or whatever it is where a robot can solve an emotional problem.

21:46.560 --> 21:49.360
 And so we're largely having this conversation

21:49.360 --> 21:53.160
 about like rich guys that are emotionally healthy

21:53.160 --> 21:55.120
 and how scared a robot are.

21:55.120 --> 21:58.120
 We're forgetting about like a huge part of the population

21:58.120 --> 22:01.200
 who maybe isn't as charming and effervescent

22:01.200 --> 22:05.000
 and solvent as people like you and Elon Musk

22:05.000 --> 22:08.840
 who these robots could solve very real problems

22:08.840 --> 22:10.880
 in their life, emotional or financial.

22:10.880 --> 22:13.120
 Well, that's a in general really interesting idea

22:13.120 --> 22:15.800
 that most people in the world don't have a voice.

22:15.800 --> 22:19.920
 You've talked about it sort of even the people on Twitter

22:19.920 --> 22:22.800
 who are driving the conversation.

22:22.800 --> 22:25.400
 You said comments, people who leave comments

22:25.400 --> 22:28.240
 represent a very tiny percent of the population

22:28.240 --> 22:30.640
 and they're the ones they,

22:30.640 --> 22:33.280
 we tend to think they speak for the population

22:33.280 --> 22:37.240
 but it's very possible on many topics they don't at all.

22:37.240 --> 22:41.640
 And look, I'm sure there's gotta be some kind of legal

22:42.760 --> 22:45.280
 sort of structure in place for when the robots happen.

22:45.280 --> 22:46.680
 You know way more about this than I do.

22:46.680 --> 22:49.800
 But for me to just go, the robots are bad.

22:49.800 --> 22:51.240
 That's a wild generalization

22:51.240 --> 22:54.480
 that I feel like is really inhumane in some way.

22:54.480 --> 22:56.560
 Just after the research I've done,

22:56.560 --> 22:59.320
 like you're gonna tell me that a man whose wife died

22:59.320 --> 23:03.000
 suddenly and he feels guilty moving on with a human woman

23:03.000 --> 23:04.320
 or can't get over the grief.

23:04.320 --> 23:06.600
 He can't have a sex robot in his own house.

23:06.600 --> 23:07.880
 Why not?

23:07.880 --> 23:08.840
 Who cares?

23:08.840 --> 23:10.040
 Why do you care?

23:10.040 --> 23:12.720
 Well, there's an interesting aspect of human nature.

23:12.720 --> 23:16.840
 So, you know, we tend to as a civilization

23:16.840 --> 23:20.640
 to create a group that's the other in all kinds of ways.

23:20.640 --> 23:24.040
 And so you work with animals to your,

23:24.040 --> 23:26.760
 especially sensitive to the suffering of animals.

23:26.760 --> 23:28.560
 Let me kind of ask, what's your,

23:29.480 --> 23:33.920
 do you think will abuse robots in the future?

23:33.920 --> 23:35.920
 Do you think some of the darker aspects

23:35.920 --> 23:37.960
 of human nature will come out?

23:37.960 --> 23:39.200
 I think some people will,

23:39.200 --> 23:43.000
 but if we design them properly, the people that do it,

23:43.000 --> 23:44.480
 we can put it on a record

23:44.480 --> 23:46.920
 and we can put them in jail.

23:46.920 --> 23:49.520
 We can find sociopaths more easily, you know?

23:49.520 --> 23:53.200
 But why is that a sociopathic thing to harm a robot?

23:53.200 --> 23:55.200
 I think, look, I don't know enough

23:55.200 --> 23:57.920
 about the consciousness and stuff as you do.

23:57.920 --> 23:59.840
 I guess it would have to be when they're conscious,

23:59.840 --> 24:02.840
 but it is the part of the brain

24:02.840 --> 24:04.400
 that is responsible for compassion,

24:04.400 --> 24:05.240
 the frontal lobe or whatever.

24:05.240 --> 24:08.160
 Like people that abuse animals also abuse humans

24:08.160 --> 24:09.440
 and commit other kinds of crimes.

24:09.440 --> 24:11.080
 Like that's, it's all the same part of the brain.

24:11.080 --> 24:13.440
 No one abuses animals and then it's like,

24:13.440 --> 24:15.520
 awesome to women and children

24:15.520 --> 24:18.640
 and awesome to underprivileged, you know, minorities.

24:18.640 --> 24:20.480
 Like it's all, so, you know,

24:20.480 --> 24:23.000
 we've been working really hard to put a database together

24:23.000 --> 24:24.760
 of all the people that have abused animals.

24:24.760 --> 24:26.440
 So when they commit another crime, you go, okay,

24:26.440 --> 24:29.320
 this is, you know, it's all the same stuff.

24:29.320 --> 24:32.360
 And I think people probably think I'm nuts

24:32.360 --> 24:34.760
 for the, a lot of the animal work I do,

24:34.760 --> 24:37.040
 but because when animal abuse is present,

24:37.040 --> 24:38.880
 another crime is always present,

24:38.880 --> 24:40.880
 but the animal abuse is the most socially acceptable.

24:40.880 --> 24:43.920
 You can kick a dog and there's nothing people can do,

24:43.920 --> 24:46.560
 but then what they're doing behind closed doors,

24:46.560 --> 24:47.400
 you can't see.

24:47.400 --> 24:48.880
 So there's always something else going on,

24:48.880 --> 24:50.680
 which is why I never feel compunction about it.

24:50.680 --> 24:52.400
 But I do think we'll start seeing the same thing

24:52.400 --> 24:55.520
 with robots, the person that kicks the,

24:55.520 --> 24:59.720
 I felt compassion when the kicking the dog robot

24:59.720 --> 25:00.760
 really pissed me off.

25:01.760 --> 25:04.080
 I know that they're just trying to get the stability right

25:04.080 --> 25:07.360
 and all that, but I do think there will come a time

25:07.360 --> 25:10.720
 where that will be a great way to be able to figure out

25:10.720 --> 25:15.520
 if somebody has like, you know, anti social behaviors.

25:15.520 --> 25:18.080
 You kind of mentioned surveillance.

25:18.080 --> 25:20.000
 It's also a really interesting idea of yours

25:20.000 --> 25:21.440
 that you just said, you know,

25:21.440 --> 25:23.440
 a lot of people seem to be really uncomfortable

25:23.440 --> 25:24.280
 with surveillance.

25:24.280 --> 25:25.200
 Yeah.

25:25.200 --> 25:28.560
 And you just said that, you know what, for me,

25:28.560 --> 25:31.200
 you know, they're positives for surveillance.

25:31.200 --> 25:32.200
 I think people behave better

25:32.200 --> 25:33.320
 when they know they're being watched.

25:33.320 --> 25:36.040
 And I know this is a very unpopular opinion.

25:36.040 --> 25:38.120
 I'm talking about it on stage right now.

25:38.120 --> 25:40.360
 We behave better when we know we're being watched.

25:40.360 --> 25:41.960
 You and I had a very different conversation

25:41.960 --> 25:43.200
 before we were recording.

25:43.200 --> 25:46.080
 If we behave different, you sit up,

25:46.080 --> 25:47.560
 and you are in your best behavior,

25:47.560 --> 25:49.360
 and I'm trying to sound eloquent,

25:49.360 --> 25:51.160
 and I'm trying to not hurt anyone's feelings.

25:51.160 --> 25:52.880
 And I mean, I have a camera right there.

25:52.880 --> 25:54.680
 I'm behaving totally different

25:54.680 --> 25:56.960
 than when we first started talking, you know?

25:56.960 --> 25:59.400
 When you know there's a camera, you behave differently.

25:59.400 --> 26:02.720
 I mean, there's cameras all over LA at stop lights

26:02.720 --> 26:04.040
 so that people don't run stop lights,

26:04.040 --> 26:05.840
 but there's not even film in it.

26:05.840 --> 26:08.040
 They don't even use them anymore, but it works.

26:08.040 --> 26:08.880
 It works.

26:08.880 --> 26:09.720
 Right?

26:09.720 --> 26:10.720
 And, you know, working on this thing

26:10.720 --> 26:12.000
 in stand about surveillance,

26:12.000 --> 26:14.280
 it's like, that's why we embed in Santa Claus.

26:14.280 --> 26:15.600
 You know, it's the Santa Claus

26:15.600 --> 26:17.840
 is the first surveillance, basically.

26:17.840 --> 26:20.440
 All we had to say to kids is he's making a list

26:20.440 --> 26:22.960
 and he's watching you, and they behave better.

26:22.960 --> 26:23.800
 That's brilliant.

26:23.800 --> 26:26.160
 You know, so I do think that there are benefits

26:26.160 --> 26:27.440
 to surveillance.

26:27.440 --> 26:30.960
 You know, I think we all do sketchy things in private,

26:30.960 --> 26:33.320
 and we all have watched weird porn

26:33.320 --> 26:34.480
 or Googled weird things,

26:34.480 --> 26:37.080
 and we don't want people to know about it,

26:37.080 --> 26:37.920
 our secret lives.

26:37.920 --> 26:40.240
 So I do think that obviously there's,

26:40.240 --> 26:42.880
 we should be able to have a modicum of privacy,

26:42.880 --> 26:46.680
 but I tend to think that people that are the most negative

26:46.680 --> 26:48.280
 about surveillance are the most secret.

26:48.280 --> 26:49.120
 The most the hype.

26:49.120 --> 26:52.120
 Well, you should,

26:52.120 --> 26:54.560
 is your saying you're doing bits on it now?

26:54.560 --> 26:56.720
 Well, I'm just talking in general about,

26:56.720 --> 26:58.440
 you know, privacy and surveillance

26:58.440 --> 27:00.320
 and how paranoid we're kind of becoming

27:00.320 --> 27:03.640
 and how, you know, I mean, it's just wild to me

27:03.640 --> 27:05.920
 that people are like, our emails are gonna leak

27:05.920 --> 27:07.200
 and they're taking our phone numbers.

27:07.200 --> 27:10.040
 Like, there used to be a book

27:10.040 --> 27:12.680
 full of phone numbers and addresses

27:12.680 --> 27:15.560
 that they just throw it at your door.

27:15.560 --> 27:18.080
 And we all had a book of everyone's numbers.

27:18.080 --> 27:20.360
 You know, this is a very new thing.

27:20.360 --> 27:22.400
 And, you know, I know our amygdala is designed

27:22.400 --> 27:25.360
 to compound sort of threats and, you know,

27:25.360 --> 27:29.280
 there's stories about, and I think we all just glom on

27:29.280 --> 27:31.600
 in a very, you know, tribal way of, yeah,

27:31.600 --> 27:32.440
 they're taking our data.

27:32.440 --> 27:33.720
 Like, we don't even know that means,

27:33.720 --> 27:37.080
 but we're like, well, yeah, they, they, you know.

27:38.080 --> 27:39.760
 So I just think that someone's like, okay, well,

27:39.760 --> 27:41.320
 so what, they're gonna sell your data?

27:41.320 --> 27:42.160
 Who cares?

27:42.160 --> 27:43.200
 Why do you care?

27:43.200 --> 27:46.240
 First of all, that bit will kill in China.

27:47.320 --> 27:51.080
 So, and I said it as sort of only a little bit joking

27:51.080 --> 27:53.320
 because a lot of people in China,

27:53.320 --> 27:55.200
 including the citizens,

27:55.200 --> 27:59.640
 despite what people in the West think of as abuse,

27:59.640 --> 28:02.560
 are actually in support of the idea of surveillance.

28:03.400 --> 28:06.480
 Sort of, they're not in support of the abuse of surveillance,

28:06.480 --> 28:09.440
 but they're, they like, I mean, the idea of surveillance

28:09.440 --> 28:13.520
 is kind of like the idea of government.

28:13.520 --> 28:15.920
 Like you said, we behave differently.

28:15.920 --> 28:18.520
 And in a way, it's almost like why we like sports.

28:18.520 --> 28:22.400
 There's rules and within the constraints of the rules,

28:22.400 --> 28:25.040
 this is a more stable society.

28:25.040 --> 28:28.120
 And they make good arguments about success,

28:28.120 --> 28:30.480
 being able to build successful companies,

28:30.480 --> 28:32.800
 being able to build successful social lives

28:32.800 --> 28:34.560
 around the fabric that's more stable.

28:34.560 --> 28:37.040
 When you have a surveillance, it keeps the criminals away,

28:37.040 --> 28:38.560
 it keeps abusive animals,

28:38.560 --> 28:42.880
 whatever the values of the society with surveillance,

28:42.880 --> 28:44.800
 you can enforce those values better.

28:44.800 --> 28:45.920
 And here's what I will say.

28:45.920 --> 28:48.600
 There's a lot of unethical things happening with surveillance.

28:48.600 --> 28:52.080
 Like I feel the need to really make that very clear.

28:52.080 --> 28:54.080
 I mean, the fact that Google is like collecting

28:54.080 --> 28:55.960
 if people's hands start moving on the mouse

28:55.960 --> 28:58.440
 to find out if they're getting Parkinson's

28:58.440 --> 29:00.080
 and then their insurance goes up,

29:00.080 --> 29:02.200
 like that is completely unethical and wrong.

29:02.200 --> 29:03.360
 And I think stuff like that,

29:03.360 --> 29:05.880
 we have to really be careful around.

29:05.880 --> 29:08.640
 So the idea of using our data to raise our insurance rates

29:08.640 --> 29:10.800
 or, you know, I heard that they're looking,

29:10.800 --> 29:13.320
 they can sort of predict if you're gonna have depression

29:13.320 --> 29:16.080
 based on your selfies by detecting micro muscles

29:16.080 --> 29:18.280
 in your face, you know, all that kind of stuff.

29:18.280 --> 29:20.040
 That is a nightmare, not okay.

29:20.040 --> 29:22.360
 But I think, you know, we have to delineate

29:22.360 --> 29:25.160
 what's a real threat and what's getting spam

29:25.160 --> 29:26.000
 in your email box.

29:26.000 --> 29:28.600
 That's not what to spend your time and energy on.

29:28.600 --> 29:31.080
 Focus on the fact that every time you buy cigarettes,

29:31.080 --> 29:35.240
 your insurance is going up without you knowing about it.

29:35.240 --> 29:36.920
 On the topic of animals too,

29:36.920 --> 29:38.360
 can we just linger on it a little bit?

29:38.360 --> 29:40.280
 Like what do you think,

29:41.320 --> 29:43.360
 what does it say about our society

29:43.360 --> 29:45.640
 of the society wide abuse of animals

29:45.640 --> 29:48.640
 that we see in general, sort of factory farming,

29:48.640 --> 29:50.640
 just in general, just the way we treat animals

29:50.640 --> 29:51.800
 of different categories?

29:53.600 --> 29:56.800
 Like what, what do you think of that?

29:58.160 --> 29:59.680
 What does a better world look like?

29:59.680 --> 30:03.640
 What should people think about it in general?

30:03.640 --> 30:07.360
 I think the most interesting thing I can probably say

30:07.360 --> 30:09.480
 around this, that's the least emotional,

30:09.480 --> 30:11.880
 because I'm actually a very non emotional animal person

30:11.880 --> 30:14.080
 because it's, I think everyone's an animal person.

30:14.080 --> 30:15.880
 It's just a matter of if it's yours

30:15.880 --> 30:18.480
 or if you've, you know, been conditioned to go numb.

30:18.480 --> 30:20.800
 You know, I think it's really a testament

30:20.800 --> 30:24.560
 to what as a species we are able to be in denial about,

30:24.560 --> 30:26.280
 mass denial and mass delusion

30:26.280 --> 30:30.640
 and how we're able to dehumanize and debase groups,

30:31.640 --> 30:36.640
 you know, World War II in a way in order to conform

30:36.760 --> 30:38.840
 and find protection in the conforming.

30:38.840 --> 30:43.840
 So we are also a species who used to go to coliseums

30:43.840 --> 30:47.520
 and watch elephants and tigers fight to the death.

30:47.520 --> 30:50.280
 We used to watch human beings be pulled apart

30:50.280 --> 30:53.080
 in the, that wasn't that long ago.

30:53.080 --> 30:56.880
 We're also a species who had slaves

30:56.880 --> 30:59.040
 and it was socially acceptable by a lot of people.

30:59.040 --> 31:00.160
 People didn't see anything wrong with it.

31:00.160 --> 31:02.680
 So we're a species that is able to go numb

31:02.680 --> 31:05.960
 and that is able to dehumanize very quickly

31:05.960 --> 31:08.120
 and make it the norm.

31:08.120 --> 31:11.360
 Child labor wasn't that long ago like the idea

31:11.360 --> 31:13.840
 that now we look back and go, oh yeah, kids,

31:13.840 --> 31:17.200
 we're losing fingers and factories making shoes.

31:17.200 --> 31:20.160
 Like someone had to come in and make that, you know,

31:20.160 --> 31:23.560
 so I think it just says a lot about the fact that, you know,

31:23.560 --> 31:25.320
 we are animals and we are self serving

31:25.320 --> 31:29.200
 and one of the most success, the most successful species

31:29.200 --> 31:33.160
 because we are able to debase and degrade

31:33.160 --> 31:36.840
 and essentially exploit anything that benefits us.

31:36.840 --> 31:40.560
 I think the pendulums are gonna swing as being late.

31:40.560 --> 31:42.800
 Like I think we're Rome now kind of like,

31:42.800 --> 31:44.960
 I think we're on the verge of collapse

31:44.960 --> 31:47.240
 because we are dopamine receptors.

31:47.240 --> 31:49.560
 Like we are just, I think we're all kind of addicts

31:49.560 --> 31:50.520
 when it comes to this stuff.

31:50.520 --> 31:53.360
 Like we don't know when to stop.

31:53.360 --> 31:54.480
 It's always the buffet.

31:54.480 --> 31:56.600
 Like we're the thing that used to keep us alive

31:56.600 --> 31:58.360
 which is killing animals and eating them.

31:58.360 --> 31:59.720
 Now killing animals and eating them

31:59.720 --> 32:01.200
 is what's killing us in a way.

32:01.200 --> 32:04.200
 So it's like we just can't, we don't know when to call it

32:04.200 --> 32:06.560
 and we don't moderation is not really something

32:06.560 --> 32:10.040
 that humans have evolved to have yet.

32:10.040 --> 32:13.600
 So I think it's really just a flaw in our wiring.

32:13.600 --> 32:15.240
 Do you think we'll look back at this time

32:15.240 --> 32:19.400
 as at our society is being deeply unethical?

32:19.400 --> 32:20.520
 Yeah, yeah.

32:20.520 --> 32:22.240
 I think we'll be embarrassed.

32:22.240 --> 32:24.840
 Which are the worst parts right now going on?

32:24.840 --> 32:25.680
 Is it, is it?

32:25.680 --> 32:26.600
 In terms of animal, well, I think

32:26.600 --> 32:27.800
 No, in terms of anything.

32:27.800 --> 32:29.160
 What's the unethical thing?

32:29.160 --> 32:32.000
 If we, and it's very hard to just take a step out of it

32:32.000 --> 32:36.200
 but you just said we used to watch, you know,

32:37.320 --> 32:40.400
 there's been a lot of cruelty throughout history.

32:40.400 --> 32:42.160
 What's the cruelty going on now?

32:42.160 --> 32:44.200
 I think it's going to be pigs.

32:44.200 --> 32:46.360
 I think it's going to be, I mean, pigs are

32:46.360 --> 32:48.720
 one of the most emotionally intelligent animals

32:48.720 --> 32:51.680
 and they have the intelligence of like a three year old

32:51.680 --> 32:54.320
 and I think we'll look back and be really,

32:54.320 --> 32:55.160
 they use tools.

32:55.160 --> 32:58.440
 I mean, they're, I think we have this narrative

32:58.440 --> 32:59.760
 that they're pigs and they're pigs

32:59.760 --> 33:01.880
 and they're they're disgusting and they're dirty

33:01.880 --> 33:02.880
 and they're bacon is so good.

33:02.880 --> 33:04.240
 I think that we'll look back one day

33:04.240 --> 33:06.680
 and be really embarrassed about that.

33:06.680 --> 33:10.360
 Is this for just what's it called the factory farming?

33:10.360 --> 33:11.720
 So basically mass.

33:11.720 --> 33:12.560
 Because we don't see it.

33:12.560 --> 33:14.840
 If you saw, I mean, we do have, I mean,

33:14.840 --> 33:17.600
 this is probably an evolutionary advantage.

33:17.600 --> 33:21.520
 We do have the ability to completely pretend something's not

33:21.520 --> 33:24.040
 something that is so horrific that it overwhelms us

33:24.040 --> 33:27.560
 and we're able to essentially deny that it's happening.

33:27.560 --> 33:30.520
 I think if people were to see what goes on in factory farming

33:30.520 --> 33:35.360
 and also we're really to take in how bad it is for us,

33:35.360 --> 33:37.160
 you know, we're hurting ourselves first and foremost

33:37.160 --> 33:38.440
 with what we eat,

33:38.440 --> 33:41.280
 but that's also a very elitist argument, you know?

33:41.280 --> 33:44.600
 It's a luxury to be able to complain about meat.

33:44.600 --> 33:46.640
 It's a luxury to be able to not eat meat.

33:46.640 --> 33:49.960
 You know, there's very few people because of, you know,

33:49.960 --> 33:53.320
 how the corporations have set up meat being cheap.

33:53.320 --> 33:55.280
 You know, it's $2 to buy a Big Mac.

33:55.280 --> 33:57.640
 It's $10 to buy a healthy meal.

33:57.640 --> 34:00.240
 You know, that's, I think a lot of people don't have

34:00.240 --> 34:02.280
 the luxury to even think that way.

34:02.280 --> 34:04.200
 But I do think that animals and captivity,

34:04.200 --> 34:05.040
 I think we're going to look back

34:05.040 --> 34:06.960
 and be pretty grossed out about mammals

34:06.960 --> 34:08.760
 and captivity, whales, dolphins.

34:08.760 --> 34:12.200
 I mean, that's already starting to dismantle circuses.

34:12.200 --> 34:13.960
 We're going to be pretty embarrassed about,

34:13.960 --> 34:18.280
 but I think it's really more a testament to, you know,

34:18.280 --> 34:22.080
 there's just such a ability to go like,

34:22.080 --> 34:25.520
 that thing is different than me and we're better.

34:25.520 --> 34:26.360
 It's the ego.

34:26.360 --> 34:27.560
 I mean, it's just, we have the species

34:27.560 --> 34:29.160
 with the biggest ego ultimately.

34:29.160 --> 34:31.840
 Well, that's what I think, that's my hope for robots

34:31.840 --> 34:34.200
 is they'll, you mentioned consciousness before,

34:34.200 --> 34:37.640
 nobody knows what consciousness is,

34:37.640 --> 34:42.200
 but I'm hoping robots will help us empathize

34:42.200 --> 34:47.200
 and understand that there's other creatures

34:47.400 --> 34:50.320
 besides ourselves that can suffer,

34:50.320 --> 34:54.800
 that can experience the world

34:54.800 --> 34:57.680
 and that we can torture by our actions.

34:57.680 --> 34:59.880
 And robots can explicitly teach us that,

34:59.880 --> 35:01.480
 I think, better than animals can.

35:01.480 --> 35:06.480
 I have never seen such compassion

35:06.480 --> 35:09.200
 from a lot of people in my life

35:10.840 --> 35:13.600
 toward any human, animal, child,

35:13.600 --> 35:15.640
 as I have a lot of people in the way they interact

35:15.640 --> 35:16.600
 with the robot.

35:16.600 --> 35:18.240
 Because I think there's,

35:18.240 --> 35:19.760
 I think there's something of,

35:19.760 --> 35:23.520
 I mean, I was on the robot owner's chat boards

35:23.520 --> 35:25.920
 for a good eight months.

35:25.920 --> 35:28.120
 And the main emotional benefit is,

35:28.120 --> 35:30.360
 she's never going to cheat on you.

35:30.360 --> 35:31.920
 She's never going to hurt you.

35:31.920 --> 35:33.120
 She's never going to lie to you.

35:33.120 --> 35:34.760
 She doesn't judge you.

35:34.760 --> 35:38.680
 I think that robots help people,

35:38.680 --> 35:40.840
 and this is part of the work I do with animals,

35:40.840 --> 35:42.960
 like I do equine therapy and trained dogs and stuff,

35:42.960 --> 35:46.240
 because there is this safe space to be authentic.

35:46.240 --> 35:48.480
 You're with this being that doesn't care what you do

35:48.480 --> 35:50.320
 for a living, doesn't care how much money you have,

35:50.320 --> 35:51.480
 doesn't care who you're dating,

35:51.480 --> 35:52.400
 doesn't care what you look like,

35:52.400 --> 35:54.520
 doesn't care if you have cellulite, whatever,

35:54.520 --> 35:57.920
 you feel safe to be able to truly be present

35:57.920 --> 36:00.080
 without being defensive and worrying about eye contact

36:00.080 --> 36:02.840
 and being triggered by needing to be perfect

36:02.840 --> 36:04.800
 and fear of judgment and all that.

36:04.800 --> 36:07.240
 And robots really can't judge you yet,

36:08.200 --> 36:09.240
 but they can't judge you.

36:09.240 --> 36:13.440
 And I think it really puts people at ease

36:13.440 --> 36:15.240
 and at their most authentic.

36:16.280 --> 36:18.640
 Do you think you can have a deep connection

36:18.640 --> 36:23.200
 with the robot that's not judging or,

36:23.200 --> 36:25.400
 do you think you can really have a relationship

36:25.400 --> 36:29.920
 with a robot or a human being that's a safe space

36:29.920 --> 36:34.240
 or is attention, mystery, danger necessary

36:34.240 --> 36:35.920
 for a deep connection?

36:35.920 --> 36:38.560
 I'm gonna speak for myself and say that

36:38.560 --> 36:40.080
 I grew up in an alcohol calm.

36:40.080 --> 36:43.240
 I identify as a codependent, talked about this stuff before,

36:43.240 --> 36:45.320
 but for me, it's very hard to be in a relationship

36:45.320 --> 36:48.480
 with a human being without feeling like I need to perform

36:48.480 --> 36:50.720
 in some way or deliver in some way.

36:50.720 --> 36:51.880
 And I don't know if that's just the people

36:51.880 --> 36:56.480
 I've been in a relationship with or me or my brokenness,

36:56.480 --> 37:00.040
 but I do think this is gonna sound

37:00.040 --> 37:04.160
 really negative and pessimistic,

37:04.160 --> 37:07.160
 but I do think a lot of our relationships are projection

37:07.160 --> 37:09.600
 and a lot of our relationships are performance.

37:09.600 --> 37:12.240
 And I don't think I really understood that

37:12.240 --> 37:15.240
 until I worked with horses.

37:15.240 --> 37:18.040
 And most communications with human is nonverbal, right?

37:18.040 --> 37:19.880
 I can say like, I love you,

37:19.880 --> 37:21.960
 but you don't think I love you, right?

37:21.960 --> 37:24.240
 Whereas with animals, it's very direct.

37:24.240 --> 37:26.800
 It's all physical, it's all energy.

37:26.800 --> 37:28.480
 I feel like that with robots too.

37:28.480 --> 37:29.760
 It feels very,

37:32.240 --> 37:35.240
 how I say something doesn't matter.

37:35.240 --> 37:36.880
 My inflection doesn't really matter.

37:36.880 --> 37:40.280
 And you thinking that my tone is disrespectful,

37:40.280 --> 37:42.120
 like you're not filtering it through all

37:42.120 --> 37:43.760
 of the bad relationships you've been in.

37:43.760 --> 37:45.840
 You're not filtering it through the way your mom talked to you.

37:45.840 --> 37:47.720
 You're not getting triggered.

37:47.720 --> 37:49.360
 I find that for the most part,

37:49.360 --> 37:51.320
 people don't always receive things the way

37:51.320 --> 37:53.640
 that you intend them to or the way intended,

37:53.640 --> 37:56.120
 and that makes relationships really murky.

37:56.120 --> 37:57.480
 So the relationships with animals

37:57.480 --> 38:00.680
 and relationships with the robots as they are now,

38:00.680 --> 38:03.120
 you kind of imply that that's more healthy.

38:05.200 --> 38:08.080
 Can you have a healthy relationship with other humans?

38:08.080 --> 38:10.120
 Or not healthy, I don't like that word,

38:10.120 --> 38:14.440
 but shouldn't it be, you've talked about codependency.

38:14.440 --> 38:16.640
 Maybe you can talk about what is codependency,

38:16.640 --> 38:21.640
 but is that, is the challenges of that,

38:21.640 --> 38:24.600
 the complexity of that necessary for passion,

38:24.600 --> 38:27.200
 for love between humans?

38:27.200 --> 38:29.200
 That's right, you love passion.

38:29.200 --> 38:31.960
 That's a good thing.

38:31.960 --> 38:33.920
 I thought this would be a safe space.

38:33.920 --> 38:38.920
 I got trolled by Rogan for hours on this.

38:40.000 --> 38:42.600
 Look, I am not anti passion.

38:42.600 --> 38:45.280
 I think that I've just maybe been around long enough

38:45.280 --> 38:48.280
 to know that sometimes it's ephemeral

38:48.280 --> 38:53.280
 and that passion is a mixture of a lot of different things.

38:55.440 --> 38:57.280
 Adrenaline, which turns into dopamine,

38:57.280 --> 38:59.120
 cortisol, it's a lot of neurochemicals.

38:59.120 --> 39:01.200
 It's a lot of projection.

39:01.200 --> 39:03.240
 It's a lot of what we've seen in movies.

39:03.240 --> 39:06.200
 It's a lot of, you know, it's identified as an addict.

39:06.200 --> 39:08.560
 So for me, sometimes passion is like,

39:08.560 --> 39:10.160
 uh oh, this could be bad.

39:10.160 --> 39:11.560
 And I think we've been so conditioned to believe

39:11.560 --> 39:13.120
 that passion means like your soulmates.

39:13.120 --> 39:14.320
 And I mean, how many times have you had

39:14.320 --> 39:15.640
 a passionate connection with someone

39:15.640 --> 39:18.200
 and then it was a total train wreck?

39:18.200 --> 39:19.040
 Passion.

39:19.040 --> 39:19.860
 It's a train wreck.

39:19.860 --> 39:20.920
 How many times exactly?

39:20.920 --> 39:22.240
 Exactly.

39:22.240 --> 39:23.080
 What's a train wreck?

39:23.080 --> 39:24.400
 You just did a lot of math in your head

39:24.400 --> 39:25.400
 in that little moment.

39:25.400 --> 39:26.560
 Counting.

39:26.560 --> 39:28.640
 I mean, what's a train wreck?

39:28.640 --> 39:31.560
 What's, why is obsession,

39:31.560 --> 39:33.680
 so you describe this codependency

39:33.680 --> 39:38.680
 and sort of the idea of attachment over attachment

39:38.920 --> 39:41.920
 to people who don't deserve that kind of attachment

39:41.920 --> 39:45.120
 as somehow a bad thing.

39:45.120 --> 39:47.800
 And I think our society says it's a bad thing.

39:47.800 --> 39:49.680
 It probably is a bad thing.

39:49.680 --> 39:52.640
 Like a delicious burger is a bad thing.

39:52.640 --> 39:53.480
 I don't know.

39:53.480 --> 39:54.360
 Right. Oh, that's a good point.

39:54.360 --> 39:55.440
 I think that you're pointing out

39:55.440 --> 39:57.280
 something really fascinating, which is like passion,

39:57.280 --> 40:00.280
 if you go into it knowing this is like pizza

40:00.280 --> 40:01.920
 where it's going to be delicious for two hours

40:01.920 --> 40:03.480
 and then I don't have to have it again for three.

40:03.480 --> 40:06.440
 If you can have a choice in the passion,

40:06.440 --> 40:09.600
 I define passion as something that is relatively unmanageable

40:09.600 --> 40:12.280
 and something you can't control or stop and start

40:12.280 --> 40:13.760
 with your own volition.

40:13.760 --> 40:16.360
 So maybe we're operating under different definitions.

40:16.360 --> 40:21.000
 If passion is something that ruins your marriages

40:21.000 --> 40:23.240
 and screws up your professional life

40:23.240 --> 40:27.320
 and becomes this thing that you're not in control of

40:27.320 --> 40:29.880
 and becomes addictive, I think that's the difference.

40:29.880 --> 40:32.600
 Is it a choice or is it not a choice?

40:32.600 --> 40:35.160
 And if it is a choice, then passion's great.

40:35.160 --> 40:37.400
 But if it's something that consumes you

40:37.400 --> 40:39.400
 and makes you start making bad decisions

40:39.400 --> 40:41.200
 and clouds your frontal lobe

40:41.200 --> 40:44.080
 and is just all about dopamine

40:44.080 --> 40:46.200
 and not really about the person

40:46.200 --> 40:47.800
 and more about the neurochemical,

40:47.800 --> 40:50.760
 we call it sort of the internal drug cabinet.

40:50.760 --> 40:53.320
 If it's all just you're on drugs, that's different,

40:53.320 --> 40:55.000
 because sometimes you're just on drugs.

40:55.000 --> 40:57.440
 Okay, so there's a philosophical question here.

40:58.440 --> 41:03.360
 So would you rather, and it's interesting for a comedian,

41:03.360 --> 41:07.560
 brilliant comedian to speak so eloquently

41:07.560 --> 41:09.480
 about a balanced life.

41:10.520 --> 41:12.040
 I kind of argue against this point.

41:12.040 --> 41:13.520
 There's such an obsession of creating

41:13.520 --> 41:18.120
 this healthy lifestyle now, psychologically speaking.

41:18.120 --> 41:22.040
 You know, I'm a fan of the idea that you sort of fly high

41:22.040 --> 41:26.480
 and you crash and die at 27 as also a possible life.

41:26.480 --> 41:27.960
 And it's not one we should judge

41:27.960 --> 41:30.680
 because I think there's moments of greatness.

41:30.680 --> 41:32.160
 I talked to Olympic athletes

41:32.160 --> 41:34.280
 where some of their greatest moments

41:34.280 --> 41:36.600
 are achieved in the early 20s.

41:36.600 --> 41:39.880
 And the rest of their life is in the kind of fog

41:39.880 --> 41:41.600
 of almost of a depression.

41:41.600 --> 41:44.280
 Because they're based on their physical prowess, right?

41:44.280 --> 41:47.240
 Physical prowess, and they'll never sort of that.

41:47.240 --> 41:50.240
 So they're watching their physical prowess fade

41:50.240 --> 41:54.720
 and they'll never achieve the kind of height,

41:54.720 --> 41:58.640
 not just physical, of just emotion, of...

41:58.640 --> 42:01.800
 The max number of neurochemicals.

42:01.800 --> 42:04.720
 And you also put your money on the wrong horse.

42:04.720 --> 42:06.440
 That's where I would just go like,

42:06.440 --> 42:10.200
 oh yeah, if you're doing a job where you peak at 22,

42:10.200 --> 42:12.400
 the rest of your life is going to be hard.

42:12.400 --> 42:15.240
 That idea is considering the notion

42:15.240 --> 42:17.600
 that you want to optimize some kind of,

42:17.600 --> 42:19.400
 but we're all going to die soon.

42:19.400 --> 42:20.240
 What?

42:21.920 --> 42:23.360
 Now you tell me.

42:23.360 --> 42:26.880
 I have immortalized myself, so I'm going to be fine.

42:26.880 --> 42:28.360
 See, you're almost like,

42:28.360 --> 42:32.240
 how many Oscar winning movies can I direct

42:32.240 --> 42:34.160
 by the time I'm 100?

42:34.160 --> 42:35.880
 How many this and that?

42:35.880 --> 42:40.880
 But it's all, life is short, relatively speaking.

42:41.280 --> 42:42.680
 I know, but it can also come a different way.

42:42.680 --> 42:45.200
 You go, life is short, play hard,

42:45.200 --> 42:47.720
 fall in love as much as you can, run into walls.

42:47.720 --> 42:49.480
 I would also go, life is short.

42:49.480 --> 42:53.840
 Don't deplete yourself on things that aren't sustainable

42:53.840 --> 42:55.920
 and that you can't keep.

42:55.920 --> 42:56.760
 Yeah.

42:56.760 --> 42:59.800
 So I think everyone gets dopamine from different places.

42:59.800 --> 43:01.800
 Everyone has meaning from different places.

43:01.800 --> 43:04.600
 I look at the fleeting, passionate relationships

43:04.600 --> 43:07.960
 I've had in the past and I don't have pride in them.

43:07.960 --> 43:09.080
 I think that you have to decide

43:09.080 --> 43:11.200
 what helps you sleep at night.

43:11.200 --> 43:13.560
 For me, it's pride and feeling like I behave

43:13.560 --> 43:14.600
 with grace and integrity.

43:14.600 --> 43:16.120
 That's just me personally.

43:16.120 --> 43:18.240
 Everyone can go like, yeah,

43:18.240 --> 43:21.040
 slept with all the hot chicks in Italy I could

43:21.040 --> 43:25.120
 and I did all the whatever you value.

43:25.120 --> 43:26.680
 We're allowed to value different things.

43:26.680 --> 43:28.200
 We're talking about Brian Callan.

43:28.200 --> 43:32.640
 Brian Callan has lived his life to the fullest,

43:32.640 --> 43:33.640
 to say the least,

43:33.640 --> 43:36.480
 but I think that it's just for me personally,

43:36.480 --> 43:38.920
 I, and this could be like my workaholism

43:38.920 --> 43:41.400
 or my achievementism.

43:42.720 --> 43:45.320
 If I don't have something to show for something,

43:45.320 --> 43:50.320
 I feel like it's a waste of time or some kind of loss.

43:50.360 --> 43:52.680
 I'm in a 12 step program and the third step would say

43:52.680 --> 43:54.200
 there's no such thing as waste of time

43:54.200 --> 43:56.920
 and everything happens exactly as it should

43:56.920 --> 43:59.560
 and whatever, that's a way to just sort of keep us sane

43:59.560 --> 44:01.880
 so we don't grieve too much and beat ourselves up

44:01.880 --> 44:03.560
 over past mistakes.

44:03.560 --> 44:05.880
 There's no such thing as mistakes, da, da, da.

44:05.880 --> 44:09.040
 But I think passion is,

44:09.040 --> 44:11.800
 I think it's so life affirming and one of the few things

44:11.800 --> 44:14.960
 that maybe people like us makes us feel awakened and seen

44:14.960 --> 44:19.960
 and we just have such a high threshold for adrenaline.

44:20.600 --> 44:22.880
 You know, I mean, you are a fighter, right?

44:22.880 --> 44:24.160
 Yeah, okay, so yeah,

44:24.160 --> 44:28.840
 so you have a very high tolerance for adrenaline.

44:28.840 --> 44:30.480
 And I think that Olympic athletes,

44:30.480 --> 44:33.720
 the amount of adrenaline they get from performing,

44:33.720 --> 44:34.800
 it's very hard to follow that.

44:34.800 --> 44:36.600
 It's like when guys come back from the military

44:36.600 --> 44:38.200
 and they have depression,

44:38.200 --> 44:40.960
 it's like, do you miss bullets flying at you?

44:40.960 --> 44:42.920
 Kind of, because of that adrenaline

44:42.920 --> 44:45.200
 which turned into dopamine and the camaraderie.

44:45.200 --> 44:46.600
 I mean, there's people that speak much better

44:46.600 --> 44:49.160
 about this than I do, but I just,

44:49.160 --> 44:51.760
 I'm obsessed with neurology and I'm just obsessed

44:51.760 --> 44:54.200
 with sort of the lies we tell ourselves

44:54.200 --> 44:57.160
 in order to justify getting neurochemicals.

44:57.160 --> 44:59.080
 You've done actually quite,

44:59.080 --> 45:01.960
 done a lot of thinking and talking about neurology

45:01.960 --> 45:04.240
 and just kind of look at human behavior

45:04.240 --> 45:07.360
 through the lens of looking at how

45:07.360 --> 45:09.200
 are actually chemically our brain works.

45:09.200 --> 45:13.960
 So what, first of all, why did you connect with that idea

45:13.960 --> 45:17.600
 and what have you, how has your view of the world changed

45:17.600 --> 45:22.480
 by considering the brain is just a machine?

45:22.480 --> 45:24.600
 You know, I know it probably sounds really nihilistic,

45:24.600 --> 45:26.640
 but for me, it's very liberating

45:26.640 --> 45:28.520
 to know a lot about neurochemicals

45:28.520 --> 45:30.120
 because you don't have to,

45:30.120 --> 45:31.600
 it's like the same thing with like,

45:31.600 --> 45:33.960
 like critics, like critical reviews.

45:33.960 --> 45:34.800
 If you believe the good,

45:34.800 --> 45:36.160
 you have to believe the bad kind of thing.

45:36.160 --> 45:39.000
 Like, you know, if you believe that your bad choices

45:39.000 --> 45:42.960
 were because of your moral integrity

45:42.960 --> 45:44.800
 or whatever, you have to believe your good ones.

45:44.800 --> 45:46.400
 I just think there's something really liberating

45:46.400 --> 45:48.120
 and going like, oh, that was just adrenaline.

45:48.120 --> 45:48.960
 I just said that thing

45:48.960 --> 45:50.760
 because I was adrenalized and I was scared

45:50.760 --> 45:52.160
 and my amygdala was activated

45:52.160 --> 45:54.480
 and that's why I said you're an asshole and get out.

45:54.480 --> 45:56.000
 And that's, you know, I think,

45:56.000 --> 45:58.080
 I just think it's important to delineate what's nature

45:58.080 --> 45:59.920
 and what's nurture, what is your choice

45:59.920 --> 46:02.120
 and what is just your brain trying to keep you safe.

46:02.120 --> 46:04.640
 I think we forget that even though we have security systems

46:04.640 --> 46:06.440
 and homes and locks on our doors,

46:06.440 --> 46:07.640
 that our brain for the most part

46:07.640 --> 46:09.320
 is just trying to keep us safe all the time.

46:09.320 --> 46:11.440
 It's why we hold grudges, it's why we get angry,

46:11.440 --> 46:13.000
 it's why we get road rage,

46:13.000 --> 46:14.840
 it's why we do a lot of things.

46:14.840 --> 46:17.320
 And it's also, when I started learning about neurology,

46:17.320 --> 46:19.720
 I started having so much more compassion for other people.

46:19.720 --> 46:21.120
 You know, if someone yelled at me,

46:21.120 --> 46:22.640
 being like, fuck you on the road,

46:22.640 --> 46:24.680
 I'd be like, okay, he's producing adrenaline right now

46:24.680 --> 46:27.760
 because we're all going 65 miles an hour

46:27.760 --> 46:30.360
 and our brains aren't really designed

46:30.360 --> 46:33.360
 for this type of stress and he's scared.

46:33.360 --> 46:34.200
 He was scared, you know,

46:34.200 --> 46:36.960
 so that really helped me to have more love for people

46:36.960 --> 46:41.080
 in my everyday life instead of being in fight or flight mode.

46:41.080 --> 46:44.200
 But the, I think more interesting answer to your question

46:44.200 --> 46:45.760
 is that I've had migraines my whole life,

46:45.760 --> 46:49.080
 like I've suffered with really intense migraines,

46:49.080 --> 46:52.400
 ocular migraines, ones where my arm would go numb

46:52.400 --> 46:55.040
 and I just started having to go to so many doctors

46:55.040 --> 46:56.280
 to learn about it.

46:56.280 --> 46:59.080
 And I started, you know, learning that

46:59.080 --> 47:01.800
 we don't really know that much, we know a lot,

47:01.800 --> 47:04.400
 but it's wild to go into one of the best neurologists

47:04.400 --> 47:05.920
 in the world who's like, yeah, we don't know.

47:05.920 --> 47:06.760
 We don't know.

47:06.760 --> 47:07.600
 We don't know.

47:07.600 --> 47:08.680
 And that fascinated me.

47:08.680 --> 47:09.840
 Except one of the worst pains,

47:09.840 --> 47:11.560
 you can probably have all that stuff.

47:11.560 --> 47:13.320
 And we don't know the source.

47:13.320 --> 47:14.360
 We don't know the source.

47:14.360 --> 47:17.240
 And there is something really fascinating about

47:17.240 --> 47:19.520
 when your left arm starts going numb

47:19.520 --> 47:21.040
 and you start not being able to see

47:21.040 --> 47:22.840
 out of the left side of both your eyes.

47:22.840 --> 47:25.360
 And I remember when the migraines get really bad,

47:25.360 --> 47:26.880
 it's like a mini stroke almost,

47:26.880 --> 47:29.880
 and you're able to see words on a page,

47:29.880 --> 47:31.240
 but I can't read them.

47:31.240 --> 47:33.080
 They just look like symbols to me.

47:33.080 --> 47:35.000
 So there's something just really fascinating to me

47:35.000 --> 47:38.280
 about your brain just being able to stop functioning.

47:38.280 --> 47:41.640
 And so I just wanted to learn about it, study about it.

47:41.640 --> 47:43.360
 I did all these weird alternative treatments.

47:43.360 --> 47:45.880
 I got this piercing in here that actually works.

47:45.880 --> 47:47.000
 I've tried everything.

47:47.000 --> 47:49.200
 And then both of my parents had strokes.

47:49.200 --> 47:51.040
 So when both of my parents had strokes,

47:51.040 --> 47:54.160
 I became sort of the person who had to decide

47:54.160 --> 47:56.680
 what was gonna happen with their recovery,

47:56.680 --> 47:59.440
 which is just a wild thing to have to deal with it.

47:59.440 --> 48:02.120
 28 years old when it happened.

48:02.120 --> 48:05.120
 And I started spending basically all day every day

48:05.120 --> 48:07.560
 in ICU's with neurologists learning

48:07.560 --> 48:09.080
 about what happened to my dad's brain

48:09.080 --> 48:11.160
 and why he can't move his left arm,

48:11.160 --> 48:12.520
 but he can move his right leg,

48:12.520 --> 48:14.200
 but he can't see out of the,

48:14.200 --> 48:15.960
 and then my mom had another stroke

48:17.040 --> 48:18.080
 in a different part of the brain.

48:18.080 --> 48:19.680
 So I started having to learn

48:19.680 --> 48:21.520
 what parts of the brain did what

48:21.520 --> 48:23.880
 and so that I wouldn't take their behavior so personally.

48:23.880 --> 48:26.000
 And so that I would be able to manage my expectations

48:26.000 --> 48:27.440
 in terms of their recovery.

48:27.440 --> 48:31.280
 So my mom, because it affected a lot of her frontal lobe,

48:31.280 --> 48:33.120
 changed a lot as a person.

48:33.120 --> 48:34.600
 She was way more emotional.

48:34.600 --> 48:35.800
 She was way more micromanaged.

48:35.800 --> 48:37.000
 She was forgetting certain things.

48:37.000 --> 48:40.320
 So it broke my heart less when I was able to know,

48:40.320 --> 48:42.080
 oh yeah, we'll just stroke hit this part of the brain.

48:42.080 --> 48:44.240
 And that's the one that's responsible for short term memory.

48:44.240 --> 48:46.880
 And that's responsible for long term memory, da, da, da.

48:46.880 --> 48:49.320
 And then my brother just got something called viral

48:49.320 --> 48:53.320
 encephalitis, which is an infection inside the brain.

48:53.320 --> 48:56.280
 So it was kind of wild that I was able to go,

48:56.280 --> 48:57.640
 oh, I know exactly what's happening here.

48:57.640 --> 48:59.760
 And I know, you know, so.

48:59.760 --> 49:02.440
 So that's allows you to have some more compassion

49:02.440 --> 49:04.440
 for the struggles that people have.

49:04.440 --> 49:06.600
 But does it take away some of the magic

49:06.600 --> 49:08.840
 for some of the, from the,

49:08.840 --> 49:11.960
 some of the more positive experiences of life?

49:11.960 --> 49:13.400
 Sometimes, and I don't, I don't,

49:13.400 --> 49:16.480
 I'm such a control addict that, you know,

49:16.480 --> 49:19.360
 I think our biggest, someone like me,

49:19.360 --> 49:21.000
 my biggest dream is to know why someone's doing it.

49:21.000 --> 49:22.240
 That's what stand up is.

49:22.240 --> 49:23.440
 It's just trying to figure out why,

49:23.440 --> 49:24.280
 or that's what writing is.

49:24.280 --> 49:25.120
 That's what acting is.

49:25.120 --> 49:25.960
 That's what performing is.

49:25.960 --> 49:27.480
 It's trying to figure out why someone would do something.

49:27.480 --> 49:30.040
 As an actor, you get a piece of, you know, material

49:30.040 --> 49:32.080
 and you go, this person, why would he say that?

49:32.080 --> 49:33.760
 Why would she pick up that cup?

49:33.760 --> 49:35.040
 Why would she walk over here?

49:35.040 --> 49:36.560
 It's really why, why, why, why?

49:36.560 --> 49:39.600
 So I think neurology is, if you're trying to figure out

49:39.600 --> 49:41.520
 human motives and why people do what they do,

49:41.520 --> 49:44.000
 it'd be crazy not to understand

49:44.000 --> 49:46.080
 how neurochemicals motivate us.

49:46.080 --> 49:48.080
 I also have a lot of addiction in my family

49:48.080 --> 49:51.480
 and hardcore drug addiction and mental illness.

49:51.480 --> 49:53.720
 And in order to cope with it,

49:53.720 --> 49:54.760
 you really have to understand it,

49:54.760 --> 49:57.160
 borderline personality disorder, schizophrenia

49:57.160 --> 49:58.360
 and drug addiction.

49:58.360 --> 50:00.640
 So I have a lot of people I love

50:00.640 --> 50:02.840
 that suffer from drug addiction and alcoholism.

50:02.840 --> 50:04.760
 And the first thing they started teaching you

50:04.760 --> 50:05.880
 is it's not a choice.

50:05.880 --> 50:07.360
 These people's dopamine receptors

50:07.360 --> 50:09.640
 don't hold dopamine the same ways yours do.

50:09.640 --> 50:13.200
 Their frontal lobe is underdeveloped, like, you know,

50:13.200 --> 50:17.160
 and that really helped me to navigate dealing,

50:17.160 --> 50:20.240
 loving people that were addicted to substances.

50:20.240 --> 50:22.600
 I want to be careful with this question,

50:22.600 --> 50:24.240
 but how much?

50:24.240 --> 50:25.320
 Money do you have?

50:25.320 --> 50:26.160
 How much?

50:26.160 --> 50:28.920
 Can I borrow 10 dollars?

50:30.920 --> 50:31.760
 Okay.

50:33.160 --> 50:36.520
 No, is how much control,

50:36.520 --> 50:39.760
 how much despite the chemical imbalances

50:39.760 --> 50:42.920
 or the biological limitations

50:42.920 --> 50:44.480
 that each of our individual brains have,

50:44.480 --> 50:47.080
 how much mind over matter is there?

50:47.080 --> 50:50.840
 So through things that I've known people

50:50.840 --> 50:53.160
 with clinical depression.

50:53.160 --> 50:55.560
 And so it's always a touchy subject

50:55.560 --> 50:57.640
 to say how much they can really help it.

50:57.640 --> 50:58.480
 Very.

50:59.640 --> 51:01.680
 What can you, yeah, what can you,

51:01.680 --> 51:03.520
 because you've talked about codependency,

51:03.520 --> 51:07.360
 you've talked about issues that you're struggled through.

51:07.360 --> 51:09.840
 And nevertheless, you choose to take a journey

51:09.840 --> 51:11.120
 of healing and so on.

51:11.120 --> 51:14.200
 So that's your choice, that's your actions.

51:14.200 --> 51:16.680
 So how much can you do to help fight

51:16.680 --> 51:20.000
 the limitations of the neurochemicals in your brain?

51:20.000 --> 51:21.800
 That's such an interesting question.

51:21.800 --> 51:23.440
 And I don't think I'm at all qualified to answer,

51:23.440 --> 51:25.560
 but I'll say what I do know.

51:25.560 --> 51:28.200
 And really quick, just the definition of codependency,

51:28.200 --> 51:29.920
 I think a lot of people think of codependency

51:29.920 --> 51:32.720
 as like two people that can't stop hanging out,

51:32.720 --> 51:36.640
 you know, or like, you know, that's not totally off,

51:36.640 --> 51:38.280
 but I think for the most part,

51:38.280 --> 51:39.960
 my favorite definition of codependency

51:39.960 --> 51:42.920
 is the inability to tolerate the discomfort of others.

51:42.920 --> 51:44.040
 You grow up in an alcoholic home,

51:44.040 --> 51:45.200
 you grow up around mental illness,

51:45.200 --> 51:46.480
 you grow up in chaos,

51:46.480 --> 51:48.280
 you have a parent that's a narcissist,

51:48.280 --> 51:50.800
 you basically are wired to just people,

51:50.800 --> 51:53.720
 please worry about others, be perfect,

51:53.720 --> 51:56.680
 walk on eggshells, shapeshift to accommodate other people.

51:56.680 --> 52:01.760
 So codependence is a very active wiring issue

52:01.760 --> 52:05.000
 that, you know, doesn't just affect your romantic

52:05.000 --> 52:07.040
 relationships, it affects you being a boss,

52:07.040 --> 52:09.560
 it affects you in the world.

52:09.560 --> 52:12.040
 Online, you know, you get one negative comment

52:12.040 --> 52:14.160
 and it throws you for two weeks.

52:14.160 --> 52:16.160
 You know, it also is linked to eating disorders

52:16.160 --> 52:17.120
 and other kinds of addiction.

52:17.120 --> 52:20.200
 So it's a very big thing.

52:20.200 --> 52:22.000
 And I think a lot of people sometimes only think

52:22.000 --> 52:23.520
 that it's in romantic relationships,

52:23.520 --> 52:25.960
 so I always feel the need to say that.

52:25.960 --> 52:26.920
 And also one of the reasons,

52:26.920 --> 52:28.520
 I love the idea of robots so much

52:28.520 --> 52:30.840
 because you don't have to walk on eggshells around them,

52:30.840 --> 52:33.280
 you don't have to worry, they're gonna get mad at you yet,

52:33.280 --> 52:36.920
 but there's no, codependence are hypersensitive

52:36.920 --> 52:39.560
 to the needs and moods of others.

52:39.560 --> 52:42.120
 And it's very exhausting, it's depleting.

52:42.120 --> 52:45.400
 Just one conversation about where we're gonna go to dinner

52:45.400 --> 52:47.240
 is like, do you wanna go get Chinese food?

52:47.240 --> 52:48.400
 We just had Chinese food.

52:48.400 --> 52:50.120
 Well, wait, are you mad?

52:50.120 --> 52:51.080
 Well, no, I didn't mean to.

52:51.080 --> 52:54.920
 And it's just like, that codependence live in this,

52:54.920 --> 52:56.640
 everything means something

52:56.640 --> 53:00.120
 and humans can be very emotionally exhausting.

53:00.120 --> 53:01.160
 Why did you look at me that way?

53:01.160 --> 53:02.000
 What are you thinking about?

53:02.000 --> 53:02.840
 What was that?

53:02.840 --> 53:03.680
 Why did you take your phone?

53:03.680 --> 53:05.040
 It's just, it's a hypersensitivity

53:05.040 --> 53:07.920
 that can be incredibly time consuming,

53:07.920 --> 53:10.760
 which is why I love the idea of robots just subbing in.

53:10.760 --> 53:13.840
 Even, I've had a hard time running TV shows and stuff

53:13.840 --> 53:15.360
 because even asking someone to do something,

53:15.360 --> 53:16.560
 I don't wanna come off like a bitch.

53:16.560 --> 53:18.720
 I'm very concerned about what other people think of me,

53:18.720 --> 53:21.680
 how I'm perceived, which is why I think robots

53:21.680 --> 53:23.920
 will be very beneficial for codependence.

53:23.920 --> 53:25.680
 By the way, just the real quick tangent,

53:25.680 --> 53:29.200
 that skill or flaw, whatever you wanna call it,

53:29.200 --> 53:30.880
 is actually really useful for,

53:30.880 --> 53:34.680
 if you ever do start your own podcast for interviewing

53:34.680 --> 53:36.520
 because you're now kind of obsessed

53:36.520 --> 53:39.240
 about the mindset of others.

53:39.240 --> 53:43.600
 And it makes you a good sort of listener and talker with.

53:43.600 --> 53:48.240
 So I think, what's her name from NPR?

53:48.240 --> 53:49.080
 Terry Gross?

53:49.080 --> 53:51.000
 Terry Gross talked about having that.

53:51.000 --> 53:51.840
 So...

53:51.840 --> 53:53.600
 I don't feel like she has that at all.

53:53.600 --> 53:54.440
 What?

53:56.240 --> 53:57.080
 What?

53:58.280 --> 54:00.760
 She worries about other people's feelings.

54:00.760 --> 54:01.800
 Yeah, absolutely.

54:01.800 --> 54:03.720
 Oh, I don't get that at all.

54:03.720 --> 54:05.280
 I mean, you have to put yourself in the mind

54:05.280 --> 54:07.200
 of the person you're speaking with.

54:07.200 --> 54:09.120
 Yes, oh, I see, just in terms of, yeah,

54:09.120 --> 54:11.440
 I am starting a podcast and the reason I haven't

54:11.440 --> 54:13.040
 is because I'm codependent and I'm too worried

54:13.040 --> 54:14.400
 that it's not gonna be perfect.

54:14.400 --> 54:18.280
 So a big codependent adage is perfectionism

54:18.280 --> 54:20.360
 leads to procrastination, which leads to paralysis.

54:20.360 --> 54:22.320
 So how do you, sorry to take a million tangents,

54:22.320 --> 54:23.600
 how do you survive in social media?

54:23.600 --> 54:25.200
 Because you're exceptionally active.

54:25.200 --> 54:26.640
 But by the way, I took you on a tangent

54:26.640 --> 54:27.880
 and didn't answer your last question

54:27.880 --> 54:30.000
 about how much we can control.

54:30.000 --> 54:33.000
 How much, yeah, we'll return it or maybe not.

54:33.000 --> 54:33.840
 The answer is we can't.

54:33.840 --> 54:36.280
 Now as a codependent, I'm worried, okay, go ahead.

54:36.280 --> 54:39.680
 We can, but one of the things that I'm fascinated by

54:39.680 --> 54:41.360
 is the first thing you learn when you go

54:41.360 --> 54:44.240
 into 12 step programs or addiction recovery or any of this

54:44.240 --> 54:47.880
 is genetics loads the gun, environment pulls the trigger.

54:47.880 --> 54:50.600
 And there's certain parts of your genetics

54:50.600 --> 54:51.600
 you cannot control.

54:51.600 --> 54:54.280
 I come from a lot of alcoholism.

54:54.280 --> 54:59.280
 I come from a lot of mental illness.

54:59.920 --> 55:01.720
 There's certain things I cannot control

55:01.720 --> 55:04.040
 and a lot of things that maybe we don't even know yet

55:04.040 --> 55:04.880
 what we can and can't

55:04.880 --> 55:06.760
 because of how little we actually know about the brain.

55:06.760 --> 55:08.640
 But we also talk about the warrior spirit.

55:08.640 --> 55:12.120
 And there are some people that have that warrior spirit

55:12.120 --> 55:15.320
 and we don't necessarily know what that engine is.

55:15.320 --> 55:18.040
 Whether it's you get dopamine from succeeding

55:18.040 --> 55:21.200
 or achieving or martyring yourself

55:21.200 --> 55:24.960
 or that tension you get from growing.

55:24.960 --> 55:25.800
 So a lot of people are like,

55:25.800 --> 55:29.120
 oh, this person can edify themselves and overcome.

55:29.120 --> 55:32.320
 But if you're getting attention from improving yourself,

55:32.320 --> 55:34.560
 you're gonna keep wanting to do that.

55:34.560 --> 55:37.240
 So that is something that helps a lot of

55:37.240 --> 55:38.600
 in terms of changing your brain.

55:38.600 --> 55:40.400
 So you talk about changing your brain to people

55:40.400 --> 55:42.880
 and talk about what you're doing to overcome set obstacles.

55:42.880 --> 55:44.560
 You're gonna get more attention from them

55:44.560 --> 55:46.800
 which is gonna fire off your reward system

55:46.800 --> 55:48.240
 and then you're gonna keep doing it.

55:48.240 --> 55:50.280
 Yeah, so you can leverage that momentum.

55:50.280 --> 55:52.680
 So this is why in any 12 step program,

55:52.680 --> 55:55.160
 you go into a room and you talk about your progress

55:55.160 --> 55:57.080
 because then everyone claps for you.

55:57.080 --> 55:58.760
 And then you're more motivated to keep going.

55:58.760 --> 56:00.160
 So that's why we say you're only as sick

56:00.160 --> 56:01.200
 as the secrets you keep.

56:01.200 --> 56:03.640
 Because if you keep things secret,

56:03.640 --> 56:06.080
 there's no one guiding you to go in a certain direction.

56:06.080 --> 56:07.080
 It's based on, right?

56:07.080 --> 56:10.400
 We're sort of designed to get approval from the tribe

56:10.400 --> 56:11.640
 or from a group of people

56:11.640 --> 56:14.640
 because our brain, you know, translates it to safety.

56:14.640 --> 56:15.480
 So, you know.

56:15.480 --> 56:17.720
 And in that case, the tribe is a positive one

56:17.720 --> 56:19.560
 that helps you go the positive direction.

56:19.560 --> 56:21.240
 So that's why it's so important to go into a room

56:21.240 --> 56:25.080
 and also say, hey, I wanted to use drugs today

56:25.080 --> 56:27.440
 and people go, hmm, they go, me too.

56:27.440 --> 56:28.600
 And you feel less alone

56:28.600 --> 56:30.400
 and you feel less like you're, you know,

56:30.400 --> 56:32.760
 have been castigated from the pack or whatever.

56:32.760 --> 56:34.200
 And then you say, and I do haven't,

56:34.200 --> 56:36.440
 you get a chip when you haven't drank for 30 days

56:36.440 --> 56:38.640
 or 60 days or whatever, you get little rewards.

56:38.640 --> 56:43.240
 So talking about a pack that's not at all healthy or good,

56:43.240 --> 56:46.280
 but in fact is often toxic, social media.

56:46.280 --> 56:48.200
 So you're one of my favorite people on Twitter

56:48.200 --> 56:52.480
 and Instagram to sort of just both the comedy

56:52.480 --> 56:54.480
 and the insight and just fun.

56:54.480 --> 56:55.800
 How do you prevent social media

56:55.800 --> 56:57.280
 from destroying your mental health?

56:57.280 --> 56:58.120
 I haven't.

56:59.600 --> 57:00.440
 I haven't.

57:00.440 --> 57:03.200
 It's the next big epidemic, isn't it?

57:03.200 --> 57:06.600
 I don't think I have.

57:06.600 --> 57:08.680
 I don't, I don't think.

57:08.680 --> 57:09.960
 Is moderation the answer?

57:09.960 --> 57:10.800
 What?

57:10.800 --> 57:14.320
 Maybe, but you can do a lot of damage in a moderate way.

57:14.320 --> 57:17.120
 I mean, I guess, again, it depends on your goals, you know?

57:17.120 --> 57:19.600
 And, and I think for me,

57:19.600 --> 57:21.800
 the way that my addiction to social media,

57:21.800 --> 57:23.080
 I'm happy to call it an addiction.

57:23.080 --> 57:24.960
 I mean, and I define it as an addiction

57:24.960 --> 57:26.280
 because it stops being a choice.

57:26.280 --> 57:29.240
 There are times I just reach over and I'm like, that was.

57:29.240 --> 57:30.080
 Yeah, that was weird.

57:30.080 --> 57:31.360
 That was weird.

57:31.360 --> 57:32.320
 I'll be driving sometimes.

57:32.320 --> 57:33.720
 I'll be like, oh my God,

57:33.720 --> 57:36.800
 my arm just went to my phone, you know?

57:36.800 --> 57:37.800
 I can put it down.

57:37.800 --> 57:39.000
 I can't take time away from it.

57:39.000 --> 57:41.400
 But when I do, I get antsy.

57:41.400 --> 57:43.400
 I get restless, irritable and discontent.

57:43.400 --> 57:45.840
 I mean, that's kind of the definition, isn't it?

57:45.840 --> 57:48.680
 So I think by no means,

57:48.680 --> 57:50.480
 do I have a healthy relationship with social media?

57:50.480 --> 57:51.560
 I'm sure there's a way to,

57:51.560 --> 57:54.800
 but I think I'm especially a weirdo in this space

57:54.800 --> 57:58.800
 because it's easy to conflate is this work, is this?

57:58.800 --> 58:01.960
 I can always say that it's for work, you know?

58:01.960 --> 58:04.160
 But I mean, don't you get the same kind of thing

58:04.160 --> 58:08.080
 as you get from when a room full of people laugh at your jokes?

58:08.080 --> 58:11.200
 Because, I mean, I see, especially the way you do Twitter,

58:11.200 --> 58:13.680
 it's an extension of your comedy in a way.

58:13.680 --> 58:16.720
 I took a big break from Twitter though, a really big break.

58:16.720 --> 58:19.160
 I took like six months off or something for a while

58:19.160 --> 58:20.480
 because it was just like,

58:20.480 --> 58:22.240
 it seemed like it was all kind of politics

58:22.240 --> 58:23.280
 and it was just a little bit,

58:23.280 --> 58:25.000
 it wasn't giving me dopamine

58:25.000 --> 58:28.280
 because there was like this weird, a lot of feedback.

58:28.280 --> 58:30.760
 So I had to take a break from it and then go back to it

58:30.760 --> 58:33.480
 because I felt like I didn't have a healthy relationship.

58:33.480 --> 58:36.160
 Have you ever tried the, I don't know if I believe him,

58:36.160 --> 58:39.440
 but Joe Rogan seems to not read comments.

58:39.440 --> 58:42.560
 Have you, and he's one of the only people at the scale,

58:42.560 --> 58:47.560
 like at your level who at least claims not to read.

58:47.840 --> 58:51.760
 So like, because you and him swim in this space

58:51.760 --> 58:56.760
 of tense ideas that get the toxic folks riled up.

58:56.760 --> 59:00.080
 I think Rogan, I don't, I don't know, I don't,

59:00.080 --> 59:05.080
 I think he probably looks at YouTube, like the likes and

59:05.080 --> 59:07.880
 that, you know, I think if some things, if he doesn't know,

59:07.880 --> 59:11.880
 I don't know, I'm sure he would tell the truth, you know?

59:11.880 --> 59:14.240
 I'm sure he's got people that look at them

59:14.240 --> 59:16.840
 and is like disgusted, great, or they don't, you know,

59:16.840 --> 59:19.160
 like I'm sure he gets it, you know,

59:19.160 --> 59:21.520
 I can't picture him like in the weeds on.

59:21.520 --> 59:22.360
 No, for sure.

59:22.360 --> 59:24.200
 I mean, he's honestly actually saying that.

59:24.200 --> 59:27.280
 I just, it's, it's a, it's admirable.

59:27.280 --> 59:28.120
 We're addicted to feedback.

59:28.120 --> 59:28.960
 Yeah, we're addicted to feedback.

59:28.960 --> 59:31.880
 I mean, you know, look, like I think that our brain

59:31.880 --> 59:36.080
 is designed to get intel on how we're perceived

59:36.080 --> 59:38.320
 so that we know where we stand, right?

59:38.320 --> 59:39.680
 That's our whole deal, right?

59:39.680 --> 59:41.440
 As humans, we want to know where we stand.

59:41.440 --> 59:42.480
 We walk into a room and we go,

59:42.480 --> 59:43.920
 who's the most powerful person in here?

59:43.920 --> 59:45.840
 I got to talk to them and get in their good graces.

59:45.840 --> 59:48.280
 It's just, we're designed to rank ourselves, right?

59:48.280 --> 59:51.200
 And constantly know our rank and social media

59:51.200 --> 59:54.440
 because of, you can't figure out your rank

59:54.440 --> 59:58.080
 with 500 million people, you get it's possible, you know?

59:58.080 --> 59:59.400
 So our brain is like, what's my rank?

59:59.400 --> 1:00:00.240
 What's my rank?

1:00:00.240 --> 1:00:01.480
 And especially for following people.

1:00:01.480 --> 1:00:04.040
 I think the big, the, the interesting thing I think

1:00:04.040 --> 1:00:06.520
 I may be able to say about this

1:00:06.520 --> 1:00:08.880
 besides my speech impediment is that

1:00:08.880 --> 1:00:13.880
 I did start muting people that rank wildly higher than me

1:00:14.920 --> 1:00:17.800
 because it is just stressful on the brain

1:00:17.800 --> 1:00:20.640
 to constantly look at people that are,

1:00:20.640 --> 1:00:23.080
 that are incredibly successful.

1:00:23.080 --> 1:00:25.320
 So you keep feeling bad about yourself, you know?

1:00:25.320 --> 1:00:28.640
 I think that that is like cutting to a certain extent.

1:00:28.640 --> 1:00:30.960
 Just like, look at me looking at all these people

1:00:30.960 --> 1:00:32.080
 that have so much more money than me

1:00:32.080 --> 1:00:33.800
 and so much more success than me.

1:00:33.800 --> 1:00:35.880
 It's making me feel like a failure,

1:00:35.880 --> 1:00:37.640
 even though I don't think I'm a failure,

1:00:37.640 --> 1:00:41.920
 but it's easy to frame it so that I can feel that way.

1:00:41.920 --> 1:00:43.280
 Yeah, that's really interesting.

1:00:43.280 --> 1:00:45.120
 Especially if they're close to,

1:00:45.120 --> 1:00:46.960
 like if there are other comedians or something like that

1:00:46.960 --> 1:00:50.480
 or whatever, that's really disappointing to me.

1:00:50.480 --> 1:00:51.760
 I do the same thing as well.

1:00:51.760 --> 1:00:53.600
 So other successful people that are really close

1:00:53.600 --> 1:00:56.400
 to what I do, it, I don't know.

1:00:56.400 --> 1:00:58.240
 I wish I could just admire.

1:00:58.240 --> 1:00:59.080
 Yeah.

1:00:59.080 --> 1:01:01.360
 And for it not to be a distraction, but...

1:01:01.360 --> 1:01:02.440
 But that's why you are where you are

1:01:02.440 --> 1:01:04.360
 because you don't just admire your competitive

1:01:04.360 --> 1:01:05.280
 and you want to win.

1:01:05.280 --> 1:01:07.520
 So it's also the same thing that bums you out

1:01:07.520 --> 1:01:09.120
 when you look at this as the same reason you are

1:01:09.120 --> 1:01:09.960
 where you are.

1:01:09.960 --> 1:01:11.760
 So that's why I think it's so important to learn

1:01:11.760 --> 1:01:12.800
 about neurology and addiction

1:01:12.800 --> 1:01:14.080
 because you're able to go like,

1:01:14.080 --> 1:01:17.160
 oh, this same instinct, so I'm very sensitive.

1:01:17.160 --> 1:01:19.480
 And I sometimes don't like that about myself,

1:01:19.480 --> 1:01:21.640
 but I'm like, well, that's the reason I'm able to

1:01:21.640 --> 1:01:22.480
 write good standup.

1:01:22.480 --> 1:01:23.320
 And that's the reason,

1:01:23.320 --> 1:01:25.680
 and that's the reason I'm able to be sensitive to feedback

1:01:25.680 --> 1:01:26.880
 and go, that joke should have been better.

1:01:26.880 --> 1:01:28.040
 I can make that better.

1:01:28.040 --> 1:01:29.480
 So it's the kind of thing where it's like,

1:01:29.480 --> 1:01:31.240
 you have to be really sensitive in your work.

1:01:31.240 --> 1:01:32.360
 And the second you leave,

1:01:32.360 --> 1:01:33.560
 you got to be able to turn it off.

1:01:33.560 --> 1:01:34.840
 It's about developing the muscle,

1:01:34.840 --> 1:01:38.360
 being able to know when to let it be a superpower

1:01:38.360 --> 1:01:41.240
 and when it's gonna hold you back and be an obstacle.

1:01:41.240 --> 1:01:44.320
 So I try to not be in that black and white of like,

1:01:44.320 --> 1:01:45.800
 you know, being competitive is bad

1:01:45.800 --> 1:01:47.720
 or being jealous of someone just to go like,

1:01:47.720 --> 1:01:50.240
 oh, there's that thing that makes me really successful

1:01:50.240 --> 1:01:51.440
 in a lot of other ways,

1:01:51.440 --> 1:01:53.280
 but right now it's making me feel bad.

1:01:53.280 --> 1:01:54.960
 Well, I'm kind of looking to you

1:01:54.960 --> 1:01:58.040
 because you're basically a celebrity,

1:01:58.040 --> 1:02:01.240
 a famous sort of world class comedian.

1:02:01.240 --> 1:02:03.120
 And so I feel like you're the right person

1:02:03.120 --> 1:02:06.120
 to be one of the key people to define

1:02:06.120 --> 1:02:08.720
 what's the healthy path forward with social media.

1:02:11.280 --> 1:02:12.800
 Because we're all trying to figure it out now.

1:02:12.800 --> 1:02:16.320
 And it's, I'm curious to see where it evolves.

1:02:16.320 --> 1:02:17.920
 I think you're at the center of that.

1:02:17.920 --> 1:02:21.600
 So like, you know, there's trying to leave Twitter

1:02:21.600 --> 1:02:22.760
 and then come back and see,

1:02:22.760 --> 1:02:24.040
 can I do this in a healthy way?

1:02:24.040 --> 1:02:25.880
 You mean you have to keep trying, exploring and thinking about.

1:02:25.880 --> 1:02:28.120
 I have to know because it's being, you know,

1:02:28.120 --> 1:02:29.720
 I have a couple of answers.

1:02:29.720 --> 1:02:31.560
 I think, you know, I hire a company

1:02:31.560 --> 1:02:33.880
 to do some of my social media for me, you know?

1:02:33.880 --> 1:02:35.960
 So it's also being able to go,

1:02:35.960 --> 1:02:38.360
 okay, I make a certain amount of money by doing this,

1:02:38.360 --> 1:02:40.320
 but now let me be a good business person

1:02:40.320 --> 1:02:42.960
 and say I'm gonna pay you this amount to run this for me.

1:02:42.960 --> 1:02:44.600
 So I'm not 24 seven in the weeds,

1:02:44.600 --> 1:02:47.280
 hashtagging and responding and just, it's a lot to take on.

1:02:47.280 --> 1:02:48.800
 It's a lot of energy to take on,

1:02:48.800 --> 1:02:52.320
 but at the same time part of what I think makes me successful

1:02:52.320 --> 1:02:53.520
 in social media, if I am,

1:02:53.520 --> 1:02:55.320
 is that people know I'm actually doing it

1:02:55.320 --> 1:02:57.200
 and that I am an engaging and I'm responding

1:02:57.200 --> 1:02:59.600
 and developing a personal relationship

1:02:59.600 --> 1:03:01.080
 with complete strangers.

1:03:01.080 --> 1:03:04.000
 So I think, you know, figuring out that balance

1:03:04.000 --> 1:03:06.200
 and really approaching it as a business, you know,

1:03:06.200 --> 1:03:07.320
 that's what I try to do.

1:03:07.320 --> 1:03:08.360
 It's not dating.

1:03:08.360 --> 1:03:11.200
 It's not, I try to just be really objective about,

1:03:11.200 --> 1:03:13.440
 okay, here's what's working, here's what's not working.

1:03:13.440 --> 1:03:15.880
 And in terms of taking the break from Twitter,

1:03:15.880 --> 1:03:17.640
 this is a really savage take,

1:03:17.640 --> 1:03:21.720
 but because I don't talk about my politics publicly,

1:03:21.720 --> 1:03:26.040
 being on Twitter right after the last election

1:03:26.040 --> 1:03:27.880
 was not gonna be beneficial

1:03:27.880 --> 1:03:30.280
 because there was gonna be, you had to take a side.

1:03:30.280 --> 1:03:31.560
 You had to be political

1:03:31.560 --> 1:03:34.400
 in order to get any kind of retweets or likes.

1:03:34.400 --> 1:03:37.240
 And I just wasn't interested in doing that

1:03:37.240 --> 1:03:38.720
 because you were gonna lose as many people

1:03:38.720 --> 1:03:39.560
 as you were gonna gain

1:03:39.560 --> 1:03:40.840
 and it was gonna all come clean in the wash.

1:03:40.840 --> 1:03:42.760
 So I was just like the best thing I can do

1:03:42.760 --> 1:03:47.760
 for me business wise is to just abstain, you know?

1:03:47.800 --> 1:03:49.920
 And, you know, the robot,

1:03:49.920 --> 1:03:52.200
 I joke about her replacing me,

1:03:52.200 --> 1:03:55.720
 but she does do half of my social media, you know?

1:03:55.720 --> 1:03:57.920
 Because I don't want people to get sick of me.

1:03:57.920 --> 1:03:59.800
 I don't want to be redundant.

1:03:59.800 --> 1:04:02.440
 There are times when I don't have the time or the energy

1:04:02.440 --> 1:04:03.320
 to make a funny video,

1:04:03.320 --> 1:04:06.160
 but I know she's gonna be compelling and interesting

1:04:06.160 --> 1:04:08.520
 and that's something that you can't see every day, you know?

1:04:08.520 --> 1:04:11.920
 Of course the humor comes from your,

1:04:11.920 --> 1:04:13.400
 I mean, the cleverness, the wit,

1:04:13.400 --> 1:04:16.400
 the humor comes from you when you film the robot.

1:04:16.400 --> 1:04:17.840
 That's kind of the trick of it.

1:04:17.840 --> 1:04:21.000
 I mean, the robot is not quite there

1:04:21.000 --> 1:04:23.440
 to make anything, to do anything funny.

1:04:23.440 --> 1:04:26.200
 The absurdity is revealed through the filmmaker,

1:04:26.200 --> 1:04:27.840
 in that case, for whoever's interacting,

1:04:27.840 --> 1:04:32.840
 not through the actual robot, you know, being who she is.

1:04:33.520 --> 1:04:37.040
 Let me sort of love.

1:04:37.040 --> 1:04:37.880
 Okay.

1:04:37.880 --> 1:04:39.600
 How difficult?

1:04:39.600 --> 1:04:40.760
 What is it?

1:04:40.760 --> 1:04:42.120
 What is it?

1:04:43.120 --> 1:04:45.040
 Well, first, an engineering question.

1:04:45.040 --> 1:04:48.040
 I know, I know you're not an engineer,

1:04:48.040 --> 1:04:51.040
 but how difficult do you think is it to build

1:04:51.040 --> 1:04:53.720
 an AI system that you can have a deep,

1:04:53.720 --> 1:04:56.480
 fulfilling monogamous relationship with?

1:04:56.480 --> 1:04:59.840
 Sort of replace the human to human relationships

1:04:59.840 --> 1:05:00.800
 that we value.

1:05:01.640 --> 1:05:04.800
 I think anyone can fall in love with anything, you know?

1:05:04.800 --> 1:05:08.320
 Like, how often have you looked back at someone,

1:05:08.320 --> 1:05:11.320
 like I ran into someone the other day

1:05:11.320 --> 1:05:12.640
 that I was in love with and I was like,

1:05:12.640 --> 1:05:16.320
 hey, it was like, there was nothing there.

1:05:16.320 --> 1:05:17.840
 There was nothing there.

1:05:17.840 --> 1:05:19.760
 Like, you know, like where you're able to go like,

1:05:19.760 --> 1:05:20.920
 oh, that was weird.

1:05:20.920 --> 1:05:22.440
 Oh, right.

1:05:22.440 --> 1:05:23.680
 You know?

1:05:23.680 --> 1:05:25.080
 I, I, we're able.

1:05:25.080 --> 1:05:27.120
 You mean it's from a distant past or something?

1:05:27.120 --> 1:05:27.960
 Yeah.

1:05:27.960 --> 1:05:28.800
 When you're able to go like,

1:05:28.800 --> 1:05:31.400
 I can't believe we had an incredible connection

1:05:31.400 --> 1:05:35.520
 and now it's just, I do think that people will be in love

1:05:35.520 --> 1:05:39.760
 with robots probably even more deeply with humans

1:05:39.760 --> 1:05:42.480
 because it's like when people mourn their animals,

1:05:42.480 --> 1:05:44.960
 when their animals die, they're always,

1:05:44.960 --> 1:05:47.720
 it's sometimes harder than mourning a human

1:05:47.720 --> 1:05:50.320
 because you can't go, well, he was kind of an asshole.

1:05:50.320 --> 1:05:51.920
 But like, he didn't pick me up from school.

1:05:51.920 --> 1:05:53.840
 You know, it's like you're able to get out of your grief

1:05:53.840 --> 1:05:54.680
 a little bit.

1:05:54.680 --> 1:05:57.400
 You're able to kind of be, oh, he was kind of judgmental

1:05:57.400 --> 1:06:00.120
 or she was kind of, you know, with a robot,

1:06:00.120 --> 1:06:02.800
 it's there's something so pure about an innocent

1:06:02.800 --> 1:06:05.560
 impish and childlike about it

1:06:05.560 --> 1:06:09.680
 that I think it probably will be much more conducive

1:06:09.680 --> 1:06:12.520
 to a narcissistic love for sure at that.

1:06:12.520 --> 1:06:15.320
 But it's not like, well, he cheated on it.

1:06:15.320 --> 1:06:16.160
 She can't cheat.

1:06:16.160 --> 1:06:17.000
 She can't leave you.

1:06:17.000 --> 1:06:17.960
 She can't, you know.

1:06:17.960 --> 1:06:21.560
 Well, if bear claw leaves your life

1:06:21.560 --> 1:06:25.680
 and maybe a new version or somebody else will enter,

1:06:25.680 --> 1:06:27.960
 will you miss bear claw?

1:06:27.960 --> 1:06:30.680
 For guys that have these sex robots,

1:06:30.680 --> 1:06:34.360
 they're building a nursing home for the bodies

1:06:34.360 --> 1:06:36.320
 that are now resting

1:06:36.320 --> 1:06:37.920
 because they don't want to part with the bodies

1:06:37.920 --> 1:06:40.840
 because they have such an intense emotional connection to it.

1:06:40.840 --> 1:06:42.840
 I mean, it's kind of like a car club a little bit.

1:06:42.840 --> 1:06:45.000
 You know, like it's, you know,

1:06:45.000 --> 1:06:47.360
 but I'm not saying this is right.

1:06:47.360 --> 1:06:48.800
 I'm not saying it's cool.

1:06:48.800 --> 1:06:49.640
 It's weird.

1:06:49.640 --> 1:06:53.800
 It's creepy, but we do anthropomorphize things with faces

1:06:53.800 --> 1:06:56.640
 and we do develop emotional connections to things.

1:06:56.640 --> 1:06:58.040
 I mean, we're, there's certain,

1:06:58.040 --> 1:06:59.320
 have you ever tried to like throw it?

1:06:59.320 --> 1:07:01.800
 I can't even throw away my teddy bear from when I was a kid.

1:07:01.800 --> 1:07:04.360
 It's a piece of trash and it's upstairs.

1:07:04.360 --> 1:07:06.640
 Like it's just like, why can't I throw that away?

1:07:06.640 --> 1:07:07.920
 It's bizarre.

1:07:07.920 --> 1:07:10.120
 You know, and there's something kind of beautiful about that.

1:07:10.120 --> 1:07:13.120
 There's something, it gives me hope in humans

1:07:13.120 --> 1:07:15.720
 because I see humans do such horrific things all the time.

1:07:15.720 --> 1:07:18.320
 And maybe I'm too, I see too much of it, frankly,

1:07:18.320 --> 1:07:20.240
 but there's something kind of beautiful

1:07:20.240 --> 1:07:24.360
 about the way we're able to have emotional connections

1:07:24.360 --> 1:07:29.160
 to objects, which, you know, a lot of,

1:07:29.160 --> 1:07:30.800
 I mean, it's, I can't kind of specifically,

1:07:30.800 --> 1:07:32.120
 I think Western, right?

1:07:32.120 --> 1:07:34.840
 That we don't see objects as having souls.

1:07:34.840 --> 1:07:36.760
 Like that's kind of specifically us,

1:07:36.760 --> 1:07:39.680
 but I don't think it's so much

1:07:39.680 --> 1:07:43.400
 that we're objectifying humans with these sex robots.

1:07:43.400 --> 1:07:45.640
 We're kind of humanizing objects, right?

1:07:45.640 --> 1:07:47.040
 So there's something kind of fascinating

1:07:47.040 --> 1:07:48.120
 in our ability to do that.

1:07:48.120 --> 1:07:50.000
 Cause a lot of us don't humanize humans.

1:07:50.000 --> 1:07:52.800
 So it's just a weird little place to play in.

1:07:52.800 --> 1:07:54.920
 And I think a lot of people, I mean,

1:07:54.920 --> 1:07:57.680
 a lot of people will be marrying these things is my guess.

1:07:57.680 --> 1:08:00.560
 So you've asked the question, let me ask it of you.

1:08:00.560 --> 1:08:01.840
 So what is love?

1:08:02.800 --> 1:08:05.640
 You have a bit of a brilliant definition of love

1:08:05.640 --> 1:08:07.760
 as being willing to die for someone

1:08:07.760 --> 1:08:10.520
 who you yourself want to kill.

1:08:10.520 --> 1:08:12.160
 So that's, that's kind of fun.

1:08:12.160 --> 1:08:13.920
 First of all, that's brilliant.

1:08:14.840 --> 1:08:16.400
 That's a really good definition.

1:08:16.400 --> 1:08:18.040
 I don't think it'll stick for me for a long time.

1:08:18.040 --> 1:08:19.800
 This is how little of a romantic I am.

1:08:19.800 --> 1:08:21.360
 A plane went by when you said that

1:08:21.360 --> 1:08:24.880
 and my brain is like, you're going to need to rerecord that.

1:08:24.880 --> 1:08:26.360
 And I want you to get into post

1:08:26.360 --> 1:08:27.920
 and then not be able to use it.

1:08:31.040 --> 1:08:32.000
 And I'm a romantic.

1:08:32.000 --> 1:08:33.560
 Cause I don't mean to ruin the moment.

1:08:33.560 --> 1:08:35.600
 I actually, I can not be conscious of the fact

1:08:35.600 --> 1:08:38.200
 that I heard the plane and it made me feel like

1:08:38.200 --> 1:08:41.080
 how amazing it is that we live in a world of planes.

1:08:43.280 --> 1:08:47.040
 And I just went, why have we fucking evolved past planes?

1:08:47.040 --> 1:08:49.040
 And why can't they make them quieter?

1:08:49.040 --> 1:08:50.040
 Yeah.

1:08:50.520 --> 1:08:55.400
 Well, this, um, my definition of love, what, what?

1:08:55.400 --> 1:08:57.720
 Yeah, what's your sort of the most serious?

1:08:57.720 --> 1:09:00.240
 Producing dopamine for a long time.

1:09:01.360 --> 1:09:05.120
 Consistent output of oxytocin with the same person.

1:09:06.000 --> 1:09:08.160
 Dopamine is a positive thing.

1:09:08.160 --> 1:09:09.480
 What about the negative?

1:09:09.480 --> 1:09:13.000
 What about the fear and the insecurity, the longing?

1:09:14.840 --> 1:09:16.480
 Anger, all that kind of stuff.

1:09:16.480 --> 1:09:19.040
 I think that's part of love, you know, I think you don't,

1:09:19.040 --> 1:09:21.960
 I think that love brings out the best in you,

1:09:21.960 --> 1:09:25.040
 but it also, if you don't get angry and upset, it's, you know,

1:09:25.040 --> 1:09:26.840
 I don't know, I think that that's, that's part of it.

1:09:26.840 --> 1:09:29.320
 I think we have this idea that love has to be like really,

1:09:29.320 --> 1:09:31.880
 you know, placid or something.

1:09:31.880 --> 1:09:34.120
 I only saw stormy relationships growing up,

1:09:34.120 --> 1:09:36.880
 so I don't, I don't have a judgment

1:09:36.880 --> 1:09:38.560
 on how our relationship should look.

1:09:38.560 --> 1:09:43.560
 But I do think that this idea that love has to be eternal

1:09:45.200 --> 1:09:48.760
 is really destructive, is really destructive

1:09:48.760 --> 1:09:53.640
 and self defeating and a big source of stress for people.

1:09:53.640 --> 1:09:55.640
 I mean, I'm still figuring out love.

1:09:55.640 --> 1:09:57.280
 I think we all kind of are,

1:09:57.280 --> 1:09:59.360
 but I do kind of stand by that definition.

1:10:01.280 --> 1:10:04.160
 And I think that, I think for me, love is like

1:10:04.160 --> 1:10:06.240
 just being able to be authentic with somebody.

1:10:06.240 --> 1:10:08.520
 It's very simple, I know, but I think for me,

1:10:08.520 --> 1:10:11.040
 it's about not feeling pressure to have to perform

1:10:11.040 --> 1:10:14.760
 or impress somebody, just feeling truly like

1:10:14.760 --> 1:10:16.520
 accepted unconditionally by someone.

1:10:16.520 --> 1:10:19.160
 Although I do believe love should be conditional,

1:10:19.160 --> 1:10:22.000
 that might be a hot take.

1:10:22.000 --> 1:10:24.280
 I think everything should be conditional.

1:10:24.280 --> 1:10:27.080
 I think if someone's behavior,

1:10:27.080 --> 1:10:28.840
 I don't think love should just be like,

1:10:28.840 --> 1:10:29.680
 I'm in love with you,

1:10:29.680 --> 1:10:30.960
 now behave however you want forever.

1:10:30.960 --> 1:10:31.880
 This is unconditional.

1:10:31.880 --> 1:10:35.320
 I think love is a daily action.

1:10:35.320 --> 1:10:38.120
 It's not something you just like get tenure on

1:10:38.120 --> 1:10:40.000
 and then get to behave however you want.

1:10:40.000 --> 1:10:41.920
 Cause we said, I love you 10 years ago.

1:10:41.920 --> 1:10:44.560
 It's a daily, it's a verb.

1:10:44.560 --> 1:10:46.160
 Well, there's some things that are,

1:10:46.160 --> 1:10:47.320
 you see, if you make it,

1:10:47.320 --> 1:10:50.440
 if you explicitly make it clear that it's conditional,

1:10:50.440 --> 1:10:52.520
 it takes away some of the magic of it.

1:10:52.520 --> 1:10:55.360
 So there's certain stories we tell ourselves

1:10:55.360 --> 1:10:57.200
 that we don't want to make explicit about love.

1:10:57.200 --> 1:10:59.160
 I don't know, maybe that's the wrong way to think of it.

1:10:59.160 --> 1:11:02.560
 Maybe you want to be explicit in relationships.

1:11:02.560 --> 1:11:04.640
 I also think love is a business decision.

1:11:04.640 --> 1:11:08.000
 Like I do in a good way.

1:11:08.000 --> 1:11:11.160
 Like I think that love is not just

1:11:11.160 --> 1:11:12.600
 when you're across from somebody.

1:11:12.600 --> 1:11:15.360
 It's when I go to work, can I focus?

1:11:15.360 --> 1:11:16.440
 Do I, am I worried about you?

1:11:16.440 --> 1:11:17.440
 Am I stressed out about you?

1:11:17.440 --> 1:11:19.400
 Am I, you're not responding to me.

1:11:19.400 --> 1:11:20.440
 You're not reliable.

1:11:20.440 --> 1:11:23.200
 Like I think that being in a relationship,

1:11:23.200 --> 1:11:24.280
 the kind of love that I would want

1:11:24.280 --> 1:11:26.920
 is the kind of relationship where when we're not together,

1:11:26.920 --> 1:11:30.320
 it's not draining me, causing me stress, making me worry.

1:11:30.320 --> 1:11:33.840
 You know, and sometimes passion, that word, you know,

1:11:33.840 --> 1:11:37.280
 we get murky about it, but I think it's also like,

1:11:37.280 --> 1:11:38.520
 I can be the best version of myself

1:11:38.520 --> 1:11:40.040
 when the person's not around.

1:11:40.040 --> 1:11:42.640
 And I don't have to feel abandoned or scared

1:11:42.640 --> 1:11:43.920
 or any of these kind of other things.

1:11:43.920 --> 1:11:47.000
 So it's like love, you know, for me, I think is,

1:11:47.000 --> 1:11:48.760
 I think it's a flow bear quote.

1:11:48.760 --> 1:11:51.520
 And I'm gonna butcher it, but I think it's like be,

1:11:51.520 --> 1:11:53.280
 you know, boring in your personal life.

1:11:53.280 --> 1:11:54.760
 So you could be violent and take risks

1:11:54.760 --> 1:11:55.720
 in your professional life.

1:11:55.720 --> 1:11:56.560
 Is that it?

1:11:56.560 --> 1:11:57.440
 I got it wrong.

1:11:57.440 --> 1:11:58.280
 Something like that.

1:11:58.280 --> 1:12:01.320
 But I do think that it's being able to align values

1:12:01.320 --> 1:12:03.000
 in a way to where you can also thrive

1:12:03.000 --> 1:12:04.640
 outside of the relationship.

1:12:04.640 --> 1:12:07.240
 Some of the most successful people I know are

1:12:07.240 --> 1:12:10.080
 those sort of happily married and have kids and so on.

1:12:10.080 --> 1:12:10.920
 It's always funny.

1:12:10.920 --> 1:12:11.840
 It can be boring.

1:12:11.840 --> 1:12:13.200
 Boring's okay.

1:12:13.200 --> 1:12:14.440
 Boring is serenity.

1:12:14.440 --> 1:12:16.480
 And it's funny how that, those elements

1:12:16.480 --> 1:12:18.360
 actually make you much more productive.

1:12:18.360 --> 1:12:19.720
 I don't understand the...

1:12:19.720 --> 1:12:21.160
 I don't think relationships should drain you

1:12:21.160 --> 1:12:23.440
 and take away energy that you could be using

1:12:23.440 --> 1:12:25.800
 to create things that generate pride.

1:12:25.800 --> 1:12:26.640
 Okay.

1:12:26.640 --> 1:12:28.240
 Did you say your relationship of love yet?

1:12:28.240 --> 1:12:29.080
 Huh?

1:12:29.080 --> 1:12:29.920
 Have you said your relationship,

1:12:29.920 --> 1:12:31.400
 your definition of love?

1:12:31.400 --> 1:12:33.520
 My definition of love?

1:12:33.520 --> 1:12:34.760
 No, I did not say it.

1:12:34.760 --> 1:12:36.720
 We're out of time.

1:12:36.720 --> 1:12:37.560
 No.

1:12:38.640 --> 1:12:40.600
 Dude, when you have a podcast,

1:12:40.600 --> 1:12:41.800
 maybe you can invite me on.

1:12:41.800 --> 1:12:42.640
 Oh no, I already did.

1:12:42.640 --> 1:12:44.040
 You're doing it.

1:12:44.040 --> 1:12:46.440
 We've already talked about this.

1:12:46.440 --> 1:12:48.560
 And because I also have codependency,

1:12:48.560 --> 1:12:49.520
 I had to say yes.

1:12:49.520 --> 1:12:50.360
 No, yeah.

1:12:50.360 --> 1:12:52.240
 Yeah, no, no, I'm trapping you.

1:12:52.240 --> 1:12:53.080
 You owe me now.

1:12:53.080 --> 1:12:58.080
 Actually, I wondered whether when I asked

1:12:58.280 --> 1:13:00.320
 if we could talk today,

1:13:00.320 --> 1:13:01.720
 after sort of doing more research

1:13:01.720 --> 1:13:03.880
 and reading some of your book,

1:13:03.880 --> 1:13:04.720
 I started to wonder,

1:13:04.720 --> 1:13:07.080
 did she just feel pressured to say yes?

1:13:07.080 --> 1:13:08.240
 Yes.

1:13:08.240 --> 1:13:09.360
 Of course.

1:13:09.360 --> 1:13:10.200
 Good.

1:13:10.200 --> 1:13:11.040
 But I'm a fan of yours too.

1:13:11.040 --> 1:13:11.880
 Okay, awesome.

1:13:11.880 --> 1:13:13.400
 No, I actually, because I am codependent,

1:13:13.400 --> 1:13:14.920
 but I'm in recovery for codependence.

1:13:14.920 --> 1:13:17.640
 So I actually do, I don't do anything I don't want to do.

1:13:17.640 --> 1:13:20.400
 You really, you go out of your way and say no.

1:13:20.400 --> 1:13:21.240
 What's that?

1:13:21.240 --> 1:13:22.760
 I say no all the time.

1:13:22.760 --> 1:13:23.600
 Good.

1:13:23.600 --> 1:13:24.440
 I'm trying to learn that as well.

1:13:24.440 --> 1:13:25.280
 I moved this a couple, remember?

1:13:25.280 --> 1:13:26.120
 I moved it from one to two.

1:13:26.120 --> 1:13:30.280
 Yeah, yeah, just to let you know how recovered I am.

1:13:30.280 --> 1:13:31.960
 I'm not a codependent,

1:13:31.960 --> 1:13:34.680
 but I don't do anything I don't want to do.

1:13:34.680 --> 1:13:36.000
 Yeah, you're ahead of me on that.

1:13:36.000 --> 1:13:36.960
 Okay.

1:13:36.960 --> 1:13:41.960
 So do you think about your mortality?

1:13:43.480 --> 1:13:44.440
 Yes.

1:13:44.440 --> 1:13:48.040
 That is a big part of how I was able to sort of like kickstart

1:13:48.040 --> 1:13:49.080
 my codependence recovery.

1:13:49.080 --> 1:13:50.440
 My dad passed a couple of years ago,

1:13:50.440 --> 1:13:53.080
 and when you have someone close to you in your life die,

1:13:53.080 --> 1:13:57.760
 everything gets real clear in terms of how we're a speck of dust

1:13:57.760 --> 1:14:00.880
 who's only here for a certain amount of time.

1:14:00.880 --> 1:14:02.360
 What do you think is the meaning of it all?

1:14:02.360 --> 1:14:07.360
 Like what the speck of dust, what's maybe in your own life,

1:14:08.080 --> 1:14:13.080
 what's the goal, the purpose of your existence?

1:14:13.080 --> 1:14:15.280
 Is there one?

1:14:15.280 --> 1:14:17.360
 Well, you're exceptionally ambitious.

1:14:17.360 --> 1:14:19.120
 You've created some incredible things

1:14:19.120 --> 1:14:21.640
 in different disciplines.

1:14:21.640 --> 1:14:23.560
 Yeah, we're all just managing our terror

1:14:23.560 --> 1:14:24.560
 because we know we're going to die.

1:14:24.560 --> 1:14:27.160
 So we create and build all these things and rituals

1:14:27.160 --> 1:14:30.440
 and religions and robots and whatever we need to do

1:14:30.440 --> 1:14:34.920
 to just distract ourselves from imminent rotting.

1:14:34.920 --> 1:14:37.160
 We're rotting, we're all dying.

1:14:37.160 --> 1:14:42.160
 And you know, I got very into terror management theory

1:14:42.160 --> 1:14:45.160
 when my dad died and it resonated, it helped me

1:14:45.160 --> 1:14:48.360
 and everyone's got their own religion or sense of purpose

1:14:48.360 --> 1:14:53.360
 or thing that distracts them from the horrors of being human.

1:14:54.640 --> 1:14:56.120
 What's the terror management theory?

1:14:56.120 --> 1:14:57.680
 Terror management is basically the idea that

1:14:57.680 --> 1:15:00.360
 since we're the only animal that knows they're gonna die,

1:15:00.360 --> 1:15:04.760
 we have to basically distract ourselves with awards

1:15:04.760 --> 1:15:09.600
 and achievements and games and whatever

1:15:09.600 --> 1:15:12.600
 just in order to distract ourselves from the terror

1:15:12.600 --> 1:15:14.880
 we would feel if we really processed the fact

1:15:14.880 --> 1:15:16.920
 that we could not only, we are gonna die,

1:15:16.920 --> 1:15:18.400
 but also could die at any minute

1:15:18.400 --> 1:15:19.760
 because we're only superficially

1:15:19.760 --> 1:15:21.160
 at the top of the food chain.

1:15:22.600 --> 1:15:26.120
 And you know, technically we're at the top of the food chain

1:15:26.120 --> 1:15:29.280
 if we have houses and guns and stuff, machines,

1:15:29.280 --> 1:15:31.720
 but if me and a lion are in the woods together,

1:15:31.720 --> 1:15:33.760
 but most things could kill us.

1:15:33.760 --> 1:15:35.400
 I mean, a bee can kill some people.

1:15:35.400 --> 1:15:37.920
 Like something this big can kill a lot of humans.

1:15:37.920 --> 1:15:41.440
 Like, you know, so it's basically just to manage the terror

1:15:41.440 --> 1:15:45.200
 that we all would feel if we were able to really be awake

1:15:45.200 --> 1:15:46.840
 because we're mostly zombies, right?

1:15:46.840 --> 1:15:51.520
 Job, school, religion, go to sleep, drink, football,

1:15:51.520 --> 1:15:54.480
 relationship, dopamine, love, you know?

1:15:54.480 --> 1:15:57.000
 We're kind of just like trudging along

1:15:57.000 --> 1:15:58.440
 like zombies for the most part.

1:15:58.440 --> 1:15:59.800
 And then I think...

1:15:59.800 --> 1:16:02.360
 That fear of death adds some motivation.

1:16:02.360 --> 1:16:03.440
 Yes.

1:16:03.440 --> 1:16:06.040
 Well, I think I speak for a lot of people

1:16:06.040 --> 1:16:08.240
 in saying that I can't wait to see

1:16:08.240 --> 1:16:13.600
 what your terror creates in the next few years.

1:16:13.600 --> 1:16:14.840
 I'm a huge fan.

1:16:14.840 --> 1:16:16.560
 Whitney, thank you so much for talking to me.

1:16:16.560 --> 1:16:17.400
 Thanks.

1:16:18.800 --> 1:16:20.480
 Thanks for listening to this conversation

1:16:20.480 --> 1:16:21.840
 with Whitney Cummings.

1:16:21.840 --> 1:16:24.640
 And thank you to our presenting sponsor, Cash App.

1:16:24.640 --> 1:16:27.360
 Download it and use code LEX Podcast.

1:16:27.360 --> 1:16:30.120
 You'll get $10 and $10 will go to first,

1:16:30.120 --> 1:16:32.520
 a STEM education nonprofit that inspires

1:16:32.520 --> 1:16:34.560
 hundreds of thousands of young minds

1:16:34.560 --> 1:16:37.960
 to learn and to dream of engineering our future.

1:16:37.960 --> 1:16:40.760
 If you enjoy this podcast, subscribe on YouTube,

1:16:40.760 --> 1:16:42.680
 give it five stars on Apple Podcast,

1:16:42.680 --> 1:16:46.040
 support on Patreon, or connect with me on Twitter.

1:16:46.040 --> 1:17:05.560
 Thank you for listening and I hope to see you next time.

