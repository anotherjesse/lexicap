WEBVTT

00:00.000 --> 00:04.240
 The following is the conversation with Scott Aronson, his second time in the podcast.

00:04.960 --> 00:11.280
 He is a professor at UT Austin, director of the Quantum Information Center, and previously a

00:11.280 --> 00:18.720
 professor at MIT. Last time we talked about quantum computing. This time we talk about

00:18.720 --> 00:25.360
 computation complexity, consciousness, and theories of everything. I'm recording this intro,

00:25.360 --> 00:34.640
 as you may be able to tell, in a very strange room in the middle of the night. I'm not really sure

00:34.640 --> 00:41.680
 how I got here or how I'm going to get out, but Hunters Thompson saying, I think, applies

00:42.480 --> 00:50.240
 to today and the last few days and actually the last couple of weeks. Life should not be a journey

00:50.240 --> 00:54.640
 to the grave with the intention of arriving safely in a pretty and well preserved body,

00:55.280 --> 01:02.400
 but rather to skid in broadside in a cloud of smoke, thoroughly used up, totally worn out,

01:03.360 --> 01:10.400
 and loudly proclaiming, wow, what a ride. So I figured whatever I'm up to here,

01:11.360 --> 01:17.280
 and yes, lots of wine is involved. I'm going to have to improvise, hence this recording.

01:17.280 --> 01:22.400
 Okay, quick mention of each sponsor, followed by some thoughts related to the episode.

01:23.200 --> 01:28.720
 First sponsor is Simply Safe, a home security company I use to monitor and protect my apartment,

01:29.360 --> 01:36.880
 though, of course, I'm always prepared with a fallback plan, as a man in this world must always be.

01:38.800 --> 01:46.080
 Second sponsor is Eight Sleep, a mattress that cools itself, measures heart rate variability,

01:46.080 --> 01:51.680
 has a nap, and has given me yet another reason to look forward to sleep, including

01:52.240 --> 01:59.200
 the all important power nap. Third sponsor is ExpressVPN, the VPN I've used for many years

01:59.200 --> 02:06.880
 to protect my privacy on the internet. Finally, the fourth sponsor is BetterHelp, online therapy

02:06.880 --> 02:12.640
 when you want to face your demons with a licensed professional, not just by doing David Goggins,

02:12.640 --> 02:18.160
 like physical challenges like I seem to do on occasion. Please check out these sponsors in

02:18.160 --> 02:24.640
 the description to get a discount and to support the podcast. As a side note, let me say that this

02:24.640 --> 02:30.400
 is the second time I've recorded a conversation outdoors. The first one was with Stephen Wolfram,

02:30.960 --> 02:36.160
 when it was actually sunny out. In this case, it was raining, which is why I found a covered

02:36.160 --> 02:43.360
 outdoor patio. But I learned a valuable lesson, which is that raindrops can be quite loud on the

02:43.360 --> 02:50.480
 hard metal surface of a patio cover. I did my best with the audio. I hope it still sounds okay to you.

02:51.280 --> 02:57.920
 I'm learning, always improving. In fact, as Scott says, if you always win, then you're

02:57.920 --> 03:02.400
 probably doing something wrong. To be honest, I get pretty upset with myself when I fail,

03:02.400 --> 03:09.840
 small, or big. But I've learned that this feeling is priceless. It can be fuel when

03:09.840 --> 03:18.080
 channeled into concrete plans of how to improve. So if you enjoy this thing, subscribe on YouTube,

03:18.080 --> 03:24.480
 review 5,000 Apple Podcasts, follow on Spotify, support on Patreon, or connect with me on Twitter

03:24.480 --> 03:32.560
 at Lex Friedman. And now here's my conversation with Scott Aronson. Let's start with the most absurd

03:32.560 --> 03:37.760
 question, but I've read you write some fascinating stuff about it. So let's go there. Are we living

03:37.760 --> 03:44.080
 in a simulation? What difference does it make, Lex? I mean, I'm serious. What difference? Because

03:44.080 --> 03:50.240
 if we are living in a simulation, it raises the question, how real does something have to be

03:50.240 --> 03:55.920
 in simulation for it to be sufficiently immersive for us humans? But I mean, even in principle,

03:55.920 --> 04:01.200
 how could we ever know if we were in one? A perfect simulation by definition is something

04:01.200 --> 04:04.480
 that's indistinguishable from the real thing. Well, we didn't say anything about perfect.

04:04.960 --> 04:10.000
 No, no, that's right. Well, if it was an imperfect simulation, if we could hack it,

04:10.560 --> 04:16.240
 find a bug in it, then that would be one thing. If this was like the matrix and there was a way

04:16.240 --> 04:22.640
 for me to do flying kung fu moves or something by hacking the simulation, well, then we would

04:22.640 --> 04:29.680
 have to cross that bridge when we came to it, wouldn't we? I mean, at that point, it's hard

04:29.680 --> 04:35.680
 to see the difference between that and just what people would ordinarily refer to as a world with

04:35.680 --> 04:41.840
 miracles. What about from a different perspective, thinking about the universe as a computation,

04:41.840 --> 04:46.960
 like a program running on a computer? Is that kind of a neighboring concept? It is. It is an

04:46.960 --> 04:53.680
 interesting and reasonably well defined question to ask, is the world computable? Does the world

04:53.680 --> 05:01.360
 satisfy what we would call in CS, the church touring thesis, that is, could we take any physical

05:01.360 --> 05:09.680
 system and simulate it to any desired precision by a touring machine, given the appropriate input

05:09.680 --> 05:16.800
 data? And so far, I think the indications are pretty strong that our world does seem to satisfy

05:16.800 --> 05:23.920
 the church touring thesis. At least if it doesn't, then we haven't yet discovered why not. But now,

05:23.920 --> 05:30.880
 does that mean that our universe is a simulation? Well, that word seems to suggest that there is

05:30.880 --> 05:37.760
 some other larger universe in which it is running. And the problem there is that if the simulation is

05:37.760 --> 05:43.680
 perfect, then we're never going to be able to get any direct evidence about that other universe.

05:44.240 --> 05:50.240
 We will only be able to see the effects of the computation that is running in this universe.

05:50.240 --> 05:56.240
 Well, let's imagine an analogy. Let's imagine a PC, a personal computer, a computer.

05:57.680 --> 06:04.960
 Is it possible with the advent of artificial intelligence for the computer to look outside

06:04.960 --> 06:12.320
 of itself to understand its creator? Is that a ridiculous connect analogy?

06:12.320 --> 06:20.640
 Well, with the computers that we actually have, first of all, we all know that humans have done

06:20.640 --> 06:28.720
 an imperfect job of enforcing the abstraction boundaries of computers. You may try to confine

06:28.720 --> 06:37.280
 some program to a playpen, but as soon as there's one memory allocation error in the C program,

06:37.280 --> 06:42.640
 then the program has gotten out of that playpen and it can do whatever it wants. This is how most

06:42.640 --> 06:50.800
 hacks work, viruses and worms and exploits. And you would have to imagine that an AI would be able

06:50.800 --> 06:57.600
 to discover something like that. Now, of course, if we could actually discover some exploit of

06:57.600 --> 07:07.120
 reality itself, then in some sense, we wouldn't have to philosophize about this. This would no

07:07.120 --> 07:14.960
 longer be a metaphysical conversation. But the question is, what would that hack look like?

07:14.960 --> 07:23.040
 Yeah, well, I have no idea. I mean, Peter Shore, the very famous person in quantum computing,

07:23.040 --> 07:30.160
 of course, has joked that maybe the reason why we haven't yet integrated general relativity in

07:30.160 --> 07:36.240
 quantum mechanics is that the part of the universe that depends on both of them was actually left

07:36.240 --> 07:42.640
 unspecified. And if we ever tried to do an experiment involving the singularity of a black

07:42.640 --> 07:48.240
 hall or something like that, then the universe would just generate an overflow error or something.

07:48.240 --> 07:56.480
 A blue screen of death. Yeah, we would just crash the universe. Now, the universe seemed to hold

07:56.480 --> 08:08.560
 up pretty well for 14 billion years. So my Occam's razor kind of guess has to be that it will continue

08:08.560 --> 08:14.480
 to hold up that the fact that we don't know the laws of physics governing some phenomenon

08:14.480 --> 08:19.360
 is not a strong sign that probing that phenomenon is going to crash the universe.

08:20.560 --> 08:24.720
 But of course, I could be wrong. But do you think on the physics side of things,

08:25.600 --> 08:32.400
 there's been recently a few folks, Eric Weinstein and Stephen Wolfram, that came out with the

08:32.400 --> 08:38.880
 theory of everything. I think there's a history of physicists dreaming and working on the unification

08:38.880 --> 08:45.440
 of all the laws of physics. Do you think it's possible that once we understand more physics,

08:45.440 --> 08:49.680
 not necessarily the unification of the laws, but just understand physics more deeply at the

08:49.680 --> 08:58.400
 fundamental level, we'll be able to start part of this as humorous, but looking to see if there's

08:58.400 --> 09:06.080
 any bugs in the universe that could be exploited for traveling at not just speed of light, but

09:06.080 --> 09:10.560
 just traveling faster than our current spaceships can travel, all that kind of stuff.

09:11.120 --> 09:15.920
 Well, I mean, to travel faster than our current spaceships could travel, you wouldn't need to

09:15.920 --> 09:22.240
 find any bug in the universe. The known laws of physics let us go much faster up to the speed of

09:22.240 --> 09:28.240
 light. And when people want to go faster than the speed of light, well, we actually know something

09:28.240 --> 09:34.400
 about what that would entail, namely that according to relativity, that seems to entail

09:34.400 --> 09:40.560
 communication backwards in time. So then you have to worry about closed time like curves and all

09:40.560 --> 09:45.760
 of that stuff. So in some sense, we know the price that you have to pay for these things.

09:48.880 --> 09:55.440
 That's right. That's right. We can't say that they're impossible, but we know that a lot

09:55.440 --> 10:03.840
 else in physics breaks. So now regarding Eric Weinstein and Stephen Wolfram, I wouldn't say

10:03.840 --> 10:09.680
 that either of them has a theory of everything. I would say that they have ideas that they hope

10:09.680 --> 10:13.760
 could someday lead to a theory of everything. Is that a worthy pursuit?

10:13.760 --> 10:19.920
 Well, I mean, certainly, let's say by theory of everything, we don't literally mean a theory of

10:19.920 --> 10:26.240
 cats and of baseball, but we just mean it in the more limited sense of everything,

10:26.240 --> 10:32.880
 a fundamental theory of physics, of all of the fundamental interactions of physics.

10:32.880 --> 10:39.680
 Of course, such a theory, even after we had it, would leave the entire question of all

10:39.680 --> 10:47.680
 the emergent behavior to be explored. So it's only everything for a specific definition of

10:47.680 --> 10:52.000
 everything. But in that sense, I would say, of course, that's worth pursuing. I mean,

10:52.000 --> 10:58.160
 that is the entire program of fundamental physics. All of my friends who do quantum gravity,

10:58.160 --> 11:02.880
 who do string theory, who do anything like that, that is what's motivating them.

11:02.880 --> 11:07.920
 Yeah, it's funny, though, but Eric Weinstein talks about this. I don't know much about the

11:07.920 --> 11:16.320
 physics world, but I know about the AI world. It is a little bit taboo to talk about AGI,

11:16.320 --> 11:24.880
 for example, on the AI side. So really, to talk about the big dream of the community, I would say,

11:24.880 --> 11:31.040
 because it seems so far away, it's almost taboo to bring it up, because it's seen as the kind of

11:31.040 --> 11:36.560
 people that dream about creating a truly superhuman level of intelligence that's really far out there,

11:37.200 --> 11:41.360
 people because we're not even close to that. And it feels like the same thing is true for

11:41.360 --> 11:47.840
 the physics community. I mean, Stephen Hawking certainly talked constantly about theory of

11:47.840 --> 11:57.680
 everything. People use those terms who were some of the most respected people in the whole world

11:57.680 --> 12:04.640
 of physics. But I think that the distinction that I would make is that people might react badly if

12:04.640 --> 12:11.440
 you use the term in a way that suggests that you thinking about it for five minutes have come up

12:11.440 --> 12:18.640
 with this major new insight about it. It's difficult. Stephen Hawking is not a great example,

12:18.640 --> 12:25.600
 because I think you can do whatever the heck you want when you get to that level. And I certainly

12:25.600 --> 12:33.440
 see seeing your faculty. At that point, one of the nice things about getting older is you

12:33.440 --> 12:39.120
 stop giving a damn. But community as a whole, they tend to roll their eyes very quickly at

12:39.120 --> 12:44.960
 stuff that's outside the quote unquote mainstream. Well, let me put it this way. If you asked Ed

12:44.960 --> 12:50.560
 Whitten, let's say, who is, you might consider a leader of the string community and thus very,

12:50.560 --> 12:56.960
 very mainstream in a certain sense, but he would have no hesitation in saying, of course,

12:56.960 --> 13:06.640
 they're looking for a unified description of nature, of general relativity, of quantum mechanics,

13:06.640 --> 13:12.880
 of all the fundamental interactions of nature, right? Now, whether people would call that a

13:12.880 --> 13:18.480
 theory of everything, whether they would use that term, that might vary. Lenny Susskin would

13:18.480 --> 13:22.400
 definitely have no problem telling you that if that's what we want, right?

13:22.400 --> 13:30.400
 For me who loves human beings and psychology, it's kind of ridiculous to say a theory that

13:30.400 --> 13:35.680
 unifies the laws of physics gets you to understand everything. I would say you're not even close to

13:35.680 --> 13:40.320
 understanding everything. Yeah, right. Well, yeah, I mean, the word everything is a little

13:40.320 --> 13:45.040
 ambiguous here, right? Because, you know, and then people will get into debates about, you know,

13:45.040 --> 13:51.920
 reductionism versus emergentism and blah, blah, blah. And so in not wanting to say theory of

13:51.920 --> 13:56.720
 everything, people might just be trying to short circuit that debate and say, you know, look,

13:56.720 --> 14:02.560
 you know, yes, we want a fundamental theory of, you know, the particles and interactions of nature.

14:02.560 --> 14:05.920
 Let me bring up the next topic that people don't want to mention, although they're getting more

14:05.920 --> 14:10.240
 comfortable with it is consciousness. You mentioned that you have a talk on consciousness

14:10.240 --> 14:14.480
 that they watched five minutes of, but the internet connection is really bad. Was this

14:14.480 --> 14:18.880
 my talk about, you know, refuting the integrated information theory? Yes, it might have been.

14:18.880 --> 14:23.040
 Which was this particular account of consciousness that, yeah, I think one can just show it doesn't

14:23.040 --> 14:27.760
 work. So let me... Much harder to say what does work. What does work, yeah. Yeah. Let me ask,

14:27.760 --> 14:34.720
 maybe it'd be nice to comment on... You talk about also like the semi hard problem of consciousness,

14:34.720 --> 14:38.640
 or like almost hard problem or kind of hard... Pretty hard problem, I think I call it.

14:38.640 --> 14:47.440
 So maybe can you talk about that, their idea of the approach to modeling consciousness and why

14:47.440 --> 14:53.680
 you don't find it convincing? What is it first of all? Okay, well, so what I called the pretty hard

14:53.680 --> 14:58.160
 problem of consciousness, this is my term, although many other people have said something

14:58.160 --> 15:07.360
 equivalent to this, okay. But it's just, you know, the problem of, you know, giving an account of

15:07.360 --> 15:12.720
 just which physical systems are conscious and which are not. Or, you know, if there are degrees of

15:12.720 --> 15:18.560
 consciousness, then quantifying how conscious a given system is. Oh, awesome. So that's the

15:18.560 --> 15:23.040
 pretty hard... Yeah, that's what I mean. That's it. I'm adopting it. I love it. That's a good

15:23.040 --> 15:29.440
 ring to it. And so, you know, the infamous hard problem of consciousness is to explain how something

15:29.440 --> 15:34.560
 like consciousness could arise at all, you know, in a material universe, right? Or, you know,

15:34.560 --> 15:40.720
 why does it ever feel like anything to experience anything, right? And, you know, so I'm trying

15:40.720 --> 15:47.520
 to distinguish from that problem, right? And say, you know, okay, I would merely settle for an account

15:47.520 --> 15:53.360
 that could say, you know, is a fetus conscious, you know, if so, which trimester, you know, is a

15:54.880 --> 16:00.560
 dog conscious, you know, what about a frog, right? Or even as a precondition, you take that both

16:00.560 --> 16:06.160
 these things are conscious, tell me which is more conscious. Yeah, for example, yes. Yeah, yeah.

16:06.160 --> 16:11.360
 I mean, if consciousness is some multidimensional vector, well, just tell me in which respects

16:11.360 --> 16:16.320
 these things are conscious and in which respect they aren't, right? And, you know, and have some

16:16.320 --> 16:21.600
 principled way to do it where you're not, you know, carving out exceptions for things that you like

16:21.600 --> 16:27.920
 or don't like, but could somehow take a description of an arbitrary physical system, and then just

16:27.920 --> 16:35.360
 based on the physical properties of that system, or the informational properties or how it's connected

16:35.360 --> 16:40.960
 or something like that, just in principle, calculate, you know, its degree of consciousness,

16:40.960 --> 16:46.240
 right? I mean, this would be the kind of thing that we would need, you know, if we wanted to

16:46.240 --> 16:51.360
 address questions like, you know, what does it take for a machine to be conscious, right,

16:51.360 --> 17:00.800
 or when should we regard AIs as being conscious? So now this IIT, this integrated information

17:00.800 --> 17:11.760
 theory, which has been put forward by Giulio Tinoni and a bunch of his collaborators over the last

17:11.760 --> 17:19.360
 decade or two. This is noteworthy, I guess, as a direct attempt to answer that question,

17:19.360 --> 17:26.080
 to, you know, answer the, to address the pretty hard problem, right? And they give a criterion

17:26.080 --> 17:32.960
 that's just based on how a system is connected. So it's up to you to sort of abstract a system

17:32.960 --> 17:39.200
 like a brain or a microchip as a collection of components that are connected to each other by

17:39.200 --> 17:45.440
 some pattern of connections, you know, and to specify how the components can influence each

17:45.440 --> 17:50.160
 other, you know, like where the inputs go, you know, where they affect the outputs. But then

17:50.160 --> 17:55.600
 once you've specified that, then they give this quantity that they call phi, you know, the Greek

17:55.600 --> 18:02.160
 letter phi. And the definition of phi has actually changed over time. It changes from one paper to

18:02.160 --> 18:08.880
 another. But in all of the variations, it involves something about what we in computer science would

18:08.880 --> 18:15.760
 call graph expansion. So basically what this means is that they want, in order to get a large value

18:15.760 --> 18:23.120
 of phi, it should not be possible to take your system and partition it into two components

18:23.120 --> 18:29.200
 that are only weekly connected to each other. Okay. So whenever we take our system and sort of

18:29.200 --> 18:34.080
 try to split it up into two, then there should be lots and lots of connections going between the

18:34.080 --> 18:39.280
 two components. Okay, well, I understand what that means on a graph. Do they formalize what,

18:40.160 --> 18:45.680
 how to construct such a graph or data structure, whatever, or is this one

18:45.680 --> 18:51.440
 of the criticism I've heard you kind of say is that a lot of the very interesting specifics are

18:51.440 --> 18:58.080
 usually communicated through like natural language, like, like through words. So it's like the details

18:58.080 --> 19:03.360
 aren't always clear. Well, they, well, it's true. I mean, they, they, they have nothing even resembling

19:03.360 --> 19:09.920
 a derivation of this phi. Okay. So what they do is they state a whole bunch of postulates,

19:09.920 --> 19:15.440
 you know, axioms that they think that consciousness should satisfy. And then there's some verbal

19:15.440 --> 19:21.520
 discussion. And then at some point, phi appears, right? And this, this was the first thing that

19:21.520 --> 19:26.640
 really made the hair stand on my neck, to be honest, because they are acting as if there's a

19:26.640 --> 19:31.440
 derivation, they're acting as if, you know, you're supposed to think that this is a derivation. And

19:31.440 --> 19:36.800
 there's nothing even remotely resembling a derivative, they just pull the phi out of a hat

19:36.800 --> 19:41.200
 completely is one of the key criticisms to use that details are missing or is there something

19:41.200 --> 19:44.640
 more fun to mention? That's not, that's not even the key criticism. That's just, that's just a side

19:44.640 --> 19:50.000
 point. Okay. The, the core of it is that I think that the, you know, that they want to say that

19:50.000 --> 19:56.720
 a system is more conscious, the larger its value of phi. And I think that that is obvious nonsense.

19:56.720 --> 20:01.680
 Okay. As soon as you think about it for like a minute, as soon as you think about it in terms of

20:01.680 --> 20:07.760
 could I construct a system that had an enormous value of phi, like, you know, even larger than

20:07.760 --> 20:13.680
 the brain has, but that is just implementing an error correcting code, you know, doing nothing

20:13.680 --> 20:19.520
 that we would associate with, you know, intelligence or consciousness or any of it. The answer is,

20:19.520 --> 20:25.200
 yes, it is easy to do that. Right. And so I wrote blog posts just making this point that, yeah,

20:25.200 --> 20:30.720
 it's easy to do that. Now, you know, Tenoni's response to that was actually kind of incredible.

20:30.720 --> 20:35.920
 Right. I mean, I, I admired it in a way because instead of disputing any of it,

20:35.920 --> 20:42.640
 he just bit the bullet in the sense, you know, he was one of the, the, the most audacious bullet

20:42.640 --> 20:49.600
 bitings I've ever seen in my career. Okay. He said, okay, then fine, you know, this system that

20:49.600 --> 20:54.400
 just applies this error correcting code, it's conscious, you know, and if it has a much larger

20:54.400 --> 21:00.160
 value of phi than you or me, it's much more conscious than you or me. You know, we just have

21:00.160 --> 21:05.600
 to accept what the theory says because, you know, science is not about confirming our intuitions.

21:05.600 --> 21:10.640
 It's about challenging them. And, you know, this is what my theory predicts that this thing is

21:10.640 --> 21:15.440
 conscious and, you know, or super duper conscious and how are you going to prove me wrong?

21:16.320 --> 21:22.800
 So the way I would argue against your blog post is I would say, yes, sure, you're right in general,

21:22.800 --> 21:28.640
 but for naturally arising systems developed through the process of evolution on earth,

21:29.280 --> 21:34.480
 the, this rule of the larger fee being associated with more consciousness is correct.

21:34.480 --> 21:39.200
 Yeah. So that's not what he said at all. Right. Right. Because he wants this to be completely

21:39.200 --> 21:43.040
 general. Right. So we can apply it to even computers. Yeah. I mean, I mean, the whole

21:43.040 --> 21:48.160
 interest of the theory is the, you know, the hope that it could be completely general, apply to

21:48.160 --> 21:58.080
 aliens, to computers, to animals, coma patients, to any of it. Right. Yeah. And so, so, so he just

21:58.080 --> 22:04.640
 said, well, you know, Scott is relying on his intuition, but, you know, I'm relying on this theory.

22:04.640 --> 22:10.160
 And, you know, to me, it was almost like, you know, are we being serious here? Like, like, like,

22:10.960 --> 22:16.800
 you know, like, like, okay, yes, in science, we try to learn highly nonintuitive things. But

22:16.800 --> 22:23.200
 what we do is we first test the theory on cases where we already know the answer. Right. Like,

22:23.200 --> 22:28.320
 if we, if someone had a new theory of temperature, right, then, you know, maybe we could check that

22:28.320 --> 22:34.240
 it says that boiling water is hotter than ice. And then if it says that the sun is hotter than

22:34.240 --> 22:40.480
 anything, you know, you've ever experienced, then maybe we, we trust that extrapolation. Right.

22:40.480 --> 22:47.840
 But like this, this theory, like, if, if, you know, it's now saying that, you know, a, a gigantic

22:47.840 --> 22:54.800
 grit, like regular grid of exclusive orgates can be way more conscious than a, you know, a person

22:54.800 --> 23:01.920
 or than, than any animal can be, you know, even if it, you know, is, you know, is, is, is so uniform

23:01.920 --> 23:07.680
 that it might as well just be a blank wall. Right. And, and so now the point is, if this theory is

23:07.680 --> 23:12.960
 sort of getting wrong, the question is a blank wall, you know, more conscious than a person,

23:12.960 --> 23:18.000
 then I would say what is, what is there for it to get right? So your sense is a blank wall

23:19.680 --> 23:24.080
 is not more conscious than a human being. Yeah. I mean, I mean, I mean, you could say that I am

23:24.080 --> 23:30.880
 taking that as one of my axioms. I'm saying, I'm saying that if, if a theory of consciousness

23:30.880 --> 23:38.560
 is, is getting that wrong, then whatever it is talking about at that point, I, I, I'm not going

23:38.560 --> 23:41.680
 to call it consciousness. I'm going to use a different word. You have to use a different word.

23:41.680 --> 23:46.720
 I mean, it's also, it's possible, just like with intelligence, that us humans conveniently

23:46.720 --> 23:50.800
 define these very difficult to understand concepts in a very human centric way.

23:50.800 --> 23:56.320
 Just like the Turing test really seems to define intelligence as a thing that's human like.

23:56.880 --> 24:00.800
 Right. But I would say that with any concept, you know, there's,

24:03.200 --> 24:09.040
 you know, like we, we, we first need to define it, right. And a definition is only a good definition

24:09.040 --> 24:13.520
 if it matches what we thought we were talking about, you know, prior to having a definition,

24:13.520 --> 24:20.240
 right. And I would say that, you know, fee as a definition of consciousness fails that test.

24:21.200 --> 24:26.480
 That is my argument. So, okay. Then let's, so let's take a further step. So you mentioned that

24:26.480 --> 24:32.160
 the universe might be a Turing machine. So like it might be computations or simulatable by one

24:32.160 --> 24:38.240
 anyway. Simulatable by one. So do you, what's your sense about consciousness? Do you think

24:38.240 --> 24:45.200
 consciousness is computation that we don't need to go to any place outside of the computable universe

24:46.080 --> 24:52.800
 to, you know, to, to understand consciousness, to build consciousness, to measure consciousness,

24:52.800 --> 24:58.080
 all those kinds of things. I don't know. These are what, you know, have been called the, the

24:58.080 --> 25:03.520
 vertiginous questions, right? There's the questions like, like, you know, that you get a feeling of

25:03.520 --> 25:10.480
 vertigo and thinking about them, right? I mean, I certainly feel like I am conscious in a way that

25:10.480 --> 25:16.800
 is not reducible to computation. But why should you believe me? Right? I mean, and, and, and if you

25:16.800 --> 25:22.960
 said the same to me, then why should I believe you? But as computer scientists, I feel like a

25:22.960 --> 25:30.000
 computer could be intelligent, could achieve human level intelligence. But, and that's actually a

25:30.000 --> 25:35.040
 feeling and a hope. That's not a scientific belief. It's just we've built up enough intuition, the

25:35.040 --> 25:39.520
 same kind of intuition you use in your blog. You know, that's what scientists do. They, I mean,

25:39.520 --> 25:44.320
 some of it is a scientific method, but some of it is just damn good intuition. I don't have a good

25:44.320 --> 25:49.840
 intuition about consciousness. Yeah, I'm not sure that anyone does or has in the, you know,

25:49.840 --> 25:55.760
 2,500 years that these things have been discussed, Lex. But do you think we will? Like one of the,

25:55.760 --> 26:01.280
 I got a chance to attend, can't wait to hear your opinion on this, but attend the Neuralink event.

26:01.920 --> 26:07.600
 And one of the dreams there is to, you know, basically push neuroscience forward. And the

26:07.600 --> 26:15.520
 hope in neuroscience is that we can inspect the machinery from which all this fun stuff emerges

26:15.520 --> 26:20.480
 and see, are we going to notice something special, some special sauce from which something like

26:20.480 --> 26:25.520
 consciousness or cognition emerges? Yeah, well, it's clear that we've learned an enormous amount

26:25.520 --> 26:31.120
 about neuroscience. We've learned an enormous amount about computation, you know, about machine

26:31.120 --> 26:37.040
 learning, about AI, how to get it to work. We've learned an enormous amount about the

26:37.760 --> 26:43.920
 underpinnings of the physical world, you know, and, you know, from one point of view, that's like

26:43.920 --> 26:48.720
 an enormous distance that we've traveled along the road to understanding consciousness.

26:48.720 --> 26:52.560
 From another point of view, you know, the distance still to be traveled on the road,

26:52.560 --> 26:58.240
 you know, maybe seems no shorter than it was at the beginning, right? So it's very hard to say.

26:58.240 --> 27:04.000
 I mean, you know, these are questions like, like in sort of trying to have a theory of consciousness,

27:04.000 --> 27:08.480
 there's sort of a problem where it feels like it's not just that we don't know how to make

27:08.480 --> 27:13.920
 progress, it's that it's hard to specify what could even count as progress, right? Because no

27:13.920 --> 27:18.800
 matter what scientific theory someone proposed, someone else could come along and say, well,

27:18.800 --> 27:24.320
 you've just talked about the mechanism, you haven't said anything about what breathes fire into the

27:24.320 --> 27:28.640
 mechanism, what really makes there's something that it's like to be it, right? And that seems

27:28.640 --> 27:34.000
 like an objection that you could always raise. Yes. No matter, you know, how much someone elucidated

27:34.000 --> 27:38.400
 the details of how the brain works. Okay, let's go to the Turing Test and Lobner Prize. I have this

27:38.400 --> 27:46.880
 intuition, call me crazy, but we, that a machine to pass the Turing Test and it's full, whatever

27:46.880 --> 27:52.000
 the spirit of it is, we can talk about how to formulate the perfect Turing Test, that that

27:52.000 --> 28:00.800
 machine has to be conscious, or we at least have to, I have a very low bar of what consciousness is.

28:00.800 --> 28:06.320
 I tend to, I tend to think that the emulation of consciousness is as good as consciousness.

28:07.120 --> 28:14.640
 So like consciousness is just a dance, a social, a social shortcut, like a nice useful tool.

28:14.640 --> 28:19.280
 But I tend to connect intelligence and consciousness together. So by that, do you

28:21.120 --> 28:27.520
 maybe just to ask what role does consciousness play? Do you think it passed in the Turing Test?

28:27.520 --> 28:32.080
 Well, look, I mean, it's almost tautologically true that if we had a machine that passed the

28:32.080 --> 28:37.200
 Turing Test, then it would be emulating consciousness, right? So if your position is that,

28:37.200 --> 28:42.640
 you know, emulation of consciousness is consciousness, then, you know, by definition,

28:42.640 --> 28:47.840
 any machine that passed the Turing Test would be conscious. But it's, but I mean,

28:47.840 --> 28:51.680
 you know, that you could say that, you know, that that is just a way to rephrase the original

28:51.680 --> 28:56.480
 question, you know, is an emulation of consciousness, you know, necessarily conscious,

28:56.480 --> 29:01.120
 right? And you can, you know, here, I'm not saying anything new that hasn't been

29:01.120 --> 29:07.360
 debated ad nauseam in the literature. Okay, but, you know, you could imagine some very hard cases,

29:07.360 --> 29:13.360
 like imagine a machine that passed the Turing Test, but they did so just by an enormous

29:13.360 --> 29:19.840
 cosmological sized lookup table that just cached every possible conversation that could be had.

29:19.840 --> 29:24.480
 The old Chinese room. Well, yeah, yeah, but this is, I mean, I mean,

29:24.480 --> 29:29.200
 the Chinese room actually would be doing some computation, at least in Searle's version, right?

29:29.200 --> 29:34.160
 Here, I'm just talking about a table lookup. Okay, now, it's true that for conversations

29:34.160 --> 29:38.800
 of a reasonable length, this, you know, lookup table would be so enormous, it wouldn't even

29:38.800 --> 29:43.360
 fit in the observable universe. Okay, but supposing that you could build a big enough

29:43.360 --> 29:49.600
 lookup table and then just, you know, pass the Turing Test just by looking up what the person

29:49.600 --> 29:55.760
 said, right? Are you going to regard that as conscious? Okay, let me try to make this formal,

29:55.760 --> 30:02.880
 and then you can shout it down. I think that the emulation of something is that something,

30:02.880 --> 30:08.240
 if there exists in that system, a black box, that's full of mystery. So like,

30:09.840 --> 30:15.520
 full of mystery to whom? To human inspectors. So does that mean that consciousness is

30:15.520 --> 30:20.560
 relative to the observer? Like, could something be conscious for us, but not conscious for an

30:20.560 --> 30:26.080
 alien that understood better what was happening inside the black box? Yes, yes. So that if inside

30:26.080 --> 30:31.120
 the black box is just a lookup table, the alien that saw that would say this is not conscious,

30:31.120 --> 30:36.000
 to us, another way to phrase the black box is layers of abstraction,

30:36.000 --> 30:40.560
 which make it very difficult to see to actually underlying functionality of the system.

30:40.560 --> 30:45.680
 And then we observe just the abstraction. And so it looks like magic to us. But once we

30:45.680 --> 30:52.160
 understand the inner machinery, it stops being magic. And so like, that's a prerequisite is

30:52.160 --> 30:58.160
 that you can't know how it works, some part of it. Because then there has to be in our human mind,

30:58.160 --> 31:04.880
 an entry point for the magic. So that's a formal definition of the system.

31:05.520 --> 31:10.640
 Yeah, well, look, I mean, I explored a view in this essay I wrote called The Ghost and the

31:10.640 --> 31:17.200
 Quantum Turing Machine seven years ago, that is related to that, except that I did not want to

31:17.200 --> 31:21.440
 have consciousness be relative to the observer, right? Because I think that, you know, if

31:21.440 --> 31:26.080
 consciousness means anything, it is something that is experienced by the entity that is

31:26.080 --> 31:31.520
 conscious, right? You know, like, I don't need you to tell me that I'm conscious, right? Nor do you

31:31.520 --> 31:40.480
 need me to tell you that you are, right? So, but basically what I explored there is, you know,

31:40.480 --> 31:49.040
 are there aspects of a system like a brain that just could not be predicted, even with

31:49.040 --> 31:54.640
 arbitrarily advanced future technologies? It's because of chaos combined with quantum

31:54.640 --> 32:01.520
 mechanical uncertainty, you know, things like that. I mean, that actually could be a property of the

32:01.520 --> 32:07.360
 brain, you know, if true, that would distinguish it in a principled way, at least from any currently

32:07.360 --> 32:11.360
 existing computer, not from any possible computer, but from, yeah, yeah.

32:11.360 --> 32:18.000
 This is a thought experiment. So if I gave you information that you're in the entire history

32:18.000 --> 32:26.080
 of your life, basically explain away free will with a lookup table, say that this was all predetermined,

32:26.080 --> 32:29.920
 that everything you experienced has already been predetermined. Wouldn't that take away

32:29.920 --> 32:35.360
 your consciousness? Wouldn't you yourself, wouldn't experience of the world change for you in a way

32:35.360 --> 32:41.840
 that you can't take back? Well, let me put it this way, if you could do like in a Greek tragedy,

32:41.840 --> 32:46.640
 where, you know, you would just write down a prediction for what I'm going to do, and then

32:46.640 --> 32:53.040
 maybe you put the prediction in a sealed box, and maybe, you know, you open it later, and you

32:53.040 --> 32:57.840
 show that you knew everything I was going to do, or, you know, of course, the even creepier version

32:57.840 --> 33:03.280
 would be you tell me the prediction, and then I try to falsify it, my very effort to falsify it

33:03.280 --> 33:09.520
 makes it come true, right? Let's, you know, let's even forget that, you know, that version as convenient

33:09.520 --> 33:14.080
 as it is for fiction writers, right? Let's just let's just do the version where you put the prediction

33:14.080 --> 33:20.880
 into a sealed envelope, okay? But if you could reliably predict everything that I was going to do,

33:20.880 --> 33:25.680
 I'm not sure that that would destroy my sense of being conscious, but I think it really would

33:25.680 --> 33:32.800
 destroy my sense of having free will, you know, and much, much more than any philosophical conversation

33:32.800 --> 33:39.680
 could possibly do that, right? And so I think it becomes extremely interesting to ask, you know,

33:39.680 --> 33:44.800
 could such predictions be done, you know, even in principle, is it consistent with the laws of

33:44.800 --> 33:50.640
 physics to make such predictions, to get enough data about someone that you could actually generate

33:50.640 --> 33:55.920
 such predictions without having to kill them in the process to, you know, slice their brain up into

33:55.920 --> 34:00.480
 little slivers or something. I mean, theoretically possible, right? Well, I don't know. I mean,

34:00.480 --> 34:05.840
 it might be possible, but only at the cost of destroying the person, right? I mean, it depends

34:05.840 --> 34:13.520
 on how low you have to go in sort of the substrate. Like if there was a nice digital abstraction layer,

34:13.520 --> 34:18.800
 if you could think of each neuron as a kind of transistor computing a digital function,

34:18.800 --> 34:24.160
 then you could imagine some nanorobots that would go in and we just scan the state of each

34:24.160 --> 34:30.800
 transistor, you know, of each neuron, and then, you know, make a good enough copy, right? But if it

34:30.800 --> 34:36.800
 was actually important to get down to the molecular or the atomic level, then, you know, eventually

34:36.800 --> 34:41.360
 you would be up against quantum effects. You would be up against the unclonability of quantum

34:41.360 --> 34:48.160
 states. So I think it's a question of how good of a replica, how good does the replica have to be

34:48.160 --> 34:53.600
 before you're going to count it as actually a copy of you or as being able to predict your actions?

34:54.240 --> 34:59.920
 That's a totally open question. Yeah, yeah, yeah. And especially once we say that, well,

34:59.920 --> 35:06.880
 look, maybe there's no way to make a deterministic prediction because, you know, we know that there's

35:06.880 --> 35:12.560
 noise buffeting the brain around, presumably even quantum mechanical uncertainty, you know,

35:12.560 --> 35:16.960
 affecting the sodium ion channels, for example, whether they open or they close,

35:18.640 --> 35:24.800
 you know, there's no reason why over a certain time scale that shouldn't be amplified just like

35:24.800 --> 35:34.000
 we imagine happens with the weather or with any other, you know, chaotic system. So if that stuff

35:34.000 --> 35:41.440
 is important, right, then, then, you know, we would say, well, you know, you can't,

35:42.160 --> 35:47.120
 you know, you're never going to be able to make an accurate enough copy. But now the hard part is,

35:47.120 --> 35:52.320
 well, what if someone can make a copy that sort of no one else can tell apart from you, right?

35:52.320 --> 35:58.000
 It says the same kinds of things that you would have said, maybe not exactly the same things,

35:58.000 --> 36:03.200
 because we agree that there's noise, but it says the same kinds of things. And maybe you alone

36:03.200 --> 36:08.720
 would say, no, I know that that's not me, you know, it's, it doesn't share my, I haven't felt my

36:08.720 --> 36:13.920
 consciousness leap over to that other thing. I still feel it localized in this version,

36:13.920 --> 36:18.480
 right? Then why should anyone else believe you? What are your thoughts? I'd be curious,

36:18.480 --> 36:24.160
 you're a really good person to ask, which is Penrose's, Roger Penrose's work on consciousness,

36:24.720 --> 36:29.680
 saying that there, you know, there is some with axons and so on. There might be some

36:29.680 --> 36:34.560
 biological places where quantum mechanics can come into play and through that create

36:34.560 --> 36:39.440
 consciousness somehow. Yeah. Okay. Well, I'm familiar with this work. Of course. You know,

36:39.440 --> 36:45.840
 I read Penrose's books as a teenager. They had a huge impact on me. Five or six years ago,

36:45.840 --> 36:50.080
 I had the privilege to actually talk these things over with Penrose, you know, at some length at

36:50.080 --> 36:57.600
 a conference in Minnesota. And, you know, he is, you know, an amazing personality. I admire the

36:57.600 --> 37:04.080
 fact that he was even raising such audacious questions at all. But, you know, to answer your

37:04.080 --> 37:09.680
 question, I think the first thing we need to get clear on is that he is not merely saying that

37:09.680 --> 37:15.280
 quantum mechanics is relevant to consciousness, right? That would be like, you know, that would be

37:15.280 --> 37:20.880
 tame compared to what he is saying, right? He is saying that, you know, even quantum mechanics

37:20.880 --> 37:26.320
 is not good enough, right? Because if supposing, for example, that the brain were a quantum computer,

37:26.320 --> 37:32.080
 maybe that's still a computer, you know, in fact, a quantum computer can be simulated by an ordinary

37:32.080 --> 37:37.520
 computer. It might merely need exponentially more time in order to do so, right? So that's simply

37:37.520 --> 37:44.080
 not good enough for him. Okay, so what he wants is for the brain to be a quantum gravitational

37:44.080 --> 37:53.120
 computer. Or he wants the brain to be exploiting as yet unknown laws of quantum gravity, okay,

37:53.120 --> 37:58.080
 which would, which would be uncomputable. Uncomputable. That's the key point. Okay, yes, yes.

37:58.080 --> 38:03.280
 That would be literally uncomputable. And I've asked him, you know, to clarify this, but

38:03.280 --> 38:10.080
 uncomputable, even if you had an oracle for the halting problem, or, you know, and, or, you know,

38:10.080 --> 38:15.600
 as high up as you want to go in the sort of high, the usual hierarchy of uncomputability,

38:15.600 --> 38:21.120
 he wants to go beyond all of that. Okay, so, so, you know, just to be clear, like, you know,

38:21.120 --> 38:26.160
 if we're keeping count of how many speculations, you know, there's probably like at least five

38:26.160 --> 38:30.800
 or six of them, right? There's first of all, that there is some quantum gravity theory that

38:30.800 --> 38:35.760
 would involve this kind of uncomputability, right? Most people who study quantum gravity

38:35.760 --> 38:40.480
 would not agree with that. They would say that what we've learned, you know, what little we

38:40.480 --> 38:47.200
 know about quantum gravity from the, this ADSCFT correspondence, for example, has been very much

38:47.200 --> 38:54.320
 consistent with the broad idea of nature being computable, right? But, but all right, but,

38:54.320 --> 39:00.720
 but supposing that he's right about that, then, you know, what most physicists would say is that

39:00.720 --> 39:06.960
 whatever new phenomena there are in quantum gravity, you know, they might be relevant at the

39:06.960 --> 39:14.320
 singularities of black holes, they might be relevant at the Big Bang. They are plainly not

39:14.320 --> 39:20.240
 relevant to something like the brain, you know, that is operating at ordinary temperatures,

39:20.240 --> 39:27.600
 you know, with ordinary chemistry, and, you know, the, the, the physics underlying the brain,

39:27.600 --> 39:31.360
 they would say that we have, you know, the fundamental physics of the brain, they would

39:31.360 --> 39:37.520
 say that we've pretty much completely known for, for generations now, right? Because,

39:37.520 --> 39:42.800
 you know, quantum field theory lets us sort of parameterize our ignorance, right? I mean,

39:42.800 --> 39:47.920
 Sean Carroll has made this case and, you know, in great detail, right? That sort of whatever

39:47.920 --> 39:52.880
 new effects are coming from quantum gravity, you know, they are sort of screened off by

39:52.880 --> 39:57.600
 quantum field theory, right? And this is, this brings, you know, brings us to the whole idea of

39:57.600 --> 40:02.960
 effective theories, right? But that, like, we have, you know, in, like, in the standard model of

40:02.960 --> 40:10.320
 elementary particles, right? We have a quantum field theory that seems totally adequate for all

40:10.320 --> 40:15.680
 of the terrestrial phenomena, right? The only things that it doesn't, you know, explain are,

40:15.680 --> 40:20.560
 well, first of all, you know, the details of gravity, if you were to probe it, like, at,

40:20.560 --> 40:26.640
 at, you know, extremes of, you know, curvature or at, like, incredibly small distances,

40:26.640 --> 40:32.400
 it doesn't explain dark matter. It doesn't explain black hole singularities, right? But these are all

40:32.400 --> 40:38.320
 very exotic things, very, you know, far removed from our life on Earth, right? So for Penrose,

40:38.320 --> 40:44.560
 to be right, he needs, you know, these phenomena to somehow affect the brain. He needs the brain

40:44.560 --> 40:52.000
 to contain antenna that are sensitive to this to this as yet unknown physics, right? And then he

40:52.000 --> 40:58.800
 needs a modification of quantum mechanics. Okay, so he needs quantum mechanics to actually be wrong.

40:58.800 --> 41:06.000
 Okay, he needs what he wants is what he calls an objective reduction mechanism or an objective

41:06.000 --> 41:11.680
 collapse. So this is the idea that once quantum states get large enough, then they somehow

41:11.680 --> 41:20.720
 spontaneously collapse, right? That, you know, and this is an idea that lots of people have explored.

41:21.440 --> 41:28.160
 You know, there's something called the GRW proposal that tries to, you know, say something along

41:28.160 --> 41:32.160
 those lines, you know, and these are theories that actually make testable predictions, right,

41:32.160 --> 41:36.640
 which is a nice feature that they have. But, you know, the very fact that they're testable may mean

41:36.640 --> 41:42.240
 that in the, you know, in the coming decades, we may well be able to test these theories and show

41:42.240 --> 41:48.480
 that they're wrong, right? You know, we may be able to test some of Penrose's ideas. If not,

41:48.480 --> 41:53.920
 not his ideas about consciousness, but at least his ideas that about an objective collapse of

41:53.920 --> 41:58.960
 quantum states, right? And people have actually, like Dick Baumeister have actually been working

41:58.960 --> 42:04.560
 to try to do these experiments. They haven't been able to do it yet to test Penrose's proposal.

42:04.560 --> 42:09.680
 Okay, but Penrose would need more than just an objective collapse of quantum states,

42:09.680 --> 42:14.560
 which would already be the biggest development in physics for a century since quantum mechanics

42:14.560 --> 42:21.760
 itself. Okay, he would need for consciousness to somehow be able to influence the direction

42:21.760 --> 42:27.040
 of the collapse so that it wouldn't be completely random, but that, you know, your dispositions

42:27.040 --> 42:32.560
 would somehow influence the quantum state to collapse more likely this way or that way.

42:32.560 --> 42:39.360
 Okay, finally, Penrose, you know, says that all of this has to be true because of an argument

42:39.360 --> 42:44.880
 that he makes based on Gertl's incompleteness theorem. Okay, now, Blake, I would say the

42:44.880 --> 42:50.320
 overwhelming majority of computer scientists and mathematicians who have thought about this,

42:51.200 --> 42:55.280
 I don't think that Gertl's incompleteness theorem can do what he needs it to do here,

42:55.280 --> 43:00.000
 right? I don't think that that argument is sound. Okay, but that is, you know,

43:00.000 --> 43:04.640
 that is sort of the tower that you have to ascend to if you're going to go where Penrose goes.

43:04.640 --> 43:09.440
 And the intuition uses with the incompleteness theorem is that basically

43:09.440 --> 43:14.720
 that there's important stuff that's not computable? No, it's not just that because,

43:14.720 --> 43:19.360
 I mean, everyone agrees that there are problems that are uncomputable, right? That's a mathematical

43:19.360 --> 43:28.400
 theorem, right? But what Penrose wants to say is that, you know, for example, there are statements,

43:28.400 --> 43:34.160
 you know, for, you know, given any formal system, you know, for doing math, right,

43:34.160 --> 43:39.600
 there will be true statements of arithmetic that that formal system, you know, if it's

43:39.600 --> 43:46.000
 adequate for math at all, if it's consistent and so on, will not be able to prove a famous example

43:46.000 --> 43:52.160
 being the statement that that system itself is consistent, right? No, you know, good formal system

43:52.160 --> 43:58.080
 can actually prove its own consistency to that can only be done from a stronger formal system,

43:58.080 --> 44:03.600
 which then can't prove its own consistency and so on forever. Okay, that's Gertl's theorem.

44:03.600 --> 44:11.120
 But now, why is that relevant to consciousness, right? Well, you know, I mean, I mean, the idea

44:11.120 --> 44:15.280
 that it might have something to do with consciousness as an old one, Gertl himself,

44:15.280 --> 44:24.240
 apparently thought that it, you know, a Lucas thought so, I think, in the 60s. And Penrose

44:24.240 --> 44:30.160
 is really just, you know, sort of updating what they and others had said. I mean, you know, the

44:30.160 --> 44:36.240
 idea that Gertl's theorem could have something to do with consciousness was, you know, in 1950,

44:36.240 --> 44:42.160
 when Alan Turing wrote his article about the Turing test, he already, you know, was writing

44:42.160 --> 44:47.680
 about that as like an old and well known idea. And as one that he, as a wrong one that he wanted

44:47.680 --> 44:54.400
 to dispense with. Okay, but the basic problem with this idea is, you know, Penrose wants to say

44:54.400 --> 45:00.480
 that and all of his predecessors, you know, want to say that, you know, even though, you know,

45:00.480 --> 45:07.520
 this given formal system cannot prove its own consistency, we as humans sort of looking at

45:07.520 --> 45:15.280
 it from the outside can just somehow see its consistency. Right. And the, you know, the rejoinder

45:15.280 --> 45:20.960
 to that, you know, from the very beginning has been, well, can we really? I mean, maybe, maybe,

45:20.960 --> 45:27.600
 you know, maybe, maybe he Penrose can, but, you know, can the rest of us? Right. And, you know,

45:27.600 --> 45:35.440
 I noticed that, that, you know, I mean, it is perfectly plausible to imagine a computer that

45:35.440 --> 45:40.720
 could say, you know, it would not be limited to working within a single formal system. Right.

45:40.720 --> 45:45.920
 They could say, I am now going to adopt the hypothesis that this, that my formal system

45:45.920 --> 45:50.720
 is consistent. Right. And I'm now going to see what can be done from that stronger vantage point

45:50.720 --> 45:56.480
 and, and so on. And, you know, and I'm going to add new axioms to my system. Totally plausible.

45:56.480 --> 46:02.800
 There's absolutely, Gertl's theorem has nothing to say about against an AI that could repeatedly

46:02.800 --> 46:09.920
 add new axioms. All it says is that there is no absolute guarantee that when the AI adds new

46:09.920 --> 46:13.920
 axioms that it will always be right. Right. Okay. And, you know, and that's of course the point

46:13.920 --> 46:19.440
 that Penrose pounces on, but the reply is obvious. And, you know, it's one that Alan Turing made

46:19.440 --> 46:24.160
 70 years ago. Namely, we don't have an absolute guarantee that we're right when we add a new

46:24.160 --> 46:30.800
 axiom. Right. We never have. And plausibly, we never will. So on Alan Turing, you took part in

46:30.800 --> 46:39.280
 the Lubna Prize. Not really. No, I didn't. I mean, there was this kind of ridiculous claim that was

46:39.280 --> 46:47.360
 made some almost a decade ago about a chat bot called Eugene Goosman. I guess you didn't participate

46:47.360 --> 46:52.880
 as a judge in the Lubna Prize, but you participated as a judge in that. I guess it was an exhibition

46:52.880 --> 46:59.440
 event or something like that. Or with Eugene, Eugene Goosman, that was just me writing a blog post

46:59.440 --> 47:03.920
 because some journalists called me to ask about it. Did you ever chat with him? I did chat with

47:03.920 --> 47:07.600
 Eugene Goosman. I mean, it was available on the web. The chat. Oh, interesting. I didn't know.

47:07.600 --> 47:13.280
 So yeah. So all that happened was that a bunch of journalists started writing

47:13.280 --> 47:19.840
 breathless articles about a first chat bot that passes the Turing test. And it was this thing

47:19.840 --> 47:26.960
 called Eugene Goosman that was supposed to simulate a 13 year old boy. And apparently,

47:26.960 --> 47:34.480
 someone had done some test where people were less than perfect, let's say, distinguishing

47:34.480 --> 47:40.960
 it from a human. And they said, well, if you look at Turing's paper and you look at the percentages

47:40.960 --> 47:49.760
 that he talked about, then it seemed like we're past that threshold. And I had a different way

47:49.760 --> 47:55.360
 to look at it instead of the legalistic way. Let's just try the actual thing out and let's

47:55.360 --> 48:03.360
 see what it can do with questions like, is Mount Everest bigger than a shoebox? Or just the most

48:03.360 --> 48:08.800
 obvious questions, right? And then, and you know, and the answer is, well, it just kind of parries

48:08.800 --> 48:13.680
 you because it doesn't know what you're talking about, right? So just clarify exactly in which

48:13.680 --> 48:20.400
 way they're obvious. They're obvious in the sense that you convert the sentences into the meaning

48:20.400 --> 48:26.720
 of the objects they represent and then do some basic obvious. We mean your common sense reasoning

48:26.720 --> 48:31.760
 with the objects that the sentences represent. Right, right. It was not able to answer, you know,

48:31.760 --> 48:36.400
 or even intelligently respond to basic common sense questions. Well, let me say something

48:36.400 --> 48:42.160
 stronger than that. There was a famous chatbot in the 60s called Eliza, right, that, you know,

48:42.160 --> 48:47.520
 that managed to actually fool, you know, a lot of people, right? Or people would pour their

48:47.520 --> 48:53.360
 hearts out into this Eliza because it simulated a therapist, right? And most of what it would do

48:53.360 --> 48:58.560
 was it would just throw back at you whatever you said, right? And this turned out to be incredibly

48:58.560 --> 49:04.640
 effective, right? Maybe, you know, therapists know this, this is, you know, one of their tricks.

49:04.640 --> 49:12.640
 But it, you know, it really had some people convinced. But, you know, this thing was just

49:12.640 --> 49:19.120
 like, I think it was literally just a few hundred lines of Lisp code, right? It was not only was

49:19.120 --> 49:24.880
 it not intelligent, it wasn't especially sophisticated. It was like a, it was a simple little hobbyist

49:24.880 --> 49:30.560
 program. And Eugene Goestman from what I could see was not a significant advance compared to

49:31.360 --> 49:37.840
 Eliza, right? So, so, and that was, that was really the point I was making. And this was,

49:37.840 --> 49:43.200
 you know, you didn't, in some sense, you didn't need a, like a computer science professor to

49:43.200 --> 49:49.280
 sort of say this, like anyone who was looking at it and who just had, you know, an ounce of sense

49:49.280 --> 49:55.120
 could have said the same thing, right? But because, you know, these journalists were, you know, calling

49:55.120 --> 50:00.240
 me, you know, like the first thing I said was, well, you know, no, you know, I'm a quantum

50:00.240 --> 50:05.040
 computing person. I'm not an AI person, you know, you shouldn't ask me. Then they said, look, you

50:05.040 --> 50:10.400
 can go here and you can try it out. I said, all right, all right, so I'll try it out. But now,

50:10.400 --> 50:15.040
 you know, did this whole discussion, I mean, it got a whole lot more interesting in just the last

50:15.040 --> 50:20.640
 few months. Yeah, I'd love to hear your thoughts about GPT3. Yeah, in the last few months,

50:20.640 --> 50:27.040
 we've had, you know, we've, we've, the world has now seen a chat engine or a text engine,

50:27.040 --> 50:34.160
 I should say, called GPT3. That, you know, I think it's still, you know, it does not pass a

50:34.160 --> 50:39.600
 Turing test. You know, there are no real claims that it passes the Turing test, right? You know,

50:39.600 --> 50:44.560
 this is, comes out of the group at OpenAI and, you know, they're, you know, they've been relatively

50:44.560 --> 50:52.720
 careful in what they've claimed about the system. But I think this, this, this, as clearly as Eugene

50:52.720 --> 50:58.960
 Goestman was not in advance over Eliza, it is equally clear that this is a major advance over,

50:58.960 --> 51:05.680
 over Eliza or really over anything that the world has seen before. This is a text engine

51:05.680 --> 51:13.120
 that can come up with kind of on topic, you know, reasonable sounding completions to just about

51:13.120 --> 51:20.960
 anything that you ask. You can ask it to write a poem about topic X in the style of Poet Y,

51:20.960 --> 51:26.320
 and it will have a go at that. And it will do, you know, not a perfect, not a great job,

51:26.320 --> 51:32.240
 not an amazing job, but, you know, a passable job, you know, definitely, you know, as, as good as,

51:32.240 --> 51:36.720
 you know, you know, in many cases, I would say better than I would have done, right?

51:36.720 --> 51:42.640
 You know, you can ask it to write, you know, an essay, like a student essay about pretty much

51:42.640 --> 51:47.760
 any topic, and it will get something that I am pretty sure would get at least a B minus, you

51:47.760 --> 51:53.440
 know, in most, you know, high school or even college classes, right? And, you know, in some sense,

51:53.440 --> 51:59.280
 you know, the way that it did this, the way that it achieves this, you know, Scott Alexander of the,

51:59.280 --> 52:05.280
 you know, the much more in the blog Slate Star Codex had a wonderful way of putting it. He said

52:05.280 --> 52:11.600
 that they basically just ground up the entire internet into a slurry, okay? And, you know,

52:12.240 --> 52:17.040
 to tell you the truth, I had wondered for a while why nobody had tried that, right? Like,

52:17.040 --> 52:24.560
 why not write a chatbot by just doing deep learning over a corpus consisting of the entire web,

52:24.560 --> 52:31.520
 right? And, and so, so, so now they finally have done that, right? And, you know, the results are,

52:31.520 --> 52:37.120
 are very impressive. You know, it's not clear that, you know, people can argue about whether this is

52:37.120 --> 52:45.440
 truly a step toward general AI or not. But this is an amazing capability that, you know, we didn't

52:45.440 --> 52:51.120
 have a few years ago, that, you know, if a few years ago, if you had told me that we would have it

52:51.120 --> 52:55.840
 now, that would have surprised me. Yeah. And I think that anyone who denies that is just not

52:55.840 --> 53:02.720
 engaging with, with what's there. So their model, it takes a large part of the internet and compresses

53:02.720 --> 53:09.680
 it in a small number of parameters relative to the size of the internet, and is able to, without

53:10.480 --> 53:16.880
 fine tuning, do a basic kind of a querying mechanism, just like you described, where you

53:16.880 --> 53:21.520
 specify a kind of poet and then you want to write a poem. And it somehow is able to do basically a

53:21.520 --> 53:26.960
 lookup on the internet of relevant things. I mean, that's what it, I mean, I mean, how else do you

53:26.960 --> 53:32.320
 explain it? Well, okay. I mean, I mean, the training involved, you know, massive amounts of data from

53:32.320 --> 53:37.840
 the internet and actually took lots and lots of computer power, lots of electricity, right? You

53:37.840 --> 53:43.920
 know, there are some, some very prosaic reasons why this wasn't done earlier, right? But, you know,

53:43.920 --> 53:48.640
 it costs some tens of millions of dollars, I think, you know, that's just for, but approximate, like

53:48.640 --> 53:54.160
 a few million dollars. Oh, okay, okay. Oh, really? Okay. It's more like four or five. Oh, all right.

53:54.160 --> 53:58.880
 All right. Thank you. I mean, as they, as they scale it up, you know, it will cost, but then the

53:58.880 --> 54:06.400
 hope is cost comes down and all that kind of stuff. But basically, you know, it is a neural net, you

54:06.400 --> 54:10.320
 know, so I mean, I mean, or what's now called a deep net, but, you know, they're basically the

54:10.320 --> 54:16.400
 same thing, right? So it's a, it's a form of, you know, algorithm that people have known about for

54:16.400 --> 54:24.080
 decades, right? But it is constantly trying to solve the problem, predict the next word, right?

54:24.080 --> 54:32.160
 So it's just trying to predict what comes next. It's not trying to decide what, what it should

54:32.160 --> 54:38.320
 say, what ought to be true. It's trying to predict what someone who had said all of the words up to

54:38.320 --> 54:43.360
 the preceding one would say next. Although to push back on that, that's how it's trained.

54:43.360 --> 54:46.640
 That's right. No, of course. But it's arguable. Yeah.

54:46.640 --> 54:50.560
 That our very cognition could be a mechanism as that simple.

54:50.560 --> 54:52.880
 Oh, of course. Of course. I never said that it wasn't.

54:54.480 --> 54:58.880
 But yeah. I mean, I mean, in some sense, that, that is, you know, if there is a deep

54:58.880 --> 55:04.240
 philosophical question that's raised by GPT three, then that is it, right? Are we doing anything

55:04.240 --> 55:09.040
 other than, you know, this, this predictive processing, just trying to constantly trying

55:09.040 --> 55:14.160
 to fill in a blank of what would come next after what we just said up to this point?

55:14.160 --> 55:19.040
 Is that what I'm doing right now? It's impossible. So the, the intuition that

55:19.040 --> 55:24.000
 a lot of people have, well, look, this thing is not going to be able to reason the mountain Everest

55:24.000 --> 55:29.760
 question. Do you think it's possible that GPT five, six and seven would be able to,

55:29.760 --> 55:37.120
 with this exact same process, begin to look, do something that looks like is indistinguishable

55:37.120 --> 55:42.720
 to us humans from reasoning? I mean, the truth is that we don't really know what the limits are,

55:42.720 --> 55:48.480
 right? Because, because, you know, what we've seen so far is that, you know, GPT three was

55:48.480 --> 55:56.000
 basically the same thing as GPT two, but just with, you know, a much larger network, you know,

55:56.000 --> 56:03.280
 more training time, bigger training corpus, right? And it was, you know, very noticeably better,

56:03.280 --> 56:08.960
 right? Then it's immediate predecessor. So we, you know, we don't know where you hit the ceiling

56:08.960 --> 56:13.680
 here, right? I mean, that's the, that's the amazing part and maybe also the scary part,

56:13.680 --> 56:19.120
 right? That, you know, now my guess would be that, that, you know, at some point, like there has to

56:19.120 --> 56:25.840
 be diminishing returns, like it can't be that simple, can it? Right? Right? Well, I wish that I had

56:25.840 --> 56:30.800
 more to base that guess on. Right. Yeah. I mean, some people say that there would be a limitation

56:30.800 --> 56:36.000
 on the, we're going to hit a limit on the amount of data that's on the internet. Yes. Yeah. So,

56:36.000 --> 56:42.720
 so sure. So there's certainly that limit. I mean, there's also, you know, like if you are looking

56:42.720 --> 56:48.080
 for questions that will stump GPT three, right, you can come up with some without, you know, like,

56:48.080 --> 56:54.000
 you know, even getting it to learn how to balance parentheses, right? Like it can, you know, it

56:54.000 --> 57:00.880
 doesn't do such a great job, right? You know, like, like, you know, and, you know, and its failures are

57:00.880 --> 57:05.440
 ironic, right? Like, like basic arithmetic, right? And you think, and you think, you know,

57:05.440 --> 57:09.760
 isn't that what computers are supposed to be best at? Yeah. Isn't that where computers already had

57:09.760 --> 57:15.120
 us beat a century ago? Yeah. Right. And, you know, and yet that's where GPT three struggles, right?

57:15.120 --> 57:19.920
 But it's, it's amazing, you know, that it's almost like a young child in that way, right?

57:19.920 --> 57:28.480
 That, but, but somehow, you know, because it is just trying to predict what, what comes next,

57:28.480 --> 57:33.200
 it doesn't know when it should stop doing that and start doing something very different,

57:33.200 --> 57:41.280
 like some more exact logical reasoning, right? And so, so, you know, the, you know, one is naturally

57:41.280 --> 57:47.440
 led to guess that our brain sort of has some element of predictive processing, but that it's

57:47.440 --> 57:52.480
 coupled to other mechanisms, right? That it's coupled to, you know, first of all, visual reasoning,

57:52.480 --> 57:57.120
 which GPT three also doesn't have any of, right? Although there's some demonstration that there's

57:57.120 --> 58:02.480
 a lot of promise there. Oh yeah, it can complete images. That's right. And using exact same kind

58:02.480 --> 58:09.760
 of transformer mechanisms to like watch videos on YouTube. And so the same, the same self supervised

58:09.760 --> 58:14.240
 mechanism to be able to look, it'd be fascinating to think what kind of completions you could do.

58:14.240 --> 58:19.120
 Oh yeah, no, absolutely. Although like if we ask it to like, you know, a word problem that

58:19.120 --> 58:23.920
 involve reasoning about the locations of things in space, I don't think it does such a great job

58:23.920 --> 58:29.600
 on those, right? To take an example. And so, so the guess would be, well, you know, humans have a

58:29.600 --> 58:33.920
 lot of predictive processing, a lot of just filling in the blanks, but we also have these other

58:33.920 --> 58:39.760
 mechanisms that we can couple to, or that we can sort of call as subroutines when we need to.

58:39.760 --> 58:45.120
 And that maybe, maybe, you know, to go further that one would want to integrate other forms of

58:45.120 --> 58:53.840
 reasoning. Let me go on another topic that is amazing, which is complexity. What,

58:55.840 --> 59:00.560
 and then start with the most absurdly romantic question of what's the most beautiful idea in

59:00.560 --> 59:05.760
 computer science or theoretical computer science to you? Like what just early on in your life,

59:05.760 --> 59:10.240
 or in general, have captivated you and just grabbed you? I think I'm going to have to go with the

59:10.240 --> 59:18.880
 idea of universality. You know, if you're really asking for the most beautiful, I mean, so universality

59:18.880 --> 59:25.440
 is the idea that, you know, you put together a few simple operations, like in the case of

59:25.440 --> 59:31.120
 Boolean logic, that might be the AND gate, the OR gate, the NOT gate, right? And then your first

59:31.120 --> 59:37.360
 guess is, okay, this is a good start. But obviously, as I want to do more complicated things, I'm going

59:37.360 --> 59:43.120
 to need more complicated building blocks to express that, right? And that was actually my guess when

59:43.120 --> 59:48.560
 I first learned what programming was. I mean, when I was, you know, an adolescent and someone showed

59:48.560 --> 59:57.920
 me AppleBasic and, you know, GWBasic. If anyone listening remembers that. Okay, but, you know,

59:57.920 --> 1:00:03.600
 I thought, okay, well, now, you know, I mean, I thought I felt like this is a revelation, you

1:00:03.600 --> 1:00:08.000
 know, it's like finding out where babies come from. It's like that level of, you know, why didn't

1:00:08.000 --> 1:00:12.800
 anyone tell me this before, right? But I thought, okay, this is just the beginning. Now I know how

1:00:12.800 --> 1:00:18.640
 to write a basic program. But, you know, really write an interesting program, like, you know,

1:00:18.640 --> 1:00:24.320
 a video game, which had always been my dream as a kid to, you know, create my own Nintendo games,

1:00:24.320 --> 1:00:29.600
 right? But, you know, obviously, I'm going to need to learn some way more complicated form

1:00:29.600 --> 1:00:35.600
 of programming than that. Okay, but, you know, eventually I learned this incredible idea of

1:00:35.600 --> 1:00:42.400
 universality. And that says that, no, you throw in a few rules, and then you can, you already have

1:00:42.400 --> 1:00:49.280
 enough to express everything. Okay, so for example, the and, the or, and the not gate can all, or in

1:00:49.280 --> 1:00:55.280
 fact, even just the and and the not gate, or even just even just the NAND gate, for example, is

1:00:55.280 --> 1:01:00.480
 already enough to express any Boolean function on any number of bits, you just have to string

1:01:00.480 --> 1:01:04.080
 together enough of them. You can build the universe with NAND gates, you can build the

1:01:04.080 --> 1:01:10.320
 universe out of NAND gates. Yeah, you know, the the simple instructions of basic are already enough,

1:01:11.120 --> 1:01:16.560
 at least in principle, you know, if we ignore details like how much memory can be accessed

1:01:16.560 --> 1:01:21.760
 and stuff like that, that is enough to express what could be expressed by any programming language

1:01:21.760 --> 1:01:27.680
 whatsoever. And the way to prove that is very simple. We simply need to show that in basic,

1:01:27.680 --> 1:01:33.760
 or whatever, we could write a an interpreter or a compiler for whatever is other programming

1:01:33.760 --> 1:01:39.200
 language we care about, like C or Java or whatever. And as soon as we had done that,

1:01:39.200 --> 1:01:45.680
 then ipso facto, anything that's expressible in C or Java is also expressible in basic.

1:01:45.680 --> 1:01:54.000
 Okay, and so this idea of universality, you know, goes back at least to Alan Turing in the 1930s,

1:01:54.000 --> 1:02:01.360
 when, you know, he wrote down this incredibly simple paired down model of a computer,

1:02:01.360 --> 1:02:06.960
 the Turing machine, right, which, you know, he paired down the instruction set to just

1:02:06.960 --> 1:02:13.920
 read a symbol, you know, go right a symbol, move to the left, move to the right, halt,

1:02:13.920 --> 1:02:20.560
 change your internal state, right, that's it. Okay, and anybody proved that, you know,

1:02:20.560 --> 1:02:26.880
 this could simulate all kinds of other things, you know, and so, so in fact, today we would say,

1:02:26.880 --> 1:02:32.720
 well, we would call it a Turing universal model of computation, that is, you know, just as it

1:02:32.720 --> 1:02:40.880
 has just the same expressive power that basic or Java or C plus plus or any of those other languages

1:02:40.880 --> 1:02:47.200
 have, because anything in those other languages could be compiled down to Turing machine. Now,

1:02:47.200 --> 1:02:52.560
 Turing also proved a different related thing, which is that there is a single Turing machine

1:02:53.360 --> 1:03:01.120
 that can simulate any other Turing machine, if you just describe that other machine on its tape,

1:03:01.120 --> 1:03:06.720
 right, and likewise, there is a single Turing machine that will run any C program, you know,

1:03:06.720 --> 1:03:12.160
 if you just put it on its tape, that's a second meaning of universality. First of all,

1:03:12.160 --> 1:03:15.600
 that he couldn't visualize it, and that was in the 30s, I think. Yeah, the 30s, that's right.

1:03:15.600 --> 1:03:23.040
 That's before computers really, I mean, I don't know how, I wonder what that felt like,

1:03:24.480 --> 1:03:30.000
 you know, learning that there's no Santa Claus or something, because I don't know if that's

1:03:30.000 --> 1:03:36.720
 empowering or paralyzing, because it doesn't give you any, it's like, you can't write a

1:03:36.720 --> 1:03:40.400
 software engineering book and make that the first chapter and say we're done.

1:03:41.040 --> 1:03:46.080
 Well, I mean, I mean, right, I mean, in one sense, it was this enormous flattening of the

1:03:46.080 --> 1:03:51.920
 universe, right? I had imagined that there was going to be some infinite hierarchy of more and

1:03:51.920 --> 1:03:56.800
 more powerful programming languages, you know, and then I kicked myself for, you know, for having

1:03:56.800 --> 1:04:01.840
 such a stupid idea. But apparently, Girdle had had the same conjecture in the 30s. Oh, good.

1:04:01.840 --> 1:04:07.840
 You're in a good company. Well, you know, and then Girdle read Turing's paper,

1:04:07.840 --> 1:04:11.680
 and he kicked himself, and he said, yeah, I was completely wrong about that. Okay,

1:04:11.680 --> 1:04:17.760
 but you know, I had thought that maybe where I can contribute will be to invent a new,

1:04:17.760 --> 1:04:22.800
 more powerful programming language that lets you express things that could never be expressed in

1:04:22.800 --> 1:04:27.200
 basic, right? And, you know, and, you know, how would you do that? Obviously, you couldn't do it

1:04:27.200 --> 1:04:33.360
 itself in basic, right? But, but, you know, there is this incredible flattening that happens once

1:04:33.360 --> 1:04:41.200
 you learn what is universality. But then it's also like an opportunity, because it means once you

1:04:41.200 --> 1:04:48.000
 know these rules, then, you know, the sky is the limit, right? Then you have kind of the same weapons

1:04:48.000 --> 1:04:53.200
 at your disposal that the world's greatest programmer has. It's now all just a question of

1:04:53.200 --> 1:05:00.000
 how you wield them, right? Exactly. But so every problem is solvable, but some problems are harder

1:05:00.000 --> 1:05:05.760
 than others. And well, yeah, there's the question of how much time, you know, of how hard is it to

1:05:05.760 --> 1:05:11.200
 write a program. And then there's also the questions of what resources does the program need? You

1:05:11.200 --> 1:05:15.360
 know, how much time, how much memory, those are much more complicated questions, of course,

1:05:15.360 --> 1:05:19.760
 ones that we're still struggling with today. Exactly. So you've, I don't know if you created

1:05:19.760 --> 1:05:25.600
 complexity zoo or... I did create the complexity zoo. What is it? What's complexity? Oh, all right,

1:05:25.600 --> 1:05:31.680
 all right, all right. Complexity theory is the study of sort of the inherent resources needed

1:05:31.680 --> 1:05:40.080
 to solve computational problems. Okay, so it's easiest to give an example. Like, let's say we

1:05:40.080 --> 1:05:48.080
 want to add two numbers, right? If I want to add them, you know, if the numbers are twice as long,

1:05:48.080 --> 1:05:53.200
 then it only, it will take me twice as long to add them, but only twice as long, right? It's

1:05:53.200 --> 1:05:58.720
 no worse than that. Or a computer. For a computer or for a person, we're using pencil and paper for

1:05:58.720 --> 1:06:03.120
 that matter. If you have a good algorithm. Yeah, that's right. I mean, even if you just use the

1:06:03.120 --> 1:06:08.480
 elementary school algorithm of just carrying, you know, then it takes time that is linear

1:06:08.480 --> 1:06:13.360
 in the length of the numbers, right? Now, multiplication, if you use the elementary school

1:06:13.360 --> 1:06:19.680
 algorithm is harder because you have to multiply each digit of the first number by each digit of

1:06:19.680 --> 1:06:25.040
 the second one. Yeah, and then deal with all the carries. So that's what we call a quadratic time

1:06:25.040 --> 1:06:31.280
 algorithm, right? If the numbers become twice as long, now you need four times as much time.

1:06:31.280 --> 1:06:40.480
 Okay. So now as it turns out, we people discovered much faster ways to multiply numbers using

1:06:40.480 --> 1:06:47.520
 computers. And today we know how to multiply two numbers that are n digits long using a number

1:06:47.520 --> 1:06:52.880
 of steps that's nearly linear in it. These are questions you can ask. But now let's think about

1:06:52.880 --> 1:06:58.160
 a different thing that people, you know, even countered in elementary school of factoring a

1:06:58.160 --> 1:07:04.320
 number. Okay, take a number and find its prime factors, right? And here, you know, if I give

1:07:04.320 --> 1:07:10.400
 you a number with 10 digits, I ask you for its prime factors. Well, maybe it's even so you know

1:07:10.400 --> 1:07:15.680
 that two is a factor, you know, maybe it ends in zero. So you know that 10 is a factor, right?

1:07:15.680 --> 1:07:20.880
 But, you know, other than a few obvious things like that, you know, if the prime factors are all

1:07:20.880 --> 1:07:26.240
 very large, then it's not clear how you even get started, right? You know, you, it seems like you

1:07:26.240 --> 1:07:33.520
 have to do an exhaustive search among an enormous number of factors. Now, and as many people might

1:07:33.520 --> 1:07:41.360
 know, the for better or worse, the security, you know, of most of the encryption that we currently

1:07:41.360 --> 1:07:47.200
 use to protect the internet is based on the belief, and this is not a theorem, it's a belief

1:07:47.760 --> 1:07:55.280
 that factoring is an inherently hard problem for our computers. We do know algorithms that are

1:07:55.280 --> 1:08:02.000
 better than just trial division and just trying all the possible divisors, but they are still

1:08:02.000 --> 1:08:09.040
 basically exponential. And exponential is hard. Yeah, exactly. So the fastest algorithms that

1:08:09.040 --> 1:08:14.400
 anyone has discovered, at least publicly discovered, you know, I'm assuming that the NSA doesn't know

1:08:14.400 --> 1:08:20.800
 something better. Yeah. Okay, but they take time that basically grows exponentially with the cube

1:08:20.800 --> 1:08:26.320
 root of the size of the number that you're factoring, right? So that cube root, that's the part that

1:08:26.320 --> 1:08:31.120
 takes all the cleverness, okay, but there's still an exponential, there's still an exponentiality

1:08:31.120 --> 1:08:37.440
 there. But what that means is that like, when people use a thousand bit keys for their cryptography,

1:08:37.440 --> 1:08:42.800
 that can probably be broken using the resources of the NSA or the world's other intelligence

1:08:42.800 --> 1:08:47.600
 agencies, you know, people have done analyses that say, you know, with a few hundred million

1:08:47.600 --> 1:08:53.120
 dollars of computer power, they could totally do this. And if you look at the documents that Snowden

1:08:53.120 --> 1:08:59.360
 released, you know, it looks a lot like they are doing that or something like that, it would kind

1:08:59.360 --> 1:09:05.200
 of be surprising if they weren't. Okay, but, you know, if that's true, then in some ways,

1:09:05.200 --> 1:09:09.360
 that's reassuring, because if that's the best that they can do, then that would say that they

1:09:09.360 --> 1:09:16.000
 can't break 2000 bit numbers, right? Right, exactly. Right, then 2000 bit numbers would be beyond

1:09:16.000 --> 1:09:19.680
 what even they could do. They haven't found an efficient algorithm. That's where all the

1:09:19.680 --> 1:09:23.760
 worries and the concerns of quantum computing came in that there could be some kind of shortcut

1:09:23.760 --> 1:09:30.240
 around that. Right, so complexity theory is a, you know, is a huge part of, let's say, the

1:09:30.240 --> 1:09:37.680
 theoretical core of computer science. You know, it started in the 60s and 70s as, you know, sort of an,

1:09:37.680 --> 1:09:43.200
 you know, autonomous field. So it was, you know, already, you know, I mean, you know, it was well

1:09:43.200 --> 1:09:51.600
 developed even by the time that I was born. But I, in 2002, I made a website called the

1:09:51.600 --> 1:09:58.640
 complexity zoo to answer your question, where I just tried to catalog the different complexity

1:09:58.640 --> 1:10:04.240
 classes, which are classes of problems that are solvable with different kinds of resources.

1:10:04.240 --> 1:10:10.560
 Okay, so these are kind of, you know, you could think of complexity classes as like being almost

1:10:10.560 --> 1:10:16.400
 to theoretical computer science, like what the elements are to chemistry, right? They're sort

1:10:16.400 --> 1:10:24.000
 of, you know, there are our most basic objects in a certain way. I feel like the elements have

1:10:25.120 --> 1:10:30.160
 have a characteristic to them where you can't just add an infinite number. Well, you could,

1:10:30.160 --> 1:10:36.000
 but beyond a certain point, they become unstable. Right, right. So it's like, you know, in theory,

1:10:36.000 --> 1:10:40.800
 you can have atoms with, you know, and look, look, I mean, I mean, a neutron star, you know,

1:10:40.800 --> 1:10:48.800
 is a nucleus with, you know, uncalled billions of, of, of, of, of, of, of, of, of neutrons in it,

1:10:48.800 --> 1:10:55.600
 of, of hadrons in it. Okay, but, you know, for, for sort of normal atoms, right, probably you

1:10:55.600 --> 1:11:02.320
 can't get much above 100, you know, atomic weight, 150 or so, or sorry, sorry, I mean, I mean,

1:11:02.320 --> 1:11:08.880
 beyond 150 or so protons without it, you know, very quickly fissioning with complexity classes.

1:11:08.880 --> 1:11:14.480
 Well, yeah, you, you can have an infinity of complexity classes. But, you know, maybe there's

1:11:14.480 --> 1:11:19.600
 only a finite number of them that are particularly interesting, right? Just like with anything else,

1:11:19.600 --> 1:11:24.800
 you know, you, you care about some more than about others. So what kind of interesting classes are

1:11:24.800 --> 1:11:31.040
 there? You can have just maybe say, what are the, if you taking a kind of computer science class,

1:11:31.040 --> 1:11:36.400
 what are the classes you learn? Good. Let me, let me tell you sort of the, the, the biggest ones,

1:11:36.400 --> 1:11:41.840
 the ones that you would learn first. So, you know, first of all, there is P, that's what it's called.

1:11:41.840 --> 1:11:47.840
 Okay, it stands for polynomial time. And this is just the class of all of the problems that you

1:11:47.840 --> 1:11:55.120
 could solve with a conventional computer, like your iPhone or your laptop, you know, by a completely

1:11:55.120 --> 1:12:03.200
 deterministic algorithm, right? Using a number of steps that grows only like the size of the input

1:12:03.200 --> 1:12:10.000
 raised to some fixed power. Okay, so if your algorithm is linear time, like, you know, for

1:12:10.000 --> 1:12:16.240
 adding numbers, okay, that, that problem is in P. If you have an algorithm that's quadratic time,

1:12:16.240 --> 1:12:20.800
 like the elementary school algorithm for multiplying two numbers, that's also in P.

1:12:20.800 --> 1:12:26.400
 Even if it was the size of the input to the tenth power or to the fiftieth power, well,

1:12:26.400 --> 1:12:31.280
 that wouldn't be very good in practice. But, you know, formally, we would still count that,

1:12:31.280 --> 1:12:37.120
 that would still be in P. Okay, but if your algorithm takes exponential time, meaning,

1:12:37.120 --> 1:12:46.320
 like, if every time I add one more data point to your input, if the time needed by the algorithm

1:12:46.320 --> 1:12:53.520
 doubles, if you need time like two to the power of the amount of input data, then that is that we

1:12:53.520 --> 1:13:00.960
 call an exponential time algorithm. Okay, and that is not polynomial. Okay, so P is all of the problems

1:13:00.960 --> 1:13:07.200
 that have some polynomial time algorithm. Okay, so that includes most of what we do with our

1:13:07.200 --> 1:13:13.200
 computers on a day to day basis, you know, all the, you know, sorting basic arithmetic, you know,

1:13:13.200 --> 1:13:20.400
 whatever is going on in your email reader or in Angry Birds. Okay, it's all in P. Then the next

1:13:20.400 --> 1:13:27.680
 super important class is called NP. That stands for non deterministic polynomial. Okay, does not

1:13:27.680 --> 1:13:35.440
 stand for not polynomial, which is a common confusion. But NP was basically all of the problems

1:13:35.440 --> 1:13:41.920
 where if there is a solution, then it is easy to check the solution if someone shows it to you.

1:13:41.920 --> 1:13:49.600
 Okay, so actually a perfect example of a problem in NP is factoring, the one I told you about before.

1:13:49.600 --> 1:13:56.240
 Like, if I gave you a number with thousands of digits, and I told you that it, you know, I asked

1:13:56.240 --> 1:14:04.400
 you, does this, does this have at least three non trivial divisors? Right, that might be a super

1:14:04.400 --> 1:14:09.200
 hard problem to solve, right, might take you millions of years using any algorithm that's

1:14:09.200 --> 1:14:15.520
 known, at least running on our existing computers. Okay, but if I simply showed you the divisors,

1:14:15.520 --> 1:14:21.360
 I said, here are three divisors of this number, then it would be very easy for you to ask your

1:14:21.360 --> 1:14:27.520
 computer to just check each one and see if it works, just divide it in, see if there's any remainder.

1:14:27.520 --> 1:14:35.040
 Right, and if they all go in, then you've checked, well, I guess there were. Right, so any problem

1:14:35.040 --> 1:14:40.560
 where, you know, wherever there's a solution, there is a short witness that can be easily,

1:14:40.560 --> 1:14:47.280
 like a polynomial size witness that can be checked in polynomial time, that we call an NP

1:14:47.280 --> 1:14:55.120
 problem. Okay, and yeah, so every problem that's in P is also an NP, right, because, you know,

1:14:55.120 --> 1:14:59.440
 you could always just ignore the witness and just, you know, if a problem is in P, you can just solve

1:14:59.440 --> 1:15:06.080
 it yourself. Right. Okay, but now the, in terms of the central, you know, mystery of theoretical

1:15:06.080 --> 1:15:14.640
 computer science is every NP problem in P. So if you can easily check the answer to a computational

1:15:14.640 --> 1:15:19.360
 problem, does that mean that you can also easily find the answer? Even though there's all these

1:15:19.360 --> 1:15:25.120
 problems that appear to be very difficult to find the answer, it's still an open question whether

1:15:25.120 --> 1:15:29.760
 a good answer exists. So what's your... Because no one has proven that there's no way to do it.

1:15:29.760 --> 1:15:36.640
 It's arguably the most, I don't know, the most famous, the most maybe interesting,

1:15:36.640 --> 1:15:40.000
 maybe you disagree with that problem in theoretical computer science. So what's your...

1:15:40.000 --> 1:15:44.480
 The most famous, for sure. P equals NP. Yeah. If you were to bet all your money,

1:15:44.480 --> 1:15:48.800
 where do you put your money? That's an easy one. P is not equal to NP. Okay, so... I like to say

1:15:48.800 --> 1:15:52.800
 that if we were physicists, we would have just declared that to be a law of nature, you know,

1:15:52.800 --> 1:15:58.560
 just like thermodynamics. That's hilarious. Given ourselves Nobel prizes for its discovery. Yeah,

1:15:58.560 --> 1:16:02.720
 yeah, no one. Look, if later, if later it turned out that we were wrong, we just give ourselves

1:16:02.720 --> 1:16:08.160
 another Nobel Prize. More Nobel Prizes, yeah. I mean, you know, but yeah, because we're...

1:16:08.160 --> 1:16:14.000
 So harsh, but so true. I mean, no, I mean, I mean, it's really just because we are mathematicians

1:16:14.000 --> 1:16:19.760
 or descended from mathematicians, you know, we have to call things conjectures that other people

1:16:19.760 --> 1:16:24.960
 would just call empirical facts or discoveries, right? But one shouldn't read more into that

1:16:24.960 --> 1:16:29.920
 difference in language, you know, about the underlying truth. So, okay, so you're a good

1:16:29.920 --> 1:16:36.240
 investor and good spender of money. So then let me ask another way. Is it possible at all?

1:16:37.520 --> 1:16:43.680
 And what would that look like if P indeed equals NP? Well, I do think that it's possible. I mean,

1:16:43.680 --> 1:16:47.920
 in fact, you know, when people really pressed me on my blog for what odds would I put,

1:16:47.920 --> 1:16:56.000
 I put, you know, two or 3% odds that P equals NP. Yeah, just because, you know, when P... I mean,

1:16:56.000 --> 1:17:02.480
 I mean, you really have to think about like, if there were 50, you know, mysteries like P versus

1:17:02.480 --> 1:17:07.920
 NP, and if I made a guess about every single one of them, would I expect to be right 50 times?

1:17:07.920 --> 1:17:14.160
 Right. And the truthful answer is no. Okay. Yeah. So, you know, and that's what you really mean

1:17:14.160 --> 1:17:19.600
 in saying that, you know, you have, you know, better than 98% odds for something. Okay. But

1:17:20.960 --> 1:17:26.480
 so, so yeah, you know, I mean, there could certainly be surprises. And look, if P equals NP,

1:17:26.480 --> 1:17:31.600
 well, then there would be the further question of, you know, is the algorithm actually efficient

1:17:31.600 --> 1:17:37.200
 in practice? Right. I mean, Don Knuth, who I know that you've interviewed as well, right? He

1:17:38.000 --> 1:17:43.680
 likes to conjecture that P equals NP, but that the algorithm is so inefficient that it doesn't

1:17:43.680 --> 1:17:49.440
 matter anyway, right? No, I don't know. I've listened to him say that. I don't know whether he says

1:17:49.440 --> 1:17:54.400
 that just because he has an actual reason for thinking it's true or just because it sounds cool.

1:17:54.400 --> 1:18:00.160
 Yeah. Okay. But, you know, that's a logical possibility, right? That the algorithm could

1:18:00.160 --> 1:18:06.640
 be n to the 10,000 time, or it could even just be n squared time, but with a leading constant of

1:18:06.640 --> 1:18:10.800
 it could be a Google times n squared, or something like that. And in that case,

1:18:10.800 --> 1:18:18.160
 the fact that P equals NP, well, it would, you know, ravage the whole theory of complexity.

1:18:18.160 --> 1:18:22.560
 We would have to, you know, rebuild from the ground up. But in practical terms, it might

1:18:22.560 --> 1:18:29.120
 mean very little, right? If the algorithm was too inefficient to run. If the algorithm could

1:18:29.120 --> 1:18:35.680
 actually be run in practice, like if it had small enough constants, you know, or if you could improve

1:18:35.680 --> 1:18:41.200
 it to where it had small enough constants that was efficient in practice, then that would change

1:18:41.200 --> 1:18:45.600
 the world. Okay. You think it would have like, what kind of impact? Well, okay. I mean, here's

1:18:45.600 --> 1:18:51.520
 an example. I mean, you could, well, okay, just for starters, you could break basically all of

1:18:51.520 --> 1:18:56.160
 the encryption that people use to protect the Internet. You could break Bitcoin and every

1:18:56.160 --> 1:19:02.800
 other cryptocurrency, or, you know, mine as much Bitcoin as you wanted, right? You know, become a,

1:19:02.800 --> 1:19:09.040
 you know, become a super duper billionaire, right? And then, and then plot your next move.

1:19:09.040 --> 1:19:11.280
 Right. Okay. That's just for starters. That's a good point.

1:19:11.280 --> 1:19:16.960
 Now, your next move might be something like, you know, you now have like a theoretically

1:19:16.960 --> 1:19:22.240
 optimal way to train any neural network to find parameters for any neural network, right?

1:19:22.240 --> 1:19:27.840
 So you could now say, like, is there any small neural network that generates the entire content

1:19:27.840 --> 1:19:33.680
 of Wikipedia? Right? If, you know, and now the question is not, can you find it? The question

1:19:33.680 --> 1:19:39.360
 has been reduced to, does that exist or not? Yes. If it does exist, then the answer would be, yes,

1:19:39.360 --> 1:19:46.320
 you can find it. Okay. If you had this algorithm in your hands, okay? You could ask your computer,

1:19:46.320 --> 1:19:50.960
 you know, I mean, I mean, P versus NP is one of these seven problems that carries this million

1:19:50.960 --> 1:19:56.160
 dollar prize from the Clay Foundation. You know, if you solve it, you know, and others are the

1:19:56.160 --> 1:20:02.400
 Riemann hypothesis, the punk array conjecture, which was solved, although the solver turned down the

1:20:02.400 --> 1:20:07.680
 prize, right? And, and, and, and four others. But what I like to say, the way that we can see that

1:20:07.680 --> 1:20:14.080
 P versus NP is the biggest of all of these questions is that if you had this fast algorithm, then you

1:20:14.080 --> 1:20:19.200
 could solve all seven of them. Okay. You just ask your computer, you know, is there a short proof of

1:20:19.200 --> 1:20:23.840
 the Riemann hypothesis, right? You know, that, that a machine could, in a language where a machine

1:20:23.840 --> 1:20:29.120
 could verify it and provided that such a proof exists, then your computer finds it in a short

1:20:29.120 --> 1:20:33.600
 amount of time without having to do a brute force search. Okay. So I mean, I mean, those are the

1:20:33.600 --> 1:20:39.760
 stakes of what we're talking about. But I hope that also helps to give your listeners some intuition

1:20:39.760 --> 1:20:45.120
 of why I and most of my colleagues would put our money on P not equaling NP.

1:20:46.080 --> 1:20:50.400
 Is it possible? I apologize. This is a really dumb question, but is it possible to

1:20:50.400 --> 1:20:58.720
 that a proof will come out that P equals NP, but an algorithm that makes P equals NP

1:20:59.360 --> 1:21:05.840
 is impossible to find? Is that like crazy? Okay. Well, well, if P equals NP, it would mean that

1:21:05.840 --> 1:21:13.120
 there is such an algorithm that it exists. Yeah. But, um, um, you know, it would, it would mean

1:21:13.120 --> 1:21:18.240
 that it exists. Now, you know, in practice, normally the way that we would prove anything

1:21:18.240 --> 1:21:22.720
 like that would be by finding the algorithm by finding one algorithm. But there is such a thing

1:21:22.720 --> 1:21:28.560
 as a nonconstructive proof that an algorithm exists. You know, this is really only reared its head,

1:21:28.560 --> 1:21:34.560
 I think a few times in the history of our field, right? But, you know, it is, it is theoretically

1:21:34.560 --> 1:21:39.360
 possible that, that, that, that such a thing could happen. But, you know, there are some,

1:21:39.360 --> 1:21:44.480
 even here, there are some amusing observations that one could make. So there is this famous

1:21:44.480 --> 1:21:50.480
 observation of Leonid Levin, who is, you know, one of the original discoverers of NP completeness,

1:21:50.480 --> 1:21:56.000
 right? And he said, well, consider the following algorithm that like I guarantee

1:21:56.000 --> 1:22:02.720
 will solve the NP problems efficiently, just as provided that P equals NP. Okay. Here is what it

1:22:02.720 --> 1:22:10.080
 does. It just runs, you know, it enumerates every possible algorithm in a gigantic infinite list,

1:22:10.080 --> 1:22:14.960
 right? From like in like alphabetical order, right? You know, and many of them maybe won't

1:22:14.960 --> 1:22:20.720
 even compile. So we just ignore those. Okay. But now we just, you know, run the first algorithm,

1:22:20.720 --> 1:22:25.920
 then we run the second algorithm, we run the first one a little bit more, then we run the first three

1:22:25.920 --> 1:22:30.560
 algorithms for a while, we run the first four for a while. This is called dovetailing, by the way.

1:22:30.560 --> 1:22:37.840
 This is a known trick in theoretical computer science. Okay. But we do it in such a way that,

1:22:37.840 --> 1:22:44.720
 you know, whatever is the algorithm out there in our list that solves NP complete, you know,

1:22:44.720 --> 1:22:50.000
 the NP problems efficiently, we'll eventually hit that one, right? And now the key is that

1:22:50.000 --> 1:22:55.600
 whenever we hit that one, you know, it, you know, by assumption, it has to solve the problem,

1:22:55.600 --> 1:23:00.320
 has to find the solution. And once it claims to find the solution, then we can check that

1:23:00.320 --> 1:23:05.920
 ourselves, right? Because these are problems, then we can check it. Now this is utterly

1:23:05.920 --> 1:23:11.920
 impractical, right? You know, you'd have to do this enormous exhaustive search among all the

1:23:11.920 --> 1:23:17.680
 algorithms. But from a certain theoretical standpoint, that is merely a constant prefactor.

1:23:18.880 --> 1:23:23.680
 That's merely a multiplier of your running time. So there are tricks like that one can do to say

1:23:23.680 --> 1:23:30.480
 that in some sense, the algorithm would have to be constructive. But you know, in the human sense,

1:23:30.480 --> 1:23:35.280
 you know, it is possible that to, you know, it's conceivable that one could prove such a thing

1:23:35.920 --> 1:23:41.600
 via a non constructive method. Is that likely? I don't think so. Not personally.

1:23:41.600 --> 1:23:46.800
 So that's P and P, but the complexity is always full of wonderful creatures.

1:23:46.800 --> 1:23:53.760
 Well, it's got about 500 of them. 500. So how do you get, yeah, what? Yeah, how do you get more?

1:23:53.760 --> 1:24:00.240
 Yeah, well, okay, I mean, I mean, I mean, just for starters, there is everything that we could do

1:24:00.240 --> 1:24:07.040
 with a conventional computer with a polynomial amount of memory, okay, but possibly an exponential

1:24:07.040 --> 1:24:12.640
 amount of time, because we get to reuse the same memory over and over again. Okay, that is called

1:24:12.640 --> 1:24:20.720
 P space. Okay, and that's actually a, we think an even larger class than NP. Okay, well, P is

1:24:20.720 --> 1:24:26.640
 contained in NP, which is contained in P space. And we think that those containments are strict.

1:24:26.640 --> 1:24:32.400
 And the constraint there is on the memory, the memory has to grow with polynomially with the size

1:24:32.400 --> 1:24:36.880
 of the practice. That's right. That's right. But in P space, we now have interesting things that

1:24:36.880 --> 1:24:44.160
 we're not in NP, like as a famous example, you know, from a given position in chess, you know,

1:24:44.160 --> 1:24:49.760
 does white or black have the win? Let's say, assuming provided that the game lasts only for a

1:24:49.760 --> 1:24:56.400
 reasonable number of moves, okay, or likewise for go. Okay, and, you know, even for the generalizations

1:24:56.400 --> 1:25:01.040
 of these games to arbitrary size boards, because with an eight by eight board, you could say that's

1:25:01.040 --> 1:25:06.240
 just a constant size problem, you just, you know, in principle, you just solve it in O of one time,

1:25:06.240 --> 1:25:14.160
 right? But so we really mean the generalizations of, you know, games to arbitrary size boards here.

1:25:14.160 --> 1:25:21.920
 Or another thing in P space would be, like, I give you some really hard constraint satisfaction

1:25:21.920 --> 1:25:28.400
 problem, like, you know, you know, traveling salesperson or, you know, packing boxes into

1:25:28.400 --> 1:25:33.040
 the trunk of your car or something like that. And I ask, not just is there a solution, which

1:25:33.040 --> 1:25:38.640
 would be an NP problem, but I ask how many solutions are there? Okay, that, you know,

1:25:38.640 --> 1:25:45.440
 count the number of solution of valid solutions. That that that actually gives those problems

1:25:45.440 --> 1:25:51.840
 lie in a complexity class called sharp P, or like, it looks like hashtag, like hashtag P. Got it.

1:25:51.840 --> 1:25:58.720
 Okay, which sits between NP and P space. There's all the problems that you can do in exponential

1:25:58.720 --> 1:26:10.000
 time. Okay, that's called X. So, and by the way, it was proven in the 60s that X is larger than P.

1:26:10.000 --> 1:26:15.120
 Okay, so we know that much. We know that there are problems that are solvable in exponential

1:26:15.120 --> 1:26:21.040
 time that are not solvable in polynomial time. Okay. In fact, we even know more, we know that

1:26:21.040 --> 1:26:26.480
 there are problems that are solvable in n cube time that are not solvable in n squared time.

1:26:26.480 --> 1:26:29.840
 And that those don't help us with a controversy between P and NP.

1:26:29.840 --> 1:26:36.240
 Unfortunately, it seems not or certainly not yet. Right. The the the techniques that we use

1:26:36.240 --> 1:26:40.960
 to establish those things, they're very, very related to how touring proved the unsolvability

1:26:40.960 --> 1:26:46.640
 of the halting problem. But they seem to break down when we're comparing two different resources,

1:26:46.640 --> 1:26:53.040
 like time versus space, or like, you know, P versus NP. Okay, but, you know, I mean, there's

1:26:53.040 --> 1:26:57.680
 there's what you can do with a randomized algorithm, right, that can sometimes, you know,

1:26:57.680 --> 1:27:03.360
 with some has some probability of making a mistake. That's called BPP, bounded error

1:27:03.360 --> 1:27:08.720
 probabilistic polynomial time. And then of course, there's one that's very close to my own heart,

1:27:08.720 --> 1:27:14.480
 what you can efficiently do, do in polynomial time using a quantum computer. Okay, and that's

1:27:14.480 --> 1:27:21.680
 called BQP. Right. And so, you know, what's understood about that class. Okay, so P is

1:27:21.680 --> 1:27:28.880
 contained in BPP, which is contained in BQP, which is contained in P space. Okay. So anything you

1:27:28.880 --> 1:27:35.360
 can, in fact, in in like, in something very similar to sharp P, BQP is basically, you know,

1:27:35.360 --> 1:27:42.000
 well, it's contained in like P with the magic power to solve sharp P problems. Okay, so why is

1:27:42.000 --> 1:27:50.800
 BQP contained in P space? Oh, that's an excellent question. So there there is, well, I mean, one

1:27:50.800 --> 1:27:59.120
 has to prove that. Okay, but the proof you could you could think of it as using Richard Feynman's

1:27:59.120 --> 1:28:04.400
 picture of quantum mechanics, which is that you can always, you know, we haven't really talked about

1:28:04.400 --> 1:28:09.360
 quantum mechanics in this, in this conversation we, we did in our previous one. Yeah, we did last

1:28:09.360 --> 1:28:14.800
 time. But yeah, we did last time. Okay, but, but basically, you could always think of a quantum

1:28:14.800 --> 1:28:23.920
 computation as like a branching tree of possibilities, where each possible path that you could take

1:28:23.920 --> 1:28:30.080
 through, you know, your the space has a complex number attached to it called an amplitude. Okay,

1:28:30.080 --> 1:28:35.360
 and now the rule is, you know, when you make a measurement at the end, will you see a random

1:28:35.360 --> 1:28:40.960
 answer? Okay, but quantum mechanics is all about calculating the probability that you're going to

1:28:40.960 --> 1:28:48.000
 see one potential answer versus another one, right? And the rule for calculating the probability

1:28:48.000 --> 1:28:53.840
 that you'll see some answer is that you have to add up the amplitudes for all of the paths that

1:28:53.840 --> 1:29:00.000
 could have led to that answer. And then, you know, that's a complex number. So that, you know, how could

1:29:00.000 --> 1:29:05.040
 that be a probability, then you take the squared absolute value of the result that gives you a

1:29:05.040 --> 1:29:11.440
 number between zero and one. Okay, so I just, I just summarized quantum mechanics in like 30

1:29:11.440 --> 1:29:18.080
 seconds. Okay, but, but now, you know, what this already tells us is that anything I can do with

1:29:18.080 --> 1:29:23.840
 a quantum computer, I could simulate with a classical computer if I only have exponentially

1:29:23.840 --> 1:29:30.480
 more time. Okay, and why is that? Because if I have exponential time, I could just write down this

1:29:30.480 --> 1:29:36.960
 entire branching tree and just explicitly calculate each of these amplitudes, right? You know, that

1:29:36.960 --> 1:29:42.560
 will be very inefficient, but it will work, right? It's enough to show that quantum computers could

1:29:42.560 --> 1:29:48.800
 not solve the halting problem, or, you know, they could never do anything that is literally uncomputable

1:29:48.800 --> 1:29:55.680
 in Turing sense. Okay, but now, as I said, there's even a stronger result, which says that BQP is

1:29:55.680 --> 1:30:03.520
 contained in P space. The way that we prove that is that we say, if all I want is to calculate the

1:30:03.520 --> 1:30:08.800
 probability of some particular output happening, you know, which is all I need to simulate a

1:30:08.800 --> 1:30:13.920
 quantum computer, really, then I don't need to write down the entire quantum state, which is

1:30:13.920 --> 1:30:20.720
 an exponentially large object. All I need to do is just calculate what is the amplitude for that

1:30:20.720 --> 1:30:27.840
 final state. And to do that, I just have to sum up all the amplitudes that lead to that state.

1:30:27.840 --> 1:30:33.920
 Okay, so that's an exponentially large sum, but I can calculate it just reusing the same memory

1:30:33.920 --> 1:30:39.680
 over and over for each term in the sum. Hence the P in the P space. Hence the P space. Yeah.

1:30:39.680 --> 1:30:46.000
 So what, out of that whole complexity zoo, and it could be BQP, what do you find is the most,

1:30:48.160 --> 1:30:53.680
 the class that captured your heart the most? The most beautiful class, it's just, yeah.

1:30:53.680 --> 1:31:04.400
 I use, as my email address, bqpqpoly at gmail.com. Yes, because bqp slash qpoly, well, you know,

1:31:04.400 --> 1:31:11.040
 amazingly no one had taken it. Amazing. But, you know, but this is a class that I was involved in

1:31:11.040 --> 1:31:18.320
 sort of defining proving the first theorems about in 2003 or so. So it was kind of close to my heart.

1:31:18.320 --> 1:31:24.560
 But this is like, if we extended bqp, which is the class of everything we can do efficiently

1:31:24.560 --> 1:31:32.000
 with a quantum computer, to allow quantum advice, which means imagine that you had some special

1:31:32.000 --> 1:31:39.440
 initial state that could somehow help you do computation. And maybe such a state would be

1:31:39.440 --> 1:31:45.600
 exponentially hard to prepare. But, you know, maybe somehow these states were formed in the

1:31:45.600 --> 1:31:50.000
 Big Bang or something, and they've just been sitting around ever since, right? If you found one,

1:31:50.000 --> 1:31:56.240
 and if this state could be like ultra power, there are no limits on how powerful it could be,

1:31:56.240 --> 1:32:01.600
 except that this state doesn't know in advance which input you've got, right? It only knows the

1:32:01.600 --> 1:32:07.680
 size of your input, you know, and that that's bqp slash qpoly. So that's that's one that I just

1:32:07.680 --> 1:32:13.600
 personally happen to love, okay? But, you know, if you're asking like, what's the, you know,

1:32:13.600 --> 1:32:19.600
 there's a class that I think is way more beautiful than, you know, or fundamental

1:32:19.600 --> 1:32:26.320
 than a lot of people even within this field realize that it is. That class is called szk,

1:32:26.320 --> 1:32:32.400
 or statistical zero knowledge. And, you know, there's a very, very easy way to define this

1:32:32.400 --> 1:32:38.880
 class, which is to say, suppose that I have two algorithms that each sample from probability

1:32:38.880 --> 1:32:45.360
 distributions, right? So each one just outputs random samples according to, you know, possibly

1:32:45.360 --> 1:32:50.960
 different distributions. And now the question I ask is, you know, let's say distributions over

1:32:50.960 --> 1:32:57.760
 strings of n bits, you know, so over an exponentially large space. Now I ask, are these two distributions

1:32:57.760 --> 1:33:04.000
 close or far as probability distributions? Okay, any problem that can be reduced to that,

1:33:04.000 --> 1:33:10.320
 you know, that can be put into that form is an szk problem. And the way that this class was

1:33:10.320 --> 1:33:14.960
 originally discovered was completely different from that. And it was kind of more complicated.

1:33:14.960 --> 1:33:20.640
 It was discovered as the class of all of the problems that have a certain kind of what's

1:33:20.640 --> 1:33:27.040
 called zero knowledge proof. The zero knowledge proofs are one of the central ideas in cryptography.

1:33:27.680 --> 1:33:33.200
 You know, Shafi Goldwasser and Silvio McCauley won the Turing Award for, you know, inventing them.

1:33:33.200 --> 1:33:38.240
 And they're at the core of even some some cryptocurrencies that, you know, people people

1:33:38.240 --> 1:33:45.520
 use nowadays. But there are zero knowledge proofs or ways of proving to someone that something is

1:33:45.520 --> 1:33:53.280
 true, like, you know, that there is a solution to this, you know, optimization problem or that

1:33:53.280 --> 1:33:59.520
 these two graphs are isomorphic to each other or something. But without revealing why it's true,

1:33:59.520 --> 1:34:06.720
 without revealing anything about why it's true. Okay, szk is all of the problems for which there

1:34:06.720 --> 1:34:13.840
 is such a proof that doesn't rely on any cryptography. Okay. And if you wonder, like, how could such a

1:34:13.840 --> 1:34:21.040
 thing possibly exist, right? Well, I can imagine that I had two graphs, and I wanted to convince you

1:34:21.040 --> 1:34:26.560
 that these two graphs are not isomorphic, meaning, you know, I cannot permute one of them so that

1:34:26.560 --> 1:34:31.120
 it's the same as the other one, right? You know, that might be a very hard statement to prove,

1:34:31.120 --> 1:34:35.840
 right? I might need, you know, you might have to do a very exhaustive enumeration of, you know,

1:34:35.840 --> 1:34:40.320
 all the different permutations before you were convinced that it was true. But what if there

1:34:40.320 --> 1:34:45.920
 were some all knowing wizard that said to you, look, I'll tell you what, just pick one of the

1:34:45.920 --> 1:34:52.160
 graphs randomly, then randomly permute it, then send it to me, and I will tell you which graph

1:34:52.160 --> 1:34:59.280
 you started with. Okay, and I will do that every single time. Right? And let's load that in. Okay,

1:34:59.280 --> 1:35:04.880
 that's got it. I got it. And let's say that that wizard did that 100 times, and it was right every

1:35:04.880 --> 1:35:10.080
 time, right? Now, if the graphs were isomorphic, then, you know, it would have been flipping a coin

1:35:10.080 --> 1:35:15.600
 each time, right? It would have had only a one in two to the 100 power chance of, you know,

1:35:15.600 --> 1:35:20.640
 of guessing right each time. But, you know, so, so if it's right every time, then now you're

1:35:20.640 --> 1:35:25.760
 statistically convinced that these graphs are not isomorphic, even though you've learned nothing

1:35:25.760 --> 1:35:31.520
 new about why they aren't so fascinating. So yeah, so so SDK is all of the problems that have

1:35:31.520 --> 1:35:37.600
 protocols like that one. But it has this beautiful other characterization. It's shown up again and

1:35:37.600 --> 1:35:42.800
 again in my in my own work and you know, a lot of people's work. And I think that it really is one

1:35:42.800 --> 1:35:46.960
 of the most fundamental classes. It's just that people didn't realize that when it was first

1:35:46.960 --> 1:35:54.080
 discovered. So we're living in the middle of a pandemic currently. Yeah. How has your life

1:35:54.080 --> 1:35:59.520
 been changed? Or no, better to ask, like, how is your perspective of the world change with this

1:36:00.400 --> 1:36:05.200
 world changing event of a pandemic over taking the entire world? Yeah, well, I mean, I mean,

1:36:05.200 --> 1:36:11.200
 all of our lives have changed, you know, like, I guess, as with no other event since I was born,

1:36:11.200 --> 1:36:15.920
 you know, you would have to go back to World War Two for something I think of this magnitude,

1:36:15.920 --> 1:36:21.760
 you know, on, you know, the way that we live our lives. As for how it has changed my worldview,

1:36:22.320 --> 1:36:30.240
 I think that the the failure of institutions, you know, like, like, like the CDC, like, you know,

1:36:30.240 --> 1:36:35.520
 other institutions that we sort of thought were trustworthy, like a lot of the media

1:36:36.160 --> 1:36:43.200
 was staggering was was absolutely breathtaking. It is something that I would not have predicted.

1:36:43.200 --> 1:36:50.400
 Right. I think I wrote on my blog that, you know, you know, it's it's it's fascinating to, like,

1:36:50.400 --> 1:36:58.080
 rewatch the movie Contagion from a decade ago, right, that correctly foresaw so many aspects of,

1:36:58.080 --> 1:37:04.320
 you know, what was going on, you know, a an airborne, you know, virus originates in China,

1:37:04.320 --> 1:37:09.680
 spreads to, you know, much of the world, you know, shuts everything down until a vaccine can be

1:37:09.680 --> 1:37:15.200
 developed. You know, everyone has to stay at home, you know, you know, it gets, you know,

1:37:15.200 --> 1:37:20.320
 an enormous number of things right. Okay. But the one thing that they could not imagine,

1:37:20.320 --> 1:37:25.840
 you know, is that like in this movie, everyone from the government is like hyper competent,

1:37:25.840 --> 1:37:30.640
 hyper, you know, dedicated to the public good, right? And the best of the best, you know, yeah,

1:37:30.640 --> 1:37:35.200
 they're the best of the best, you know, they could, you know, and there are these conspiracy

1:37:35.200 --> 1:37:40.640
 theorists, right, who think, you know, you know, this is all fake news, there's no there's not

1:37:40.640 --> 1:37:45.520
 really a pandemic. And those are some random people on the internet, who are the hyper competent

1:37:45.520 --> 1:37:50.720
 government people have to, you know, oppose, right? They, you know, in trying to envision the

1:37:50.720 --> 1:37:55.920
 worst thing that could happen, like, you know, the the there was a failure of imagination,

1:37:55.920 --> 1:38:02.000
 the movie makers did not imagine that the conspiracy theorists and the, you know, and the

1:38:02.000 --> 1:38:07.600
 incompetence in the nutcases would have captured our institutions and be the ones actually running

1:38:07.600 --> 1:38:14.480
 things. So you had a certain I love competence in all walks of life. I love so much energy. I'm

1:38:14.480 --> 1:38:20.800
 so excited, but people do amazing job. And I like you. Well, maybe you can clarify, but I had maybe

1:38:20.800 --> 1:38:28.160
 not intuition, but I hope that government is best could be ultra competent. What, first of all,

1:38:28.160 --> 1:38:32.960
 two questions, like, how do you explain lack of confidence? And the other maybe on the positive

1:38:32.960 --> 1:38:39.680
 side, how can we build a more competent government? Well, there's an election in two months. I mean,

1:38:39.680 --> 1:38:45.120
 you know, you have a faith that the election, I, you know, it's not going to fix everything. But,

1:38:45.120 --> 1:38:49.200
 you know, it's like, I feel like there is a ship that is sinking, and you could at least stop the

1:38:49.200 --> 1:38:54.560
 sinking. But, you know, I think that there are there are much, much deeper problems. I mean,

1:38:54.560 --> 1:39:01.760
 I think that, you know, it is it is plausible to me that, you know, a lot of the the failures,

1:39:01.760 --> 1:39:07.120
 you know, with the CDC, with some of the other health agencies, even, you know, you know,

1:39:07.120 --> 1:39:13.040
 predate Trump, you know, predate the, you know, right wing populism that is sort of taken over

1:39:13.040 --> 1:39:21.280
 much of the world now. And, you know, I think that, you know, it was is, you know, it is very

1:39:21.280 --> 1:39:27.920
 I'm actually, you know, I've actually been strongly in favor of, you know, rushing vaccines of,

1:39:29.360 --> 1:39:34.080
 you know, I thought that we could have done, you know, human human challenge trials,

1:39:34.080 --> 1:39:39.120
 you know, which were not done, right, we could have, you know, like I had, you know, volunteers,

1:39:39.120 --> 1:39:46.240
 you know, to actually, you know, be, you know, get vaccines, get, you know, exposed to COVID.

1:39:46.240 --> 1:39:50.240
 So, you know, innovative ways of accelerating what we've done previously over a long

1:39:50.240 --> 1:39:55.200
 time. I thought that, you know, each, each month that you, that, that a vaccine is, is closer

1:39:55.200 --> 1:40:00.640
 is like trillions of dollars. Are you surprised? And of course, lives, you know, at least, you

1:40:00.640 --> 1:40:04.960
 know, hundreds of thousands of lives. Are you surprised that it's taking this long? We still

1:40:04.960 --> 1:40:09.440
 don't have a plan. They're still not a feeling like anyone is actually doing anything in terms of

1:40:10.880 --> 1:40:16.080
 alleviate like any kind of plan. So there's a bunch of stuff, this vaccine, but you could also do

1:40:16.080 --> 1:40:21.280
 a testing infrastructure where everybody's tested nonstop with contact tracing, all that kind of

1:40:21.280 --> 1:40:26.800
 stuff. Well, I mean, I'm as surprised as almost everyone else. I mean, this is a historic failure.

1:40:26.800 --> 1:40:33.360
 It is one of the biggest failures in the 240 year history of the United States, right? And we should

1:40:33.360 --> 1:40:38.960
 be, you know, crystal clear about that. And, you know, one thing that I think has been missing,

1:40:38.960 --> 1:40:45.840
 you know, even, even from the more competent side is like, you know, is sort of the, the World War II

1:40:45.840 --> 1:40:52.960
 mentality, right? The, you know, the mentality of, you know, let, let's just, you know, you know,

1:40:52.960 --> 1:40:59.120
 if, if, if we can, by breaking a whole bunch of rules, you know, get a vaccine and, you know,

1:40:59.120 --> 1:41:04.480
 and even half the amount of time as we thought, then let's just do that because, you know,

1:41:04.480 --> 1:41:10.480
 you, you know, like, like we have to, we have to weigh all of the moral qualms that we have about

1:41:10.480 --> 1:41:16.720
 doing that against the moral qualms of not doing. And one key little aspect of that, that's deeply

1:41:16.720 --> 1:41:22.960
 important to me and we'll go in that topic next is the World War II mentality wasn't just about,

1:41:22.960 --> 1:41:26.960
 you know, breaking all the rules to get the job done. There was a togetherness to it. There's,

1:41:26.960 --> 1:41:34.960
 so I would, if I were president right now, it seems quite elementary to unite the country

1:41:35.840 --> 1:41:41.840
 because we're facing a crisis. It's easy to make the virus the enemy. And it's very surprising to

1:41:41.840 --> 1:41:48.480
 me that the division, the division has increased as opposed to decreased. That's, that's hard

1:41:48.480 --> 1:41:52.400
 breaking. Yeah. Well, look, I mean, it's been said by others that this is the first time in the

1:41:52.400 --> 1:41:57.920
 country's history that we have a president who does not even pretend to, you know, want to unite

1:41:57.920 --> 1:42:03.840
 the country, right? Yeah. You know, I mean, I mean, Lincoln, who fought a civil war, you know,

1:42:04.400 --> 1:42:11.760
 you know, said he wanted to unite the country, right? You know, and, and I do, I do worry enormously

1:42:11.760 --> 1:42:17.920
 about what happens if the results of this election are contested, you know, and, you know, will there

1:42:17.920 --> 1:42:23.440
 be violence as a result of that? And will we have a clear path of succession? And, you know,

1:42:23.440 --> 1:42:27.840
 look, I mean, you know, this is all we're, we're going to find out the answers to this in two

1:42:27.840 --> 1:42:32.640
 months. And if none of that happens, maybe I'll look foolish, but I am willing to go on the record

1:42:32.640 --> 1:42:37.680
 and say, I am terrified about that. We have been reading the rise and fall, the third right.

1:42:39.360 --> 1:42:46.400
 So if I can, this, this is like one little voice just to put out there that I think November

1:42:46.400 --> 1:42:53.360
 will be a really critical month for people to breathe and put love out there. Do not,

1:42:53.920 --> 1:42:59.120
 you know, anger in those, in that context, no matter who wins, no matter what is said,

1:42:59.760 --> 1:43:04.960
 will destroy our country, may destroy our country, may destroy the world because of the power of

1:43:04.960 --> 1:43:10.640
 the country. So it's really important to be patient, loving, empathetic. Like one of the

1:43:10.640 --> 1:43:16.960
 things that it troubles me is that even people on the left are unable to have a love and respect

1:43:16.960 --> 1:43:21.840
 for people who voted for Trump. They can't imagine that there's good people that could vote for the

1:43:21.840 --> 1:43:26.320
 opposite side. And that's... Oh, I know there are, because I know some of them, right? I mean,

1:43:26.320 --> 1:43:31.840
 you know, it's still, you know, maybe it baffles me, but, you know, I know such people.

1:43:31.840 --> 1:43:37.120
 Let me ask you this. It's also heartbreaking to me on the topic of cancel culture. So in the

1:43:37.120 --> 1:43:44.800
 machine learning community, I've seen it a little bit, that there's aggressive attacking of people

1:43:44.800 --> 1:43:52.400
 who are trying to have a nuanced conversation about things. And it's troubling because it feels like

1:43:52.400 --> 1:43:58.240
 nuanced conversation is the only way to talk about difficult topics. And when there's a thought

1:43:58.240 --> 1:44:05.600
 police and speech police on any nuanced conversation that everybody has to, like in an animal farm,

1:44:05.600 --> 1:44:10.640
 chant that racism is bad and sexism is bad, which is things that everybody believes.

1:44:11.520 --> 1:44:17.520
 And they can't possibly say anything nuanced. It feels like it goes against any kind of progress

1:44:17.520 --> 1:44:22.560
 from my kind of shallow perspective. But you've written a little bit about cancel culture. Do

1:44:22.560 --> 1:44:28.000
 you have thoughts that are interesting to say about this? Well, I mean, to say that I am opposed to,

1:44:28.000 --> 1:44:34.640
 you know, this trend of cancellations or of, you know, shouting people down rather than engaging

1:44:34.640 --> 1:44:40.320
 them, that would be a massive understatement, right? And I feel like, you know, I have put my

1:44:40.320 --> 1:44:46.160
 money where my mouth is, you know, not as much as some people have, but, you know, I've tried to do

1:44:46.160 --> 1:44:52.240
 something. I mean, I have defended, you know, some unpopular people and unpopular, you know,

1:44:52.240 --> 1:45:02.160
 ideas on my blog. I've, you know, tried to defend, you know, norms of open discourse, of, you know,

1:45:02.160 --> 1:45:07.760
 reasoning with our opponents, even when I've been shouted down for that on social media,

1:45:07.760 --> 1:45:12.160
 you know, called a racist, called a sexist, all of those things. And which, by the way, I should

1:45:12.160 --> 1:45:17.040
 say, you know, I would be perfectly happy to, you know, say, you know, if we had time to say,

1:45:17.040 --> 1:45:24.880
 you know, you know, 10,000 times, you know, my hatred of racism, of sexism, of homophobia,

1:45:24.880 --> 1:45:32.800
 right? But what I don't want to do is to cede to some particular political faction the right to

1:45:32.800 --> 1:45:38.720
 define exactly what is meant by those terms to say, well, then you have to agree with all of these

1:45:38.720 --> 1:45:45.440
 other extremely contentious positions, or else you are a misogynist, or else you are a racist,

1:45:45.440 --> 1:45:52.560
 right? I say that, well, no, you know, you know, don't like, don't I or, you know, don't people

1:45:52.560 --> 1:45:58.320
 like me also get a say in the discussion about, you know, what is racism, about what is going to

1:45:58.320 --> 1:46:05.840
 be the most effective to combat racism, right? And, you know, this cancellation mentality,

1:46:05.840 --> 1:46:12.400
 I think, is spectacularly ineffective at its own professed goal of, you know, combating racism and

1:46:12.400 --> 1:46:19.440
 sexism. What's a positive way out? So I try to, I don't know if you see what I do on Twitter,

1:46:19.440 --> 1:46:25.520
 but on Twitter, I mostly, in my whole, in my life, I've actually, it's who I am to the core,

1:46:25.520 --> 1:46:31.440
 is like, I really focus on the positive, and I try to put love out there in the world. And still,

1:46:32.720 --> 1:46:38.880
 I get attacked. And I look at that and I wonder like, you too, I didn't know, like, I haven't

1:46:38.880 --> 1:46:44.960
 actually said anything difficult and nuanced. You talk about somebody like Steven Pinker,

1:46:44.960 --> 1:46:52.320
 who I actually don't know the full range of things that that he's attacked for, but he tries to say

1:46:52.320 --> 1:46:57.440
 difficult, he tries to be thoughtful about difficult topics. He does. And obviously he

1:46:57.440 --> 1:47:04.880
 just gets slaughtered by, well, I mean, I mean, I mean, I mean, yes, but it's also amazing how well

1:47:04.880 --> 1:47:10.080
 Steve has withstood it. I mean, he just survived an attempt to cancel him just a couple of months

1:47:10.080 --> 1:47:15.360
 ago, right? Psychologically, he survives it too, which worries me because I don't think I can.

1:47:15.360 --> 1:47:20.000
 Yeah, I've gotten to know Steve a bit. He is incredibly unperturbed by this stuff.

1:47:20.960 --> 1:47:26.400
 And I admire that and I envy it. I wish that I could be like that. I mean, my impulse when I'm

1:47:26.400 --> 1:47:32.960
 getting attacked is I just want to engage every single, like, anonymous person on Twitter and Reddit

1:47:32.960 --> 1:47:38.000
 who is saying mean stuff about me. And I want to say, well, look, can we just talk this over for

1:47:38.000 --> 1:47:42.720
 an hour? And then, you know, you'll see that I'm not that bad. And, you know, sometimes that even

1:47:42.720 --> 1:47:48.960
 works. The problem is then there's the, you know, the 20,000 other ones, right? And that's not, but

1:47:48.960 --> 1:47:54.320
 psychologically, does that wear on you? It does. It does. But yeah, I mean, in terms of what is the

1:47:54.320 --> 1:47:59.520
 solution, I mean, I wish I knew, right? And so, you know, in a certain way, these problems are

1:47:59.520 --> 1:48:07.200
 maybe harder than P versus NP, right? I mean, you know, but I think that part of it has to be for,

1:48:07.200 --> 1:48:13.600
 you know, that I think that there's a lot of sort of silent support for what I'll call the open

1:48:13.600 --> 1:48:19.280
 discourse side, the, you know, reasonable enlightenment side. And I think that that support

1:48:19.280 --> 1:48:25.840
 has to become less silent, right? I think that a lot of people, they sort of, you know, like agree

1:48:25.840 --> 1:48:32.400
 that a lot of these cancellations and attacks are ridiculous, but are just afraid to say so,

1:48:32.400 --> 1:48:38.000
 right? Or else they'll get shouted down as well, right? That's just the standard witch hunt dynamic,

1:48:38.000 --> 1:48:43.040
 which, you know, of course, this, you know, this faction understands and exploits to its great

1:48:43.040 --> 1:48:49.600
 advantage. But, you know, more people just, you know, said, you know, like, we're not going to

1:48:49.600 --> 1:48:56.720
 stand for this, right? You know, this is, you know, guess what? We're against racism, too. But,

1:48:56.720 --> 1:49:02.080
 you know, this, you know, what you're doing is ridiculous, right? You know, and the hard part is,

1:49:02.080 --> 1:49:07.120
 like, it takes a lot of mental energy. It takes a lot of time, you know, even if you feel like

1:49:07.120 --> 1:49:11.760
 you're not going to be canceled or, you know, you're staying on the safe side, like, it takes a lot

1:49:11.760 --> 1:49:18.720
 of time to, to, to phrase things in exactly the right way and to, you know, respond to everything

1:49:18.720 --> 1:49:25.360
 people say. So, but I think that, you know, the more people speak up than, you know, from, from,

1:49:25.360 --> 1:49:30.640
 from all political persuasions, you know, from like all, you know, walks of life, then, you know,

1:49:30.640 --> 1:49:38.160
 the easier it is to move forward. Since we've been talking about love, can you, last time I

1:49:38.160 --> 1:49:43.840
 talked to you about the meaning of life a little bit, but here has, it's a weird question to ask

1:49:43.840 --> 1:49:51.520
 a computer scientist, but has love for other human beings, for, for things, for the world around you

1:49:51.520 --> 1:49:59.440
 played an important role in your life? Have you, you know, it's easy for a world class

1:49:59.440 --> 1:50:06.160
 computer scientist, you could even call yourself like a physicist, everything to be lost in the

1:50:06.160 --> 1:50:11.040
 books. Is the connection to other humans, love for other humans played an important role?

1:50:11.040 --> 1:50:23.280
 Well, I love my kids. I love my wife. I love my parents. You know, I am probably not, not

1:50:23.280 --> 1:50:28.880
 different from most people in loving their families. And, and in that being very important

1:50:29.600 --> 1:50:36.320
 in my life. Now, I should remind you that, you know, I am a theoretical computer scientist.

1:50:36.320 --> 1:50:40.640
 If you're looking for deep insight about the nature of love, you're probably looking in the

1:50:40.640 --> 1:50:48.000
 wrong place to ask me, but, but sure, it's been important. But is it, is there something from

1:50:48.000 --> 1:50:53.600
 a computer science perspective to be said about love? Is there, or is that, is that even beyond

1:50:53.600 --> 1:50:57.760
 into the realm of, beyond the realm of consciousness and all that? There was, there was this great

1:50:58.960 --> 1:51:05.120
 cartoon. I think it was one of the classic XKCDs where it's, it shows like a heart and it's like,

1:51:05.120 --> 1:51:10.720
 you know, squaring the heart, taking the four year transform of the heart, you know, integrating the

1:51:10.720 --> 1:51:16.640
 heart, you know, you know, each, each thing. And then it says, you know, my normal approach is useless

1:51:16.640 --> 1:51:23.920
 here. I'm so glad I asked this question. I think there's no better way to, to end this. I hope we

1:51:23.920 --> 1:51:28.160
 get a chance to talk again. This is an amazing, cool experiment to do it outside. And I'm really

1:51:28.160 --> 1:51:32.480
 glad you made it out. Yeah. Well, I appreciate it a lot. It's been a pleasure. And I'm glad you

1:51:32.480 --> 1:51:37.600
 were able to come out to Austin. Thanks. Thanks for listening to this conversation with Scott

1:51:37.600 --> 1:51:46.080
 Aronson. And thank you to our sponsors, Aidsleep, SimplySafe, ExpressVPN, and BetterHelp. Please

1:51:46.080 --> 1:51:51.600
 check out these sponsors in the description to get a discount and to support this podcast.

1:51:52.560 --> 1:51:57.200
 If you enjoy this thing, subscribe on YouTube, review it with five stars and up a podcast,

1:51:57.200 --> 1:52:02.800
 follow on Spotify, support on Patreon, or connect with me on Twitter at Lex Freedman.

1:52:03.600 --> 1:52:08.320
 And now let me leave you with some words from Scott Aronson that I also gave to you in the

1:52:08.320 --> 1:52:15.760
 introduction, which is if you always win, then you're probably doing something wrong. Thank you

1:52:15.760 --> 1:52:21.600
 for listening and for putting up with the intro and outro in this strange room in the middle of

1:52:21.600 --> 1:52:27.600
 nowhere. And I very much hope to see you next time in many more ways than one.

