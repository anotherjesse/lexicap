WEBVTT

00:00.000 --> 00:02.960
 The following is a conversation with Rohit Prasad.

00:02.960 --> 00:06.360
 He's the vice president and head scientist of Amazon Alexa

00:06.360 --> 00:08.880
 and one of its original creators.

00:08.880 --> 00:12.120
 The Alexa team embodies some of the most challenging,

00:12.120 --> 00:14.960
 incredible, impactful, and inspiring work

00:14.960 --> 00:17.040
 that is done in AI today.

00:17.040 --> 00:19.120
 The team has to both solve problems

00:19.120 --> 00:21.720
 at the cutting edge of natural language processing

00:21.720 --> 00:24.040
 and provide a trustworthy, secure,

00:24.040 --> 00:27.440
 and enjoyable experience to millions of people.

00:27.440 --> 00:29.400
 This is where state of the art methods

00:29.400 --> 00:31.800
 in computer science meet the challenges

00:31.800 --> 00:33.680
 of real world engineering.

00:33.680 --> 00:37.280
 In many ways, Alexa and the other voice assistants

00:37.280 --> 00:39.480
 are the voices of artificial intelligence

00:39.480 --> 00:43.120
 to millions of people and an introduction to AI

00:43.120 --> 00:46.920
 for people who have only encountered it in science fiction.

00:46.920 --> 00:49.920
 This is an important and exciting opportunity.

00:49.920 --> 00:52.880
 And so the work that Rohit and the Alexa team are doing

00:52.880 --> 00:55.920
 is an inspiration to me and to many researchers

00:55.920 --> 00:58.800
 and engineers in the AI community.

00:58.800 --> 01:01.880
 This is the Artificial Intelligence Podcast.

01:01.880 --> 01:04.360
 If you enjoy it, subscribe on YouTube,

01:04.360 --> 01:06.320
 give it five stars on Apple Podcasts,

01:06.320 --> 01:07.680
 support it on Patreon,

01:07.680 --> 01:09.760
 or simply connect with me on Twitter.

01:09.760 --> 01:13.640
 Alex Friedman spelled F R I D M A N.

01:13.640 --> 01:16.880
 If you leave a review on Apple Podcasts especially,

01:16.880 --> 01:19.960
 but also Cast Box or comment on YouTube,

01:19.960 --> 01:23.560
 consider mentioning topics, people, ideas, questions, quotes,

01:23.560 --> 01:26.320
 and science, tech, or philosophy that you find interesting.

01:26.320 --> 01:28.840
 And I'll read them on this podcast.

01:28.840 --> 01:31.680
 I won't call out names, but I love comments

01:31.680 --> 01:33.280
 with kindness and thoughtfulness in them,

01:33.280 --> 01:35.760
 so I thought I'd share them.

01:35.760 --> 01:37.520
 Someone on YouTube highlighted a quote

01:37.520 --> 01:40.320
 from the conversation with Ray Dalio,

01:40.320 --> 01:42.000
 where he said that you have to appreciate

01:42.000 --> 01:45.320
 all the different ways that people can be AI players.

01:45.320 --> 01:47.040
 This connected with me too.

01:47.040 --> 01:49.280
 On teams of engineers, it's easy to think

01:49.280 --> 01:52.000
 that raw productivity is the measure of excellence,

01:52.000 --> 01:53.480
 but there are others.

01:53.480 --> 01:55.800
 I worked with people who brought a smile to my face

01:55.800 --> 01:57.960
 every time I got to work in the morning.

01:57.960 --> 02:01.280
 Their contribution to the team is immeasurable.

02:01.280 --> 02:03.080
 I recently started doing podcast ads

02:03.080 --> 02:04.720
 at the end of the introduction.

02:04.720 --> 02:07.680
 I'll do one or two minutes after introducing the episode,

02:07.680 --> 02:09.200
 and never any ads in the middle

02:09.200 --> 02:11.560
 that break the flow of the conversation.

02:11.560 --> 02:13.040
 I hope that works for you.

02:13.040 --> 02:15.720
 It doesn't hurt the listening experience.

02:15.720 --> 02:17.880
 This show is presented by Cash App,

02:17.880 --> 02:20.400
 the number one finance app in the App Store.

02:20.400 --> 02:23.040
 I personally use Cash App to send money to friends,

02:23.040 --> 02:24.760
 but you can also use it to buy, sell,

02:24.760 --> 02:27.200
 and deposit Bitcoin in just seconds.

02:27.200 --> 02:30.400
 Cash App also has a new investing feature.

02:30.400 --> 02:33.680
 You can buy fractions of a stock, save $1 worth,

02:33.680 --> 02:35.840
 no matter what the stock price is.

02:35.840 --> 02:38.720
 Brokerage services are provided by Cash App Investing,

02:38.720 --> 02:42.480
 a subsidiary of Square and Member SIPC.

02:42.480 --> 02:44.480
 I'm excited to be working with Cash App

02:44.480 --> 02:47.600
 to support one of my favorite organizations called First,

02:47.600 --> 02:50.960
 best known for their first robotics and Lego competitions.

02:50.960 --> 02:54.400
 They educate and inspire hundreds of thousands of students

02:54.400 --> 02:56.280
 in over 110 countries,

02:56.280 --> 02:58.880
 and have a perfect rating on Charity Navigator,

02:58.880 --> 03:00.960
 which means the donated money is used

03:00.960 --> 03:03.480
 to maximum effectiveness.

03:03.480 --> 03:06.440
 When you get Cash App from the App Store, Google Play,

03:06.440 --> 03:10.280
 and use code LEX Podcast, you'll get $10,

03:10.280 --> 03:13.280
 and Cash App will also donate $10 to First,

03:13.280 --> 03:15.160
 which again is an organization

03:15.160 --> 03:18.200
 that I've personally seen inspire girls and boys

03:18.200 --> 03:20.760
 to dream of engineering a better world.

03:20.760 --> 03:24.240
 This podcast is also supported by ZipRecruiter.

03:24.240 --> 03:26.240
 Hiring great people is hard,

03:26.240 --> 03:28.960
 and to me is one of the most important elements

03:28.960 --> 03:31.440
 of a successful mission driven team.

03:31.440 --> 03:33.480
 I've been fortunate to be a part of

03:33.480 --> 03:36.000
 and lead several great engineering teams.

03:36.000 --> 03:37.680
 The hiring I've done in the past

03:37.680 --> 03:40.560
 was mostly through tools we built ourselves,

03:40.560 --> 03:42.800
 but reinventing the wheel was painful.

03:42.800 --> 03:45.960
 ZipRecruiter is a tool that's already available for you.

03:45.960 --> 03:49.400
 It seeks to make hiring simple, fast, and smart.

03:49.400 --> 03:52.760
 For example, codable cofounder Gretchen Hebner

03:52.760 --> 03:55.200
 used ZipRecruiter to find a new game artist

03:55.200 --> 03:57.440
 to join our education tech company.

03:57.440 --> 03:59.600
 By using ZipRecruiter's screening questions

03:59.600 --> 04:00.880
 to filter candidates,

04:00.880 --> 04:03.840
 Gretchen found it easier to focus on the best candidates

04:03.840 --> 04:06.800
 and finally hiring the perfect person for the role

04:06.800 --> 04:10.040
 in less than two weeks from start to finish.

04:10.040 --> 04:13.040
 ZipRecruiter, the smartest way to hire.

04:13.040 --> 04:17.040
 CY ZipRecruiter is effective for businesses of all sizes

04:17.040 --> 04:21.080
 by signing up, as I did, for free at ziprecruiter.com

04:21.080 --> 04:26.080
 slash lexpod, that's ziprecruiter.com slash lexpod.

04:27.800 --> 04:31.800
 And now, here's my conversation with Rohit Prasad.

04:33.040 --> 04:36.280
 In the movie, Her, I'm not sure if you've ever seen her.

04:36.280 --> 04:39.880
 Human falls in love with the voice of an AI system.

04:39.880 --> 04:42.120
 Let's start at the highest philosophical level

04:42.120 --> 04:45.200
 before we get to deep learning and some of the fun things.

04:45.200 --> 04:48.160
 Do you think this, what the movie, Her, shows,

04:48.160 --> 04:49.360
 is within our reach?

04:50.800 --> 04:54.240
 I think, not specifically about her,

04:54.240 --> 04:58.760
 but I think what we are seeing is a massive increase

04:58.760 --> 05:02.200
 in adoption of AI assistance or AI

05:02.200 --> 05:05.200
 and all parts of our social fabric.

05:05.200 --> 05:08.560
 And I think it's, what I do believe

05:08.560 --> 05:11.560
 is that the utility these AIs provide

05:12.560 --> 05:14.000
 some of the functionality

05:14.000 --> 05:16.920
 some of the functionalities that are shown

05:16.920 --> 05:18.800
 are absolutely within reach.

05:20.480 --> 05:22.200
 So some of the functionality in terms

05:22.200 --> 05:24.000
 of the interactive elements,

05:24.000 --> 05:27.040
 but in terms of the deep connection,

05:27.040 --> 05:29.160
 that's purely voice based.

05:29.160 --> 05:31.560
 Do you think such a close connection is possible

05:31.560 --> 05:33.000
 with voice alone?

05:33.000 --> 05:34.640
 It's been a while since I saw Her,

05:34.640 --> 05:36.600
 but I would say in terms of the,

05:37.680 --> 05:40.480
 in terms of interactions which are both human like

05:40.480 --> 05:44.280
 and in these AI assistance, you have to value

05:44.280 --> 05:45.840
 what is also superhuman.

05:46.720 --> 05:49.640
 We as humans can be in only one place.

05:49.640 --> 05:53.160
 AI assistance can be in multiple places at the same time.

05:53.160 --> 05:55.600
 One with you on your mobile device,

05:55.600 --> 05:58.280
 one at your home, one at work.

05:58.280 --> 06:01.240
 So you have to respect these superhuman capabilities too.

06:02.200 --> 06:05.000
 Plus as humans, we have certain attributes

06:05.000 --> 06:07.000
 we're very good at, very good at reasoning.

06:07.000 --> 06:09.200
 AI assistance not yet there,

06:09.200 --> 06:11.920
 but in the realm of AI assistance,

06:11.920 --> 06:14.360
 what they're great at is computation, memory.

06:14.360 --> 06:16.240
 It's infinite and pure.

06:16.240 --> 06:18.040
 These are the attributes you have to start respecting.

06:18.040 --> 06:19.960
 So I think the comparison with human like

06:19.960 --> 06:21.880
 versus the other aspect,

06:21.880 --> 06:23.080
 which is also superhuman,

06:23.080 --> 06:24.520
 has to be taken into consideration.

06:24.520 --> 06:27.040
 So I think we need to elevate the discussion

06:27.040 --> 06:28.840
 to not just human like.

06:28.840 --> 06:32.080
 So there's certainly elements we just mentioned.

06:32.080 --> 06:35.560
 Alex is everywhere, computation is speaking.

06:35.560 --> 06:37.320
 So this is a much bigger infrastructure

06:37.320 --> 06:38.760
 than just the thing that sits there

06:38.760 --> 06:40.240
 in the room with you.

06:40.240 --> 06:44.840
 But it certainly feels to us mere humans

06:44.840 --> 06:49.280
 that there's just another little creature there

06:49.280 --> 06:50.240
 when you're interacting with it.

06:50.240 --> 06:51.720
 You're not interacting with the entirety

06:51.720 --> 06:54.160
 of the infrastructure, you're interacting with the device.

06:54.160 --> 06:58.400
 The feeling is, okay, sure, we anthropomorphize things,

06:58.400 --> 07:00.520
 but that feeling is still there.

07:00.520 --> 07:03.920
 So what do you think we as humans,

07:03.920 --> 07:06.960
 the purity of the interaction with a smart assistant,

07:06.960 --> 07:08.480
 what do you think we look for?

07:08.480 --> 07:10.240
 And in that interaction?

07:10.240 --> 07:12.280
 I think in the certain interactions,

07:12.280 --> 07:15.960
 I think we'll be very much where it does feel like a human

07:15.960 --> 07:18.200
 because it has a person of its own.

07:19.120 --> 07:20.680
 And in certain ones, it wouldn't be.

07:20.680 --> 07:23.280
 So I think a simple example to think of it is

07:23.280 --> 07:25.240
 if you're walking through the house

07:25.240 --> 07:28.000
 and you just wanna turn on your lights on and off

07:28.000 --> 07:29.880
 and you're issuing a command,

07:29.880 --> 07:32.080
 that's not very much like a human like interaction.

07:32.080 --> 07:33.880
 And that's where the AI shouldn't come back

07:33.880 --> 07:35.280
 and have a conversation with you.

07:35.280 --> 07:38.120
 Just it should simply complete that command.

07:38.120 --> 07:40.080
 So I think the blend of,

07:40.080 --> 07:43.160
 we have to think about this is not human, human alone.

07:43.160 --> 07:44.960
 It is a human machine interaction

07:44.960 --> 07:48.040
 and certain aspects of humans are needed

07:48.040 --> 07:49.800
 and certain aspects and situations

07:49.800 --> 07:51.520
 demanded to be like a machine.

07:51.520 --> 07:54.920
 So I told you, it's gonna be full soft code in parts.

07:54.920 --> 07:57.320
 What's the difference between human and machine

07:57.320 --> 07:58.520
 in that interaction?

07:58.520 --> 08:00.640
 When we interact to humans,

08:00.640 --> 08:03.880
 especially those who are friends and loved ones

08:03.880 --> 08:08.880
 versus you and a machine that you also are close with.

08:10.240 --> 08:13.640
 I think you have to think about the roles the AI plays, right?

08:13.640 --> 08:16.120
 So, and it differs from different customer to customer,

08:16.120 --> 08:17.880
 different situation to situation,

08:19.080 --> 08:21.400
 especially I can speak from Alexa's perspective.

08:21.400 --> 08:25.880
 It is a companion, a friend at times, an assistant

08:25.880 --> 08:27.360
 and an advisor down the line.

08:27.360 --> 08:31.080
 So I think most AI's will have this kind of attributes

08:31.080 --> 08:32.880
 and it will be very situational in nature.

08:32.880 --> 08:34.480
 So where is the boundary?

08:34.480 --> 08:36.920
 I think the boundary depends on exact context

08:36.920 --> 08:39.120
 in which you're interacting with the AI.

08:39.120 --> 08:42.760
 So the depth and the richness of natural language conversation

08:42.760 --> 08:45.680
 has been, by Alan Turing,

08:45.680 --> 08:50.320
 been used to try to define what it means to be intelligent.

08:50.320 --> 08:52.120
 There's a lot of criticism of that kind of test,

08:52.120 --> 08:55.680
 but what do you think is a good test of intelligence

08:55.680 --> 08:58.200
 in your view in the context of the Turing test?

08:58.200 --> 09:03.040
 And Alexa, with the Alexa prize, this whole realm,

09:03.040 --> 09:07.000
 do you think about this human intelligence,

09:07.000 --> 09:08.000
 what it means to define it,

09:08.000 --> 09:09.920
 what it means to reach that level?

09:09.920 --> 09:12.320
 I do think the ability to converse

09:12.320 --> 09:15.000
 is a sign of an ultimate intelligence.

09:15.000 --> 09:17.360
 I think that there's no question about it.

09:18.200 --> 09:20.400
 So if you think about all aspects of humans,

09:20.400 --> 09:22.680
 there are sensors we have

09:22.680 --> 09:26.240
 and those are basically a data collection mechanism.

09:26.240 --> 09:28.080
 And based on that, we make some decisions

09:28.080 --> 09:30.440
 with our sensory brains, right?

09:30.440 --> 09:32.600
 And from that perspective,

09:32.600 --> 09:35.080
 I think there are elements we have to talk about

09:35.080 --> 09:36.920
 how we sense the word

09:36.920 --> 09:40.200
 and then how we act based on what we sense.

09:40.200 --> 09:43.520
 Those elements clearly machines have.

09:43.520 --> 09:46.640
 But then there's the other aspects of computation

09:46.640 --> 09:48.240
 that is way better.

09:48.240 --> 09:49.920
 I also mentioned about memory again

09:49.920 --> 09:51.760
 in terms of being near infinite,

09:51.760 --> 09:54.080
 depending on the storage capacity you have.

09:54.080 --> 09:58.080
 And the retrieval can be extremely fast and pure

09:58.080 --> 10:00.080
 in terms of like, there's no ambiguity of

10:00.080 --> 10:02.000
 who did I see when, right?

10:02.000 --> 10:04.320
 I mean, if machines can remember that quite well.

10:04.320 --> 10:06.720
 So again, on a philosophical level,

10:06.720 --> 10:10.720
 I do subscribe to the fact that to be able to converse

10:10.720 --> 10:13.280
 and as part of that to be able to reason

10:13.280 --> 10:15.120
 based on the world knowledge you've acquired

10:15.120 --> 10:18.200
 and the sensory knowledge that is there

10:18.200 --> 10:21.960
 is definitely very much the essence of intelligence.

10:21.960 --> 10:25.160
 But intelligence can go beyond human level,

10:25.160 --> 10:28.560
 intelligence based on what machines are getting capable of.

10:28.560 --> 10:32.120
 So what do you think maybe stepping outside of Alexa

10:32.120 --> 10:34.440
 broadly as an AI field?

10:34.440 --> 10:37.480
 What do you think is a good test of intelligence?

10:37.480 --> 10:39.880
 Put it another way outside of Alexa,

10:39.880 --> 10:41.680
 because so much of Alexa is a product,

10:41.680 --> 10:43.600
 is an experience for the customer.

10:43.600 --> 10:45.120
 On the research side,

10:45.120 --> 10:47.920
 what would impress the heck out of you if you saw?

10:47.920 --> 10:50.720
 What is the test where you said, wow,

10:50.720 --> 10:55.720
 wow, this thing is now starting to encroach

10:56.960 --> 10:59.000
 into the realm of what we loosely think

10:59.000 --> 11:00.320
 of as human intelligence?

11:00.320 --> 11:02.360
 So, well, we think of it as AGI

11:02.360 --> 11:04.320
 and human intelligence altogether, right?

11:04.320 --> 11:07.960
 So in some sense, and I think we are quite far from that.

11:07.960 --> 11:11.440
 I think an unbiased view I have

11:11.440 --> 11:16.440
 is that the Alexa's intelligence capability is a great test.

11:17.720 --> 11:20.560
 I think of it as there are many other true points

11:20.560 --> 11:22.200
 like self driving cars,

11:23.000 --> 11:25.280
 game playing like go or chess.

11:26.280 --> 11:28.640
 Let's take those two for as an example.

11:28.640 --> 11:31.760
 Clearly requires a lot of data driven learning

11:31.760 --> 11:35.080
 and intelligence, but it's not as hard a problem

11:35.080 --> 11:39.760
 as conversing with as an AI is with humans

11:39.760 --> 11:42.320
 to accomplish certain tasks or open domain chat,

11:42.320 --> 11:43.960
 as you mentioned, Alexa prize.

11:44.840 --> 11:47.760
 In those settings, the key differences

11:47.760 --> 11:51.920
 that the end goal is not defined unlike game playing.

11:51.920 --> 11:55.720
 You also do not know exactly what state you are in

11:55.720 --> 11:58.960
 in a particular goal completion scenario.

11:58.960 --> 12:02.080
 In certain sense, sometimes you can if it's a simple goal,

12:02.080 --> 12:04.480
 but if you're even certain examples

12:04.480 --> 12:07.120
 like planning a weekend or you can imagine

12:07.120 --> 12:09.920
 how many things change along the way.

12:09.920 --> 12:11.960
 You look for whether you may change your mind

12:11.960 --> 12:14.880
 and you change the destination

12:14.880 --> 12:17.040
 or you want to catch a particular event

12:17.040 --> 12:19.440
 and then you decide, no, I want this other event

12:19.440 --> 12:20.560
 I want to go to.

12:20.560 --> 12:24.800
 So these dimensions of how many different steps are possible

12:24.800 --> 12:27.440
 when you're conversing as a human with a machine

12:27.440 --> 12:29.120
 makes it an extremely daunting problem.

12:29.120 --> 12:32.400
 And I think it is the ultimate test for intelligence.

12:32.400 --> 12:35.720
 And don't you think that natural language

12:35.720 --> 12:39.040
 is enough to prove that conversation?

12:39.040 --> 12:40.400
 Just pure conversation.

12:40.400 --> 12:42.320
 From a scientific standpoint,

12:42.320 --> 12:45.040
 natural language is a great test,

12:45.040 --> 12:47.840
 but I would go beyond, I don't want to limit it

12:47.840 --> 12:51.120
 to as natural language as simply understanding an intent

12:51.120 --> 12:52.800
 or parsing for entities and so forth.

12:52.800 --> 12:55.680
 We are really talking about dialogue.

12:55.680 --> 12:58.520
 So I would say human machine dialogue

12:58.520 --> 13:02.960
 is definitely one of the best tests of intelligence.

13:02.960 --> 13:06.680
 So can you briefly speak to the Alexa prize

13:06.680 --> 13:08.640
 for people who are not familiar with it

13:08.640 --> 13:12.640
 and also just maybe where things stand

13:12.640 --> 13:15.440
 and what have you learned and what's surprising?

13:15.440 --> 13:16.920
 What have you seen that surprising

13:16.920 --> 13:18.440
 from this incredible competition?

13:18.440 --> 13:20.960
 Absolutely, it's a very exciting competition.

13:20.960 --> 13:24.040
 Alexa prize is essentially a grand challenge

13:24.040 --> 13:26.880
 in conversational artificial intelligence

13:26.880 --> 13:29.440
 where we threw the gauntlet to the universities

13:29.440 --> 13:32.360
 who do active research in the field to say,

13:32.360 --> 13:35.360
 can you build what we call a social bot

13:35.360 --> 13:37.320
 that can converse with you coherently

13:37.320 --> 13:39.800
 and engagingly for 20 minutes?

13:39.800 --> 13:43.600
 That is an extremely hard challenge talking to someone

13:43.600 --> 13:46.480
 who you're meeting for the first time

13:46.480 --> 13:49.640
 or even if you've met them quite often

13:49.640 --> 13:53.560
 to speak at 20 minutes on any topic

13:53.560 --> 13:57.720
 and evolving nature of topics is super hard.

13:57.720 --> 14:01.600
 We have completed two successful years of the competition.

14:01.600 --> 14:03.400
 The first was one with the University of Washington,

14:03.400 --> 14:05.560
 second University of California.

14:05.560 --> 14:06.880
 We are in our third instance.

14:06.880 --> 14:09.640
 We have an extremely strong team of 10 cohorts

14:09.640 --> 14:13.960
 and the third instance of the Alexa prize is underway now.

14:14.840 --> 14:17.480
 And we are seeing a constant evolution.

14:17.480 --> 14:18.920
 First year was definitely a learning.

14:18.920 --> 14:21.200
 It was a lot of things to be put together.

14:21.200 --> 14:23.640
 We had to build a lot of infrastructure

14:23.640 --> 14:26.400
 to enable these universities to be able

14:26.400 --> 14:28.280
 to build magical experiences

14:28.280 --> 14:31.560
 and do high quality research.

14:31.560 --> 14:33.920
 Just a few quick questions, sorry for the interruption.

14:33.920 --> 14:37.280
 What does failure look like in the 20 minute session?

14:37.280 --> 14:40.120
 So what does it mean to fail not to reach the 20 minute mark?

14:40.120 --> 14:41.240
 Awesome question.

14:41.240 --> 14:43.360
 So there are one, first of all,

14:43.360 --> 14:45.360
 I forgot to mention one more detail.

14:45.360 --> 14:46.560
 It's not just 20 minutes,

14:46.560 --> 14:49.320
 but the quality of the conversation too that matters.

14:49.320 --> 14:51.480
 And the beauty of this competition

14:51.480 --> 14:53.800
 before I answer that question on what failure means

14:53.800 --> 14:56.600
 is first that you actually converse

14:56.600 --> 14:59.000
 with millions and millions of customers

14:59.000 --> 15:00.840
 as these social bots.

15:00.840 --> 15:05.000
 So during the judging phases, there are multiple phases.

15:05.000 --> 15:06.320
 Before we get to the finals,

15:06.320 --> 15:08.640
 which is a very controlled judging in a situation

15:08.640 --> 15:11.760
 where we bring in judges and we have contractors

15:11.760 --> 15:14.400
 who interact with these social bots,

15:14.400 --> 15:15.920
 that is a much more controlled setting.

15:15.920 --> 15:18.960
 But till the point we get to the finals,

15:18.960 --> 15:22.720
 all the judging is essentially by the customers of Alexa.

15:22.720 --> 15:26.200
 And there you basically rate on a simple question

15:26.200 --> 15:28.480
 how good your experience was.

15:28.480 --> 15:29.920
 So that's where we are not testing

15:29.920 --> 15:32.800
 for a 20 minute boundary being crossed

15:32.800 --> 15:37.080
 because you do want it to be very much like a clear cut winner,

15:37.080 --> 15:40.080
 be chosen and it's an absolute bar.

15:40.080 --> 15:42.800
 So did you really break that 20 minute barrier?

15:42.800 --> 15:45.920
 Is why we have to test it in a more controlled setting

15:45.920 --> 15:48.680
 with actors, essentially interactors

15:48.680 --> 15:50.840
 and see how the conversation goes.

15:50.840 --> 15:54.200
 So this is why it's a subtle difference

15:54.200 --> 15:57.040
 between how it's being tested in the field

15:57.040 --> 16:00.520
 with real customers versus in the lab to award the prize.

16:00.520 --> 16:03.560
 So on the latter one, what it means is that

16:03.560 --> 16:08.040
 essentially there are three judges

16:08.040 --> 16:10.320
 and two of them have to say this conversation

16:10.320 --> 16:11.720
 is stalled, essentially.

16:13.080 --> 16:13.920
 Got it.

16:13.920 --> 16:15.760
 And the judges are human experts.

16:15.760 --> 16:16.960
 Judges are human experts.

16:16.960 --> 16:17.800
 Okay, great.

16:17.800 --> 16:19.080
 So this is in the third year.

16:19.080 --> 16:20.840
 So what's been the evolution?

16:20.840 --> 16:24.560
 How far, so the DARPA challenge in the first year,

16:24.560 --> 16:27.720
 the autonomous vehicles and nobody finished in the second year,

16:27.720 --> 16:30.600
 a few more finished in the desert.

16:30.600 --> 16:34.320
 So how far along in this, I would say,

16:34.320 --> 16:36.320
 much harder challenge are we?

16:36.320 --> 16:39.200
 This challenge has come a long way to the extent that

16:39.200 --> 16:41.800
 we're definitely not close to the 20 minute barrier

16:41.800 --> 16:44.720
 being with coherence and engaging conversation.

16:44.720 --> 16:46.840
 I think we are still five to 10 years away

16:46.840 --> 16:49.480
 in that horizon to complete that.

16:49.480 --> 16:51.360
 But the progress is immense.

16:51.360 --> 16:54.080
 Like what you're finding is the accuracy

16:54.080 --> 16:57.360
 and what kind of responses these social bots generate

16:57.360 --> 16:59.480
 is getting better and better.

16:59.480 --> 17:03.320
 What's even amazing to see that now there's humor coming in.

17:03.320 --> 17:04.880
 The bots are quite...

17:04.880 --> 17:06.200
 Awesome.

17:06.200 --> 17:09.440
 You're talking about ultimate science of intelligence.

17:09.440 --> 17:11.840
 I think humor is a very high bar

17:11.840 --> 17:14.880
 in terms of what it takes to create humor.

17:14.880 --> 17:16.520
 And I don't mean just being goofy.

17:16.520 --> 17:19.440
 I really mean good sense of humor

17:19.440 --> 17:21.600
 is also a sign of intelligence in my mind

17:21.600 --> 17:23.120
 and something very hard to do.

17:23.120 --> 17:25.040
 So these social bots are now exploring

17:25.040 --> 17:28.560
 not only what we think of natural language abilities

17:28.560 --> 17:30.360
 but also personality attributes

17:30.360 --> 17:34.080
 and aspects of when to inject an appropriate joke,

17:34.080 --> 17:38.400
 when you don't know the domain,

17:38.400 --> 17:41.360
 how you come back with something more intelligible

17:41.360 --> 17:43.160
 so that you can continue the conversation.

17:43.160 --> 17:45.200
 If you and I are talking about AI

17:45.200 --> 17:47.480
 and we are domain experts, we can speak to it.

17:47.480 --> 17:49.280
 But if you suddenly switch a topic to that,

17:49.280 --> 17:50.480
 I don't know off.

17:50.480 --> 17:52.160
 How do I change the conversation?

17:52.160 --> 17:55.240
 So you're starting to notice these elements as well.

17:55.240 --> 17:58.560
 And that's coming from partly by the nature

17:58.560 --> 18:00.120
 of the 20 minute challenge

18:00.120 --> 18:02.520
 that people are getting quite clever

18:02.520 --> 18:05.600
 on how to really converse

18:05.600 --> 18:08.600
 and essentially mask some of the understanding defects

18:08.600 --> 18:09.880
 if they exist.

18:09.880 --> 18:12.720
 So some of this, this is not Alexa the product.

18:12.720 --> 18:17.000
 This is somewhat for fun, for research, for innovation

18:17.000 --> 18:17.840
 and so on.

18:17.840 --> 18:20.280
 I have a question sort of in this modern era,

18:20.280 --> 18:23.440
 there's a lot of, if you look at Twitter

18:23.440 --> 18:25.840
 and Facebook and so on, there's discourse,

18:25.840 --> 18:27.200
 public discourse going on

18:27.200 --> 18:28.840
 and some things that are a little bit too edgy,

18:28.840 --> 18:30.680
 people get blocked and so on.

18:30.680 --> 18:32.280
 I'm just out of curiosity.

18:32.280 --> 18:36.000
 Are people in this context pushing the limits?

18:36.000 --> 18:37.760
 Is anyone using the F word?

18:37.760 --> 18:42.760
 Is anyone sort of pushing back sort of arguing,

18:44.760 --> 18:46.920
 I guess I should say as part of the dialogue

18:46.920 --> 18:48.320
 to really draw people in?

18:48.320 --> 18:50.360
 First of all, let me just back up a bit

18:50.360 --> 18:52.160
 in terms of why we are doing this, right?

18:52.160 --> 18:54.320
 So you said it's fun.

18:54.320 --> 18:59.320
 I think fun is more part of the engaging part for customers.

18:59.960 --> 19:04.360
 It is one of the most used skills as well in our skill store.

19:04.360 --> 19:07.240
 But up that apart, the real goal was essentially

19:07.240 --> 19:08.760
 what was happening is

19:08.760 --> 19:11.920
 with a lot of AI research moving to industry,

19:11.920 --> 19:14.200
 we felt that academia has the risk

19:14.200 --> 19:16.800
 of not being able to have the same resources

19:16.800 --> 19:20.480
 at disposal that we have, which is lots of data,

19:20.480 --> 19:22.720
 massive computing power,

19:22.720 --> 19:26.320
 and a clear ways to test these AI advances

19:26.320 --> 19:28.520
 with real customer benefits.

19:28.520 --> 19:30.880
 So we brought all these three together in the Alexa prize.

19:30.880 --> 19:33.880
 That's why it's one of my favorite projects in Amazon.

19:33.880 --> 19:37.520
 And with that, the secondary effect is,

19:37.520 --> 19:40.960
 yes, it has become engaging for our customers as well.

19:40.960 --> 19:43.920
 We're not there in terms of where we want it to be, right?

19:43.920 --> 19:45.080
 But it's a huge progress.

19:45.080 --> 19:47.120
 But coming back to your question on

19:47.120 --> 19:48.840
 how do the conversations evolve?

19:48.840 --> 19:51.040
 Yes, there is some natural attributes

19:51.040 --> 19:52.800
 of what you said in terms of argument

19:52.800 --> 19:54.200
 and some amount of swearing.

19:54.200 --> 19:56.040
 The way we take care of that

19:56.040 --> 19:59.120
 is that there is a sensitive filter we have built.

19:59.120 --> 20:00.440
 That's some keywords and so on.

20:00.440 --> 20:03.520
 It's more than keywords, a little more in terms of,

20:03.520 --> 20:04.920
 of course, there's keyword based too,

20:04.920 --> 20:06.960
 but there's more in terms of,

20:06.960 --> 20:09.480
 these words can be very contextual, as you can see.

20:09.480 --> 20:12.640
 And also the topic can be something

20:12.640 --> 20:15.480
 that you don't want a conversation to happen

20:15.480 --> 20:17.360
 because this is a communal device as well.

20:17.360 --> 20:19.320
 A lot of people use these devices.

20:19.320 --> 20:22.680
 So we have put a lot of guardrails for the conversation

20:22.680 --> 20:26.000
 to be more useful for advancing AI

20:26.000 --> 20:31.000
 and not so much of these other issues you attributed

20:31.160 --> 20:32.960
 what's happening in the AI field as well.

20:32.960 --> 20:35.360
 Right, so this is actually a serious opportunity.

20:35.360 --> 20:36.920
 I didn't use the right word, fun.

20:36.920 --> 20:40.520
 I think it's an open opportunity to do some,

20:40.520 --> 20:43.960
 some of the best innovation in conversational agents

20:43.960 --> 20:44.800
 in the world.

20:44.800 --> 20:45.960
 Absolutely.

20:45.960 --> 20:49.040
 Why just universities?

20:49.040 --> 20:49.960
 Why just universities?

20:49.960 --> 20:53.240
 Because as I said, I really felt the young minds,

20:53.240 --> 20:57.960
 it's also to, if you think about the other aspect

20:57.960 --> 21:01.440
 of where the whole industry is moving with AI,

21:01.440 --> 21:04.920
 there's a dearth of talent in, in given the demands.

21:04.920 --> 21:09.920
 So you do want universities to have a clear place

21:09.920 --> 21:12.520
 where they can invent and research and not fall behind

21:12.520 --> 21:13.960
 with that they can't motivate students.

21:13.960 --> 21:18.960
 Imagine all grad students left to, to industry, like us,

21:19.640 --> 21:22.920
 or faculty members, which has happened too.

21:22.920 --> 21:25.240
 So this is a way that if you're so passionate

21:25.240 --> 21:28.640
 about the field where you feel industry and academia

21:28.640 --> 21:31.400
 need to work well, this is a great example

21:31.400 --> 21:34.480
 and a great way for universities to participate.

21:35.440 --> 21:37.320
 So what do you think it takes to build a system

21:37.320 --> 21:39.640
 that wins Deluxe Surprise?

21:39.640 --> 21:44.640
 I think you have to start focusing on aspects of reasoning

21:46.240 --> 21:50.800
 that it is, there are still more lookups

21:50.800 --> 21:54.200
 of what intents the customer is asking for

21:54.200 --> 21:58.960
 and responding to those rather than really reasoning

21:58.960 --> 22:02.520
 about the elements of the, of the conversation.

22:02.520 --> 22:06.280
 For instance, if you have, if you're playing,

22:06.280 --> 22:08.120
 if the conversation is about games

22:08.120 --> 22:11.280
 and it's about a recent sports event,

22:11.280 --> 22:13.320
 there's so much context involved

22:13.320 --> 22:15.840
 and you have to understand the entities

22:15.840 --> 22:19.080
 that are being mentioned so that the conversation

22:19.080 --> 22:21.560
 is coherent rather than you suddenly just switch

22:21.560 --> 22:25.200
 to knowing some fact about a sports entity

22:25.200 --> 22:26.680
 and you're just relaying that rather

22:26.680 --> 22:28.720
 than understanding the true context of the game.

22:28.720 --> 22:32.320
 Like if you just said, I learned this fun fact

22:32.320 --> 22:36.000
 about Tom Brady rather than really say

22:36.000 --> 22:39.320
 how he played the game the previous night,

22:39.320 --> 22:42.840
 then the conversation is not really that intelligent.

22:42.840 --> 22:46.200
 So you have to go to more reasoning elements

22:46.200 --> 22:49.160
 of understanding the context of the dialogue

22:49.160 --> 22:51.240
 and giving more appropriate responses,

22:51.240 --> 22:53.720
 which tells you that we are still quite far

22:53.720 --> 22:57.440
 because a lot of times it's more facts being looked up

22:57.440 --> 22:59.960
 and something that's close enough as an answer

22:59.960 --> 23:02.080
 but not really the answer.

23:02.080 --> 23:05.080
 So that is where the research needs to go more

23:05.080 --> 23:08.400
 and actual true understanding and reasoning.

23:08.400 --> 23:10.480
 And that's why I feel it's a great way to do it

23:10.480 --> 23:14.240
 because you have an engaged set of users working

23:14.240 --> 23:18.080
 to make help these AI advances happen in this case.

23:18.080 --> 23:20.360
 You mentioned customers, they're quite a bit,

23:20.360 --> 23:24.120
 and there's a skill, what is the experience

23:24.120 --> 23:26.560
 for the user that's helping?

23:26.560 --> 23:30.120
 So just to clarify, this isn't, as far as I understand,

23:30.120 --> 23:32.560
 the Alexa, so this skill is a standalone

23:32.560 --> 23:34.240
 for the Alexa prize, I mean it's focused

23:34.240 --> 23:37.320
 on the Alexa prize, it's not you ordering certain things

23:37.320 --> 23:39.280
 on Amazon.com or checking the weather

23:39.280 --> 23:42.080
 or playing Spotify, right, it's a separate skill.

23:42.080 --> 23:45.680
 And so you're focused on helping that,

23:45.680 --> 23:48.560
 I don't know how do people, how do customers think of it?

23:48.560 --> 23:49.840
 Are they having fun?

23:49.840 --> 23:52.080
 Are they helping teach the system?

23:52.080 --> 23:53.080
 What's the experience like?

23:53.080 --> 23:54.680
 I think it's both, actually,

23:54.680 --> 23:57.840
 and let me tell you how you invoke this skill.

23:57.840 --> 24:00.240
 So all you have to say, Alexa, let's chat.

24:00.240 --> 24:03.360
 And then the first time you say, Alexa, let's chat,

24:03.360 --> 24:04.720
 it comes back with a clear message

24:04.720 --> 24:06.280
 that you're interacting with one of those

24:06.280 --> 24:09.320
 university social bots, and there's a clear,

24:09.320 --> 24:11.840
 so you know exactly how you interact, right?

24:11.840 --> 24:14.080
 And that is why it's very transparent.

24:14.080 --> 24:16.280
 You are being asked to help, right?

24:16.280 --> 24:20.960
 And we have a lot of mechanisms where as the,

24:20.960 --> 24:23.680
 we are in the first phase of feedback phase,

24:23.680 --> 24:26.720
 then you send a lot of emails to our customers,

24:26.720 --> 24:31.720
 and then they know that the team needs a lot of interactions

24:31.720 --> 24:33.920
 to improve the accuracy of the system.

24:33.920 --> 24:35.880
 So we know we have a lot of customers

24:35.880 --> 24:38.920
 who really want to help these university bots,

24:38.920 --> 24:40.400
 and they're conversing with that.

24:40.400 --> 24:42.680
 And some are just having fun with just saying,

24:42.680 --> 24:44.000
 Alexa, let's chat.

24:44.000 --> 24:47.320
 And also some adversarial behavior to see whether,

24:47.320 --> 24:50.240
 how much do you understand as a social bot?

24:50.240 --> 24:52.280
 So I think we have a good, healthy mix

24:52.280 --> 24:53.920
 of all three situations.

24:53.920 --> 24:58.040
 So what is the, if we talk about solving the Alexa challenge,

24:58.040 --> 25:03.040
 the Alexa prize, what's the data set

25:04.040 --> 25:07.520
 of really engaging pleasant conversations look like?

25:07.520 --> 25:08.360
 Because if we think of this

25:08.360 --> 25:10.600
 as a supervised learning problem,

25:10.600 --> 25:12.200
 I don't know if it has to be,

25:12.200 --> 25:15.400
 but if it does, maybe you can comment on that.

25:15.400 --> 25:17.480
 Do you think there needs to be a data set

25:17.480 --> 25:21.160
 of what it means to be an engaging,

25:21.160 --> 25:22.640
 successful, fulfilling conversation?

25:22.640 --> 25:24.800
 I think that's part of the research question here.

25:24.800 --> 25:29.240
 This was, I think, we at least got the first spot right,

25:29.240 --> 25:34.240
 which is have a way for universities to build and test

25:34.280 --> 25:35.840
 in a real world setting.

25:35.840 --> 25:38.640
 Now you're asking in terms of the next phase of questions,

25:38.640 --> 25:41.120
 which we are still, we're also asking, by the way,

25:41.120 --> 25:45.440
 what does success look like from a optimization function?

25:45.440 --> 25:46.280
 That's what you're asking.

25:46.280 --> 25:48.400
 In terms of, we as researchers are used

25:48.400 --> 25:51.360
 to having a great corpus of annotated data

25:51.360 --> 25:56.280
 and then making or then sort of tune our algorithms

25:56.280 --> 25:57.640
 on those, right?

25:57.640 --> 26:00.680
 And fortunately and unfortunately,

26:00.680 --> 26:02.960
 in this world of Alexa prize,

26:02.960 --> 26:05.440
 that is not the way we are going after it.

26:05.440 --> 26:07.760
 So you have to focus more on learning

26:07.760 --> 26:10.960
 based on live feedback.

26:10.960 --> 26:13.000
 That is another element that's unique,

26:13.000 --> 26:17.320
 where just now I started with giving you how you ingress

26:17.320 --> 26:21.560
 and experience this capability as a customer.

26:21.560 --> 26:23.640
 What happens when you're done?

26:23.640 --> 26:27.560
 So they ask you a simple question on a scale of one to five,

26:27.560 --> 26:31.920
 how likely are you to interact with this social border game?

26:31.920 --> 26:33.880
 That is a good feedback

26:33.880 --> 26:37.480
 and customers can also leave more open ended feedback.

26:37.480 --> 26:42.160
 And I think partly that to me is one part of the question

26:42.160 --> 26:44.640
 you're asking, which I'm saying is a mental model shift

26:44.640 --> 26:48.600
 that as researchers also, you have to change your mindset

26:48.600 --> 26:52.720
 that this is not a DARPA evaluation or NSF funded study

26:52.720 --> 26:55.000
 and you have a nice corpus.

26:55.000 --> 26:57.000
 This is where it's real world.

26:57.000 --> 26:58.760
 You have real data.

26:58.760 --> 27:01.600
 The scale is amazing and that's a beautiful thing.

27:01.600 --> 27:05.800
 And then the customer, the user can quit the conversation

27:05.800 --> 27:06.640
 at any time.

27:06.640 --> 27:07.480
 Exactly, the user can.

27:07.480 --> 27:11.760
 That is also a signal for how good you were at that point.

27:11.760 --> 27:15.000
 So, and then on a scale of one to five, one to three,

27:15.000 --> 27:17.720
 do they say how likely are you or is it just a binary?

27:17.720 --> 27:18.720
 How one to five?

27:18.720 --> 27:20.000
 One to five.

27:20.000 --> 27:20.840
 Wow, okay.

27:20.840 --> 27:22.680
 That's such a beautifully constructed challenge.

27:22.680 --> 27:23.520
 Okay.

27:24.800 --> 27:30.040
 You said the only way to make a smart assistant really smart

27:30.040 --> 27:32.480
 is to give it eyes and let it explore the world.

27:34.560 --> 27:36.840
 I'm not sure you might have been taken out of context,

27:36.840 --> 27:38.240
 but can you comment on that?

27:38.240 --> 27:40.080
 Can you elaborate on that idea?

27:40.080 --> 27:43.120
 Is that I personally also find that idea super exciting

27:43.120 --> 27:46.240
 from a social robotics, personal robotics perspective?

27:46.240 --> 27:48.400
 Yeah, a lot of things do get taken out of context.

27:48.400 --> 27:52.040
 My, this particular one was just as philosophical discussion

27:52.040 --> 27:55.560
 we were having on terms of what does intelligence look like?

27:55.560 --> 27:59.200
 And the context was in terms of learning,

27:59.200 --> 28:03.040
 I think just we said we as humans are empowered

28:03.040 --> 28:05.480
 with many different sensory abilities.

28:05.480 --> 28:09.560
 I do believe that eyes are an important aspect of it

28:09.560 --> 28:13.720
 in terms of if you think about how we as humans learn,

28:14.640 --> 28:18.360
 it is quite complex and it's also not unimodal

28:18.360 --> 28:22.040
 that you are fed a ton of text or audio

28:22.040 --> 28:23.360
 and you just learn that way.

28:23.360 --> 28:27.240
 No, you learn by experience, you learn by seeing,

28:27.240 --> 28:31.960
 you're taught by humans and we are very efficient

28:31.960 --> 28:33.240
 in how we learn.

28:33.240 --> 28:35.320
 Machines on the contrary are very inefficient

28:35.320 --> 28:38.480
 on how they learn, especially these AIs.

28:38.480 --> 28:40.800
 I think the next wave of research

28:40.800 --> 28:44.360
 is going to be with less data,

28:44.360 --> 28:48.240
 not just less human, not just with less labeled data

28:48.240 --> 28:51.080
 but also with a lot of weak supervision

28:51.080 --> 28:55.160
 and where you can increase the learning rate.

28:55.160 --> 28:57.280
 I don't mean less data in terms of not having

28:57.280 --> 28:59.000
 a lot of data to learn from that.

28:59.000 --> 29:00.360
 We are generating so much data

29:00.360 --> 29:04.920
 but it is more about from a aspect of how fast can you learn?

29:04.920 --> 29:07.040
 So improving the quality of the data

29:07.040 --> 29:09.960
 that's the quality of data and the learning process.

29:09.960 --> 29:11.480
 I think more on the learning process.

29:11.480 --> 29:13.600
 I think we have to, we as humans learn

29:13.600 --> 29:15.760
 with a lot of noisy data, right?

29:15.760 --> 29:20.760
 And I think that's the part that I don't think should change.

29:21.480 --> 29:23.920
 What should change is how we learn, right?

29:23.920 --> 29:26.120
 So if you look at, you mentioned supervised learning,

29:26.120 --> 29:28.000
 we have making transformative shifts

29:28.000 --> 29:31.200
 from moving to more unsupervised, more weak supervision.

29:31.200 --> 29:34.880
 Those are the key aspects of how to learn.

29:34.880 --> 29:37.800
 And I think in that setting, I hope you agree with me

29:37.800 --> 29:41.680
 that having other senses is very crucial

29:41.680 --> 29:43.480
 in terms of how you learn.

29:43.480 --> 29:46.680
 So absolutely, and from a machine learning perspective

29:46.680 --> 29:49.680
 which I hope we get a chance to talk to a few aspects

29:49.680 --> 29:52.480
 that are fascinating there, but to stick on the point

29:52.480 --> 29:56.280
 of sort of a body, you know, an embodiment.

29:56.280 --> 29:57.520
 So Alexa has a body.

29:57.520 --> 30:01.600
 It has a very minimalistic, beautiful interface

30:01.600 --> 30:02.840
 where there's a ring and so on.

30:02.840 --> 30:06.520
 I mean, I'm not sure of all the flavors of the devices

30:06.520 --> 30:09.560
 that Alexa lives on, but there's a minimalistic,

30:09.560 --> 30:11.000
 basic interface.

30:13.320 --> 30:15.560
 And nevertheless, we humans, so I have a room,

30:15.560 --> 30:18.280
 but I have all kinds of robots all over everywhere.

30:18.280 --> 30:23.280
 So what do you think the Alexa of the future looks like

30:24.720 --> 30:28.520
 if it begins to shift what his body looks like?

30:28.520 --> 30:31.200
 What, maybe beyond the Alexa, what do you think

30:31.200 --> 30:33.760
 are the different devices in the home

30:33.760 --> 30:36.920
 as they start to embody their intelligence more and more?

30:36.920 --> 30:38.120
 What do you think that looks like?

30:38.120 --> 30:41.200
 Philosophically, a future, what do you think that looks like?

30:41.200 --> 30:43.600
 I think let's look at what's happening today.

30:43.600 --> 30:46.840
 You mentioned, I think, other devices as an Amazon devices,

30:46.840 --> 30:48.640
 but I also wanted to point out Alexa

30:48.640 --> 30:51.360
 is already integrated in a lot of third party devices

30:51.360 --> 30:54.840
 which also come in lots of forms and shapes.

30:54.840 --> 30:56.360
 Some in robots, right?

30:56.360 --> 31:00.280
 Some in microwaves, some in appliances

31:00.280 --> 31:02.600
 that you use in everyday life.

31:02.600 --> 31:07.600
 So I think it's not just the shape Alexa takes

31:07.720 --> 31:09.200
 in terms of form factors,

31:09.200 --> 31:13.000
 but it's also where all it's available.

31:13.000 --> 31:14.240
 And it's getting in cars,

31:14.240 --> 31:16.720
 it's getting in different appliances in homes,

31:16.720 --> 31:18.720
 even toothbrushes, right?

31:18.720 --> 31:20.760
 So I think you have to think about it

31:20.760 --> 31:25.440
 as not a physical assistant.

31:25.440 --> 31:28.480
 It will be in some embodiment as you said,

31:28.480 --> 31:31.120
 we already have these nice devices.

31:31.120 --> 31:33.760
 But I think it's also important to think of it

31:33.760 --> 31:35.640
 as a virtual assistant.

31:35.640 --> 31:37.200
 It is superhuman in the sense

31:37.200 --> 31:40.280
 that it is in multiple places at the same time.

31:40.280 --> 31:45.200
 So I think the actual embodiment in some sense

31:45.200 --> 31:46.680
 to me doesn't matter.

31:47.600 --> 31:52.600
 I think you have to think of it as not as human like

31:52.800 --> 31:56.080
 and more of what its capabilities are

31:56.080 --> 31:58.800
 that derive a lot of benefit for customers

31:58.800 --> 32:00.680
 and how there are different ways to delight it

32:00.680 --> 32:03.960
 and delight customers and different experiences.

32:03.960 --> 32:06.680
 And I think I'm a big fan of it

32:06.680 --> 32:09.240
 not being just human like,

32:09.240 --> 32:11.120
 it should be human like in certain situations.

32:11.120 --> 32:13.360
 Alexa Price, social bot in terms of conversation

32:13.360 --> 32:14.920
 is a great way to look at it,

32:14.920 --> 32:18.800
 but there are other scenarios where human like

32:18.800 --> 32:22.080
 I think is underselling the abilities of this AI.

32:22.080 --> 32:26.120
 So if I could trivialize what we're talking about.

32:26.120 --> 32:29.400
 So if you look at the way Steve Jobs thought

32:29.400 --> 32:31.400
 about the interaction with the device

32:31.400 --> 32:33.440
 that Apple produced,

32:33.440 --> 32:36.760
 there was a extreme focus on controlling the experience

32:36.760 --> 32:40.200
 by making sure there's only these Apple produced devices.

32:40.200 --> 32:44.040
 You see the voice of Alexa being,

32:44.040 --> 32:45.600
 taking all kinds of forms

32:45.600 --> 32:47.080
 depending on what the customers want.

32:47.080 --> 32:49.840
 And that means it could be anywhere

32:49.840 --> 32:53.760
 from the microwave to vacuum cleaner to the home

32:53.760 --> 32:56.920
 and so on the voice is the essential element

32:56.920 --> 32:57.760
 of the interaction.

32:57.760 --> 32:59.760
 I think voice is an essence.

32:59.760 --> 33:02.160
 It's not all, but it's a key aspect.

33:02.160 --> 33:05.640
 I think to your question in terms of

33:05.640 --> 33:08.200
 you should be able to recognize Alexa.

33:08.200 --> 33:09.920
 And that's a huge problem.

33:09.920 --> 33:12.000
 I think in terms of a huge scientific problem,

33:12.000 --> 33:13.720
 I should say like what are the traits?

33:13.720 --> 33:16.120
 What makes it look like Alexa,

33:16.120 --> 33:17.520
 especially in different settings

33:17.520 --> 33:20.360
 and especially if it's primarily voice what it is.

33:20.360 --> 33:22.200
 But Alexa is not just voice either, right?

33:22.200 --> 33:25.000
 I mean, we have devices with a screen.

33:25.000 --> 33:28.480
 Now you're seeing just other behaviors of Alexa.

33:28.480 --> 33:31.360
 So I think we're in very early stages of what that means.

33:31.360 --> 33:34.920
 And this will be an important topic for the following years.

33:34.920 --> 33:38.200
 But I do believe that being able to recognize

33:38.200 --> 33:40.480
 and tell when it's Alexa versus it's not

33:40.480 --> 33:43.360
 is going to be important from an Alexa perspective.

33:43.360 --> 33:46.000
 I'm not speaking for the entire AI community,

33:46.000 --> 33:49.440
 but from, but I think attribution.

33:49.440 --> 33:53.600
 And as we go into more of understanding

33:53.600 --> 33:56.840
 who did what, that identity of the AI

33:56.840 --> 33:58.720
 is crucial in the coming world.

33:58.720 --> 34:01.040
 I think from the broad AI community perspective,

34:01.040 --> 34:02.840
 that's also a fascinating problem.

34:02.840 --> 34:06.200
 So basically if I close my eyes and listen to the voice,

34:06.200 --> 34:08.760
 what would it take for me to recognize that this is Alexa?

34:08.760 --> 34:09.600
 Exactly.

34:09.600 --> 34:11.320
 Or at least the Alexa that I've come to know

34:11.320 --> 34:13.720
 from my personal experience in my home

34:13.720 --> 34:15.040
 through my interactions that come.

34:15.040 --> 34:15.880
 Yeah.

34:15.880 --> 34:17.600
 And the Alexa here in the US is very different.

34:17.600 --> 34:20.160
 The Alexa in UK and the Alexa in India,

34:20.160 --> 34:22.200
 even though they are all speaking English

34:22.200 --> 34:23.960
 or the Australian version.

34:23.960 --> 34:26.600
 So again, when, so now think about

34:26.600 --> 34:28.320
 when you go into a different culture,

34:28.320 --> 34:30.640
 a different community, but you travel there,

34:30.640 --> 34:32.440
 what do you recognize Alexa?

34:32.440 --> 34:34.840
 I think these are super hard questions actually.

34:34.840 --> 34:37.480
 So there's a team that works on personality.

34:37.480 --> 34:40.040
 So if we talk about those different flavors

34:40.040 --> 34:41.720
 of what it means, culturally speaking,

34:41.720 --> 34:45.280
 India, UK, US, what does it mean to add?

34:45.280 --> 34:48.400
 So the problem that we just stated is just fascinating.

34:48.400 --> 34:52.640
 How do we make it purely recognizable that it's Alexa?

34:53.640 --> 34:57.280
 Assuming that the qualities of the voice are not sufficient.

34:58.560 --> 35:01.560
 It's also the content of what is being said.

35:01.560 --> 35:02.680
 How do we do that?

35:02.680 --> 35:04.840
 How does the personality keep on coming to play?

35:04.840 --> 35:07.320
 What's that research you would look like?

35:07.320 --> 35:08.640
 I mean, it's such a fascinating.

35:08.640 --> 35:11.840
 We have some very fascinating folks who,

35:11.840 --> 35:14.160
 from both the UX background and human factors,

35:14.160 --> 35:17.480
 are looking at these aspects and these exact questions.

35:17.480 --> 35:21.640
 But I'll definitely say it's not just how it sounds,

35:21.640 --> 35:24.440
 the choice of words, the tone,

35:24.440 --> 35:26.840
 not just, I mean, the voice identity of it,

35:26.840 --> 35:30.120
 but the tone matters, the speed matters,

35:30.120 --> 35:32.600
 how you speak, how you enunciate words,

35:32.600 --> 35:36.320
 how, what choice of words are you using?

35:36.320 --> 35:40.720
 How terse are you or how lengthy in your explanations you are?

35:40.720 --> 35:42.920
 All of these are factors.

35:42.920 --> 35:45.440
 And you also mentioned something crucial

35:45.440 --> 35:50.240
 that it may have personalized Alexa to some extent

35:50.240 --> 35:53.400
 in your homes or in the devices you are interacting with.

35:53.400 --> 35:57.560
 So you, as your individual,

35:57.560 --> 35:59.200
 how you prefer Alexa sounds

35:59.200 --> 36:01.200
 can be different than how I prefer.

36:01.200 --> 36:04.400
 And the amount of customizability you want to give

36:04.400 --> 36:07.600
 is also a key debate we always have.

36:07.600 --> 36:10.680
 But I do want to point out it's more than the voice actor

36:10.680 --> 36:13.960
 that recorded and it sounds like that actor.

36:13.960 --> 36:16.880
 It is more about the choices of words,

36:16.880 --> 36:18.960
 the attributes of tonality,

36:18.960 --> 36:21.400
 the volume in terms of how you raise your pitch

36:21.400 --> 36:23.840
 and so forth, all of that matters.

36:23.840 --> 36:25.400
 This is such a fascinating problem

36:25.400 --> 36:27.560
 from a product perspective.

36:27.560 --> 36:29.440
 I could see those debates just happening

36:29.440 --> 36:31.080
 inside of the Alexa team

36:31.080 --> 36:32.800
 of how much personalization do you do

36:32.800 --> 36:34.400
 for the specific customer?

36:34.400 --> 36:38.200
 Because you're taking a risk if you over personalize.

36:38.200 --> 36:40.320
 Because you don't,

36:40.320 --> 36:44.400
 if you create a personality for a million people,

36:44.400 --> 36:46.040
 you can test that better.

36:46.040 --> 36:48.600
 You can create a rich, fulfilling experience

36:48.600 --> 36:50.040
 that will do well.

36:50.040 --> 36:52.280
 But the more you personalize it,

36:52.280 --> 36:53.480
 the less you can test it,

36:53.480 --> 36:56.320
 the less you can know that it's a great experience.

36:56.320 --> 36:59.720
 So how much personalization, what's the right balance?

36:59.720 --> 37:01.600
 I think the right balance depends on the customer.

37:01.600 --> 37:02.800
 Give them the control.

37:02.800 --> 37:07.400
 So I'll say, I think the more control you give customers,

37:07.400 --> 37:09.600
 the better it is for everyone.

37:09.600 --> 37:13.840
 And I'll give you some key personalization features.

37:13.840 --> 37:15.840
 I think we have a feature called remember this,

37:15.840 --> 37:19.440
 which is where you can tell Alexa to remember something.

37:19.440 --> 37:23.080
 There you have an explicit sort of control

37:23.080 --> 37:23.920
 in customer's hand

37:23.920 --> 37:26.520
 because they have to say Alexa, remember X, Y, Z.

37:26.520 --> 37:28.000
 What kind of things would that be used for?

37:28.000 --> 37:30.360
 So you can like use it.

37:30.360 --> 37:33.240
 I have stored my tire specs for my car

37:33.240 --> 37:36.560
 because it's so hard to go and find and see what it is

37:36.560 --> 37:39.040
 right when you're having some issues.

37:39.040 --> 37:41.400
 I store my mileage plan numbers

37:41.400 --> 37:43.080
 for all the frequent flyer ones

37:43.080 --> 37:46.480
 where I'm sometimes just looking at it and it's not handy.

37:46.480 --> 37:49.920
 So those are my own personal choices I've made

37:49.920 --> 37:52.280
 for Alexa to remember something on my behalf.

37:52.280 --> 37:56.000
 So again, I think the choice was be explicit

37:56.000 --> 38:00.000
 about how you provide that to a customer as a control.

38:00.000 --> 38:03.440
 So I think these are the aspects of what you do.

38:03.440 --> 38:06.320
 Like think about where we can use

38:06.320 --> 38:08.600
 speaker recognition capabilities that it's,

38:08.600 --> 38:12.960
 if you taught Alexa that you are Lex

38:12.960 --> 38:16.320
 and this person in your household is person two,

38:16.320 --> 38:17.920
 then you can personalize the experiences.

38:17.920 --> 38:22.840
 Again, these are very in the CX customer experience patterns

38:22.840 --> 38:26.520
 are very clear about and transparent

38:26.520 --> 38:30.040
 when a personalization action is happening.

38:30.040 --> 38:31.400
 And then you have other ways

38:31.400 --> 38:34.080
 like you go through explicit control right now

38:34.080 --> 38:36.920
 through your app that your multiple service providers,

38:36.920 --> 38:39.520
 let's say for music, which one is your preferred one?

38:39.520 --> 38:41.360
 So when you say place sting,

38:41.360 --> 38:43.840
 depend on your, whether you have preferred Spotify

38:43.840 --> 38:45.760
 or Amazon music or Apple music

38:45.760 --> 38:48.320
 that the decision is made where to play it from.

38:49.520 --> 38:52.440
 So what's Alexa's backstory from her perspective?

38:52.440 --> 38:57.440
 Is there, I remember just asking as probably

38:57.880 --> 39:00.000
 a lot of us are just the basic questions

39:00.000 --> 39:02.440
 about love and so on of Alexa,

39:02.440 --> 39:03.880
 just to see what the answer would be.

39:03.880 --> 39:07.760
 Just it feels like there's a little bit of a back,

39:07.760 --> 39:08.600
 like there's a,

39:08.600 --> 39:10.360
 this feels like there's a little bit of personality

39:10.360 --> 39:12.880
 but not too much.

39:12.880 --> 39:17.880
 Is Alexa have a metaphysical presence

39:18.400 --> 39:21.920
 in this human universe who live in

39:21.920 --> 39:23.760
 or is it something more ambiguous?

39:23.760 --> 39:25.120
 Is there a past?

39:25.120 --> 39:26.280
 Is there a birth?

39:26.280 --> 39:28.960
 Is there a family kind of idea

39:28.960 --> 39:31.160
 even for joking purposes and so on?

39:31.160 --> 39:33.480
 I think, well, it does tell you,

39:33.480 --> 39:35.760
 if I think you, I should double check this,

39:35.760 --> 39:37.160
 but if you said, when were you born?

39:37.160 --> 39:39.000
 I think we do respond.

39:39.000 --> 39:40.120
 I need to double check that,

39:40.120 --> 39:41.480
 but I'm pretty positive about it.

39:41.480 --> 39:42.320
 I think that you do it

39:42.320 --> 39:44.000
 because I think I've tested that.

39:44.000 --> 39:46.760
 But that's like a, that's like how,

39:46.760 --> 39:49.120
 like I was born in your brand of champagne

39:49.120 --> 39:50.960
 and whatever the year kind of thing.

39:50.960 --> 39:51.800
 Yeah.

39:51.800 --> 39:53.440
 So on terms of the metaphysical,

39:53.440 --> 39:55.760
 I think it's early,

39:55.760 --> 40:00.400
 does it have the historic knowledge about herself

40:00.400 --> 40:01.480
 to be able to do that?

40:01.480 --> 40:03.760
 Maybe, have we crossed that boundary?

40:03.760 --> 40:04.600
 Not yet, right?

40:04.600 --> 40:06.560
 In terms of being, thank you.

40:06.560 --> 40:08.640
 Have we thought about it quite a bit,

40:08.640 --> 40:11.520
 but I wouldn't say that we have come to a clear decision

40:11.520 --> 40:13.040
 in terms of what it should look like.

40:13.040 --> 40:15.880
 But you can imagine though,

40:15.880 --> 40:19.240
 and I bring this back to the Alexa Prize social bot one,

40:19.240 --> 40:21.200
 there you will start seeing some of that.

40:21.200 --> 40:23.480
 Like you, these bots have their identity.

40:23.480 --> 40:24.680
 And in terms of that,

40:24.680 --> 40:26.840
 you may find, you know,

40:26.840 --> 40:28.440
 this is such a great research topic

40:28.440 --> 40:32.160
 that some academia team may think of these problems

40:32.160 --> 40:34.120
 and start solving them too.

40:35.120 --> 40:38.920
 So let me ask a question.

40:38.920 --> 40:41.160
 It's kind of difficult, I think,

40:41.160 --> 40:43.320
 but it feels fascinating to me

40:43.320 --> 40:45.360
 because I'm fascinated with psychology.

40:45.360 --> 40:48.200
 It feels that the more personality you have,

40:48.200 --> 40:50.400
 the more dangerous it is.

40:50.400 --> 40:54.440
 In terms of a customer perspective, a product,

40:54.440 --> 40:57.080
 if you want to create a product that's useful.

40:57.080 --> 41:01.320
 By dangerous, I mean creating an experience that upsets me.

41:02.320 --> 41:06.680
 And so, how do you get that right?

41:06.680 --> 41:10.040
 Because if you look at the relationships,

41:10.040 --> 41:11.800
 maybe I'm just a screwed up Russian,

41:11.800 --> 41:15.040
 but if you look at the human relationship,

41:15.040 --> 41:18.120
 some of our deepest relationships have fights,

41:18.120 --> 41:21.200
 have tension, have the push and pull,

41:21.200 --> 41:22.800
 have a little flavor in them.

41:24.160 --> 41:26.200
 Do you want to have such flavor

41:26.200 --> 41:28.080
 in an interaction with Alexa?

41:28.080 --> 41:29.440
 How do you think about that?

41:29.440 --> 41:32.440
 So there's one other common thing that you didn't say,

41:32.440 --> 41:36.200
 but we think of it as paramount for any deep relationship.

41:36.200 --> 41:37.760
 That's trust.

41:37.760 --> 41:38.600
 Trust, yeah.

41:38.600 --> 41:42.120
 So I think if you trust every attribute you said,

41:42.120 --> 41:46.000
 a fight, some tension is all healthy.

41:46.000 --> 41:51.000
 But what is sort of unnegotiable in this instance is trust.

41:51.400 --> 41:54.400
 And I think the bar to earn customer trust for AI

41:54.400 --> 41:57.960
 is very high, in some sense, more than a human.

41:57.960 --> 42:02.960
 It's not just about personal information or your data,

42:03.520 --> 42:06.560
 it's also about your actions on a daily basis.

42:06.560 --> 42:09.360
 How trustworthy are you in terms of consistency,

42:09.360 --> 42:12.600
 in terms of how accurate are you in understanding me?

42:12.600 --> 42:15.120
 Like if you're talking to a person on the phone,

42:15.120 --> 42:16.360
 if you have a problem with your,

42:16.360 --> 42:17.760
 let's say your internet or something,

42:17.760 --> 42:19.160
 if the person's not understanding,

42:19.160 --> 42:20.520
 you lose trust right away.

42:20.520 --> 42:22.560
 You don't want to talk to that person.

42:22.560 --> 42:25.920
 That whole example gets amplified by a factor of 10

42:25.920 --> 42:29.760
 because when you're a human interacting with an AI,

42:29.760 --> 42:31.240
 you have a certain expectation.

42:31.240 --> 42:33.560
 Either you expect it to be very intelligent

42:33.560 --> 42:35.760
 and then you get upset, why is it behaving this way?

42:35.760 --> 42:39.080
 Or you expect it to be not so intelligent

42:39.080 --> 42:40.320
 and when it surprises you are like,

42:40.320 --> 42:42.480
 really, you're trying to be too smart.

42:42.480 --> 42:45.240
 So I think we grapple with these hard questions as well,

42:45.240 --> 42:49.120
 but I think the key is actions need to be trustworthy

42:49.120 --> 42:52.160
 from these AIs, not just about data protection,

42:52.160 --> 42:54.720
 your personal information protection,

42:54.720 --> 42:58.560
 but also from how accurately it accomplishes

42:58.560 --> 43:01.080
 all commands or all interactions.

43:01.080 --> 43:03.560
 Well, it's tough to hear because trust,

43:03.560 --> 43:04.480
 you're absolutely right,

43:04.480 --> 43:06.920
 but trust is such a high bar with AI systems

43:06.920 --> 43:08.760
 because people, and I see this

43:08.760 --> 43:10.200
 because I work with autonomous vehicles,

43:10.200 --> 43:13.000
 I mean, the bar that's placed on AI system

43:13.000 --> 43:14.800
 is unreasonably high.

43:14.800 --> 43:17.400
 Yeah, that is going to be, I agree with you.

43:17.400 --> 43:21.280
 And I think of it as, it's a challenge

43:21.280 --> 43:24.240
 and it's also keeps my job, right?

43:24.240 --> 43:27.520
 So from that perspective, I totally,

43:27.520 --> 43:31.320
 I think of it at both sides as a customer and as a researcher.

43:31.320 --> 43:32.840
 I think as a researcher,

43:32.840 --> 43:34.760
 yes, occasionally it will frustrate me

43:34.760 --> 43:38.080
 that why is the bar so high for these AIs?

43:38.080 --> 43:40.400
 And as a customer, then I say absolutely

43:40.400 --> 43:42.080
 it has to be that high, right?

43:42.080 --> 43:45.200
 So I think that's the trade off we have to balance,

43:45.200 --> 43:47.760
 but doesn't change the fundamentals

43:47.760 --> 43:49.560
 that trust has to be earned.

43:49.560 --> 43:52.120
 And the question then becomes is,

43:52.120 --> 43:54.200
 are we holding the AIs to a different bar

43:54.200 --> 43:57.000
 in accuracy and mistakes than we hold humans?

43:57.000 --> 43:59.000
 That's going to be a great societal questions

43:59.000 --> 44:01.080
 for years to come, I think for us.

44:01.080 --> 44:02.960
 Well, one of the questions that we grapple

44:02.960 --> 44:06.200
 as a society now that I think about a lot,

44:06.200 --> 44:08.560
 I think a lot of people in the AI think about a lot

44:08.560 --> 44:12.400
 and Alexis taking on head on is privacy.

44:12.400 --> 44:17.400
 Is the reality is us giving over data

44:18.040 --> 44:23.040
 to any AI system can be used to enrich our lives

44:23.360 --> 44:25.840
 in profound ways.

44:25.840 --> 44:28.560
 So if basically any product that does anything awesome

44:28.560 --> 44:31.720
 for you, the more data has,

44:31.720 --> 44:34.080
 the more awesome things it can do.

44:34.080 --> 44:37.080
 And yet, at the other side,

44:37.080 --> 44:39.480
 people imagine the worst case possible scenario

44:39.480 --> 44:42.240
 of what can you possibly do with that data?

44:42.240 --> 44:45.680
 People, it boils down to trust, as you said before.

44:45.680 --> 44:47.240
 There's a fundamental distrust

44:47.240 --> 44:50.440
 of in certain groups of governments and so on,

44:50.440 --> 44:52.920
 depending on the government, depending on who's empowered,

44:52.920 --> 44:55.400
 depending on all these kinds of factors.

44:55.400 --> 44:57.920
 And so here's Alexa in the middle of all of it

44:59.040 --> 45:02.320
 in the home trying to do good things for the customers.

45:02.320 --> 45:05.000
 So how do you think about privacy in this context,

45:05.000 --> 45:06.720
 the smart assistance in the home?

45:06.720 --> 45:08.680
 How do you maintain, how do you earn trust?

45:08.680 --> 45:12.400
 Absolutely, so as you said, trust is the key here.

45:12.400 --> 45:15.360
 So you start with trust and then privacy

45:15.360 --> 45:16.760
 is a key aspect of it.

45:16.760 --> 45:20.240
 It has to be designed from very beginning about that.

45:20.240 --> 45:23.920
 And we believe in two fundamental principles.

45:23.920 --> 45:26.840
 One is transparency and second is control.

45:26.840 --> 45:30.720
 So by transparency, I mean when we build

45:30.720 --> 45:33.360
 what is now called smart speaker or the first echo.

45:34.360 --> 45:38.400
 We were quite judicious about making these right tradeoffs

45:38.400 --> 45:41.960
 on customers behalf that it is pretty clear

45:41.960 --> 45:44.200
 when the audio is being sent to cloud.

45:44.200 --> 45:46.520
 The light ring comes on when it has heard you say

45:46.520 --> 45:49.760
 the word wake word and then the streaming happens, right?

45:49.760 --> 45:52.200
 So when the light ring comes up, we also had,

45:52.200 --> 45:55.520
 we put a physical mute button on it,

45:55.520 --> 45:57.880
 just so if you didn't want it to be listening,

45:57.880 --> 45:58.720
 even for the wake word,

45:58.720 --> 46:01.760
 then you turn the mute button on

46:01.760 --> 46:04.920
 and that disables the microphones.

46:04.920 --> 46:06.600
 That's just the first decision

46:06.600 --> 46:09.720
 on essentially transparency and control.

46:09.720 --> 46:11.720
 Over then, even when we launched,

46:11.720 --> 46:13.800
 we gave the control in the hands of the customers

46:13.800 --> 46:16.360
 that you can go and look at any of your individual utterances

46:16.360 --> 46:19.560
 that is recorded and delete them anytime.

46:19.560 --> 46:22.520
 And we've got to do that promise, right?

46:22.520 --> 46:26.000
 So and that is super, again, a great instance

46:26.000 --> 46:29.080
 of showing how you have the control.

46:29.080 --> 46:30.440
 Then we made it even easier.

46:30.440 --> 46:33.080
 You can say, like I said, delete what I said today.

46:33.080 --> 46:36.880
 So that is now making it even just more control

46:36.880 --> 46:39.360
 in your hands with what's most convenient

46:39.360 --> 46:42.000
 about this technology is voice.

46:42.000 --> 46:44.400
 You delete it with your voice now.

46:44.400 --> 46:48.040
 So these are the types of decisions we continually make.

46:48.040 --> 46:51.200
 We just recently launched this feature called

46:51.200 --> 46:53.680
 what we think of it as if you wanted humans

46:53.680 --> 46:57.960
 not to review your data because you mentioned

46:57.960 --> 46:59.120
 supervised learning, right?

46:59.120 --> 47:01.120
 So in supervised learning,

47:01.120 --> 47:03.760
 humans have to give some annotation.

47:03.760 --> 47:07.080
 And that also is now a feature where you can,

47:07.080 --> 47:09.280
 essentially, if you've selected that flag,

47:09.280 --> 47:11.280
 your data will not be reviewed by a human.

47:11.280 --> 47:13.600
 So these are the types of controls

47:13.600 --> 47:17.440
 that we have to constantly offer with customers.

47:18.400 --> 47:22.760
 So why do you think it bothers people so much

47:22.760 --> 47:26.840
 that, so everything you just said is really powerful.

47:26.840 --> 47:28.320
 So the control, the ability to delete,

47:28.320 --> 47:31.080
 because we collect, we have studies here running at MIT

47:31.080 --> 47:32.720
 that collects huge amounts of data

47:32.720 --> 47:34.800
 and people consent and so on.

47:34.800 --> 47:38.000
 The ability to delete that data is really empowering.

47:38.000 --> 47:39.960
 And almost nobody ever asked to delete it,

47:39.960 --> 47:44.160
 but the ability to have that control is really powerful.

47:44.160 --> 47:47.920
 But still, there's these popular anecdotal evidence

47:47.920 --> 47:50.920
 that people say they like to tell that

47:50.920 --> 47:53.120
 them and a friend were talking about something,

47:53.120 --> 47:56.080
 I don't know, sweaters for cats.

47:56.080 --> 47:58.160
 And all of a sudden they'll have advertisements

47:58.160 --> 48:00.960
 for cat sweaters on Amazon.

48:00.960 --> 48:02.640
 There's that, that's a popular anecdote

48:02.640 --> 48:04.640
 as if something is always listening.

48:06.280 --> 48:07.760
 Can you explain that anecdote,

48:07.760 --> 48:09.080
 that experience that people have?

48:09.080 --> 48:10.960
 What's the psychology of that?

48:10.960 --> 48:13.040
 What's that experience?

48:13.040 --> 48:15.040
 And can you, you've answered it,

48:15.040 --> 48:18.240
 but let me just ask, is Alexa listening?

48:18.240 --> 48:22.520
 No, Alexa listens only for the wake word on the device, right?

48:22.520 --> 48:23.880
 And the wake word is?

48:23.880 --> 48:27.240
 The words like Alexa, Amazon, Echo,

48:27.240 --> 48:29.600
 and you, but you only choose one at a time.

48:29.600 --> 48:31.600
 So you choose one and it listens only

48:31.600 --> 48:32.960
 for that on our devices.

48:34.000 --> 48:36.440
 So that's first, from a listening perspective,

48:36.440 --> 48:38.360
 you have to be very clear that it's just the wake word.

48:38.360 --> 48:41.240
 So you said, why is there this anxiety, if you may?

48:41.240 --> 48:42.080
 Yeah, exactly.

48:42.080 --> 48:43.560
 It's because there's a lot of confusion

48:43.560 --> 48:45.320
 what it really listens to, right?

48:45.320 --> 48:48.680
 And I think it's partly on us to keep educating

48:48.680 --> 48:52.200
 our customers and the general media more

48:52.200 --> 48:54.040
 in terms of like what really happens

48:54.040 --> 48:55.720
 and we've done a lot of it.

48:56.560 --> 49:00.800
 And our pages on information are clear,

49:00.800 --> 49:04.000
 but still people have to have more,

49:04.000 --> 49:06.640
 there's always a hunger for information and clarity.

49:06.640 --> 49:09.080
 And we'll constantly look at how best to communicate.

49:09.080 --> 49:10.520
 If you go back and read everything,

49:10.520 --> 49:12.240
 yes, it states exactly that.

49:12.240 --> 49:14.840
 And then people could still question it.

49:14.840 --> 49:17.440
 And I think that's absolutely okay to question.

49:17.440 --> 49:21.160
 What we have to make sure is that we are,

49:21.160 --> 49:24.320
 because our fundamental philosophy is customer first,

49:24.320 --> 49:26.720
 customer obsession is our leadership principle.

49:26.720 --> 49:29.520
 If you put, as researchers,

49:29.520 --> 49:32.680
 I put myself in the shoes of the customer

49:32.680 --> 49:36.520
 and all decisions in Amazon are made with that and that.

49:36.520 --> 49:37.520
 And trust has to be earned

49:37.520 --> 49:38.920
 and we have to keep earning the trust

49:38.920 --> 49:41.320
 of our customers in this setting.

49:41.320 --> 49:44.040
 And to your other point on like,

49:44.040 --> 49:45.520
 is there something showing up

49:45.520 --> 49:46.640
 based on your conversations?

49:46.640 --> 49:49.600
 No, I think the answer is like you,

49:49.600 --> 49:51.360
 a lot of times when those experiences happen,

49:51.360 --> 49:52.800
 you have to also be know that, okay,

49:52.800 --> 49:54.560
 it may be a winter season,

49:54.560 --> 49:56.440
 people are looking for sweaters, right?

49:56.440 --> 49:58.520
 And it shows up on your Amazon.com

49:58.520 --> 49:59.640
 because it is popular.

49:59.640 --> 50:01.440
 So there are many of these,

50:02.720 --> 50:06.320
 you mentioned that personality or personalization.

50:06.320 --> 50:09.120
 Turns out we are not that unique either, right?

50:09.120 --> 50:12.040
 So those things we, as humans, start thinking,

50:12.040 --> 50:14.120
 oh, must be because something was heard

50:14.120 --> 50:16.680
 and that's why this other thing showed up.

50:16.680 --> 50:17.720
 The answer is no.

50:17.720 --> 50:21.520
 Probably it is just the season for sweaters.

50:21.520 --> 50:23.800
 I'm not gonna ask you this question

50:23.800 --> 50:25.840
 because it's just, because you're also,

50:25.840 --> 50:27.160
 because people have so much paranoia.

50:27.160 --> 50:29.200
 But for my, let me just say, from my perspective,

50:29.200 --> 50:31.760
 I hope there's a day when the customer

50:31.760 --> 50:34.240
 can ask Alexa to listen all the time

50:35.200 --> 50:37.360
 to improve the experience, to improve,

50:37.360 --> 50:39.800
 because I personally don't see the negative

50:40.800 --> 50:42.160
 because if you have the control

50:42.160 --> 50:43.920
 and if you have the trust,

50:43.920 --> 50:45.640
 there's no reason why I shouldn't be listening

50:45.640 --> 50:47.040
 all the time to the conversations

50:47.040 --> 50:48.320
 to learn more about you.

50:48.320 --> 50:53.320
 Because ultimately, as long as you have control and trust,

50:53.840 --> 50:56.920
 every data you provide to the device

50:56.920 --> 51:01.280
 that the device wants is going to be useful.

51:01.280 --> 51:05.080
 And so to me, as a machine learning person,

51:05.080 --> 51:09.480
 I think it worries me how sensitive people are

51:09.480 --> 51:14.480
 about their data relative to how empowering

51:18.560 --> 51:21.440
 it could be for the devices around them,

51:21.440 --> 51:23.720
 enriching it could be for their own life

51:23.720 --> 51:25.440
 to improve the product.

51:25.440 --> 51:28.320
 So it's something I think about sort of a lot,

51:28.320 --> 51:29.520
 how do we make that devices?

51:29.520 --> 51:32.200
 Obviously Alexa thinks about it a lot as well.

51:32.200 --> 51:34.200
 I don't know if you wanna comment on that.

51:34.200 --> 51:37.080
 So have you seen, let me ask it in the form of a question.

51:37.080 --> 51:40.200
 Okay, have you seen an evolution

51:40.200 --> 51:44.200
 in the way people think about their private data

51:44.200 --> 51:46.400
 in the previous several years?

51:46.400 --> 51:48.680
 So as we as a society get more and more comfortable

51:48.680 --> 51:52.600
 to the benefits we get by sharing more data.

51:53.520 --> 51:55.080
 First, let me answer that part

51:55.080 --> 51:55.960
 and then I'll wanna go back

51:55.960 --> 51:58.480
 to the other aspect you were mentioning.

51:58.480 --> 52:01.200
 So as a society, on a general,

52:01.200 --> 52:03.120
 we are getting more comfortable as a society.

52:03.120 --> 52:05.840
 Doesn't mean that everyone is

52:05.840 --> 52:07.400
 and I think we have to respect that.

52:07.400 --> 52:10.320
 I don't think one size fits all

52:10.320 --> 52:13.480
 is always gonna be the answer for all, right?

52:13.480 --> 52:14.320
 By definition.

52:14.320 --> 52:17.160
 So I think that's something to keep in mind in these.

52:17.160 --> 52:22.160
 Going back to your on what more magical experiences

52:22.800 --> 52:26.040
 can be launched in these kind of AI settings.

52:26.040 --> 52:28.640
 I think again, if you give the control,

52:29.960 --> 52:32.080
 it's possible certain parts of it.

52:32.080 --> 52:33.960
 So we have a feature called followup mode

52:33.960 --> 52:38.320
 where if you turn it on and Alexa,

52:38.320 --> 52:42.000
 after you've spoken to it will open the mics again,

52:42.000 --> 52:44.680
 thinking you will answer something again.

52:44.680 --> 52:48.560
 Like if you're adding lists to your shopping items,

52:48.560 --> 52:51.440
 shopping list or to do list, you're not done.

52:51.440 --> 52:52.280
 You want to keep.

52:52.280 --> 52:53.600
 So in that setting, it's awesome

52:53.600 --> 52:56.200
 that it opens the mic for you to say eggs and milk

52:56.200 --> 52:57.160
 and then bread, right?

52:57.160 --> 52:59.920
 So these are the kind of things which you can empower.

52:59.920 --> 53:02.320
 So, and then another feature we have

53:02.320 --> 53:04.960
 which is called Alexa guard.

53:04.960 --> 53:07.800
 I said it only listens for the wake word, all right?

53:07.800 --> 53:10.480
 But if you have a, let's say you're going to say,

53:10.480 --> 53:13.080
 Alexa, you leave your home and you want Alexa

53:13.080 --> 53:15.040
 to listen for a couple of sound events

53:15.040 --> 53:17.200
 like smoke alarm going off

53:17.200 --> 53:19.280
 or someone breaking your glass, right?

53:19.280 --> 53:22.160
 So it's like just to keep your peace of mind.

53:22.160 --> 53:25.880
 So you can say Alexa on guard or I'm away

53:25.880 --> 53:29.240
 or and then it can be listening for these sound events.

53:29.240 --> 53:33.040
 And when you're home, you come out of that mode, right?

53:33.040 --> 53:35.560
 So this is another one where you again gave controls

53:35.560 --> 53:38.040
 in the hands of the user or the customer

53:38.040 --> 53:42.440
 and to enable some experience that is high utility

53:42.440 --> 53:44.600
 and maybe even more delightful in the certain settings

53:44.600 --> 53:46.600
 like follow up mode and so forth.

53:46.600 --> 53:48.880
 And again, this general principle is the same,

53:48.880 --> 53:50.760
 control in the hands of the customer.

53:52.640 --> 53:55.480
 So I know we kind of started with a lot of philosophy

53:55.480 --> 53:56.840
 and a lot of interesting topics

53:56.840 --> 53:58.280
 and we're just jumping all over the place.

53:58.280 --> 54:00.280
 But really some of the fascinating things

54:00.280 --> 54:03.000
 that the Alexa team and Amazon is doing

54:03.000 --> 54:05.440
 is in the algorithm side, the data side,

54:05.440 --> 54:07.480
 the technology, the deep learning, machine learning

54:07.480 --> 54:08.840
 and so on.

54:08.840 --> 54:13.000
 So can you give a brief history of Alexa

54:13.000 --> 54:15.400
 from the perspective of just innovation,

54:15.400 --> 54:18.600
 the algorithms, the data of how it was born,

54:18.600 --> 54:22.240
 how it came to be, how it has grown, where it is today?

54:22.240 --> 54:24.280
 Yeah, it starts with the, in Amazon,

54:24.280 --> 54:26.960
 everything starts with the customer.

54:26.960 --> 54:30.280
 And we have a process called working backwards.

54:30.280 --> 54:35.000
 Alexa, and more specifically than the product Echo,

54:35.000 --> 54:37.280
 there was a working backwards document essentially

54:37.280 --> 54:38.840
 that reflected what it would be,

54:38.840 --> 54:43.840
 started with a very simple vision statement, for instance,

54:44.240 --> 54:47.120
 that morphed into a full fledged document

54:47.120 --> 54:51.040
 along the way it changed into what all it can do, right?

54:51.040 --> 54:54.120
 You can, but the inspiration was the Star Trek computer.

54:54.120 --> 54:56.080
 So when you think of it that way,

54:56.080 --> 54:58.240
 everything is possible, but when you launch a product,

54:58.240 --> 55:00.920
 you have to start with someplace.

55:00.920 --> 55:05.400
 And when I joined, the product was already in conception

55:05.400 --> 55:08.800
 and we started working on the far field speech recognition

55:08.800 --> 55:10.800
 because that was the first thing to solve.

55:10.800 --> 55:12.760
 By that we mean that you should be able to speak

55:12.760 --> 55:15.160
 to the device from a distance.

55:15.160 --> 55:18.720
 And in those days, that wasn't a common practice.

55:18.720 --> 55:22.240
 And even in the previous research world I was in,

55:22.240 --> 55:24.520
 was considered to an unsolvable problem then

55:24.520 --> 55:28.280
 in terms of whether you can converse from a length.

55:28.280 --> 55:30.280
 And here I'm still talking about the first part

55:30.280 --> 55:32.360
 of the problem where you say,

55:32.360 --> 55:34.000
 get the attention of the device,

55:34.000 --> 55:37.040
 as in by saying what we call the wake word,

55:37.040 --> 55:40.320
 which means the word Alexa has to be detected

55:40.320 --> 55:44.800
 with a very high accuracy because it is a very common word.

55:44.800 --> 55:48.200
 It has sound units that map with words like I like you

55:48.200 --> 55:51.080
 or Alec, Alex, right?

55:51.080 --> 55:56.080
 So it's an undoubtedly hard problem to detect

55:56.240 --> 56:00.560
 the right mentions of Alexa's address to the device

56:00.560 --> 56:02.880
 versus I like Alexa.

56:02.880 --> 56:04.280
 So you have to pick up that signal

56:04.280 --> 56:06.120
 when there's a lot of noise.

56:06.120 --> 56:09.360
 Not only noise, but a lot of conversation in the house, right?

56:09.360 --> 56:10.360
 You remember on the device,

56:10.360 --> 56:13.240
 you're simply listening for the wake word Alexa.

56:13.240 --> 56:15.840
 And there's a lot of words being spoken in the house.

56:15.840 --> 56:18.120
 How do you know it's Alexa?

56:18.120 --> 56:21.800
 And directed at Alexa.

56:21.800 --> 56:23.680
 Because I could say, I love my Alexa.

56:23.680 --> 56:25.400
 I hate my Alexa.

56:25.400 --> 56:27.080
 I want Alexa to do this.

56:27.080 --> 56:29.360
 And in all these three sentences I said Alexa,

56:29.360 --> 56:31.400
 I didn't want it to wake up.

56:31.400 --> 56:33.800
 So can I just pause on that second?

56:33.800 --> 56:36.760
 What would be your device that I should probably

56:36.760 --> 56:40.000
 in the introduction of this conversation give to people

56:40.000 --> 56:43.560
 in terms of with them turning off their Alexa device,

56:43.560 --> 56:48.560
 if they're listening to this podcast conversation out loud?

56:49.360 --> 56:51.720
 Like what's the probability that an Alexa device

56:51.720 --> 56:53.440
 will go off because we mentioned Alexa

56:53.440 --> 56:55.240
 like a million times.

56:55.240 --> 56:58.200
 So it will, we have done a lot of different things

56:58.200 --> 57:03.200
 where we can figure out that there is the device,

57:03.800 --> 57:08.280
 the speech is coming from a human versus over the air.

57:08.280 --> 57:11.800
 Also, I mean, in terms of like also it is think about ads

57:11.800 --> 57:14.280
 or so we also launched a technology

57:14.280 --> 57:16.320
 for watermarking kind of approaches

57:16.320 --> 57:18.840
 in terms of filtering it out.

57:18.840 --> 57:21.640
 But yes, if this kind of a podcast is happening,

57:21.640 --> 57:24.400
 it's possible your device will wake up a few times, right?

57:24.400 --> 57:27.920
 It's an unsolved problem, but it is definitely

57:28.840 --> 57:31.080
 something we care very much about.

57:31.080 --> 57:33.920
 But the idea is you want to detect Alexa.

57:33.920 --> 57:35.720
 Meant for the device.

57:35.720 --> 57:37.600
 I mean, first of all, just even hearing Alexa

57:37.600 --> 57:41.080
 versus I like something, I mean, that's a fascinating part.

57:41.080 --> 57:43.120
 So that was the first relief.

57:43.120 --> 57:43.960
 That's the first.

57:43.960 --> 57:46.040
 The world's best detector of Alexa.

57:46.040 --> 57:48.760
 Yeah, the world's best wake word detector

57:48.760 --> 57:51.120
 in a far field setting, not like something

57:51.120 --> 57:53.880
 where the phone is sitting on the table.

57:53.880 --> 57:56.720
 This is like people have devices 40 feet away,

57:56.720 --> 57:58.400
 like in my house or 20 feet away

57:58.400 --> 58:00.680
 and you still get an answer.

58:00.680 --> 58:02.480
 So that was the first part.

58:02.480 --> 58:05.880
 The next is, okay, you're speaking to the device.

58:05.880 --> 58:09.040
 Of course, you're gonna issue many different requests.

58:09.040 --> 58:11.560
 Some may be simple, some may be extremely hard,

58:11.560 --> 58:13.760
 but it's a large vocabulary speech recognition problem,

58:13.760 --> 58:17.640
 essentially, where the audio is now not coming

58:17.640 --> 58:20.360
 onto your phone or a handheld mic like this

58:20.360 --> 58:23.880
 or a close talking mic, but it's from 20 feet away

58:23.880 --> 58:26.280
 where if you're in a busy household,

58:26.280 --> 58:28.880
 your son may be listening to music,

58:28.880 --> 58:31.640
 your daughter may be running around with something

58:31.640 --> 58:33.840
 and asking your mom something and so forth, right?

58:33.840 --> 58:36.400
 So this is like a common household setting

58:36.400 --> 58:40.200
 where the words you're speaking to Alexa

58:40.200 --> 58:43.400
 need to be recognized with very high accuracy, right?

58:43.400 --> 58:45.800
 Now, we're still just in the recognition problem.

58:45.800 --> 58:48.160
 You haven't yet come to the understanding one, right?

58:48.160 --> 58:50.160
 And if we pause them, sorry, once again,

58:50.160 --> 58:53.880
 what year was this, is this before neural networks

58:53.880 --> 58:58.480
 began to start to seriously prove themselves

58:58.480 --> 59:00.480
 in the audio space?

59:00.480 --> 59:05.480
 Yeah, this is around, so I joined in 2013 in April, right?

59:05.480 --> 59:08.800
 So the early research in neural networks coming back

59:08.800 --> 59:11.240
 and showing some promising results

59:11.240 --> 59:13.560
 in speech recognition space had started happening,

59:13.560 --> 59:15.360
 but it was very early.

59:15.360 --> 59:20.000
 But we just now build on that on the very first thing we did

59:20.000 --> 59:23.800
 when I joined the team and remember,

59:23.800 --> 59:25.960
 it was a very much of a startup environment,

59:25.960 --> 59:28.080
 which is great about Amazon.

59:28.080 --> 59:31.240
 And we doubled on deep learning right away

59:31.240 --> 59:36.240
 and we knew we'll have to improve accuracy fast.

59:36.600 --> 59:39.920
 And because of that, we worked on and the scale of data

59:39.920 --> 59:43.240
 once you have a device like this, if it is successful,

59:43.240 --> 59:44.960
 will improve big time.

59:44.960 --> 59:48.040
 Like you'll suddenly have large volumes of data

59:48.040 --> 59:51.080
 to learn from to make the customer experience better.

59:51.080 --> 59:52.480
 So how do you scale deep learning?

59:52.480 --> 59:54.560
 So we did one of the first works

59:54.560 --> 59:57.600
 in training with distributed GPUs

59:57.600 --> 1:00:01.480
 and where the training time was linear

1:00:01.480 --> 1:00:04.000
 in terms of like in the amount of data.

1:00:04.000 --> 1:00:06.240
 So that was quite important work

1:00:06.240 --> 1:00:07.840
 where it was algorithmic improvements

1:00:07.840 --> 1:00:09.920
 as well as a lot of engineering improvements

1:00:09.920 --> 1:00:14.040
 to be able to train on thousands and thousands of speech.

1:00:14.040 --> 1:00:15.600
 And that was an important factor.

1:00:15.600 --> 1:00:19.360
 So if you ask me like back in 2013 and 2014

1:00:19.360 --> 1:00:22.440
 when we launched Echo,

1:00:22.440 --> 1:00:25.680
 the combination of large scale data,

1:00:25.680 --> 1:00:29.720
 deep learning progress, near infinite GPUs

1:00:29.720 --> 1:00:33.120
 we had available on AWS even then

1:00:33.120 --> 1:00:36.400
 was all came together for us to be able to

1:00:36.400 --> 1:00:38.400
 solve the far field speech recognition

1:00:38.400 --> 1:00:40.600
 to the extent it could be useful to the customers.

1:00:40.600 --> 1:00:41.440
 It's still not solved.

1:00:41.440 --> 1:00:44.520
 Like I mean, it's not that we are perfect at recognizing speech

1:00:44.520 --> 1:00:46.800
 but we are great at it in terms of the settings

1:00:46.800 --> 1:00:48.360
 that are in homes, right?

1:00:48.360 --> 1:00:50.920
 So and that was important even in the early stages.

1:00:50.920 --> 1:00:53.360
 So first of all, just even I'm trying to look back

1:00:53.360 --> 1:00:58.360
 at that time, if I remember correctly it was,

1:00:58.760 --> 1:01:02.080
 it seems like the task would be pretty daunting.

1:01:02.080 --> 1:01:06.320
 So like, so we kind of take it for granted that it works now.

1:01:06.320 --> 1:01:07.640
 Yes, so you're right.

1:01:07.640 --> 1:01:10.800
 So let me like how, first of all you mentioned startup

1:01:10.800 --> 1:01:12.800
 I wasn't familiar how big the team was.

1:01:12.800 --> 1:01:15.200
 I kind of, because I know there's a lot of really smart

1:01:15.200 --> 1:01:16.040
 people working on it.

1:01:16.040 --> 1:01:17.760
 So now it's very, very large team.

1:01:19.240 --> 1:01:20.760
 How big was the team?

1:01:20.760 --> 1:01:24.400
 How likely were you to fail in the highs of everyone else?

1:01:25.400 --> 1:01:26.720
 And ourselves?

1:01:26.720 --> 1:01:28.560
 And yourself, so like what?

1:01:28.560 --> 1:01:31.560
 I'll give you a very interesting anecdote on that.

1:01:31.560 --> 1:01:35.360
 When I joined the team, the speech recognition team

1:01:35.360 --> 1:01:38.840
 was six people, my first meeting

1:01:38.840 --> 1:01:41.640
 and we had hired a few more people, it was 10 people.

1:01:42.920 --> 1:01:47.960
 Nine out of 10 people thought it can't be done, right?

1:01:47.960 --> 1:01:48.800
 Who was the one?

1:01:48.800 --> 1:01:52.960
 The one was me, say, actually I should say,

1:01:52.960 --> 1:01:58.960
 and one was semi optimistic and eight were trying to convince

1:01:59.120 --> 1:02:01.720
 let's go to the management and say,

1:02:01.720 --> 1:02:03.600
 let's not work on this problem,

1:02:03.600 --> 1:02:07.720
 let's work on some other problem like either telephony speech

1:02:07.720 --> 1:02:10.160
 for customer service calls and so forth.

1:02:10.160 --> 1:02:12.040
 But this is the kind of belief you must have.

1:02:12.040 --> 1:02:14.320
 And I had experience with far field speech recognition

1:02:14.320 --> 1:02:17.720
 and my eyes lit up when I saw a problem like that saying,

1:02:17.720 --> 1:02:20.840
 okay, we have been in speech recognition

1:02:20.840 --> 1:02:23.400
 always looking for that killer app.

1:02:23.400 --> 1:02:25.840
 And this was a killer use case

1:02:25.840 --> 1:02:28.840
 to bring something delightful in the hands of customers.

1:02:28.840 --> 1:02:31.160
 So you mentioned the way you kind of think of it

1:02:31.160 --> 1:02:32.640
 in the product way in the future,

1:02:32.640 --> 1:02:35.760
 have a press release and an FAQ and you think backwards.

1:02:35.760 --> 1:02:39.880
 Did you have, did the team have the echo in mind?

1:02:41.000 --> 1:02:43.040
 So this far field speech recognition,

1:02:43.040 --> 1:02:45.360
 actually putting a thing in the home that works

1:02:45.360 --> 1:02:46.640
 that's able to interact with,

1:02:46.640 --> 1:02:48.200
 was that the press release?

1:02:48.200 --> 1:02:49.040
 What was the...

1:02:49.040 --> 1:02:51.480
 Very close, I would say in terms of the,

1:02:51.480 --> 1:02:54.840
 as I said, the vision was start a computer, right?

1:02:54.840 --> 1:02:56.920
 So, or the inspiration.

1:02:56.920 --> 1:03:00.640
 And from there, I can't divulge all the exact specifications,

1:03:00.640 --> 1:03:05.640
 but one of the first things that was magical on Alexa

1:03:07.240 --> 1:03:08.840
 was music.

1:03:08.840 --> 1:03:11.200
 It brought me to back to music

1:03:11.200 --> 1:03:14.240
 because my taste is still in when I was an undergrad.

1:03:14.240 --> 1:03:15.640
 So I still listen to those songs

1:03:15.640 --> 1:03:18.440
 and I, it was too hard for me

1:03:18.440 --> 1:03:21.440
 to be a music fan with a phone, right?

1:03:21.440 --> 1:03:24.240
 So I hate things in my ears.

1:03:24.240 --> 1:03:28.160
 So from that perspective, it was quite hard

1:03:28.160 --> 1:03:30.600
 and music was part of the,

1:03:32.040 --> 1:03:33.680
 at least the documents I've seen, right?

1:03:33.680 --> 1:03:36.160
 So from that perspective, I think, yes,

1:03:36.160 --> 1:03:40.680
 in terms of how far are we from the original vision?

1:03:40.680 --> 1:03:42.080
 I can't reveal that,

1:03:42.080 --> 1:03:44.560
 but that's why I have done a fun at work

1:03:44.560 --> 1:03:46.440
 because every day we go in

1:03:46.440 --> 1:03:49.040
 and thinking like these are the new set of challenges to solve.

1:03:49.040 --> 1:03:51.880
 Yeah, it's a great way to do great engineering

1:03:51.880 --> 1:03:53.600
 as you think of the product, the press release.

1:03:53.600 --> 1:03:55.000
 I like that idea actually.

1:03:55.000 --> 1:03:56.800
 Maybe we'll talk about it a bit later,

1:03:56.800 --> 1:03:59.280
 which is a super nice way to have a focus.

1:03:59.280 --> 1:04:01.360
 I'll tell you this, you're a scientist

1:04:01.360 --> 1:04:03.720
 and a lot of my scientists have adopted that.

1:04:03.720 --> 1:04:06.960
 They have now, they love it as a process

1:04:06.960 --> 1:04:08.400
 because it was very,

1:04:08.400 --> 1:04:10.920
 as scientists, you're trained to write great papers,

1:04:10.920 --> 1:04:13.480
 but they are all after you've done the research

1:04:13.480 --> 1:04:16.600
 or you've proven like, and your PhD dissertation proposal

1:04:16.600 --> 1:04:18.440
 is something that comes closest

1:04:18.440 --> 1:04:21.160
 or a DARPA proposal or a NSF proposal

1:04:21.160 --> 1:04:23.600
 is the closest that comes to a press release.

1:04:23.600 --> 1:04:27.000
 But that process is now ingrained in our scientists,

1:04:27.000 --> 1:04:29.760
 which is like delightful for me to see.

1:04:30.920 --> 1:04:33.040
 You write the paper first and then make it happen.

1:04:33.040 --> 1:04:33.880
 That's right.

1:04:33.880 --> 1:04:34.720
 I mean, in fact, it's not...

1:04:34.720 --> 1:04:36.280
 State of the art results.

1:04:36.280 --> 1:04:38.400
 Or you leave the results section open,

1:04:38.400 --> 1:04:41.640
 but you have a thesis about here's what I expect, right?

1:04:41.640 --> 1:04:44.920
 And here's what it will change, right?

1:04:44.920 --> 1:04:46.480
 So I think it is a great thing.

1:04:46.480 --> 1:04:48.160
 It works for researchers as well.

1:04:48.160 --> 1:04:49.000
 Yeah.

1:04:49.000 --> 1:04:50.680
 So far field recognition.

1:04:50.680 --> 1:04:52.320
 Yeah.

1:04:52.320 --> 1:04:53.840
 What was the big leap?

1:04:53.840 --> 1:04:55.400
 What were the breakthroughs

1:04:55.400 --> 1:04:58.360
 and what was that journey like to today?

1:04:58.360 --> 1:05:00.160
 Yeah, I think the, as you said first,

1:05:00.160 --> 1:05:01.560
 there was a lot of skepticism

1:05:01.560 --> 1:05:03.320
 on whether far field speech recognition

1:05:03.320 --> 1:05:06.440
 will ever work to be good enough, right?

1:05:06.440 --> 1:05:09.960
 And what we first did was got a lot of training data

1:05:09.960 --> 1:05:11.440
 in a far field setting.

1:05:11.440 --> 1:05:13.960
 And that was extremely hard to get

1:05:13.960 --> 1:05:16.120
 because none of it existed.

1:05:16.120 --> 1:05:20.040
 So how do you collect data in far field setup, right?

1:05:20.040 --> 1:05:21.360
 With no customer base at this time.

1:05:21.360 --> 1:05:22.600
 With no customer base, right?

1:05:22.600 --> 1:05:24.720
 So that was first innovation.

1:05:24.720 --> 1:05:27.200
 And once we had that, the next thing was, okay,

1:05:27.200 --> 1:05:30.680
 if you have the data, first of all,

1:05:30.680 --> 1:05:31.800
 we didn't talk about like,

1:05:31.800 --> 1:05:35.200
 what would magical mean in this kind of a setting?

1:05:35.200 --> 1:05:37.440
 What is good enough for customers, right?

1:05:37.440 --> 1:05:40.360
 That's always, since you've never done this before,

1:05:40.360 --> 1:05:41.560
 what would be magical?

1:05:41.560 --> 1:05:44.160
 So it wasn't just a research problem.

1:05:44.160 --> 1:05:47.600
 You had to put some, in terms of accuracy

1:05:47.600 --> 1:05:49.840
 and customer experience features,

1:05:49.840 --> 1:05:51.400
 some stakes on the ground saying,

1:05:51.400 --> 1:05:54.880
 here's where I think it should get to.

1:05:54.880 --> 1:05:55.960
 So you established a bar

1:05:55.960 --> 1:05:57.800
 and then how do you measure progress towards it?

1:05:57.800 --> 1:06:01.640
 Given you have no customers right now.

1:06:01.640 --> 1:06:04.120
 So from that perspective, we went,

1:06:04.120 --> 1:06:07.480
 so first was the data without customers.

1:06:07.480 --> 1:06:11.840
 Second was doubling down on deep learning as a way to learn.

1:06:11.840 --> 1:06:16.080
 And I can just tell you that the combination of the two

1:06:16.080 --> 1:06:19.120
 got our error rates by a factor of five.

1:06:19.120 --> 1:06:22.200
 From where we were when I started to,

1:06:22.200 --> 1:06:24.240
 within six months of having that data,

1:06:24.240 --> 1:06:28.320
 we, at that point, I got the conviction

1:06:28.320 --> 1:06:29.840
 that this will work, right?

1:06:29.840 --> 1:06:31.560
 So because that was magical

1:06:31.560 --> 1:06:33.760
 in terms of when it started working.

1:06:33.760 --> 1:06:37.640
 And that reached the magic bar, became close to the magical bar.

1:06:37.640 --> 1:06:39.440
 That to the bar, right?

1:06:39.440 --> 1:06:44.200
 That we felt would be where people will use it,

1:06:44.200 --> 1:06:45.280
 which was critical.

1:06:45.280 --> 1:06:48.800
 Because you really have one chance at this.

1:06:48.800 --> 1:06:50.480
 If we had launched in November,

1:06:50.480 --> 1:06:51.840
 2014 is when we launched,

1:06:51.840 --> 1:06:53.040
 if it was below the bar,

1:06:53.040 --> 1:06:58.040
 I don't think this category exists if you don't meet the bar.

1:06:58.040 --> 1:07:02.000
 Yeah, and just having looked at voice based interactions,

1:07:02.000 --> 1:07:05.960
 like in the car or earlier systems,

1:07:05.960 --> 1:07:08.280
 it's a source of huge frustration for people.

1:07:08.280 --> 1:07:10.280
 In fact, we use voice based interaction

1:07:10.280 --> 1:07:14.600
 for collecting data on subjects to measure frustration.

1:07:14.600 --> 1:07:18.240
 So as a training set for computer vision, for face data,

1:07:18.240 --> 1:07:20.600
 so we can get a data set of frustrated people.

1:07:20.600 --> 1:07:22.240
 That's the best way to get frustrated people

1:07:22.240 --> 1:07:25.520
 is having them interact with a voice based system in the car.

1:07:25.520 --> 1:07:28.520
 So that bar, I imagine, was pretty high.

1:07:28.520 --> 1:07:29.480
 It was very high.

1:07:29.480 --> 1:07:32.720
 And we talked about how also errors are perceived

1:07:32.720 --> 1:07:35.400
 from AIs versus errors by humans.

1:07:36.920 --> 1:07:39.880
 But we are not done with the problems that ended up,

1:07:39.880 --> 1:07:41.200
 we had to solve to get it to launch.

1:07:41.200 --> 1:07:42.640
 So do you want the next one?

1:07:42.640 --> 1:07:44.040
 Yeah, the next one.

1:07:44.040 --> 1:07:45.640
 No.

1:07:45.640 --> 1:07:49.480
 So the next one was what I think of as

1:07:49.480 --> 1:07:52.480
 multi domain natural language understanding.

1:07:52.480 --> 1:07:54.720
 It's very, I wouldn't say easy,

1:07:54.720 --> 1:07:57.480
 but it is during those days,

1:07:57.480 --> 1:08:02.480
 solving it, understanding in one domain, a narrow domain,

1:08:02.800 --> 1:08:07.520
 was doable, but for these multiple domains,

1:08:07.520 --> 1:08:10.160
 like music, like information,

1:08:10.160 --> 1:08:14.080
 other kinds of household productivity, alarms, timers,

1:08:14.080 --> 1:08:15.760
 even though it wasn't as big as it is,

1:08:15.760 --> 1:08:17.400
 in terms of the number of skills Alexa has

1:08:17.400 --> 1:08:22.400
 in the confusion space has grown by three hours of magnitude,

1:08:22.400 --> 1:08:24.680
 it was still daunting even those days.

1:08:24.680 --> 1:08:26.320
 Again, no customer base yet.

1:08:26.320 --> 1:08:27.920
 Again, no customer base.

1:08:27.920 --> 1:08:29.880
 So now you're looking at meaning understanding

1:08:29.880 --> 1:08:31.880
 and intent understanding and taking actions

1:08:31.880 --> 1:08:35.080
 on behalf of customers based on their requests.

1:08:35.080 --> 1:08:37.920
 And that is the next hard problem.

1:08:37.920 --> 1:08:41.440
 Even if you have gotten the words recognized,

1:08:41.440 --> 1:08:43.000
 how do you make sense of them?

1:08:44.080 --> 1:08:48.920
 In those days, there was still a lot of emphasis

1:08:48.920 --> 1:08:52.360
 on rule based systems for writing grammar patterns

1:08:52.360 --> 1:08:53.880
 to understand the intent,

1:08:53.880 --> 1:08:57.160
 but we had a statistical first approach even then,

1:08:57.160 --> 1:08:58.760
 where for our language understanding,

1:08:58.760 --> 1:09:03.760
 we had in even those starting days an entity recognizer

1:09:04.240 --> 1:09:08.120
 and an intent classifier, which was all trained statistically.

1:09:08.120 --> 1:09:11.400
 In fact, we had to build the deterministic matching

1:09:11.400 --> 1:09:16.200
 as a follow up to fix bugs that statistical models have, right?

1:09:16.200 --> 1:09:18.240
 So it was just a different mindset

1:09:18.240 --> 1:09:22.040
 where we focused on data driven statistical understanding.

1:09:22.040 --> 1:09:24.760
 When's in the end if you have a huge data set?

1:09:24.760 --> 1:09:26.480
 Yes, it is contingent on that.

1:09:26.480 --> 1:09:29.160
 And that's why it came back to how do you get the data?

1:09:29.160 --> 1:09:32.520
 Before customers, the fact that this is why data

1:09:32.520 --> 1:09:35.360
 becomes crucial to get to the point

1:09:35.360 --> 1:09:40.160
 that you have the understanding system built in, built up.

1:09:40.160 --> 1:09:44.560
 And notice that we were talking about human machine dialogue

1:09:44.560 --> 1:09:46.840
 and even those early days,

1:09:46.840 --> 1:09:49.320
 even it was very much transactional,

1:09:49.320 --> 1:09:52.600
 do one thing, one shot utterances in great way.

1:09:52.600 --> 1:09:54.920
 There was a lot of debate on how much should Alexa talk back

1:09:54.920 --> 1:09:57.480
 in terms of if you misunderstood you

1:09:57.480 --> 1:10:01.560
 or you said play songs by the stones

1:10:01.560 --> 1:10:04.880
 and let's say it doesn't know early days,

1:10:04.880 --> 1:10:07.120
 knowledge can be sparse.

1:10:07.120 --> 1:10:09.240
 Who are the stones, right?

1:10:09.240 --> 1:10:10.840
 It's the rolling stones, right?

1:10:10.840 --> 1:10:14.360
 So, and you don't want the match

1:10:14.360 --> 1:10:17.320
 to be stone temple pilots or rolling stones, right?

1:10:17.320 --> 1:10:19.000
 So you don't know which one it is.

1:10:19.000 --> 1:10:22.600
 So these kind of other signals to,

1:10:22.600 --> 1:10:24.680
 no, there we had great assets, right?

1:10:24.680 --> 1:10:27.160
 From Amazon in terms of.

1:10:27.160 --> 1:10:28.480
 UX, like what is it?

1:10:28.480 --> 1:10:31.320
 What kind of, yeah, how do you solve that problem?

1:10:31.320 --> 1:10:32.360
 In terms of what we think of it

1:10:32.360 --> 1:10:34.080
 as an entity resolution problem, right?

1:10:34.080 --> 1:10:36.280
 So, which one is it, right?

1:10:36.280 --> 1:10:40.200
 I mean, even if you figured out the stones as an entity,

1:10:40.200 --> 1:10:42.280
 you have to resolve it to whether it's the stones

1:10:42.280 --> 1:10:44.920
 or the stone temple pilots or some other stones.

1:10:44.920 --> 1:10:47.120
 Maybe I misunderstood, is the resolution

1:10:47.120 --> 1:10:50.560
 the job of the algorithm or is the job of UX

1:10:50.560 --> 1:10:52.480
 communicating with the human to help the resolution?

1:10:52.480 --> 1:10:54.320
 Well, there is both, right?

1:10:54.320 --> 1:10:58.840
 It is, you want 90% or high 90s to be done

1:10:58.840 --> 1:11:01.280
 without any further questioning or UX, right?

1:11:01.280 --> 1:11:04.240
 So, but it's absolutely okay.

1:11:04.240 --> 1:11:06.960
 Just like as humans, we ask the question,

1:11:06.960 --> 1:11:09.040
 I didn't understand your legs.

1:11:09.040 --> 1:11:10.680
 It's fine for Alexa to occasionally say,

1:11:10.680 --> 1:11:12.160
 I did not understand you, right?

1:11:12.160 --> 1:11:14.720
 And that's an important way to learn.

1:11:14.720 --> 1:11:16.280
 And I'll talk about where we have come

1:11:16.280 --> 1:11:19.200
 with more self learning with these kind of feedback signals.

1:11:20.160 --> 1:11:23.320
 But in those days, just solving the ability

1:11:23.320 --> 1:11:26.560
 of understanding the intent and resolving to an action

1:11:26.560 --> 1:11:28.800
 where action could be play a particular artist

1:11:28.800 --> 1:11:32.040
 or a particular song was super hard.

1:11:32.040 --> 1:11:35.480
 Again, the bar was high as we were talking about, right?

1:11:35.480 --> 1:11:40.320
 So, while we launched it in sort of 13 big domains,

1:11:40.320 --> 1:11:42.440
 I would say in terms of our thing,

1:11:42.440 --> 1:11:44.840
 we think of it as 13 of the big skills we had,

1:11:44.840 --> 1:11:47.800
 like music is a massive one when we launched it.

1:11:47.800 --> 1:11:51.600
 And now we have 90,000 plus skills on Alexa.

1:11:51.600 --> 1:11:52.760
 So, what are the big skills?

1:11:52.760 --> 1:11:53.720
 Can you just go over them?

1:11:53.720 --> 1:11:55.600
 Because the only thing I use it for

1:11:55.600 --> 1:11:57.760
 is music, weather, and shopping.

1:11:58.960 --> 1:12:02.600
 So, we think of it as music information, right?

1:12:02.600 --> 1:12:05.440
 So, whether it is a part of an information, right?

1:12:05.440 --> 1:12:08.080
 So, when we launched, we didn't have smart home,

1:12:08.080 --> 1:12:10.440
 but within, by smart home, I mean,

1:12:10.440 --> 1:12:12.120
 you connect your smart devices,

1:12:12.120 --> 1:12:13.160
 you control them with voice.

1:12:13.160 --> 1:12:15.040
 If you haven't done it, it's worth,

1:12:15.040 --> 1:12:15.880
 it will change your life.

1:12:15.880 --> 1:12:16.720
 By turning on the lights and so on.

1:12:16.720 --> 1:12:20.200
 Yeah, turning on your light to anything that's connected

1:12:20.200 --> 1:12:21.520
 and has a, it's just that.

1:12:21.520 --> 1:12:23.240
 What's your favorite smart device for you?

1:12:23.240 --> 1:12:24.080
 The light.

1:12:24.080 --> 1:12:24.920
 The light.

1:12:24.920 --> 1:12:26.320
 And now you have the smart plug with,

1:12:26.320 --> 1:12:29.920
 and you don't, you also have this Echo plug, which is...

1:12:29.920 --> 1:12:30.760
 Oh yeah, you can plug in anything.

1:12:30.760 --> 1:12:31.600
 You can plug in anything,

1:12:31.600 --> 1:12:33.560
 and now you can turn that one on and off.

1:12:33.560 --> 1:12:35.080
 I use this conversation motivation

1:12:35.080 --> 1:12:35.920
 and get one and something.

1:12:35.920 --> 1:12:38.720
 The garage door, you can check your status

1:12:38.720 --> 1:12:40.280
 of the garage door and things like,

1:12:40.280 --> 1:12:43.240
 and we have gone make Alexa more and more proactive,

1:12:43.240 --> 1:12:45.120
 where it even has hunches now,

1:12:45.120 --> 1:12:49.120
 that looks hunches like you left your light on.

1:12:50.520 --> 1:12:51.640
 Let's say you've gone to your bed

1:12:51.640 --> 1:12:52.840
 and you left the garage light on.

1:12:52.840 --> 1:12:56.160
 So, it will help you out in these settings, right?

1:12:56.160 --> 1:12:57.000
 So...

1:12:57.000 --> 1:12:58.320
 That's smart devices.

1:12:58.320 --> 1:13:01.120
 Information smart devices, you said music.

1:13:01.120 --> 1:13:02.920
 Yeah, so I don't remember everything we had,

1:13:02.920 --> 1:13:05.000
 but our last timers were the big ones,

1:13:05.000 --> 1:13:09.480
 like that was, the timers were very popular right away.

1:13:09.480 --> 1:13:13.440
 Music also, like you could play song, artist, album,

1:13:13.440 --> 1:13:17.000
 everything, and so that was like a clear win

1:13:17.000 --> 1:13:19.400
 in terms of the customer experience.

1:13:19.400 --> 1:13:22.760
 So that's, again, this is language understanding.

1:13:22.760 --> 1:13:24.080
 Now things have evolved, right?

1:13:24.080 --> 1:13:27.280
 So where we want Alexa definitely to be

1:13:27.280 --> 1:13:29.800
 more accurate, competent, trustworthy,

1:13:29.800 --> 1:13:33.080
 based on how well it does these core things,

1:13:33.080 --> 1:13:35.200
 but we have evolved in many different dimensions.

1:13:35.200 --> 1:13:37.240
 First is what I think of her doing,

1:13:37.240 --> 1:13:39.160
 more conversational for high utility,

1:13:39.160 --> 1:13:40.880
 not just for chat, right?

1:13:40.880 --> 1:13:43.480
 And there, at RIMARS this year,

1:13:43.480 --> 1:13:44.880
 which is our AI conference,

1:13:44.880 --> 1:13:48.520
 we launched what is called Alexa Conversations.

1:13:48.520 --> 1:13:52.920
 That is providing the ability for developers to author

1:13:52.920 --> 1:13:56.440
 multi turn experiences on Alexa with no code, essentially,

1:13:56.440 --> 1:13:58.840
 where in terms of the dialogue code,

1:13:58.840 --> 1:14:02.560
 initially it was like, you know, all these IVR systems,

1:14:02.560 --> 1:14:05.080
 you have to fully author,

1:14:05.080 --> 1:14:07.520
 if the customer says this, do that, right?

1:14:07.520 --> 1:14:11.440
 So the whole dialogue flow is hand author.

1:14:11.440 --> 1:14:13.600
 And with Alexa Conversations,

1:14:13.600 --> 1:14:16.720
 the way it is that you just provide a sample interaction data

1:14:16.720 --> 1:14:18.000
 with your service or an API,

1:14:18.000 --> 1:14:19.080
 let's say your Atom tickets

1:14:19.080 --> 1:14:23.360
 that provides a service for buying movie tickets.

1:14:23.360 --> 1:14:24.760
 You provide a few examples

1:14:24.760 --> 1:14:27.800
 of how your customers will interact with your APIs.

1:14:27.800 --> 1:14:29.920
 And then the dialogue flow is automatically constructed

1:14:29.920 --> 1:14:33.320
 using a regular neural network train on that data.

1:14:33.320 --> 1:14:35.880
 So that simplifies the developer experience.

1:14:35.880 --> 1:14:38.400
 We just launched our preview for the developers

1:14:38.400 --> 1:14:40.560
 to try this capability out.

1:14:40.560 --> 1:14:42.080
 And then the second part of it,

1:14:42.080 --> 1:14:45.680
 which shows even increased utility for customers,

1:14:45.680 --> 1:14:49.960
 is you and I, when we interact with Alexa or any customer,

1:14:50.880 --> 1:14:53.120
 as I'm coming back to our initial part of the conversation,

1:14:53.120 --> 1:14:58.120
 the goal is often unclear or unknown to the AI.

1:14:58.920 --> 1:15:02.640
 If I say, Alexa, what movies are playing nearby?

1:15:02.640 --> 1:15:07.640
 Am I trying to just buy movie tickets?

1:15:08.000 --> 1:15:11.360
 Am I actually even, do you think I'm looking

1:15:11.360 --> 1:15:12.840
 for just movies for curiosity,

1:15:12.840 --> 1:15:15.920
 whether the Avengers is still in theater or when is it?

1:15:15.920 --> 1:15:18.440
 Maybe it's gone and maybe it will come on my missed it.

1:15:18.440 --> 1:15:22.640
 So I may watch it on prime, which happened to me.

1:15:22.640 --> 1:15:25.440
 So from that perspective now,

1:15:25.440 --> 1:15:28.480
 you're looking into what is my goal?

1:15:28.480 --> 1:15:33.160
 And let's say I now complete the movie ticket purchase.

1:15:33.160 --> 1:15:35.840
 Maybe I would like to get dinner nearby.

1:15:37.400 --> 1:15:40.400
 So what is really the goal here?

1:15:40.400 --> 1:15:43.800
 Is it night out or is it movies?

1:15:43.800 --> 1:15:45.800
 As in just go watch a movie?

1:15:45.800 --> 1:15:48.000
 The answer is, we don't know.

1:15:48.000 --> 1:15:52.560
 So can Alexa now figure we have the intelligence

1:15:52.560 --> 1:15:55.440
 that I think this meta goal is really night out

1:15:55.440 --> 1:15:57.560
 or at least say to the customer

1:15:57.560 --> 1:16:00.000
 when you've completed the purchase of movie tickets

1:16:00.000 --> 1:16:03.240
 from Adam tickets or Fandango or Pick Your Anyone.

1:16:03.240 --> 1:16:04.320
 Then the next thing is,

1:16:04.320 --> 1:16:09.320
 do you want to get an Uber to the theater?

1:16:10.800 --> 1:16:14.400
 Or do you want to book a restaurant next to it?

1:16:14.400 --> 1:16:18.960
 And then not ask the same information over and over again.

1:16:18.960 --> 1:16:23.960
 What time, how many people in your party?

1:16:23.960 --> 1:16:28.080
 So this is where you shift the cognitive burden

1:16:28.080 --> 1:16:30.440
 from the customer to the AI,

1:16:30.440 --> 1:16:33.600
 where it's thinking of what is your,

1:16:33.600 --> 1:16:35.560
 it anticipates your goal

1:16:35.560 --> 1:16:38.840
 and takes the next best action to complete it.

1:16:38.840 --> 1:16:41.080
 Now that's the machine learning problem.

1:16:42.160 --> 1:16:45.200
 But essentially the way we saw this first instance

1:16:45.200 --> 1:16:48.240
 and we have a long way to go to make it scale

1:16:48.240 --> 1:16:50.120
 to everything possible in the world.

1:16:50.120 --> 1:16:51.520
 But at least for this situation,

1:16:51.520 --> 1:16:54.400
 it is from at every instance,

1:16:54.400 --> 1:16:56.000
 Alexa is making the determination,

1:16:56.000 --> 1:16:57.640
 whether it should stick with the experience

1:16:57.640 --> 1:17:02.560
 with Adam tickets or offer or you,

1:17:02.560 --> 1:17:03.760
 based on what you say,

1:17:03.760 --> 1:17:06.240
 whether either you have completed the interaction

1:17:06.240 --> 1:17:07.760
 or you said, no, get me an Uber now.

1:17:07.760 --> 1:17:09.120
 So it will shift context

1:17:09.120 --> 1:17:12.840
 into another experience or scale or another service.

1:17:12.840 --> 1:17:15.360
 So that's a dynamic decision making.

1:17:15.360 --> 1:17:16.480
 That's making Alexa,

1:17:16.480 --> 1:17:18.120
 you can say more conversational

1:17:18.120 --> 1:17:20.160
 for the benefit of the customer

1:17:20.160 --> 1:17:22.480
 rather than simply complete transactions

1:17:22.480 --> 1:17:25.200
 which are well thought through.

1:17:25.200 --> 1:17:27.800
 You as a customer has fully specified

1:17:27.800 --> 1:17:29.640
 what you want to be accomplished.

1:17:29.640 --> 1:17:30.800
 It's accomplishing that.

1:17:30.800 --> 1:17:32.400
 So it's kind of as,

1:17:32.400 --> 1:17:34.040
 we do this with pedestrians,

1:17:34.040 --> 1:17:36.800
 like intent modeling is predicting

1:17:36.800 --> 1:17:38.680
 what your possible goals are

1:17:38.680 --> 1:17:39.960
 and what's the most likely goal

1:17:39.960 --> 1:17:42.400
 and then switching that depending on the things you say.

1:17:42.400 --> 1:17:44.400
 So my question is there,

1:17:44.400 --> 1:17:46.520
 it seems maybe it's a dumb question,

1:17:46.520 --> 1:17:51.400
 but it would help a lot if Alexa remembered me

1:17:51.400 --> 1:17:53.040
 what I said previously.

1:17:53.040 --> 1:17:57.880
 Is it trying to use some memories

1:17:57.880 --> 1:17:58.720
 for the customers?

1:17:58.720 --> 1:18:00.840
 It is using a lot of memory within that.

1:18:00.840 --> 1:18:02.720
 So right now, not so much in terms of,

1:18:02.720 --> 1:18:05.400
 okay, which restaurant do you prefer?

1:18:05.400 --> 1:18:06.840
 That is a more long term memory,

1:18:06.840 --> 1:18:08.360
 but within the short term memory,

1:18:08.360 --> 1:18:09.880
 within the session,

1:18:09.880 --> 1:18:11.880
 it is remembering how many people did you,

1:18:11.880 --> 1:18:13.880
 so if you said buy four tickets,

1:18:13.880 --> 1:18:15.720
 now it has made an implicit assumption

1:18:15.720 --> 1:18:18.360
 that you are gonna have,

1:18:18.360 --> 1:18:21.800
 you need at least four seats at a restaurant, right?

1:18:21.800 --> 1:18:24.360
 So these are the kind of context it's preserving

1:18:24.360 --> 1:18:26.880
 between these skills, but within that session,

1:18:26.880 --> 1:18:28.160
 but you're asking the right question

1:18:28.160 --> 1:18:32.200
 in terms of for it to be more and more useful,

1:18:32.200 --> 1:18:33.840
 it has to have more long term memory

1:18:33.840 --> 1:18:35.280
 and that's also an open question.

1:18:35.280 --> 1:18:37.520
 And again, these are still early days.

1:18:37.520 --> 1:18:40.400
 So for me, I mean, everybody's different,

1:18:40.400 --> 1:18:44.080
 but yeah, I'm definitely not representative

1:18:44.080 --> 1:18:45.000
 of the general population

1:18:45.000 --> 1:18:47.960
 in the sense that I do the same thing every day.

1:18:47.960 --> 1:18:48.840
 Like I eat the same,

1:18:48.840 --> 1:18:51.960
 like I do everything the same, the same thing.

1:18:51.960 --> 1:18:55.600
 Wear the same thing clearly, this or the black shirt.

1:18:55.600 --> 1:18:59.200
 So it's frustrating when Alexa doesn't get what I'm saying

1:18:59.200 --> 1:19:03.040
 because I have to correct her every time in the exact same way.

1:19:03.040 --> 1:19:05.680
 This has to do with certain songs.

1:19:05.680 --> 1:19:08.480
 Like she doesn't know certain weird songs.

1:19:08.480 --> 1:19:11.440
 And doesn't know, I've complained to Spotify about this,

1:19:11.440 --> 1:19:15.240
 I talked to the head of RDA Spotify, Stairway to Heaven.

1:19:15.240 --> 1:19:16.560
 I have to correct it every time.

1:19:16.560 --> 1:19:18.760
 It doesn't play Led Zeppelin correctly.

1:19:18.760 --> 1:19:21.040
 It plays cover of Led Zeppelin.

1:19:21.040 --> 1:19:23.240
 So you should figure out,

1:19:23.240 --> 1:19:26.360
 you should send me your next time it fails.

1:19:26.360 --> 1:19:27.480
 Feel free to send it to me.

1:19:27.480 --> 1:19:28.440
 You will take care of it.

1:19:28.440 --> 1:19:29.280
 Okay.

1:19:29.280 --> 1:19:31.680
 Because Led Zeppelin is one of my favorite brands

1:19:31.680 --> 1:19:32.520
 that it works for me.

1:19:32.520 --> 1:19:34.160
 So I'm like shocked, it doesn't work for you.

1:19:34.160 --> 1:19:35.480
 This is an official bug report.

1:19:35.480 --> 1:19:39.080
 I'll put it, I'll make it public or make everybody retweet it.

1:19:39.080 --> 1:19:41.000
 We're gonna fix the Stairway to Heaven problem.

1:19:41.000 --> 1:19:43.240
 Anyway, but the point is,

1:19:43.240 --> 1:19:45.160
 you know, I'm pretty boring and do the same thing.

1:19:45.160 --> 1:19:48.360
 But I'm sure most people do the same set of things.

1:19:48.360 --> 1:19:51.400
 Do you see Alexa sort of utilizing that in the future

1:19:51.400 --> 1:19:52.800
 for improving the experience?

1:19:52.800 --> 1:19:53.640
 Yes.

1:19:53.640 --> 1:19:56.240
 And not only utilizing, it's already doing some of it.

1:19:56.240 --> 1:19:59.560
 We call it where Alexa is becoming more self learning.

1:19:59.560 --> 1:20:04.400
 So Alexa is now auto correcting millions and millions

1:20:04.400 --> 1:20:08.760
 of utterances in the US without any human supervision involved.

1:20:08.760 --> 1:20:11.920
 The way it does it is, let's take an example

1:20:11.920 --> 1:20:14.760
 of a particular song didn't work for you.

1:20:14.760 --> 1:20:15.720
 What do you do next?

1:20:15.720 --> 1:20:18.440
 You either, it played the wrong song and you said,

1:20:18.440 --> 1:20:20.760
 Alexa, no, that's not the song I want.

1:20:20.760 --> 1:20:25.200
 Or you say Alexa, play that, you try it again.

1:20:25.200 --> 1:20:27.480
 And that is a signal to Alexa

1:20:27.480 --> 1:20:30.120
 that she may have done something wrong.

1:20:30.120 --> 1:20:33.520
 And from that perspective, we can learn

1:20:33.520 --> 1:20:36.720
 if there's that failure pattern or that action

1:20:36.720 --> 1:20:41.080
 of song A was played when song B was requested.

1:20:41.080 --> 1:20:44.360
 And it's very common with station names because play NPR,

1:20:44.360 --> 1:20:47.200
 you can have N be confused as an M.

1:20:47.200 --> 1:20:51.880
 And then you, for a certain accent like mine,

1:20:51.880 --> 1:20:54.760
 people confuse my N and M all the time.

1:20:54.760 --> 1:20:57.680
 And because I have an Indian accent,

1:20:57.680 --> 1:20:59.640
 they're confusable to humans.

1:20:59.640 --> 1:21:01.640
 It is for Alexa too.

1:21:01.640 --> 1:21:05.120
 And in that part, but it starts auto correcting.

1:21:05.120 --> 1:21:09.720
 And we collect, we correct a lot of these automatically

1:21:09.720 --> 1:21:12.720
 without a human looking at the failures.

1:21:12.720 --> 1:21:17.400
 So the, one of the things that's for me missing in Alexa,

1:21:17.400 --> 1:21:19.760
 I don't know if I'm a representative customer,

1:21:19.760 --> 1:21:22.960
 but every time I correct it,

1:21:22.960 --> 1:21:26.160
 it would be nice to know that that made a difference.

1:21:26.160 --> 1:21:27.000
 Yes.

1:21:27.000 --> 1:21:27.840
 You know what I mean?

1:21:27.840 --> 1:21:31.920
 Like the sort of like, I heard you like a sort of.

1:21:31.920 --> 1:21:33.840
 Some acknowledgement of that.

1:21:33.840 --> 1:21:37.480
 We work a lot with Tesla, we study autopilot and so on.

1:21:37.480 --> 1:21:40.720
 And a large amount of the customers that use Tesla autopilot,

1:21:40.720 --> 1:21:43.000
 they feel like they're always teaching the system.

1:21:43.000 --> 1:21:44.440
 They're almost excited by the possibility

1:21:44.440 --> 1:21:45.280
 that they're teaching.

1:21:45.280 --> 1:21:48.440
 I don't know if Alexa customers generally think of it

1:21:48.440 --> 1:21:51.120
 as they're teaching to improve the system.

1:21:51.120 --> 1:21:52.720
 And that's a really powerful thing.

1:21:52.720 --> 1:21:55.240
 Again, I would say it's a spectrum.

1:21:55.240 --> 1:21:57.360
 Some customers do think that way.

1:21:57.360 --> 1:22:01.200
 And some would be annoyed by Alexa acknowledging that.

1:22:01.200 --> 1:22:04.160
 Or so there's a, again, no one,

1:22:04.160 --> 1:22:05.760
 you know, while there are certain patterns,

1:22:05.760 --> 1:22:08.280
 not everyone is the same in this way.

1:22:08.280 --> 1:22:13.280
 But we believe that again, customers helping Alexa

1:22:13.640 --> 1:22:15.680
 is a tenet for us in terms of improving it.

1:22:15.680 --> 1:22:18.240
 And more self learning is by, again,

1:22:18.240 --> 1:22:20.080
 this is like fully unsupervised, right?

1:22:20.080 --> 1:22:23.560
 There is no human in the loop and no labeling happening.

1:22:23.560 --> 1:22:27.120
 And based on your actions as a customer,

1:22:27.120 --> 1:22:29.000
 Alexa becomes smarter.

1:22:29.000 --> 1:22:31.120
 Again, it's early days,

1:22:31.120 --> 1:22:35.840
 but I think this whole area of teachable AI

1:22:35.840 --> 1:22:38.680
 is gonna get bigger and bigger in the whole space,

1:22:38.680 --> 1:22:40.760
 especially in the AI assistant space.

1:22:40.760 --> 1:22:43.440
 So that's the second part where I mentioned

1:22:43.440 --> 1:22:46.520
 more conversational, this is more self learning.

1:22:46.520 --> 1:22:48.320
 The third is more natural.

1:22:48.320 --> 1:22:50.240
 And the way I think of more natural

1:22:50.240 --> 1:22:53.280
 is we talked about how Alexa sounds.

1:22:53.280 --> 1:22:58.080
 And we've done a lot of advances in our text to speech

1:22:58.080 --> 1:23:00.480
 by using again, neural network technology

1:23:00.480 --> 1:23:03.520
 for it to sound very human like.

1:23:03.520 --> 1:23:05.640
 From the individual texture of the sound

1:23:05.640 --> 1:23:09.280
 to the timing, the tonality, the tone, everything.

1:23:09.280 --> 1:23:11.040
 I would think in terms of,

1:23:11.040 --> 1:23:13.400
 there's a lot of controls in each of the places

1:23:13.400 --> 1:23:16.680
 for how, I mean, the speed of the voice,

1:23:16.680 --> 1:23:18.080
 the prosthetic patterns,

1:23:18.080 --> 1:23:23.080
 the actual smoothness of how it sounds.

1:23:23.400 --> 1:23:25.880
 All of those are factored and we do ton of listening tests

1:23:25.880 --> 1:23:27.120
 to make sure it was that,

1:23:27.120 --> 1:23:30.760
 but naturalness, how it sounds should be very natural.

1:23:30.760 --> 1:23:33.680
 How it understands requests is also very important.

1:23:33.680 --> 1:23:37.160
 Like, and in terms of, like we have 95,000 skills

1:23:37.160 --> 1:23:41.480
 and if we have, imagine that in many of these skills,

1:23:41.480 --> 1:23:43.400
 you have to remember the skill name

1:23:43.400 --> 1:23:48.400
 and say Alexa ask the tied skill to tell me X, right?

1:23:49.840 --> 1:23:53.000
 Or now, if you have to remember the skill name,

1:23:53.000 --> 1:23:56.680
 that means the discovery and the interaction is unnatural.

1:23:56.680 --> 1:24:00.960
 And we are trying to solve that by what we think of as,

1:24:00.960 --> 1:24:05.760
 again, this was, you don't have to have the app metaphor here.

1:24:05.760 --> 1:24:07.440
 These are not individual apps, right?

1:24:07.440 --> 1:24:08.400
 Even though they're,

1:24:08.400 --> 1:24:11.440
 so you're not sort of opening one at a time and interacting.

1:24:11.440 --> 1:24:14.040
 So it should be seamless because it's voice.

1:24:14.040 --> 1:24:15.200
 And when it's voice,

1:24:15.200 --> 1:24:17.600
 you have to be able to understand these requests

1:24:17.600 --> 1:24:20.640
 independent of the specificity, like a skill name.

1:24:20.640 --> 1:24:22.880
 And to do that, what we have done is again,

1:24:22.880 --> 1:24:24.480
 built a deep learning base capability

1:24:24.480 --> 1:24:27.080
 where we shortlist a bunch of skills

1:24:27.080 --> 1:24:28.920
 when you say, Alexa, get me a car.

1:24:28.920 --> 1:24:30.120
 And then we figure it out, okay,

1:24:30.120 --> 1:24:33.360
 it's meant for an Uber skill versus a Lyft

1:24:33.360 --> 1:24:34.920
 or based on your preferences.

1:24:34.920 --> 1:24:38.360
 And then you can rank the responses from the skill

1:24:38.360 --> 1:24:41.320
 and then choose the best response for the customer.

1:24:41.320 --> 1:24:43.280
 So that's on the more natural,

1:24:43.280 --> 1:24:46.400
 other examples of more natural is like,

1:24:46.400 --> 1:24:49.160
 we were talking about lists, for instance.

1:24:49.160 --> 1:24:51.760
 And you want to, you don't want to say Alexa add milk,

1:24:51.760 --> 1:24:55.200
 Alexa add eggs, Alexa add cookies.

1:24:55.200 --> 1:24:57.320
 No, Alexa add cookies, milk and eggs,

1:24:57.320 --> 1:24:59.280
 and that in one shot, right?

1:24:59.280 --> 1:25:01.800
 So that works, that helps with the naturalness.

1:25:01.800 --> 1:25:05.440
 We talked about memory, like if you said,

1:25:05.440 --> 1:25:09.080
 you can say Alexa, remember, I have to go to mom's house

1:25:09.080 --> 1:25:11.200
 or you may have entered a calendar event

1:25:11.200 --> 1:25:13.560
 through your calendar that's linked to Alexa.

1:25:13.560 --> 1:25:15.840
 You don't want to remember whether it's in my calendar

1:25:15.840 --> 1:25:18.400
 or did I tell you to remember something

1:25:18.400 --> 1:25:21.000
 or some other reminder, right?

1:25:21.000 --> 1:25:25.320
 So you have to now, independent of how customers

1:25:25.320 --> 1:25:28.440
 create these events, it should just say Alexa,

1:25:28.440 --> 1:25:29.880
 when do I have to go to mom's house?

1:25:29.880 --> 1:25:32.360
 And it tells you when you have to go to mom's house.

1:25:32.360 --> 1:25:33.720
 Now that's a fascinating problem.

1:25:33.720 --> 1:25:35.280
 Who's that problem on?

1:25:35.280 --> 1:25:37.520
 So there's people who create skills.

1:25:38.520 --> 1:25:42.840
 Who's tasked with integrating all of that knowledge together?

1:25:42.840 --> 1:25:44.640
 So the skills become seamless.

1:25:44.640 --> 1:25:49.080
 Is it the creators of the skills or is it an infrastructure

1:25:49.080 --> 1:25:51.200
 that Alexa provides problem?

1:25:51.200 --> 1:25:52.040
 It's both.

1:25:52.040 --> 1:25:54.280
 I think the large problem in terms

1:25:54.280 --> 1:25:56.640
 of making sure your skill quality is high,

1:25:58.440 --> 1:26:02.280
 that has to be done by our tools because it's a,

1:26:02.280 --> 1:26:04.600
 so these skills, just to put the context,

1:26:04.600 --> 1:26:06.200
 they're built through Alexa skills kit,

1:26:06.200 --> 1:26:11.200
 which is a self serve way of building an experience on Alexa.

1:26:11.200 --> 1:26:12.840
 This is like any developer in the world

1:26:12.840 --> 1:26:14.720
 could go to Alexa skills kit

1:26:14.720 --> 1:26:16.760
 and build an experience on Alexa.

1:26:16.760 --> 1:26:18.160
 Like if you're a dominoes,

1:26:18.160 --> 1:26:20.040
 you can build a domino skills.

1:26:20.040 --> 1:26:22.440
 For instance, that does pizza ordering.

1:26:22.440 --> 1:26:25.240
 When you've authored that,

1:26:25.240 --> 1:26:30.040
 you do want to now, if people say Alexa open dominoes

1:26:30.040 --> 1:26:35.040
 or Alexa ask dominoes to get a particular type of pizza,

1:26:35.280 --> 1:26:37.720
 that will work, but the discovery is hard.

1:26:37.720 --> 1:26:39.240
 You can't just say Alexa, get me a pizza

1:26:39.240 --> 1:26:42.360
 and then Alexa figures out what to do.

1:26:42.360 --> 1:26:44.920
 That latter part is definitely our responsibility

1:26:44.920 --> 1:26:48.840
 in terms of when the request is not fully specific.

1:26:48.840 --> 1:26:51.440
 How do you figure out what's the best skill

1:26:51.440 --> 1:26:56.000
 or a service that can fulfill the customer's request?

1:26:56.000 --> 1:26:57.160
 And it can keep evolving.

1:26:57.160 --> 1:26:59.200
 Imagine going to the situation I said,

1:26:59.200 --> 1:27:00.920
 which was the night out planning that it,

1:27:00.920 --> 1:27:03.400
 the goal could be more than that individual request

1:27:03.400 --> 1:27:08.400
 that came up a pizza ordering could mean a nighting.

1:27:08.520 --> 1:27:11.320
 When you're having an event with your kids in their house

1:27:11.320 --> 1:27:15.200
 and you're, so this is welcome to the word of conversational AI.

1:27:15.200 --> 1:27:20.040
 This is super exciting because it's not the academic problem

1:27:20.040 --> 1:27:21.760
 of NLP of natural English processing,

1:27:21.760 --> 1:27:23.080
 understanding dialogue.

1:27:23.080 --> 1:27:24.600
 This is like real world.

1:27:24.600 --> 1:27:27.120
 And there's the stakes are high in the sense

1:27:27.120 --> 1:27:30.000
 that customers get frustrated quickly,

1:27:30.000 --> 1:27:31.800
 people get frustrated quickly.

1:27:31.800 --> 1:27:33.120
 So you have to get it right.

1:27:33.120 --> 1:27:35.280
 You have to get that interaction right.

1:27:35.280 --> 1:27:36.840
 So it's, I love it.

1:27:36.840 --> 1:27:41.840
 But so from that perspective, what are the challenges today?

1:27:41.880 --> 1:27:45.000
 What are the problems that really need to be solved

1:27:45.000 --> 1:27:45.840
 in the next few years?

1:27:45.840 --> 1:27:49.200
 I think first and foremost, as I mentioned that

1:27:50.800 --> 1:27:53.240
 get the basics right is still true.

1:27:53.240 --> 1:27:56.960
 Basically, even the one shot request,

1:27:56.960 --> 1:27:58.800
 which we think of as transactional request

1:27:58.800 --> 1:28:01.640
 needs to work magically, no question about that.

1:28:01.640 --> 1:28:03.520
 If it doesn't turn your light on and off,

1:28:03.520 --> 1:28:05.160
 you'll be super frustrated.

1:28:05.160 --> 1:28:07.040
 Even if I can complete the night out for you

1:28:07.040 --> 1:28:10.680
 and not do that, that is unacceptable for as a customer.

1:28:10.680 --> 1:28:14.080
 So that you have to get the foundational understanding

1:28:14.080 --> 1:28:15.400
 going very well.

1:28:15.400 --> 1:28:17.720
 The second aspect when I said more conversational

1:28:17.720 --> 1:28:20.080
 is, as you imagine, is more about reasoning.

1:28:20.080 --> 1:28:24.320
 It is really about figuring out what the latent goal is

1:28:24.320 --> 1:28:28.480
 of the customer based on what I have the information now

1:28:28.480 --> 1:28:31.320
 and the history and what's the next best thing to do.

1:28:31.320 --> 1:28:33.360
 So that's a complete reasoning

1:28:33.360 --> 1:28:35.360
 and decision making problem.

1:28:35.360 --> 1:28:37.000
 Just like your self driving car,

1:28:37.000 --> 1:28:38.640
 but the goal is still more finite.

1:28:38.640 --> 1:28:41.920
 Here it evolves, your environment is super hard

1:28:41.920 --> 1:28:46.200
 and self driving and the cost of a mistake is huge.

1:28:46.200 --> 1:28:48.480
 Here, but there are certain similarities,

1:28:48.480 --> 1:28:52.600
 but if you think about how many decisions Alexa is making

1:28:52.600 --> 1:28:54.240
 or evaluating at any given time,

1:28:54.240 --> 1:28:56.440
 it's a huge hypothesis space.

1:28:56.440 --> 1:28:59.720
 And we're only talked about so far

1:28:59.720 --> 1:29:02.040
 about what I think of reactive decision

1:29:02.040 --> 1:29:03.640
 in terms of you asked for something

1:29:03.640 --> 1:29:05.920
 and Alexa is reacting to it.

1:29:05.920 --> 1:29:07.760
 If you bring the proactive part,

1:29:07.760 --> 1:29:10.040
 which is Alexa having hunches.

1:29:10.040 --> 1:29:11.720
 So any given instance then,

1:29:11.720 --> 1:29:15.360
 it's really a decision at any given point

1:29:15.360 --> 1:29:17.200
 based on the information.

1:29:17.200 --> 1:29:20.120
 Alexa has to determine what's the best thing it needs to do.

1:29:20.120 --> 1:29:22.520
 So these are the ultimate AI problem

1:29:22.520 --> 1:29:25.080
 about decisions based on the information you have.

1:29:25.080 --> 1:29:27.480
 Do you think, just from my perspective,

1:29:27.480 --> 1:29:31.120
 I work a lot with sensing of the human face.

1:29:31.120 --> 1:29:32.320
 Do you think they'll,

1:29:32.320 --> 1:29:34.400
 and we touched this topic a little bit earlier,

1:29:34.400 --> 1:29:36.560
 but do you think it'll be a day soon

1:29:36.560 --> 1:29:38.880
 when Alexa can also look at you

1:29:38.880 --> 1:29:43.200
 to help improve the quality of the hunch it has

1:29:43.200 --> 1:29:48.000
 or at least detect frustration or detect,

1:29:48.000 --> 1:29:51.600
 improve the quality of its perception

1:29:51.600 --> 1:29:54.360
 of what you're trying to do?

1:29:54.360 --> 1:29:57.160
 I mean, let me again bring back to what it already does.

1:29:57.160 --> 1:30:01.800
 We talked about how based on you barge in over Alexa,

1:30:01.800 --> 1:30:04.960
 clearly it's a very high probability

1:30:04.960 --> 1:30:06.600
 it must have done something wrong.

1:30:06.600 --> 1:30:08.560
 That's why you barged in.

1:30:08.560 --> 1:30:11.520
 The next extension of whether frustration

1:30:11.520 --> 1:30:13.280
 is a signal or not,

1:30:13.280 --> 1:30:15.360
 of course, is a natural thought

1:30:15.360 --> 1:30:18.200
 in terms of how that should be in a signal too.

1:30:18.200 --> 1:30:19.560
 You can get that from voice.

1:30:19.560 --> 1:30:21.320
 You can get from voice, but it's very hard.

1:30:21.320 --> 1:30:25.960
 Like, I mean, frustration as a signal historically,

1:30:25.960 --> 1:30:28.520
 if you think about emotions of different kinds,

1:30:29.720 --> 1:30:31.480
 there's a whole field of affective computing,

1:30:31.480 --> 1:30:34.560
 something that MIT has also done a lot of research in,

1:30:34.560 --> 1:30:35.640
 is super hard.

1:30:35.640 --> 1:30:39.080
 And you're now talking about a far field device

1:30:39.080 --> 1:30:41.960
 as in you're talking to a distance, noisy environment.

1:30:41.960 --> 1:30:44.120
 And in that environment,

1:30:44.120 --> 1:30:47.600
 it needs to have a good sense for your emotions.

1:30:47.600 --> 1:30:49.560
 This is a very, very hard problem.

1:30:49.560 --> 1:30:51.000
 Very hard problem, but you haven't shied away

1:30:51.000 --> 1:30:51.840
 from hard problems.

1:30:51.840 --> 1:30:55.280
 So deep learning has been at the core

1:30:55.280 --> 1:30:57.440
 of a lot of this technology.

1:30:57.440 --> 1:30:59.720
 Are you optimistic about the current deep learning approaches

1:30:59.720 --> 1:31:03.240
 to solving the hardest aspects of what we're talking about?

1:31:03.240 --> 1:31:05.360
 Or do you think there will come a time

1:31:05.360 --> 1:31:07.280
 where new ideas need to,

1:31:07.280 --> 1:31:09.360
 if you look at reasoning,

1:31:09.360 --> 1:31:10.720
 so open AI, deep mind,

1:31:10.720 --> 1:31:13.880
 a lot of folks are now starting to work in reasoning,

1:31:13.880 --> 1:31:16.600
 trying to see how it can make neural networks reason.

1:31:16.600 --> 1:31:20.520
 Do you see that new approaches need to be invented

1:31:20.520 --> 1:31:23.320
 to take the next big leap?

1:31:23.320 --> 1:31:27.200
 Absolutely, I think there has to be a lot more investment

1:31:27.200 --> 1:31:29.400
 and I think in many different ways.

1:31:29.400 --> 1:31:32.400
 And there are these, I would say nuggets of research

1:31:32.400 --> 1:31:33.560
 forming in a good way,

1:31:33.560 --> 1:31:36.080
 like learning with less data

1:31:36.080 --> 1:31:39.680
 or like zero short learning, one short learning.

1:31:39.680 --> 1:31:41.440
 And the active learning stuff you've talked about

1:31:41.440 --> 1:31:43.360
 is an incredible stuff.

1:31:43.360 --> 1:31:45.680
 So transfer learning is also super critical,

1:31:45.680 --> 1:31:48.600
 especially when you're thinking about applying knowledge

1:31:48.600 --> 1:31:52.040
 from one task to another or one language to another, right?

1:31:52.040 --> 1:31:53.000
 That's really ripe.

1:31:53.000 --> 1:31:55.320
 So these are great pieces.

1:31:55.320 --> 1:31:56.800
 Deep learning has been useful too.

1:31:56.800 --> 1:31:58.880
 And now we are sort of matting deep learning

1:31:58.880 --> 1:32:02.480
 with transfer learning and active learning,

1:32:02.480 --> 1:32:04.640
 of course, that's more straightforward

1:32:04.640 --> 1:32:05.880
 in terms of applying deep learning

1:32:05.880 --> 1:32:07.000
 and an active learning setup.

1:32:07.000 --> 1:32:12.000
 But I do think in terms of now looking

1:32:12.160 --> 1:32:14.240
 into more reasoning based approaches

1:32:14.240 --> 1:32:19.240
 is going to be key for our next wave of the technology.

1:32:19.440 --> 1:32:20.880
 But there is a good news.

1:32:20.880 --> 1:32:23.320
 The good news is that I think for keeping on

1:32:23.320 --> 1:32:24.440
 to delight customers,

1:32:24.440 --> 1:32:27.880
 that a lot of it can be done by prediction tasks.

1:32:27.880 --> 1:32:30.680
 So, and so we haven't exhausted that.

1:32:30.680 --> 1:32:34.480
 So we don't need to give up

1:32:34.480 --> 1:32:37.320
 on the deep learning approaches for that.

1:32:37.320 --> 1:32:39.560
 So that's just, I wanted to sort of

1:32:39.560 --> 1:32:42.600
 creating a rich, fulfilling, amazing experience

1:32:42.600 --> 1:32:44.240
 that makes Amazon a lot of money

1:32:44.240 --> 1:32:46.400
 and a lot of everybody a lot of money

1:32:46.400 --> 1:32:49.880
 because it does awesome things, deep learning is enough.

1:32:49.880 --> 1:32:51.120
 The point, the point.

1:32:51.120 --> 1:32:52.880
 I don't think, no, I mean,

1:32:52.880 --> 1:32:54.200
 I wouldn't say deep learning is enough.

1:32:54.200 --> 1:32:56.680
 I think for the purposes of Alexa

1:32:56.680 --> 1:32:58.440
 accomplish the task for customers,

1:32:58.440 --> 1:33:02.240
 I'm saying there's still a lot of things we can do

1:33:02.240 --> 1:33:05.200
 with prediction based approaches that do not reason.

1:33:05.200 --> 1:33:08.640
 I'm not saying that, and we haven't exhausted those,

1:33:08.640 --> 1:33:12.480
 but for the kind of high utility experiences

1:33:12.480 --> 1:33:14.280
 that I'm personally passionate about

1:33:14.280 --> 1:33:18.800
 of what Alexa needs to do, reasoning has to be solved.

1:33:18.800 --> 1:33:21.000
 To the same extent as you can think

1:33:21.000 --> 1:33:23.560
 of natural language understanding

1:33:23.560 --> 1:33:25.480
 and speech recognition to the extent

1:33:25.480 --> 1:33:29.000
 of understanding intents has been,

1:33:29.000 --> 1:33:30.120
 how accurate it has become.

1:33:30.120 --> 1:33:32.760
 But reasoning, we have very, very early days.

1:33:32.760 --> 1:33:34.040
 Let me ask you another way.

1:33:34.040 --> 1:33:36.760
 How hard of a problem do you think that is?

1:33:36.760 --> 1:33:37.800
 Hardest of them.

1:33:39.160 --> 1:33:42.520
 I would say hardest of them because again,

1:33:42.520 --> 1:33:47.520
 the hypothesis space is really, really large.

1:33:47.520 --> 1:33:50.000
 And when you go back in time, like you were saying,

1:33:50.000 --> 1:33:53.040
 I want Alexa to remember more things.

1:33:53.040 --> 1:33:56.320
 That once you go beyond a session of interaction,

1:33:56.320 --> 1:33:59.200
 which is by session, I mean a time span,

1:33:59.200 --> 1:34:01.880
 which is today, two verses remembering

1:34:01.880 --> 1:34:03.160
 which restaurant I like.

1:34:03.160 --> 1:34:05.480
 And then when I'm planning a night out to say,

1:34:05.480 --> 1:34:07.520
 do you want to go to the same restaurant?

1:34:07.520 --> 1:34:09.720
 Now you're up the stakes big time.

1:34:09.720 --> 1:34:12.840
 And this is where the reasoning dimension

1:34:12.840 --> 1:34:14.720
 also goes way, way bigger.

1:34:14.720 --> 1:34:17.720
 So you think the space, we'll be elaborating

1:34:17.720 --> 1:34:20.720
 that a little bit, just philosophically speaking.

1:34:20.720 --> 1:34:24.680
 Do you think when you reason about trying to model

1:34:24.680 --> 1:34:28.240
 what the goal of a person is in the context

1:34:28.240 --> 1:34:31.320
 of interacting with Alexa, you think that space is huge?

1:34:31.320 --> 1:34:32.280
 It's huge.

1:34:32.280 --> 1:34:33.120
 Absolutely huge.

1:34:33.120 --> 1:34:36.040
 Do you think so like another sort of devil's advocate

1:34:36.040 --> 1:34:38.720
 would be that we human beings are really simple

1:34:38.720 --> 1:34:41.520
 and we all want like just a small set of things.

1:34:41.520 --> 1:34:45.560
 And so you think it's possible because we're not talking

1:34:45.560 --> 1:34:49.280
 about a fulfilling general conversation.

1:34:49.280 --> 1:34:50.960
 Perhaps actually the Alexa prize

1:34:50.960 --> 1:34:53.360
 is a little bit more about after that.

1:34:53.360 --> 1:34:56.080
 Creating a customer, like there's so many

1:34:56.080 --> 1:35:01.080
 of the interactions, it feels like are clustered

1:35:01.080 --> 1:35:06.080
 in groups that don't require general reasoning.

1:35:06.520 --> 1:35:09.360
 I think yeah, you're right in terms of the head

1:35:09.360 --> 1:35:11.800
 of the distribution of all the possible things

1:35:11.800 --> 1:35:13.760
 customers may want to accomplish.

1:35:13.760 --> 1:35:18.200
 But the tail is long and it's diverse, right?

1:35:18.200 --> 1:35:23.200
 So from that perspective, I think you have

1:35:24.880 --> 1:35:27.680
 to solve that problem otherwise.

1:35:27.680 --> 1:35:28.800
 And everyone's very different.

1:35:28.800 --> 1:35:32.360
 Like I mean, we see this already in terms of the skills, right?

1:35:32.360 --> 1:35:37.000
 I mean, if you're an average surfer, which I am not, right?

1:35:37.000 --> 1:35:41.680
 But somebody is asking Alexa about surfing conditions, right?

1:35:41.680 --> 1:35:45.520
 And there's a skill that is there for them to get to, right?

1:35:45.520 --> 1:35:47.880
 That tells you that the tail is massive.

1:35:47.880 --> 1:35:50.760
 Like in terms of like what kind of skills

1:35:50.760 --> 1:35:54.240
 people have created, it's humongous in terms of it.

1:35:54.240 --> 1:35:57.000
 And which means there are these diverse needs.

1:35:57.000 --> 1:36:01.000
 And when you start looking at the combinations of these, right?

1:36:01.000 --> 1:36:05.440
 Even if you have pairs of skills and 90,000 choose two,

1:36:05.440 --> 1:36:07.920
 it's still a big combination.

1:36:07.920 --> 1:36:11.720
 So I'm saying there's a huge to do here now.

1:36:11.720 --> 1:36:16.720
 And I think customers are wonderfully frustrated with things

1:36:18.080 --> 1:36:20.880
 and they have to keep getting to do better things for them.

1:36:20.880 --> 1:36:23.920
 And they're not known to be super patient.

1:36:23.920 --> 1:36:25.600
 So you have to do it fast.

1:36:25.600 --> 1:36:26.960
 You have to do it fast.

1:36:26.960 --> 1:36:29.800
 So you've mentioned the idea of a press release,

1:36:29.800 --> 1:36:34.800
 the research and development, Amazon, Alexa and Amazon in general,

1:36:34.800 --> 1:36:36.920
 you kind of think of what the future product will look like

1:36:36.920 --> 1:36:39.680
 and you kind of make it happen, you work backwards.

1:36:39.680 --> 1:36:42.440
 So can you draft for me?

1:36:42.440 --> 1:36:45.120
 You probably already have one, but can you make up one?

1:36:45.120 --> 1:36:48.520
 For 10, 20, 30, 40 years out

1:36:48.520 --> 1:36:52.480
 that you see the Alexa team putting out

1:36:52.480 --> 1:36:56.160
 just in broad strokes, something that you dream about?

1:36:56.160 --> 1:36:59.840
 I think let's start with the five years first.

1:36:59.840 --> 1:37:03.280
 Right? So and I'll get to the 40 is too hard to take.

1:37:03.280 --> 1:37:06.000
 Because I'm pretty sure you have a real five year one.

1:37:06.000 --> 1:37:08.320
 Because I didn't want to.

1:37:08.320 --> 1:37:10.160
 But yeah, in broad strokes, let's start with five years.

1:37:10.160 --> 1:37:13.640
 I think the five years is where, I mean, I think of in these spaces,

1:37:13.640 --> 1:37:16.160
 it's hard, especially if you're in the pick of things

1:37:16.160 --> 1:37:17.960
 to think beyond the five years space

1:37:17.960 --> 1:37:20.280
 because a lot of things change, right?

1:37:20.280 --> 1:37:22.200
 I mean, if you ask me five years back,

1:37:22.200 --> 1:37:24.200
 will Alexa will be here?

1:37:24.200 --> 1:37:26.360
 I wouldn't have, I think it has surpassed

1:37:26.360 --> 1:37:29.040
 my imagination of that time, right?

1:37:29.040 --> 1:37:33.160
 So I think from the next five years perspective,

1:37:33.160 --> 1:37:37.080
 from an AI perspective, what we're going to see

1:37:37.080 --> 1:37:39.080
 is that notion which you said,

1:37:39.080 --> 1:37:42.400
 goal oriented dialogues and open domain like Alexa Prize.

1:37:42.400 --> 1:37:45.200
 I think that bridge is going to get closed.

1:37:45.200 --> 1:37:46.400
 They won't be different.

1:37:46.400 --> 1:37:48.520
 And I'll give you why that's the case.

1:37:48.520 --> 1:37:52.360
 You mentioned shopping. How do you shop?

1:37:52.360 --> 1:37:55.680
 Do you shop in one shot?

1:37:55.680 --> 1:38:00.320
 Sure, your AA batteries, paper towels, yes.

1:38:00.320 --> 1:38:04.120
 How long does it take for you to buy a camera?

1:38:04.120 --> 1:38:05.960
 You do a ton of research.

1:38:05.960 --> 1:38:07.440
 Then you make a decision.

1:38:07.440 --> 1:38:11.400
 So is that a goal oriented dialogue

1:38:11.400 --> 1:38:15.440
 when somebody says, Alexa, find me a camera?

1:38:15.440 --> 1:38:18.600
 Is it simply inquisitiveness, right?

1:38:18.600 --> 1:38:20.840
 So even in the something that you think of it as shopping,

1:38:20.840 --> 1:38:23.960
 which you said, you yourself use a lot of.

1:38:23.960 --> 1:38:29.720
 If you go beyond where it's reorders or items

1:38:29.720 --> 1:38:33.160
 where you sort of are not brand conscious and so forth.

1:38:33.160 --> 1:38:34.400
 So that was just in shot.

1:38:34.400 --> 1:38:36.080
 Yeah, just to comment quickly,

1:38:36.080 --> 1:38:38.000
 I've never bought anything through Alexa

1:38:38.000 --> 1:38:41.120
 that I haven't bought before on Amazon on the desktop

1:38:41.120 --> 1:38:43.960
 after I clicked in a bunch of, read a bunch of reviews,

1:38:43.960 --> 1:38:45.720
 that kind of stuff. So it's repurchase.

1:38:45.720 --> 1:38:49.360
 So now you think in even for something that you felt like

1:38:49.360 --> 1:38:52.560
 is a finite goal, I think the space is huge

1:38:52.560 --> 1:38:56.240
 because even products, the attributes are many,

1:38:56.240 --> 1:38:59.040
 like and you want to look at reviews some on Amazon,

1:38:59.040 --> 1:39:01.920
 some outside, some you want to look at what CNET is saying

1:39:01.920 --> 1:39:05.160
 or another consumer forum is saying

1:39:05.160 --> 1:39:06.840
 about even a product, for instance, right?

1:39:06.840 --> 1:39:11.600
 So that's just shopping where you could argue

1:39:11.600 --> 1:39:13.920
 the ultimate goal is sort of known.

1:39:13.920 --> 1:39:15.640
 And we haven't talked about Alexa,

1:39:15.640 --> 1:39:18.840
 what's the weather in Cape Cod this weekend, right?

1:39:18.840 --> 1:39:22.440
 So why am I asking that weather question, right?

1:39:22.440 --> 1:39:27.440
 So I think of it as how do you complete goals

1:39:27.440 --> 1:39:30.000
 with minimum steps for our customers, right?

1:39:30.000 --> 1:39:32.360
 And when you think of it that way,

1:39:32.360 --> 1:39:35.920
 the distinction between goal oriented and conversations

1:39:35.920 --> 1:39:38.560
 for open domain say goes away.

1:39:38.560 --> 1:39:43.160
 I may want to know what happened in the presidential debate,

1:39:43.160 --> 1:39:45.760
 right? And is it I'm seeking just information

1:39:45.760 --> 1:39:49.480
 or I'm looking at who's winning, winning the debates, right?

1:39:49.480 --> 1:39:53.320
 So these are all quite hard problems.

1:39:53.320 --> 1:39:55.480
 So even the five year horizon problem,

1:39:55.480 --> 1:39:59.760
 I'm like, I sure hope we'll solve these.

1:39:59.760 --> 1:40:03.360
 And you're optimistic because that's a hard problem.

1:40:03.360 --> 1:40:05.000
 Which part?

1:40:05.000 --> 1:40:09.520
 The reasoning enough to be able to help explore

1:40:09.520 --> 1:40:12.280
 complex goals that are beyond something simplistic.

1:40:12.280 --> 1:40:16.520
 That feels like it could be, well, five years is a nice.

1:40:16.520 --> 1:40:18.200
 Is a nice bar for that, right?

1:40:18.200 --> 1:40:21.200
 I think you will, it's a nice ambition.

1:40:21.200 --> 1:40:23.680
 And do we have press releases for that?

1:40:23.680 --> 1:40:25.800
 Absolutely, can I tell you what specifically

1:40:25.800 --> 1:40:28.000
 the roadmap will be now, right?

1:40:28.000 --> 1:40:32.040
 And will we solve all of it in the five year space now?

1:40:32.040 --> 1:40:35.480
 This will work on this forever, actually.

1:40:35.480 --> 1:40:37.880
 This is the hardest of the AI problems.

1:40:37.880 --> 1:40:42.160
 And I don't see that being solved even in a 40 year horizon

1:40:42.160 --> 1:40:45.160
 because even if you limit to the human intelligence,

1:40:45.160 --> 1:40:47.600
 we know we are quite far from that.

1:40:47.600 --> 1:40:52.600
 In fact, every aspects of our sensing to neural processing

1:40:52.600 --> 1:40:56.280
 to how brain stores information and how it processes it,

1:40:56.280 --> 1:40:58.960
 we don't yet know how to represent knowledge, right?

1:40:58.960 --> 1:41:02.880
 So we are still in those early stages.

1:41:02.880 --> 1:41:06.320
 So I wanted to start, that's why at the five year.

1:41:06.320 --> 1:41:09.080
 Because the five year success would look like that

1:41:09.080 --> 1:41:11.200
 and solving these complex goals.

1:41:11.200 --> 1:41:14.520
 And the 40 year would be where it's just natural

1:41:14.520 --> 1:41:18.680
 to talk to these in terms of more of these complex goals.

1:41:18.680 --> 1:41:21.400
 Right now, we've already come to the point where

1:41:21.400 --> 1:41:24.040
 these transactions you mentioned of asking for weather

1:41:24.040 --> 1:41:28.520
 or reordering something or listening to your favorite tune,

1:41:28.520 --> 1:41:30.680
 it's natural for you to ask Alexa.

1:41:30.680 --> 1:41:33.840
 It's now unnatural to pick up your phone, right?

1:41:33.840 --> 1:41:36.560
 And that I think is the first five year transformation.

1:41:36.560 --> 1:41:38.760
 The next five year transformation would be,

1:41:38.760 --> 1:41:40.920
 okay, I can plan my weekend with Alexa

1:41:40.920 --> 1:41:43.640
 or I can plan my next meal with Alexa

1:41:43.640 --> 1:41:47.800
 or my next night out with seamless effort.

1:41:47.800 --> 1:41:51.160
 So just to pause and look back at the big picture of it all,

1:41:51.160 --> 1:41:55.560
 it's a year apart of a large team

1:41:55.560 --> 1:41:58.680
 that's creating a system that's in the home,

1:41:58.680 --> 1:42:02.800
 that's not human, that gets to interact with human beings.

1:42:02.800 --> 1:42:06.120
 So we human beings, we these descendants of apes

1:42:06.120 --> 1:42:09.000
 have created an artificial intelligence system

1:42:09.000 --> 1:42:10.960
 that's able to have conversations.

1:42:10.960 --> 1:42:15.960
 I mean, that to me, the two most transformative robots

1:42:15.960 --> 1:42:19.520
 of this century, I think will be autonomous vehicles,

1:42:20.520 --> 1:42:23.600
 but they're a little bit transformative in a more boring way.

1:42:23.600 --> 1:42:25.400
 It's like a tool.

1:42:25.400 --> 1:42:31.400
 I think conversational agents in the home is like an experience.

1:42:31.880 --> 1:42:33.360
 How does that make you feel

1:42:33.360 --> 1:42:35.640
 that you're at the center of creating that?

1:42:35.640 --> 1:42:40.320
 Did you sit back in awe sometimes?

1:42:40.320 --> 1:42:43.640
 What is your feeling?

1:42:43.640 --> 1:42:47.320
 What is your feeling about the whole mess of it?

1:42:47.320 --> 1:42:50.800
 Can you even believe that we're able to create something like this?

1:42:50.800 --> 1:42:52.400
 I think it's a privilege.

1:42:52.400 --> 1:42:57.400
 I'm so fortunate, like where I ended up, right?

1:42:57.600 --> 1:43:00.760
 And it's been a long journey,

1:43:00.760 --> 1:43:03.760
 like I've been in this space for a long time in Cambridge, right?

1:43:03.760 --> 1:43:07.040
 And it's so heartwarming to see

1:43:07.040 --> 1:43:11.400
 the kind of adoption conversational agents are having now.

1:43:11.400 --> 1:43:14.480
 Five years back, it was almost like,

1:43:14.480 --> 1:43:18.440
 should I move out of this because we are unable to find

1:43:18.440 --> 1:43:21.320
 this killer application that customers would love

1:43:21.320 --> 1:43:26.080
 that would not simply be a good to have thing in research labs.

1:43:26.080 --> 1:43:29.160
 And it's so fulfilling to see it make a difference

1:43:29.160 --> 1:43:32.240
 to millions and billions of people worldwide.

1:43:32.240 --> 1:43:34.400
 The good thing is that it's still very early.

1:43:34.400 --> 1:43:38.240
 So I have another 20 years of job security doing what I love.

1:43:38.240 --> 1:43:42.000
 Like, so I think from that perspective, I feel,

1:43:42.000 --> 1:43:46.240
 I tell every researcher that joins or every member of my team,

1:43:46.240 --> 1:43:47.640
 that this is a unique privilege.

1:43:47.640 --> 1:43:49.600
 Like, I think, and we have,

1:43:49.600 --> 1:43:52.800
 and I would say not just launching Alexa in 2014,

1:43:52.800 --> 1:43:54.400
 which was first of its kind,

1:43:54.400 --> 1:43:57.360
 along the way we have, when we launched Alexa SkillsKit,

1:43:57.360 --> 1:43:59.720
 it became democratizing AI,

1:43:59.720 --> 1:44:02.440
 when before that there was no good evidence

1:44:02.440 --> 1:44:04.960
 of an SDK for speech and language.

1:44:04.960 --> 1:44:06.640
 Now we are coming to this where you and I,

1:44:06.640 --> 1:44:10.280
 having this conversation where I'm not saying,

1:44:10.280 --> 1:44:14.560
 oh, Lex, planning a night out with an AI agent, impossible.

1:44:14.560 --> 1:44:17.080
 I'm saying it's in the realm of possibility

1:44:17.080 --> 1:44:19.480
 and not only possibility will be launching this, right?

1:44:19.480 --> 1:44:21.480
 So some elements of that,

1:44:21.480 --> 1:44:23.760
 every, it will keep getting better.

1:44:23.760 --> 1:44:25.600
 We know that is a universal truth.

1:44:25.600 --> 1:44:30.120
 Once you have these kind of agents out there being used,

1:44:30.120 --> 1:44:32.040
 they get better for your customers.

1:44:32.040 --> 1:44:33.880
 And I think that's where,

1:44:33.880 --> 1:44:37.640
 I think the amount of research topics we are throwing out

1:44:37.640 --> 1:44:39.440
 at our budding researchers

1:44:39.440 --> 1:44:41.800
 is just gonna be exponentially hard.

1:44:41.800 --> 1:44:45.600
 And the great thing is you can now get immense satisfaction

1:44:45.600 --> 1:44:47.240
 by having customers use it,

1:44:47.240 --> 1:44:51.120
 not just a paper and new reps or another conference.

1:44:51.120 --> 1:44:53.120
 I think everyone, myself included,

1:44:53.120 --> 1:44:54.800
 are deeply excited about that feature.

1:44:54.800 --> 1:44:58.040
 So I don't think there's a better place to end, Rohit.

1:44:58.040 --> 1:44:58.880
 Thank you so much for talking to us.

1:44:58.880 --> 1:44:59.720
 Thank you so much.

1:44:59.720 --> 1:45:00.560
 This was fun.

1:45:00.560 --> 1:45:02.200
 Thank you, same here.

1:45:02.200 --> 1:45:04.200
 Thanks for listening to this conversation

1:45:04.200 --> 1:45:05.720
 with Rohit Prasad.

1:45:05.720 --> 1:45:08.840
 And thank you to our presenting sponsor, Cash App.

1:45:08.840 --> 1:45:11.560
 Download it, use code LEGS Podcast.

1:45:11.560 --> 1:45:14.680
 You'll get $10 and $10 will go to first,

1:45:14.680 --> 1:45:16.480
 a STEM education nonprofit

1:45:16.480 --> 1:45:19.720
 that inspires hundreds of thousands of young minds

1:45:19.720 --> 1:45:23.280
 to learn and to dream of engineering our future.

1:45:23.280 --> 1:45:26.160
 If you enjoy this podcast, subscribe on YouTube,

1:45:26.160 --> 1:45:28.160
 give it five stars on Apple Podcast,

1:45:28.160 --> 1:45:29.600
 support it on Patreon,

1:45:29.600 --> 1:45:31.680
 or connect with me on Twitter.

1:45:31.680 --> 1:45:34.920
 And now let me leave you with some words of wisdom

1:45:34.920 --> 1:45:37.480
 from the great Alan Turing.

1:45:37.480 --> 1:45:41.640
 Sometimes it is the people no one can imagine anything of

1:45:41.640 --> 1:45:44.160
 who do the things no one can imagine.

1:45:44.160 --> 1:46:01.200
 Thank you for listening and hope to see you next time.

